{"config":{"lang":["en"],"separator":"[\\s\\u200b\\u3000\\-\u3001\u3002\uff0c\uff0e\uff1f\uff01\uff1b]+","pipeline":["stemmer"]},"docs":[{"location":"markdown/HomePage/","title":"HomePage","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"markdown/HomePage/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"markdown/HomePage/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"markdown/HomePage/#code-annotation-examples","title":"Code Annotation Examples","text":""},{"location":"markdown/HomePage/#codeblocks","title":"Codeblocks","text":"<p>Some <code>code</code> goes here.</p>"},{"location":"markdown/HomePage/#plain-codeblock","title":"Plain codeblock","text":"<p>A plain codeblock\uff1a </p> <pre><code>Some code here\ndef my_func():\n    # This is for test.\n    print(\"Hello, Leo.\")\n</code></pre>"},{"location":"markdown/HomePage/#code-for-a-specific-language","title":"Code for a specific language","text":"<p>Some more code with the <code>py</code> at the start:</p> <pre><code>def my_func():\n    # This is for test.\n    print(\"Hello, Leo.\")\n</code></pre> <p>With a title:</p> test.py<pre><code>def my_func():\n    # This is for test.\n    print(\"Hello, Leo.\")\n</code></pre> <p>With a line number:</p> test.py<pre><code>def my_func():\n    # This is for test.\n    print(\"Hello, Leo.\")\n</code></pre>"},{"location":"markdown/HomePage/#icons-and-emojs","title":"Icons and Emojs","text":"<p>For more details about emojs, visit the official document.</p>"},{"location":"markdown/HomePage/#markdown-usage","title":"MarkDown usage","text":"<p>For more details about markdown, visit this blog.</p>"},{"location":"markdown/books_and_literatures/The_Almanack_of_Naval_Ravikant/","title":"\u7eb3\u74e6\u5c14\u5b9d\u5178\u8bfb\u4e66\u7b14\u8bb0","text":""},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML1/","title":"AFML\u7b14\u8bb01: Data Preprocessing","text":"<p>\u5468\u672b\u62bd\u7a7a\u770b\u4e86\u8fd9\u672c\u8457\u540d\u7684\u4e66\u7684\u524d\u51e0\u7ae0\uff0c\u611f\u89c9\u8fd8\u662f\u6709\u70b9\u4f53\u4f1a\u7684\u3002\u7ed3\u5408\u6211\u81ea\u5df1\u5728\u505a\u7684\u5de5\u4f5c\u603b\u7ed3\u4e00\u4e0b\uff1a</p> <ol> <li>\u4e66\u7684\u524d\u51e0\u7ae0\u4e3b\u8981\u8bb2\u4e86\u5982\u4f55\u5bf9\u91d1\u878d\u6570\u636e\u8fdb\u884c\u57fa\u672c\u5904\u7406\uff0c\u8f6c\u6362\u4e3a\u53ef\u4ee5\u8fdb\u884c\u673a\u5668\u5b66\u4e60\u7684\u683c\u5f0f\u3002\u786e\u5b9e\uff0c\u5bf9\u673a\u5668\u5b66\u4e60\u6765\u8bf4\uff0c\u8f93\u5165\u7684\u6570\u636e\u751a\u81f3\u6bd4\u6a21\u578b\u3001\u8c03\u53c2\u7b49\u7b49\u66f4\u52a0\u91cd\u8981\u3002</li> <li>\u9996\u5148\u5bf9\u4ece\u4ea4\u6613\u6240\u5f97\u5230\u7684tick\u6570\u636e\uff0c\u9700\u8981\u805a\u5408\u6210bar\u3002\u4e00\u822c\u6765\u8bf4\u805a\u5408\u6210time bar\u5c31\u633a\u597d\uff0c\u590d\u6742\u4e00\u70b9\u53ef\u4ee5\u8003\u8651\u805a\u5408\u6210 volume bar,dollar bar\uff0c \u4e3b\u8981\u662f\u4e3a\u4e86\u65f6\u5e8f\u4e0a\u7684\u5e73\u7a33\u3002\u66f4\u52a0\u590d\u6742\u7684\u4e8b\u4ef6\u9a71\u52a8\u578b\u7684bar\u4e5f\u6709\uff0c\u4f46\u662f\u4e00\u822c\u4e0d\u4f1a\u7528\u5230\uff0c\u9664\u975e\u662f\u5f88\u7279\u6b8a\u7684\u6807\u7684\u3002\u4e0d\u8fc7\u8fd9\u90e8\u5206\u6211\u7684\u5de5\u4f5c\u5e76\u6ca1\u6709\u6d89\u53ca\u5230\uff0c\u6211\u662f\u76f4\u63a5\u4f7f\u7528time bar\u7684\u6570\u636e\u3002</li> <li>\u5c06\u6570\u636e\u805a\u5408\u6210bar\u540e\uff0c\u4e5f\u4e0d\u80fd\u76f4\u63a5\u4e00\u80a1\u8111\u5168\u585e\u5230\u6a21\u578b\u4e2d\uff0c\u6700\u597d\u662f\u6839\u636e\u67d0\u4e2a\u4e8b\u4ef6\u7684\u7d2f\u8ba1\u53d1\u751f\u6b21\u6570\u8fdb\u884c\u62bd\u6837\uff08cumsum method\uff09\u3002</li> <li>labelling issue\uff1a\u6211\u4e00\u822c\u5c31\u76f4\u63a5\u4f7f\u7528\u6536\u76ca\u7387\u505a\u56de\u5f52\u6a21\u578b\u4e86\uff0c\u4f46\u662f\u4e66\u4e2d\u5efa\u8bae\u7684\u662f\u7528-1\uff0c0\uff0c1\u505a\u5206\u7c7b\u6a21\u578b\uff0c\u4f7f\u7528triple-barrier method\uff0c\u5916\u52a0\u6839\u636e\u6536\u76ca\u7387\u6ce2\u52a8\u7387\u52a8\u6001\u8c03\u6574\u7684horizon threshold\u3002\u53e6\u5916\uff0c\u53ef\u4ee5\u8003\u8651meta label\u3002</li> <li>sample weight\uff1a\u8bad\u7ec3\u6a21\u578b\u7684\u6837\u672c\u6743\u91cd\u3002\u8fd9\u5757\u4e3b\u8981\u89e3\u51b3\u7684\u662f\u91d1\u878d\u6570\u636e\u6837\u672c\u4e4b\u95f4\u4e0d\u662fiid\u7684\u95ee\u9898\u3002\u4e0d\u8fc7\u8fd9\u91cc\u4e2a\u4eba\u7406\u89e3\u4e00\u822c\u662f\u9488\u5bf9\u975etime bar\u7684\u60c5\u51b5\u3002\u91d1\u878d\u6570\u636e\u7684\u6807\u7b7e\u662frolling return\u5f97\u5230\u7684\uff0c\u5177\u6709\u65f6\u5e8f\u4e0a\u7684\u76f8\u5173\u6027\u3002</li> <li>\u5dee\u5206\u7684\u95ee\u9898\u3002\u4f5c\u8005\u8bf4\u4f7f\u7528\u4e00\u9636\u5dee\u5206\u786e\u5b9e\u53ef\u4ee5\u5728\u65f6\u5e8f\u4e0a\u5e73\u7a33\uff0c\u4f46\u662f\u4f1a\u635f\u5931\u8fc7\u591a\u7684predictive power\uff0c\u6240\u4ee5\u5efa\u8bae\u6839\u636eADF test\u7684\u7ed3\u679c\u9009\u62e9\u4e00\u4e2a\u53ef\u4ee5\u4fdd\u8bc1\u65f6\u5e8f\u5e73\u7a33\u4f46\u662f\u53c8\u6bd4\u8f83\u5c0f\u7684\u3002</li> <li>\u5c0f\u6570\u5dee\u5206d\uff0c\u8fd9\u6837\u5c31\u4e0d\u4f1a\u635f\u5931\u9884\u6d4b\u80fd\u529b\u3002\u8fd9\u70b9\u6211\u89c9\u5f97\u53ef\u4ee5\u548clabelling\u7ed3\u5408\uff0c\u7528\u5206\u6570\u9636\u5dee\u5206\u66ff\u4ee3\u6536\u76ca\u7387\u4f5c\u4e3alabel\u3002</li> </ol>"},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML10/","title":"AFML\u7b14\u8bb010: Backtest Statistics &amp; Strategy Risk","text":"<p>\u9996\u5148\u662f\u4e00\u4e9b\u5e38\u89c1\u7684\u56de\u6d4b\u6307\u6807\uff0c\u5305\u62ec\u590f\u666e\u3001\u6362\u624b\u7b49\u7b49\uff0c\u8fd9\u91cc\u6211\u5f3a\u8c03\u51e0\u4e2a\u3002 1. \u8d44\u91d1\u5bb9\u91cf\uff1a\u8d44\u91d1\u5bb9\u91cf\u662f\u6307\u7b56\u7565\u80fd\u591f\u5bb9\u7eb3\u7684\u8d44\u91d1\u89c4\u6a21\uff0c\u4efb\u4f55\u7b56\u7565\u90fd\u662f\u6709\u8d44\u91d1\u5bb9\u91cf\u7684\u3002\u4e00\u822c\u6765\u8bf4\uff0c \u4e00\u4e2a\u7b56\u7565\u7684\u8d44\u91d1\u5bb9\u91cf\u662f\u6307\u6700\u5927\u7684\u80fd\u4fdd\u8bc1\u76ee\u6807\u98ce\u9669\u8c03\u6574\u540e\u8868\u73b0\u7684AUM(asset under management) 2. \u6700\u5927\u6301\u4ed3\uff1a\u53ef\u4ee5\u548c\u8d44\u91d1\u5bb9\u91cf\u7ed3\u5408\u6765\u770b\uff0c\u5173\u6ce8\u7b56\u7565\u7684\u6700\u5927\u6301\u4ed3\u548c\u7b56\u7565\u7684\u5141\u8bb8\u8d44\u91d1\u5bb9\u91cf\u662f\u5426\u5927\u81f4\u76f8\u540c\u3002</p> <p>\u7136\u540e\u662f\u7b56\u7565\u98ce\u9669\u7684\u5185\u5bb9</p> <ol> <li>\u524d\u9762\u7ae0\u8282\u6211\u4eec\u5b66\u4e60\u4e86\u591a\u79cd\u56de\u6d4b\u7684\u6846\u67b6\u7ed3\u6784\uff0c\u5305\u62ec\u5386\u53f2\u6570\u636e\u56de\u6d4b(walk forward)\u3001\u60c5\u666f\u6a21\u62df(CV, CPCV)\u3001\u751f\u6210\u6570\u636e\u56de\u6d4b(synthetic data)\u4e09\u79cd\u3002</li> <li>\u9996\u5148\uff0c\u6bcf\u4e2a\u7b56\u7565\u90fd\u53ef\u4ee5\u62bd\u8c61\u4e3a\u4e00\u4e2abet\u7684\u5e8f\u5217\uff0c\u6bcf\u4e2abet\u4ee3\u8868\u4e00\u4e2a\u4ea4\u6613\u4fe1\u53f7\uff08\u591aor\u7a7a\uff09\u3002\u6bcf\u4e2a\u4fe1\u53f7\u5e26\u6765\u7684\u6536\u76ca\u90fd\u662f\u4e00\u4e2a\u4e24\u70b9\u5206\u5e03\uff0c\u5206\u522b\u4e3aprofit\u3001loss\u3002 \u8fd9\u91cc\u7684profit\u548closs\u53ef\u4ee5\u4e92\u4e3a\u76f8\u53cd\u6570\uff0c\u4e5f\u53ef\u4ee5\u6709\u4e0d\u540c\u7684\u7edd\u5bf9\u503c\u3002</li> <li>\u901a\u8fc7\u8fd9\u4e2a\u7b80\u5355\u7684\u6a21\u578b\uff0c\u6211\u4eec\u53ef\u4ee5\u63a8\u5bfc\u51fa\u5e74\u5316sharpe\u3001\u4ea4\u6613\u9891\u7387\u548c\u80dc\u7387\u4e4b\u95f4\u7684\u5173\u7cfb\uff1a\u5f88\u9ad8\u7684\u4ea4\u6613\u9891\u7387\u53ef\u4ee5\u5728\u80dc\u7387\u7565\u5fae\u8d85\u8fc750%\u7684\u65f6\u5019\u5c31\u5e26\u6765\u9ad8sharpe\uff08\u4e0d\u8003\u8651\u624b\u7eed\u8d39\u7684\u8bdd\uff09\u3002</li> <li>\u7b56\u7565\u5931\u8d25\u6307\u7684\u662f\u7b56\u7565\u7684sharpe\u4f4e\u4e8e\u6211\u4eec\u8bbe\u5b9a\u7684\u9884\u671fsharpe\u3002p\u662f\u6307\u7b56\u7565\u4e0d\u5931\u8d25\u6240\u9700\u7684\u6700\u4f4e\u80dc\u7387\u3002\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528\u5386\u53f2\u6570\u636e\u4f30\u8ba1\u7b56\u7565\u5931\u8d25\u7684\u6982\u7387\u3002\u5177\u4f53\u505a\u6cd5\u662f\u4ece\u5386\u53f2\u6570\u636e\u4e2d\u62bd\u6837\uff0c \u6bcf\u6b21\u62bd\u6837\u90fd\u8ba1\u7b97\u4e00\u4e2a\u80dc\u7387\uff08Bootstrap\uff09\uff0c\u6211\u4eec\u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a\u80dc\u7387\u5e8f\u5217\u3002\u6839\u636e\u8fd9\u4e2a\u80dc\u7387\u5e8f\u5217\uff0c\u6211\u4eec\u53ef\u4ee5\u6839\u636eKDE\u6216\u8005\u6b63\u6001\u5206\u5e03\uff08k\u8db3\u591f\u5927\u7684\u65f6\u5019\uff09\u4f30\u8ba1\u80dc\u7387\u7684pdf\u3002 \u5f97\u5230pdf\u540e\uff0c\u6211\u4eec\u5bf9\u8d77\u4ece\u8d1f\u65e0\u7a77\u4e00\u76f4\u5230p\u7684\u533a\u95f4\u79ef\u5206\uff0c\u5c31\u662f\u7b56\u7565\u5931\u8d25\u7684\u6982\u7387\u3002</li> </ol>"},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML11/","title":"AFML\u7b14\u8bb011\uff1aUseful financial features","text":"<p>\u9664\u4e86\u81ea\u5df1\u7684\u4e00\u4e9b\u56e0\u5b50\u53ef\u4ee5\u4f5c\u4e3aML\u6a21\u578b\u7279\u5f81\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u4e00\u4e9b\u7ecf\u5178\u7684\u7279\u5f81\u4f5c\u4e3a\u6a21\u578b\u81ea\u53d8\u91cf\u3002 1. structural break\u7279\u5f81\uff1a\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u8bc6\u522bstructural break\u7684\u65b9\u6cd5\u6765\u6784\u9020\u7279\u5f81\u3002 2. entropy features\uff1a\u5229\u7528\u4fe1\u606f\u71b5\u6784\u9020\u7279\u5f81\u3002 3. Microstructure features\uff1a\u57fa\u4e8e\u5fae\u89c2\u7ed3\u6784\u7684\u7279\u5f81\uff0c\u4f8b\u5982bid-ask spread\u7684\u8bc4\u4ef7\u6307\u6807\u3001\u5e02\u573a\u6d41\u52a8\u6027\u7684\u8861\u91cf\u6307\u6807\u03bb\u3001PIN\u7b49\u90fd\u53ef\u4ee5\u4f5c\u4e3a\u7279\u5f81\u3002</p> <p>\u81f3\u6b64\uff0c\u6574\u672c\u4e66\u6211\u60f3\u8981\u770b\u7684\u5730\u65b9\u5df2\u7ecf\u7ed3\u675f\u4e86\u3002\u540e\u7eed\u7ae0\u8282\u8bb2\u4e86\u4e00\u4e9b\u5173\u4e8e\u5982\u4f55\u5e76\u884c\u8ba1\u7b97\u52a0\u901f\u65b9\u9762\u7684\u77e5\u8bc6\uff0c \u6211\u5176\u5b9e\u5e73\u65f6\u4e5f\u6709\u7528\u5230\uff0c\u6240\u4ee5\u5c31\u4e0d\u770b\u4e66\u4e0a\u7684\uff0c\u6309\u7167\u6211\u81ea\u5df1\u7684\u65b9\u6cd5\u6765\u4e86\u3002</p>"},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML2/","title":"AFML\u7b14\u8bb02: Model","text":"<p>model\u8fd9\u5757\u4e3b\u8981\u4ee5RF\u4e3a\u4f8b\u6982\u8ff0\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002\u91cd\u70b9\u5728\u4e8e\u65b9\u6cd5\u8bba\u7684\u4ecb\u7ecd\u800c\u4e0d\u662f\u5177\u4f53\u6a21\u578b\u7684\u7b97\u6cd5\u3002\u5982\u679c\u60f3\u8981\u6df1\u5165\u4e86\u89e3\u5177\u4f53\u6a21\u578b\uff0c\u5efa\u8bae\u989d\u5916\u5bfb\u627e\u8d44\u6599\u5b66\u4e60\u3002</p> <ol> <li>\u9996\u5148\u662f\u96c6\u6210\u5b66\u4e60\u6a21\u578b\uff0c\u4e3b\u8981\u5206\u4e3abagging\u548cboosting\u3002\u5bf9\u4e8ebagging\u6a21\u578b\uff0c\u53ea\u8981\u57fa\u5b66\u4e60\u5668\u4e4b\u95f4\u76f8\u5173\u6027\u8f83\u4f4e\uff0c\u5c31\u53ef\u4ee5\u964d\u4f4e\u65b9\u5dee\uff0c\u9632\u6b62\u8fc7\u62df\u5408\u540c\u65f6\u63d0\u5347\u6b63\u786e\u7387\u3002bagging\u6a21\u578b\u4e5f\u662f\u4f5c\u8005\u4e3b\u8981\u63a8\u8350\u7528\u5728\u91d1\u878d\u9886\u57df\u7684\uff0c\u56e0\u4e3aboosting\u6a21\u578b\u4e3b\u8981\u5904\u7406\u7684\u662funderfit\uff0c\u8fd9\u5728\u91d1\u878d\u9886\u57df\u4e0a\u4e00\u822c\u6ca1\u6709overfit\u95ee\u9898\u91cd\u8981\u3002</li> <li>\u89c2\u5bdf\u503c\u7684\u5197\u4f59\uff08\u6837\u672c\u4e4b\u95f4\u7684\u76f8\u5173\u6027\uff09\u4f1a\u5bf9bagging\u6709\u4e0d\u597d\u5f71\u54cd\uff1a\u9996\u5148\u6bcf\u6b21bootstrap\u62bd\u53d6\u7684\u6837\u672c\u4e4b\u95f4\u76f8\u5173\u6027\u5f3a\uff0c\u5bfc\u81f4\u8bad\u7ec3\u51fa\u7684\u57fa\u5206\u7c7b\u5668\u4e4b\u95f4\u76f8\u5173\u6027\u4e5f\u5f3a\uff1b\u5176\u6b21out-of-bag accuracy\u4f1a\u53d7\u5230\u5f71\u54cd\uff08\u88ab\u9ad8\u4f30\uff09\u3002</li> <li>bagging\u7684\u7ecf\u5178\u6a21\u578b\u968f\u673a\u68ee\u6797\u76f8\u6bd4\u57fa\u7840\u7684bagging classifier\uff0c\u5f15\u5165\u4e86\u4e24\u6b21\u76f8\u5173\u6027\uff08\u8fd8\u6709\u4e00\u6b21\u662f\u5728\u6bcf\u6b21\u5206\u652f\u7684\u65f6\u5019\u53ea\u8003\u8651\u4e00\u4e2a\u968f\u673a\u7684\u5b50\u7279\u5f81\u96c6\u5408\uff09\u3002</li> <li>bagging\u6a21\u578b\u65e0\u6cd5\u627f\u62c5\u8fc7\u5927\u7684\u6837\u672c\u91cf\uff08\u6bd4\u5982SVM\uff09\uff0c\u90a3\u4e48\u53ef\u4ee5\u5bf9\u57fa\u6a21\u578b\u4f7f\u7528\u65e9\u505c\uff0c\u7136\u540e\u518d\u5229\u7528bagging\u964d\u4f4e\u96c6\u6210\u6a21\u578b\u7684\u65b9\u5dee\u3002</li> </ol>"},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML3/","title":"AFML\u7b14\u8bb03: Cross Validation","text":"<p>\u8fd9\u5757\u4e3b\u8981\u4ecb\u7ecd\u4e86\u4ea4\u53c9\u9a8c\u8bc1\u7684\u4f7f\u7528\u3002</p> <ol> <li>\u91d1\u878d\u9886\u57df\u4e2d\u4ea4\u53c9\u9a8c\u8bc1\u5931\u8d25\u7684\u4e3b\u8981\u539f\u56e0\u662finformational leakage\uff0c\u4e3b\u8981\u539f\u56e0\u4ecd\u7136\u662f\u524d\u9762\u4ecb\u7ecd\u7684\u6837\u672c\u5197\u4f59\u5bfc\u81f4\u7684\u76f8\u5173\u6027\u3002\u6ce8\u610f\uff0c\u53ea\u6709\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u4e2d\u7684X\u548cy\u540c\u65f6\u76f8\u5173\uff0c\u6211\u4eec\u624d\u80fd\u8bf4\u5b58\u5728informational leakage\u3002</li> <li>\u89e3\u51b3informational leakage\u7684\u65b9\u6cd5\uff1a</li> <li>Purge\uff1a\u89e3\u51b3\u7684\u662f\u6837\u672c\u6807\u7b7e\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u3002 </li> <li>embargo\uff1a\u89e3\u51b3\u7684\u662f\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u7684serial correlation\u3002 </li> <li>\u6700\u7ec8\u7684\u7ed3\u679c\uff1a\u4f7f\u7528PurgedKFold\uff0c\u6ce8\u610f\u8fd9\u91cc\u5b9a\u4e49\u4e86\u65b0\u7684\u7c7b\uff0c\u53ef\u4ee5\u76f4\u63a5\u7528\u4e8e\u540e\u7eed\u7684GridSearchCV\u4e2d\u7684cv\u53c2\u6570\uff0c\u5b9e\u73b0\u81ea\u5b9a\u4e49\u7f51\u683c\u641c\u7d22\u4ea4\u53c9\u9a8c\u8bc1\uff08\u6216\u968f\u673a\u641c\u7d22\u4e5f\u884c\uff09\u3002</li> </ol>"},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML4/","title":"AFML\u7b14\u8bb04: Feature Importance","text":"<ol> <li>\u7279\u5f81\u91cd\u8981\u6027\u4e5f\u662f\u4e00\u79cd\u6709\u52a9\u4e8e\u7f13\u89e3\u8fc7\u62df\u5408\u95ee\u9898\u7684\u65b9\u6cd5\uff1a\u56de\u6d4b\u7684\u597d\u7ed3\u679c\u5f88\u53ef\u80fd\u4ea7\u751f\u4e8e\u8fc7\u62df\u5408\u3002\u7814\u7a76\u7279\u5f81\u91cd\u8981\u6027\uff0c\u800c\u4e0d\u53ea\u770b\u56de\u6d4b\u662f\u66f4\u52a0\u79d1\u5b66\u7684\u65b9\u6cd5\u3002</li> <li>\u6709\u591a\u79cd\u8861\u91cf\u7279\u5f81\u91cd\u8981\u6027\u7684\u65b9\u6cd5\u3002\u9996\u5148\u662fMean Decrease Impurity\u3002\u8fd9\u4e2a\u662f\u9ed8\u8ba4\u7684\u63a8\u8350\u65b9\u6cd5\uff0csklearn\u4e2d\u7684RF\u53ef\u4ee5\u76f4\u63a5\u8f93\u51fa\uff08\u5f53\u7136\u53ef\u4ee5\u4e0d\u6b62\u8fd0\u7528\u5728RF\u4e0a\uff09\u3002\u57fa\u672c\u539f\u7406\u662f\u5ea6\u91cf\u91c7\u7528\u4e00\u4e2a\u53d8\u91cf\u8fdb\u884c\u5206\u88c2\u6240\u5e26\u6765\u7684\u7eaf\u5ea6\u4e0b\u964d\u7684\u5e73\u5747\u503c\uff0c\u597d\u5904\u662f\u6240\u6709\u53d8\u91cf\u7684MDI\u76f8\u52a0\u7b49\u4e8e1\uff0c\u53ef\u4ee5\u76f4\u89c2\u6bd4\u8f83\u5927\u5c0f\uff0c\u4f46\u662f\u4f1a\u53d7\u5230substitution effect\u7684\u5f71\u54cd\u5bfc\u81f4\u91cd\u8981\u6027\u88ab\u4f4e\u4f30\u3002</li> <li>Mean Decrease Accuracy\uff1a\u8fd9\u4e2a\u65b9\u6cd5\u66f4\u597d\u7406\u89e3\uff0c\u4e3b\u8981\u662f\u5728OOS\u4e0a\u8ba1\u7b97\u7279\u5f81\u91cd\u6392\u5217\u524d\u540e\u7684\u51c6\u786e\u7387\u4e4b\u5dee\u3002\u4f46\u662f\u53ef\u80fd\u6240\u6709\u6837\u672c\u7684MDA\u90fd\u5f88\u5c0f\uff0c\u540c\u65f6\u4e5f\u4f1a\u53d7\u5230substitution effect\u7684\u5f71\u54cd\u5bfc\u81f4\u91cd\u8981\u6027\u88ab\u4f4e\u4f30\u3002</li> <li>Single Feature Importance\uff1a\u72ec\u7acb\u8ba1\u7b97\u6bcf\u4e2a\u7279\u5f81\u5728OOS\u4e0a\u7684\u5f97\u5206\u3002\u597d\u5904\u662f\u6392\u9664\u4e86substitution effect\u7684\u5f71\u54cd\uff0c\u5c40\u9650\u6027\u5728\u4e8eSFI\u6bcf\u6b21\u53ea\u8003\u8651\u5355\u4e2a\u7279\u5f81\uff0c\u5ffd\u89c6\u4e86\u7279\u5f81\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u53ef\u80fd\u4f7f\u5f97\u6a21\u578b\u6548\u679c\u66f4\u597d\u3002\u8fd9\u91cc\u6211\u7684\u7406\u89e3\u662f\uff0c\u5982\u679c\u6709\u4e09\u4e2a\u7279\u5f81a\u548cb\u548cc\uff0c\u5047\u8bbe\u4ed6\u4eec\u7684SFI\u5206\u522b\u662f0.1\uff0c0.2\uff0c0.5\uff0c\u90a3\u4e48\u6211\u4eec\u80af\u5b9a\u8ba4\u4e3ac\u6700\u597d\u3002\u4f46\u662f\u5982\u679ca\u548cb\u7ec4\u5408\u4e4b\u540eSFI\u53d8\u6210\u4e860.8\uff0c\u90a3\u4e48\u663e\u7136a\u548cb\u7ec4\u5408\u540e\u5f97\u5230\u4e86\u4e00\u4e2a\u66f4\u597d\u7684\u7279\u5f81\u3002\u4f46\u662fSFI\u65b9\u6cd5\u6ca1\u6709\u8003\u8651\u5230\u8fd9\u4e2a\u3002</li> <li>\u5728\u4f7f\u7528MDI\u6216MDA\u4e4b\u524d\u505aPCA\u8fdb\u884c\u7279\u5f81\u6b63\u4ea4\u5316\u53ef\u4ee5\u964d\u4f4esubstitution effect\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u6b63\u4ea4\u5316\u3002PCA\u8fd8\u6709\u989d\u5916\u7684\u597d\u5904\uff1a\u9996\u5148\u6709\u52a9\u4e8e\u51cf\u5c11\u7279\u5f81\uff0c\u52a0\u901f\u8ba1\u7b97\uff1b\u5176\u6b21\u53ef\u4ee5\u5728\u4e0doverfitting\u7684\u60c5\u51b5\u4e0b\u8bc6\u522b\u5230\u91cd\u8981\u7279\u5f81\u3002</li> <li>Parallelized \u548c stacked feature importance\u662f\u4e24\u79cd\u4f7f\u7528panel data\u8ba1\u7b97feature importance\u7684\u65b9\u6cd5\u3002\u533a\u522b\u5728\u4e8e\u524d\u8005\u662fgroupby instrument\u7136\u540e\u5e76\u884c\u8ba1\u7b97\uff0c\u800c\u540e\u8005\u662f\u5148\u5408\u5e76\u6210\u4e00\u4e2ainstrument\u7136\u540e\u518d\u8ba1\u7b97\u3002\u4f5c\u8005\u63a8\u8350stack\u65b9\u6cd5\uff0c\u4e3b\u8981\u662f\u56e0\u4e3asubstitution effect\u7684\u5f71\u54cd\u66f4\u5c0f\uff0c\u800c\u4e14\u7ed3\u679c\u66f4\u52a0\u7a33\u5065\u3002</li> </ol>"},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML5/","title":"AFML\u7b14\u8bb05: Hyper-Parameter Tuning with CV","text":"<p>\u8fd9\u4e00\u7ae0\u4e3b\u8981\u4ecb\u7ecd\u4e86\u5982\u4f55\u4f7f\u7528\u4ea4\u53c9\u9a8c\u8bc1\u8c03\u6574\u8d85\u53c2\u6570\u3002</p> <ol> <li>\u7f51\u683c\u641c\u7d22\u4ea4\u53c9\u9a8c\u8bc1\u548c\u968f\u673a\u641c\u7d22\u4ea4\u53c9\u9a8c\u8bc1\u90fd\u53ef\u4ee5\u5728\u5bf9\u53c2\u6570\u7684\u5148\u9a8c\u6ca1\u6709\u8ba4\u77e5\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u8d85\u53c2\u8c03\u6574\uff0c\u53ea\u8981\u8bbe\u5b9a\u53c2\u6570\u7f51\u683c\u548c\u4ea4\u53c9\u9a8c\u8bc1\u65b9\u6cd5cv\u5373\u53ef\u3002\u8fd9\u91cc\u7684cv\u8bbe\u7f6e\u53c2\u8003\u4e86\u524d\u51e0\u7ae0\u7684\u5185\u5bb9\uff0c\u53ef\u4ee5\u770b\u6211\u4e4b\u524d\u7684\u7b14\u8bb0\u3002</li> <li>\u6839\u636e\u6211\u7684\u7ecf\u9a8c\uff0c\u7f51\u683c\u641c\u7d22\u901f\u5ea6\u4e00\u822c\u592a\u6162\u4e86\uff0c\u6240\u4ee5\u6211\u8fd8\u662f\u63a8\u8350\u4f7f\u7528\u968f\u673a\u641c\u7d22\u3002</li> <li>\u5982\u679c\u6a21\u578b\u5bf9\u53c2\u6570\u7684\u53d8\u5316\u654f\u611f\u5ea6\u975e\u7ebf\u6027\uff0c\u90a3\u4e48\u53c2\u6570\u7f51\u683c\u7684\u8bbe\u7f6e\u53ef\u4ee5\u91c7\u7528log-uniform\u7684\u5f62\u5f0f\uff08\u9488\u5bf9\u53c2\u6570\u662f\u6b63\u6570\u4e14\u968f\u7740\u53c2\u6570\u589e\u5927\u6a21\u578b\u7684\u654f\u611f\u5ea6\u4e0b\u964d\u7684\u60c5\u51b5\uff09\u3002</li> <li>\u5173\u4e8e\u53c2\u6570\u641c\u7d22\u4e2dscoring\u7684\u9009\u62e9\uff0c\u5728meta-labelling\u7684\u60c5\u51b5\u4e0b\uff0c\u63a8\u8350\u4f7f\u7528f1 score\u3002\u56e0\u4e3a\u53ef\u4ee5\u5f88\u597d\u5730\u5e73\u8861Precision\u548cRecall\uff08\u8001\u751f\u5e38\u8c08\u7684\u95ee\u9898\u4e86\uff09\u3002</li> <li>\u5176\u5b83\u60c5\u51b5 \u63a8\u8350\u4f7f\u7528neg_log_loss\uff0c\u56e0\u4e3a\u53ef\u4ee5\u66f4\u597d\u5730\u60e9\u7f5a\u4e0d\u540c\u7a0b\u5ea6\uff08\u4e0d\u540c\u9884\u6d4b\u6982\u7387\uff09\u7684\u9519\u8bef\u5206\u7c7b\u60c5\u51b5\uff0c\u4e5f\u5c31\u662f\u5bf9\u9519\u8bef\u5f00\u4ed3\u7684\u60e9\u7f5a\u529b\u5ea6\u66f4\u5927\uff0c \u800c\u5982\u679c\u4f7f\u7528accuracy\uff0c\u5bf9\u4efb\u4f55\u9884\u6d4b\u6982\u7387\u7684\u9519\u8bef\u5206\u7c7b\uff0c\u60e9\u7f5a\u529b\u5ea6\u90fd\u4e00\u6837\uff0c\u5728meta-label or triple-barrier method\u4f5c\u4e3a\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\u65e0\u6cd5\u5f88\u597d\u5730\u6a21\u62df\u9519\u8bef\u4ed3\u4f4d\u5e26\u6765\u7684\u635f\u5931\u3002</li> </ol>"},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML6/","title":"AFML\u7b14\u8bb06\uff1a bet sizing","text":"<p>\u4e66\u7684\u7b2c\u4e09\u90e8\u5206\u4e3b\u8981\u8bb2\u8ff0\u4e86\u56de\u6d4b\u65f6\u5019\u7684\u6ce8\u610f\u70b9\u3002\u9996\u5148\u4ecb\u7ecd\u4e86bet sizing\u3002</p> <ol> <li>\u4e2a\u4eba\u8ba4\u4e3abet sizing\u53ef\u4ee5\u7406\u89e3\u4e3a\u56e0\u5b50\u503c\uff08\u5bf9\u4e8e\u671f\u8d27\u65f6\u5e8f\u7b56\u7565\uff0c\u56e0\u5b50\u503c\u4e5f\u53ef\u4ee5\u7406\u89e3\u4e3a\u4ed3\u4f4d\uff09\uff0c\u800c\u672c\u4e66\u7684\u5f88\u591a\u5199\u6cd5\u5176\u5b9e\u90fd\u662f\u9488\u5bf9\u884d\u751f\u54c1\u7684\u3002 \u90a3\u4e48\uff0c\u6211\u4eec\u5982\u4f55\u6839\u636e\u4fe1\u53f7\uff0c\u5f97\u5230\u6070\u5f53\u7684bet size\u5462\uff1f\u4f5c\u8005\u4ecb\u7ecd\u4e86\u5f88\u591a\u79cd\u65b9\u6cd5\uff0c\u5176\u4e2d\u6211\u8ba4\u4e3a\u91cd\u8981\u7684\u65b9\u6cd5\u662fmeta-labelling\u6807\u7b7e\u8f6c\u5316\u4e3a\u56e0\u5b50\u503c\uff0c \u5177\u4f53\u5982\u4e0b\uff1a\u5c06\u524d\u51e0\u7ae0\u7684meta-labelling\u83b7\u5f97\u7684\u6982\u7387\u8f6c\u6362\u4e3a\u56e0\u5b50\u503c\u3002\u5177\u4f53\u8f6c\u6362\u65b9\u6cd5\u662f\u5047\u8bbe\u4fe1\u53f7\u7684sharpe\u670d\u4eceGauss\u5206\u5e03\uff0c \u7136\u540e\u4f7f\u7528CDF\u51fd\u6570\u503c\u4f5c\u4e3abet size\u3002 \u4e14\u6ce8\u610f\u9700\u8981\u5bf9bet size \u505a[-1, 1]\u7684\u5f52\u4e00\u5316\uff082*x - 1\uff09\u3002</li> <li>\u8ba1\u7b97average active bets\u3002\u8fd9\u662f\u56e0\u4e3a\u6bcf\u4e2a\u4fe1\u53f7\u90fd\u6709\u4e00\u5b9a\u7684\u751f\u547d\u5468\u671f\uff0c\u5728\u6bcf\u4e2a\u65f6\u523b\u57fa\u672c\u90fd\u4f1a\u540c\u65f6\u5b58\u5728\u591a\u4e2a\u4fe1\u53f7\u3002 \u6211\u4eec\u5f53\u7136\u53ef\u4ee5\u5728\u51fa\u53d1\u65b0\u4fe1\u53f7\u7684\u540c\u65f6\uff0c\u5c31\u76f4\u63a5\u5173\u95ed\u65e7\u4fe1\u53f7\uff08\u5e73\u4ed3\uff09\uff0c\u4f46\u662f\u8fd9\u6837\u4e0d\u597d\uff0c\u56e0\u4e3a\u65e7\u4fe1\u53f7\u8fd8\u6ca1\u6709\u51fa\u53d1\u6b62\u635f\u6761\u4ef6\uff0c\u4e0d\u80fd\u5c06\u65b0\u4fe1\u53f7\u7684\u51fa\u73b0\u4f5c\u4e3a\u65e7\u4fe1\u53f7\u7684\u6b62\u635f\u6761\u4ef6\uff01 \u66f4\u597d\u7684\u65b9\u5f0f\u662f\u5728\u6bcf\u4e2a\u65f6\u523b\u53d6\u4fe1\u53f7\u7684\u5e73\u5747\u503c\u3002\u5176\u5b9e\u4ed4\u7ec6\u7422\u78e8\uff0c\u4e2a\u4eba\u8ba4\u4e3a\u6784\u9020\u56e0\u5b50\u65f6\u5019\u5e38\u89c1\u7684\u5bf9\u56e0\u5b50\u503c\u5e73\u6ed1\u5904\u7406\u548c\u8fd9\u91cc\u7684\u8ba1\u7b97\u5e73\u5747\u6d3b\u8dc3bet\u662f\u5f02\u66f2\u540c\u5de5\u7684\uff0c \u4e0d\u8fc7\u5e73\u6ed1\u5316\u5904\u7406\u5047\u8bbe\u4e86\u6240\u6709bet\u7684\u751f\u547d\u5468\u671f\u76f8\u540c\u3002</li> <li>\u4ed3\u4f4d\u79bb\u6563\u5316\uff1a\u4e3a\u4e86\u964d\u4f4e\u6362\u624b\uff0c\u4ece\u800c\u964d\u4f4e\u53ef\u80fd\u7684\u4ea4\u6613\u624b\u7eed\u8d39\u3002\u8fd9\u91cc\u5c31\u662f\u5e38\u89c4\u7684\u79bb\u6563\u5316\u4ed3\u4f4d\u5904\u7406\u3002</li> <li>\u52a8\u6001\u8c03\u6574bet size\uff1a\u968f\u7740\u6211\u4eec\u9884\u6d4b\u7684\u4ef7\u683c\u548c\u5b9e\u9645\u7684\u4ef7\u683c\u6ce2\u52a8\uff0c\u6211\u4eec\u53ef\u4ee5\u52a8\u6001\u8c03\u6574bet size\u3002\u5f53\u5b9e\u9645\u4ef7\u683c\u548c\u9884\u6d4b\u4ef7\u683c\u4e4b\u95f4\u7684\u4ef7\u5dee\u6536\u655b\u65f6\uff0c \u6211\u4eec\u4f1a\u7f13\u6162\u51fa\u573a\uff0c\u56e0\u4e3a\u60f3\u8981\u9501\u5b9aprofit\u3002</li> </ol>"},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML7/","title":"AFML\u7b14\u8bb07: The dangers of backtesting","text":"<p>\u8fd9\u7ae0\u4e3b\u8981\u8bb2\u8ff0\u4e86backtesting\u7684\u4e00\u4e9b\u5371\u9669\u70b9\uff0c\u5305\u62ec\u4e3a\u4f55\u4f1a\u5bfc\u81f4\u8fc7\u62df\u5408\u7b49\u3002\u56e0\u4e3a\u5185\u5bb9\u8fc7\u591a\uff0c\u6211\u5c31\u53ea\u8bb0\u5f55\u4e0b\u4e2a\u4eba\u8ba4\u4e3a\u6709\u542f\u53d1\u7684\u70b9\u3002</p> <ol> <li>\u5373\u4f7f\u56de\u6d4b\u6846\u67b6\u5b8c\u7f8e\uff0c\u4e0d\u5b58\u5728\u6570\u636e\u6cc4\u9732\u7b49\u95ee\u9898\uff0c\u4f46\u662f\u56e0\u4e3a\u5728\u540c\u6837\u7684path\u4e0b\u4e00\u904d\u53c8\u4e00\u904d\u5730\u6d4b\u8bd5\u6a21\u578b\uff0c\u4e5f\u4f1a\u4ea7\u751fselection bias\uff08false discovery\uff09\u3002</li> <li>backtest\u7684\u76ee\u7684\u5728\u4e8e\u4e22\u5f03\u4e0d\u597d\u7684\u6a21\u578b\uff0c\u800c\u4e0d\u80fd\u7528\u4e8e\u6539\u826f\u6a21\u578b\u3002\u56e0\u4e3a\u4e00\u65e6\u6539\u826f\u6a21\u578b\uff0c\u5c31\u4f1a\u9677\u5165overfit\uff0c\u800c\u4e14\u56e0\u4e3a\u5e38\u89c4WF backtest\u7684path\u53ea\u6709\u4e00\u6761\uff0c\u6240\u4ee5\u66f4\u52a0\u5bb9\u6613\u8fc7\u62df\u5408\uff08\u540e\u7eed\u7ae0\u8282\u4f1a\u8bb2\u8ff0\u5982\u4f55\u6539\u8fdb\u8fd9\u4e00\u70b9\uff09\u3002\u8fd9\u91cc\u672c\u8d28\u662f\u56e0\u4e3a\u4e0d\u80fd\u4f7f\u7528\u8bad\u7ec3\u96c6\uff08\u5386\u53f2\u6570\u636e\uff09\u8c03\u53c2\u3002</li> <li>\u4f5c\u8005\u4e5f\u63d0\u51fa\u4e86\u4e00\u4e9b\u6539\u8fdb\u56de\u6d4b\u4e0d\u597d\u8868\u73b0\u7684\u65b9\u6cd5\uff0c\u5305\u62ecbagging\u62bd\u6837\u3001\u5bf9\u5168\u54c1\u79cd\u8fdb\u884c\u56de\u6d4b\u3001\u4f7f\u7528\u60c5\u666f\u6a21\u62df\u7b49\u65b9\u5f0f\u4ee3\u66ff\u5386\u53f2\u6570\u636e\u56de\u6d4b\u3001\u4e0d\u8981\u56e0\u4e3a\u56de\u6d4b\u7ed3\u679c\u4e0d\u597d\u800c\u8c03\u53c2\uff0c\u800c\u5e94\u8be5\u4ece\u903b\u8f91\u51fa\u53d1\u6362\u4e00\u4e2a\u6a21\u578b\u7b49\u3002</li> <li>\u4f5c\u8005\u4ecb\u7ecd\u4e86\u4e00\u79cd\u9009\u62e9\u7b56\u7565\u7684\u65b9\u5f0f\uff1aPBO\u3002PBO\u8861\u91cf\u7b56\u7565\u5728\u56de\u6d4b\u65f6\u51fa\u73b0\u8fc7\u62df\u5408\u7684\u6982\u7387\u3002\u5047\u8bbe\u603b\u5171\u6709N\u79cd\u6a21\u578b\u6784\u9020\u65b9\u5f0f\uff08\u7b56\u7565\uff09\uff0c\u6211\u4eec\u4ece\u4e2d\u9009\u62e9\u6700\u4f73\u7b56\u7565\uff0c\u90a3\u4e48\u8fc7\u62df\u5408\u7684\u6982\u7387\u5c31\u662fPBO\u3002</li> </ol>"},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML8/","title":"AFML\u7b14\u8bb08: Backtesting Through Cross-Validation","text":"<p>\u8fd9\u7ae0\u4e3b\u8981\u8bb2\u4e86\u4ea4\u53c9\u9a8c\u8bc1\u5982\u4f55\u5e94\u7528\u5728\u56de\u6d4b\u4e2d\u3002</p> <ol> <li>walk forward backtesting (WF)\u65b9\u6cd5\u662f\u6700\u5e38\u89c4\u7684\u56de\u6d4b\u65b9\u6cd5\uff0c\u4f46\u662f\u5f88\u5bb9\u6613\u8fc7\u62df\u5408\uff0c\u5e76\u4e14\u4e00\u5f00\u59cb\u7684\u5f88\u591a\u9884\u6d4b\u7ed3\u679c\u662f\u57fa\u4e8e\u5c0f\u6837\u672c\u91cf\u7684\uff0c\u4f1a\u5bfc\u81f4sharpe\u7b49\u53c2\u6570\u4f30\u8ba1\u65b9\u5dee\u8fc7\u5927\uff0c\u540c\u65f6walk backward\u7684\u7ed3\u679c\u53ef\u80fd\u548cWF\u7684\u7ed3\u679c\u76f8\u5dee\u5f88\u5927\uff0c\u8bf4\u660eWF\u65b9\u6cd5\u4e0d\u5177\u5907\u5bf9\u672a\u6765\u53ef\u80fd\u60c5\u5f62\u7684\u7a33\u5065\u6027\u3002</li> <li>CV\u53ef\u4ee5\u89e3\u51b3\u4e0a\u8ff0\u5f88\u591a\u7684WF\u65b9\u6cd5\u7684\u7f3a\u70b9\u3002\u9996\u5148\u6211\u4eec\u8981\u660e\u786eCV\u7684\u76ee\u7684\uff1a\u4e0d\u662f\u4e3a\u4e86\u67e5\u770b\u5386\u53f2\u6570\u636e\u4e0a\u7b56\u7565\u7684\u771f\u5b9e\u8868\u73b0\uff0c\u800c\u662f\u67e5\u770b\u7b56\u7565\u5728\u672a\u77e5\u60c5\u5f62\u4e0b\u7684\u8868\u73b0\uff0c\u8fd9\u5c31\u662f\u524d\u9762\u63d0\u5230\u8fc7\u7684\u60c5\u5f62\u6a21\u62df\u3002\u8fd9\u53ef\u4ee5\u5e2e\u52a9\u964d\u4f4e\u8fc7\u62df\u5408\u3002</li> <li>CV\u4e5f\u6709\u4e00\u4e9b\u7f3a\u70b9\uff0c\u6bd4\u5982\u4e5f\u53ea\u5b58\u5728\u4e00\u6761path\uff08\u867d\u7136\u4e0d\u662f\u6cbf\u7740\u65f6\u95f4\u6d41\u5411\u7684path\uff09\u3002</li> <li>\u4f5c\u8005\u63d0\u51faCPCV\u7684\u65b9\u5f0f\uff0c\u4e3b\u8981\u662f\u5c06CV\u7ed3\u5408\u4e86\u524d\u9762\u7ae0\u8282\u7684purge\u548cembargo\u65b9\u6cd5\uff0c\u540c\u65f6\u901a\u8fc7\u5728\u6bcf\u6b21\u4ea4\u53c9\u9a8c\u8bc1\u7684\u65f6\u5019\u7ed9\u6d4b\u8bd5\u96c6\u5b89\u6392\u5927\u4e8e\u4e00\u4efd\u7684\u5206\u5272\u540e\u7684\u5b50\u6837\u672c\uff0c\u589e\u52a0\u4e86\u4ea4\u53c9\u9a8c\u8bc1\u7684path\u6570\u91cf\uff0c\u51cf\u5c0f\u4e86\u4f30\u8ba1\u7ed3\u679c\u7684\u65b9\u5dee\u3002\u5982\u679c\u6d4b\u8bd5\u96c6\u5305\u542b\u7684\u5b50\u6837\u672c\u6570\u91cf\u7b49\u4e8e1\uff0c\u90a3\u4e48CPCV\u5c31\u4f1a\u9000\u5316\u6210\u4e3a\u666e\u901a\u7684CV\u3002\u56e0\u6b64\uff0cCPCV\u53ef\u4ee5\u7406\u89e3\u4e3a a generalization of CV\u3002</li> <li>CPCV\u9700\u8981\u518d\u4ea7\u751f\u6bcf\u6761path\u6240\u4f7f\u7528\u7684\u8bad\u7ec3\u96c6\u5927\u5c0f\u3001path\u7684\u6570\u91cf\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002\u8fd9\u4e24\u8005\u5176\u4e2d\u4e00\u4e2a\u589e\u52a0\uff0c\u53e6\u5916\u4e00\u4e2a\u5c31\u9700\u8981\u51cf\u5c0f\u3002\u8fd9\u70b9\u6211\u7406\u89e3\u672c\u8d28\u4e0a\u662f\u504f\u5dee\u65b9\u5dee\u5747\u8861\u3002</li> <li>CPCV\u4e3a\u4ec0\u4e48\u53ef\u4ee5\u7f13\u89e3overfit\u7684\u95ee\u9898\uff1f\u9996\u5148\uff0cWF\u5bfc\u81f4sharpe\u7b49\u6307\u6807\u7684\u8ba1\u7b97\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d7\u5230\u5c0f\u90e8\u5206\u6837\u672c\u7684\u5f71\u54cd\uff0c\u65b9\u5dee\u5f88\u5927\uff0c\u65b9\u5dee\u5927\u5c31\u4f1a\u5bfc\u81f4false discovery\u3002CV\u65b9\u6cd5\u867d\u7136\u964d\u4f4e\u4e86false discovery\uff0c\u4f46\u662fpath\u4ecd\u7136\u53ea\u6709\u4e00\u6761\u3002\u800cCPCV\u65b9\u6cd5\u901a\u8fc7\u591a\u6761path\u6709\u6548\u964d\u4f4e\u4e86\u4f30\u8ba1\u7684\u65b9\u5dee\u3002</li> </ol>"},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML9/","title":"AFML\u7b14\u8bb09: Backtesting on Synthetic Data","text":"<p>\u5982\u679c\u6211\u4eec\u4e0d\u901a\u8fc7\u5386\u53f2\u6570\u636e\u56de\u6d4b\uff0c\u90a3\u4e48\u8fd8\u6709\u4ec0\u4e48\u65b9\u6cd5\u53ef\u4ee5\u8bc4\u4f30\u7b56\u7565\u7684\u6709\u6548\u6027\u5462\uff1f\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u751f\u6210\u7684\u6a21\u62df\u6570\u636e\u5bf9\u7b56\u7565\u8fdb\u884c\u6d4b\u8bd5\u3002 \u901a\u8fc7\u6a21\u62df\u6570\u636e\u800c\u4e0d\u662f\u5386\u53f2\u6570\u636e\u6d4b\u8bd5\u8fd8\u6709\u4e00\u4e2a\u597d\u5904\uff0c\u5c31\u662f\u53ef\u4ee5\u964d\u4f4e\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u56e0\u4e3a\u4fdd\u8bc1\u4e86\u7b56\u7565\u4e0d\u4f1a\u56e0\u4e3a\u8fc7\u62df\u5408\u4e8e\u67d0\u4e00\u4e2a\u7279\u5b9a\u5386\u53f2\u65f6\u671f\u4e0a\u7684\u6570\u636e\u3002</p> <ol> <li>\u9996\u5148\uff0c\u9700\u8981\u7406\u89e3trading rule\uff08R\uff09\u3002\u6211\u4e2a\u4eba\u7406\u89e3\u662f\u4efb\u4f55\u7b56\u7565\u672c\u8d28\u4e0a\u90fd\u53ef\u4ee5\u62bd\u8c61\u4e3a\u4e00\u4e2a\u89e6\u53d1\u4ea4\u6613\u4fe1\u53f7\uff08\u591a\u5934or\u7a7a\u5934\uff09\u3001\u4e00\u4e2a\u6b62\u76c8\u4fe1\u53f7\u3001\u4e00\u4e2a\u6b62\u635f\u4fe1\u53f7\u3002\u5176\u4e2d\u6b62\u76c8\u6b62\u635f\u4fe1\u53f7\u4e5f\u53ef\u4ee5\u7701\u7565\u3002\u8fd9\u91cc\u7684trading rule\u5c31\u662f\u4e00\u4e2a\u7279\u5b9a\u7b56\u7565\u7684\u6b62\u76c8\u6b62\u635f\u4fe1\u53f7\u3002</li> <li>\u5728\u5b9a\u4e49\u4e86trading rule\u540e\uff0c\u5bf9\u67d0\u4e2a\u7279\u5b9a\u7b56\u7565\uff0c\u6211\u4eec\u53ef\u4ee5\u7ed9\u5b9a\u4e00\u4e2aR\u7684\u96c6\u5408\u03a9\uff0c\u7136\u540e\u7f51\u683c\u641c\u7d22IS\u5f97\u5230\u6700\u4f73\u7684R\u3002\u540c\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u5b9a\u4e49R\u5b58\u5728\u8fc7\u62df\u5408\u7684\u6761\u4ef6\uff1aR*\u5728OOS\u4e0a\u8868\u73b0\u751a\u81f3\u4e0d\u5982R\u7684\u4e2d\u4f4d\u6570\uff08\u7c7b\u6bd4PBO\u7684\u5b9a\u4e49\uff09\u3002</li> <li>\u4f5c\u8005\u5148\u5047\u5b9a\u4ef7\u683c\u670d\u4eceO-U process\uff0c\u7136\u540e\u6839\u636e\u7ed9\u5b9a\u6bcf\u79cd\u7b56\u7565\u4f30\u8ba1O-U process\u7684\u53c2\u6570\uff0c\u63a5\u7740\u5229\u7528\u4f30\u8ba1\u7684\u53c2\u6570\u8fdb\u884c\u8499\u7279\u5361\u6d1b\u6a21\u62df\uff1a\u751f\u6210\u4ef7\u683c\u8def\u5f84\uff0c\u5bf9\u6bcf\u4e2aR\u2208\u03a9\u8ba1\u7b97sharpe\uff0c\u7136\u540e\u9009\u51fa\u6700\u4f73\u7684R\u3002</li> <li>\u6700\u540e\u4f5c\u8005\u901a\u8fc7\u5b9e\u9a8c\u6d4b\u8bd5\u4e86\u4e0a\u8ff0\u65b9\u6cd5\uff0c\u7ed3\u8bba\u662f\u7ed9\u5b9a\u4ef7\u683c\u548c\u7b56\u7565\uff0c\u5b58\u5728\u4e00\u4e2a\u6700\u4f73\u7684R*\uff0c\u4f7f\u5f97\u7b56\u7565\u7684sharpe\u6700\u5927\u3002</li> </ol>"},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML_summary/","title":"AFML \u603b\u7ed3","text":"<p>\u4e3b\u8981\u8bb0\u5f55\u4e00\u4e0b\u80fd\u591f\u5bf9\u6211\u7684\u5de5\u4f5c\u4ea7\u751f\u6539\u8fdb\u7684\u5730\u65b9</p>"},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML_summary/#_1","title":"\u6570\u636e\u9884\u5904\u7406","text":"<ol> <li>tick\u7ea7\u522b\u7684\u6570\u636e\u7684\u805a\u5408\uff1aDollar or Volume or Event-driven bars \u53ef\u4ee5\u5c1d\u8bd5\uff0c\u4e0d\u8fc7\u4e00\u822c\u5c31\u662f\u4f7f\u7528time bar</li> <li>\u5206\u7ea2 or \u6d3e\u606f\u7b49\u95ee\u9898\u7684\u5904\u7406\uff1athe ETF trick</li> <li>\u671f\u8d27\u6362\u6708\u7684\u5904\u7406\uff1a\u5c06\u6362\u6708\u7684\u6536\u76ca\u4ece\u4ef7\u683c\u5e8f\u5217\u4e2d\u51cf\u53bb</li> <li>\u62bd\u6837\uff1a\u4e0d\u80fd\u76f4\u63a5\u5c06\u5168\u90e8\u7684\u6570\u636e\u4f5c\u4e3a\u6837\u672c\u653e\u5165ML model\u4e2d\uff0c\u56e0\u4e3a\u8fd9\u6837\u4f1a\u5bfc\u81f4\u9884\u6d4b\u6548\u679c\u5f88\u5dee\u3002\u4f7f\u7528cumsum filter: \u53ea\u62bd\u53d6\u5f02\u5e38\u73b0\u8c61\u7d2f\u79ef\u5230\u4e00\u5b9a\u91cf\u7684\u6837\u672c</li> <li>labelling: \u7ed9\u6837\u672c\u6253\u6807\u7b7e\uff0c\u6709\u591a\u79cd\u65b9\u6cd5\uff1a</li> <li>\u76f4\u63a5\u4f7f\u7528\u672a\u6765\u6536\u76ca\u7387\uff0c\u4f46\u662f\u56e0\u4e3atime bar\u7684\u6536\u76ca\u7387\u7684\u6ce2\u52a8\u7387\u4e0d\u662f\u7a33\u5b9a\u7684\uff0c \u4e00\u822c\u4f7f\u7528\u6ce2\u52a8\u7387\u8c03\u6574\u7684\u672a\u6765\u6536\u76ca\u7387\u6216\u8005\u4f7f\u7528\u4f7f\u7528volume or dollar bar\u3002 </li> <li>triple-barrier method\uff1a\u8bbe\u7f6e\u4e86\u6b62\u76c8\u6b62\u635f\u548c\u65f6\u95f4\u4e09\u4e2abarrier</li> <li>meta-labelling</li> <li>sampling weight\uff1a\u4e3b\u8981\u89e3\u51b3\u6837\u672c\u7684\u6807\u7b7e\u5177\u6709\u65f6\u5e8f\u4e0a\u7684\u76f8\u5173\u6027\uff0c\u4e0d\u6ee1\u8db3\u5f88\u591a\u6a21\u578b\u5bf9\u4e8e\u6837\u672c\u4e4b\u95f4iid\u7684\u5047\u8bbe\u8fd9\u4e2a\u95ee\u9898\u3002</li> <li>\u5dee\u5206\uff1a\u5dee\u5206\u5e26\u6765\u5e73\u7a33\u4f46\u662f\u8ba9\u5e8f\u5217\u5931\u53bb\u65f6\u5e8f\u4e0a\u7684\u9884\u6d4b\u80fd\u529b\u3002\u90a3\u4e48\u8003\u8651\u5c0f\u6570\u9636\u5dee\u5206\uff1a\u65e2\u4fdd\u8bc1\u4e86\u6570\u636e\u7684\u5e73\u7a33\u6027\uff0c\u53c8\u4fdd\u7559\u4e86\u5927\u90e8\u5206\u6570\u636e\u7684\u9884\u6d4b\u80fd\u529b\u3002 \u5177\u4f53\u505a\u6cd5\u4e0a\uff0c\u4f7f\u7528ADF test\uff0c\u627e\u5230\u4f7f\u5f97\u5e8f\u5217\u901a\u8fc7ADF\u68c0\u9a8c\uff08\u8bf4\u660e\u5e8f\u5217\u5e73\u7a33\uff09\u7684\u6700\u5c0f\u5206\u6570d</li> </ol>"},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML_summary/#_2","title":"\u6a21\u578b","text":"<ol> <li>bagging\u6a21\u578b\u76f8\u6bd4boosting\u66f4\u52a0\u64c5\u957f\u89e3\u51b3\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u66f4\u52a0\u63a8\u8350\u4f7f\u7528\u5728\u91d1\u878d\u6570\u636e\u4e0a\uff0c\u56e0\u4e3a\u91d1\u878d\u95ee\u9898\u4e00\u822c\u53d7\u5230\u8fc7\u62df\u5408\u5f71\u54cd\u3002</li> <li>\u6837\u672c\u5197\u4f59\u5bfc\u81f4\u968f\u673a\u68ee\u6797\u6a21\u578b\u5bb9\u6613\u8fc7\u62df\u5408\uff0c\u53ef\u4ee5\u6709\u591a\u79cd\u89e3\u51b3\u65b9\u6cd5\uff1a\u89c1\u4e66p98</li> <li>bagging\u6a21\u578b\u5982\u679c\u65e0\u6cd5\u627f\u62c5\u8fc7\u5927\u7684\u6837\u672c\u91cf\uff08\u6bd4\u5982SVM\uff09\uff0c\u90a3\u4e48\u53ef\u4ee5\u5bf9\u57fa\u6a21\u578b\u4f7f\u7528\u65e9\u505c\uff0c\u7136\u540e\u518d\u5229\u7528\u5c06\u591a\u4e2a\u6a21\u578bbagging\u5728\u4e00\u8d77\u964d\u4f4e\u65b9\u5dee\u3002\\</li> </ol>"},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML_summary/#_3","title":"\u4ea4\u53c9\u9a8c\u8bc1","text":"<ol> <li>\u6837\u672c\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u4f1a\u5bfc\u81f4\u666e\u901a\u7684k\u6298\u4ea4\u53c9\u9a8c\u8bc1\u5931\u6548\uff0c\u56e0\u4e3a\u6d4b\u8bd5\u96c6\u4e2d\u7528\u5230\u4e86\u8bad\u7ec3\u96c6\u7684\u4fe1\u606f\uff0c\u89c1\u4e66p107\u3002\u53ef\u4ee5\u91c7\u53d6Purge\u548cembargo\u4e24\u79cd\u65b9\u6cd5\u3002 \u4e0d\u8fc7\u6211\u4e4b\u524d\u4f7f\u7528\u7684\u8bad\u7ec3\u5c31\u662f\u7b80\u5355\u7684\u6eda\u52a8\u8bad\u7ec3\uff0c\u6ca1\u6709\u7528\u5230k\u6298\u4ea4\u53c9\u9a8c\u8bc1\u3002\u53ef\u4ee5\u5c1d\u8bd5\u4f7f\u7528k\u6298\u4ea4\u53c9\u9a8c\u8bc1\u3002</li> <li>\u7f51\u683c\u6216\u968f\u673a\u641c\u7d22\u4ea4\u53c9\u9a8c\u8bc1\u53ef\u4ee5\u7528\u6765\u8c03\u6574\u6a21\u578b\u7684\u8d85\u53c2\u6570\u3002\u6709\u5982\u4e0b\u51e0\u4e2a\u6ce8\u610f\u70b9\u3002</li> <li>\u4f7f\u7528sklearn\u4e2dGridSearchCV\u7684cv\u53c2\u6570\u9700\u8981\u81ea\u5b9a\u4e49\u4e3aPurgedKFold\u65b9\u6cd5\u3002</li> <li>meta-labelling\u7684\u60c5\u51b5\u4e0b\uff0cGridSearchCV\u7684scoring\u53c2\u6570\u5efa\u8bae\u8bbe\u7f6e\u4e3af1</li> <li>\u975emeta-labelling\u7684\u60c5\u51b5\u4e0b\uff0cGridSearchCV\u7684scoring\u53c2\u6570\u5efa\u8bae\u8bbe\u7f6e\u4e3aneg_log_loss\uff0c\u89c1\u4e66p134</li> <li>\u5bf9\u7279\u5b9a\u6a21\u578b\uff0c\u904d\u5386\u53c2\u6570\u7684\u8303\u56f4\u5206\u5e03\u53ef\u4ee5\u4f7f\u7528log-uniform\uff0c\u89c1\u4e66p132</li> </ol>"},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML_summary/#_4","title":"\u56de\u6d4b","text":"<ol> <li>\u7279\u5f81\u91cd\u8981\u6027\u7684\u7814\u7a76\u6bd4\u56de\u6d4b\u7ed3\u679c\u66f4\u52a0\u91cd\u8981\u3002\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528Mean Decrease Impurity\u3001Mean Decrease Accuracy\u8fd8\u6709Single Feature Importance \u7b49\u624b\u6bb5\u8861\u91cf\u7279\u5f81\u91cd\u8981\u6027\u3002\u7279\u5f81\u91cd\u8981\u6027\u6709\u52a9\u4e8e\u6211\u4eec\u4e86\u89e3ML\u8fd9\u4e2a\u9ed1\u7bb1\u3002</li> <li>\u5373\u4f7f\u56de\u6d4b\u6846\u67b6\u5b8c\u7f8e\uff0c\u4e0d\u5b58\u5728\u6570\u636e\u6cc4\u9732\u7b49\u95ee\u9898\uff0c\u4f46\u662f\u56e0\u4e3a\u5728\u540c\u6837\u7684path\u4e0b\u4e00\u904d\u53c8\u4e00\u904d\u5730\u6d4b\u8bd5\u6a21\u578b\uff0c\u4e5f\u4f1a\u4ea7\u751fselection bias\uff08false discovery\uff09\u3002</li> <li>backtest\u7684\u76ee\u7684\u5728\u4e8e\u4e22\u5f03\u4e0d\u597d\u7684\u6a21\u578b\uff0c\u800c\u4e0d\u80fd\u7528\u4e8e\u6539\u826f\u6a21\u578b\u3002\u56e0\u4e3a\u4e00\u65e6\u6539\u826f\u6a21\u578b\uff0c\u5c31\u4f1a\u9677\u5165overfit\uff0c \u800c\u4e14\u56e0\u4e3a\u5e38\u89c4WF backtest\u7684path\u53ea\u6709\u4e00\u6761\uff0c\u6240\u4ee5\u66f4\u52a0\u5bb9\u6613\u8fc7\u62df\u5408\u3002\u8fd9\u91cc\u672c\u8d28\u662f\u56e0\u4e3a\u4e0d\u80fd\u4f7f\u7528\u8bad\u7ec3\u96c6\uff08\u5386\u53f2\u6570\u636e\uff09\u8c03\u53c2\u3002</li> <li>\u53ef\u4ee5\u4f7f\u7528PBO\u8861\u91cf\u4ece\u591a\u4e2a\u56e0\u5b50\u4e2d\u9009\u62e9\u4e00\u4e2a\u6700\u4f73\u56e0\u5b50\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\uff0c\u51fa\u73b0\u8fc7\u62df\u5408\u7684\u6982\u7387\u3002</li> <li>\u4f7f\u7528\u4ea4\u53c9\u9a8c\u8bc1CV\u8fdb\u884c\u56de\u6d4b\uff0c\u53ef\u4ee5\u89e3\u51b3\u5f88\u591a\u7684WF\u65b9\u6cd5\u7684\u7f3a\u70b9\u3002\u9996\u5148\u6211\u4eec\u8981\u660e\u786eCV\u7684\u76ee\u7684\uff1a\u4e0d\u662f\u4e3a\u4e86\u67e5\u770b\u5386\u53f2\u6570\u636e\u4e0a\u7b56\u7565\u7684\u771f\u5b9e\u8868\u73b0\uff0c \u800c\u662f\u67e5\u770b\u7b56\u7565\u5728\u672a\u77e5\u60c5\u5f62\u4e0b\u7684\u8868\u73b0\u3002\u8fd9\u5c31\u662f\u6240\u8c13\u60c5\u5f62\u6a21\u62df\uff0c\u53ef\u4ee5\u5e2e\u52a9\u964d\u4f4e\u8fc7\u62df\u5408\u3002\u4e0d\u8fc7CV\u4e5f\u53ea\u6709\u4e00\u6761path\uff0c\u4ee3\u8868\u6bcf\u6b21CV\u53ea\u80fd\u751f\u6210\u4e00\u4e2a\uff08\u62fc\u63a5\u540e\u7684\uff09\u56de\u6d4b\u7ed3\u679c\u3002</li> <li>\u4f7f\u7528CPCV\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6539\u5584CV\u3002CPCV\u7ed3\u5408\u4e86\u524d\u9762\u7ae0\u8282\u7684purge\u548cembargo\u65b9\u6cd5\uff0c\u540c\u65f6\u901a\u8fc7\u5728\u6bcf\u6b21\u4ea4\u53c9\u9a8c\u8bc1\u7684\u65f6\u5019\u7ed9\u6d4b\u8bd5\u96c6\u5b89\u6392\u5927\u4e8e\u4e00\u4efd\u7684\u5206\u5272\u540e\u7684\u5b50\u6837\u672c\uff0c\u89c1\u4e66p165\u3002</li> <li>\u76f4\u63a5\u5728\u6a21\u62df\u6570\u636e\u4e0a\u56de\u6d4b\uff0c\u4e5f\u53ef\u4ee5\u964d\u4f4e\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u56e0\u4e3a\u4fdd\u8bc1\u4e86\u7b56\u7565\u4e0d\u4f1a\u56e0\u4e3a\u8fc7\u62df\u5408\u4e8e\u67d0\u4e00\u4e2a\u7279\u5b9a\u5386\u53f2\u65f6\u671f\u4e0a\u7684\u6570\u636e\u3002 \u5177\u4f53\u5b9e\u73b0\u65b9\u5f0f\u662f\u5148\u5047\u5b9a\u4ef7\u683c\u7684\u5206\u5e03\u5e76\u4e14\u4f30\u8ba1\u5206\u5e03\u53c2\u6570\uff0c\u518d\u56de\u6d4b\u3002\u89c1\u4e66p169\u3002</li> <li>\u6211\u4eec\u53ef\u4ee5\u63a8\u5bfc\u51fa\u5e74\u5316sharpe\u3001\u4ea4\u6613\u9891\u7387\u548c\u80dc\u7387\u4e4b\u95f4\u7684\u5173\u7cfb\uff08\u6216\u8bb8\u53ef\u4ee5\u5199\u51e0\u4e2a\u7b80\u5355\u7684\u5173\u7cfb\u5f0f\u51fd\u6570\uff0c\u5e2e\u52a9\u5feb\u901f\u5224\u65ad\uff09\u3002 </li> <li>\u7b56\u7565\u7684\u98ce\u9669\u53ef\u4ee5\u901a\u8fc7\u7b56\u7565\u7684sharpe\u5bf9\u80dc\u7387\u7684\u654f\u611f\u7a0b\u5ea6\u8861\u91cf\u3002\u4e5f\u53ef\u4ee5\u6c42\u51fa\u4f7f\u5f97\u7b56\u7565\u7684sharpe\u5927\u4e8e\u7b49\u4e8e\u76ee\u6807\u6240\u8981\u6c42\u7684\u6700\u4f4e\u80dc\u7387\u6765\u8861\u91cf\u3002</li> </ol>"},{"location":"markdown/books_and_literatures/advanced_financial_machine_learning/AFML_summary/#_5","title":"\u56e0\u5b50\u6784\u9020","text":"<ol> <li>bet sizing\u6307\u7684\u662f\u6211\u4eec\u7684\u4ed3\u4f4d\u5927\u5c0f\uff0c\u5bf9\u65f6\u5e8f\u7b56\u7565\u53ef\u4ee5\u7406\u89e3\u4e3a\u56e0\u5b50\u503c\u3002\u8fd9\u91cc\u7684\u95ee\u9898\u662f\u6211\u4eec\u6709\u65f6\u5019\u4f7f\u7528\u7684ML\u6a21\u578b\u662f\u4e00\u4e2a\u5206\u7c7b\u5668\uff08\u6bd4\u5982meta-labelling\uff09\uff0c \u90a3\u4e48\u6211\u4eec\u9700\u8981\u5c06\u5206\u7c7b\u5668\u7684\u7ed3\u679c\u8f6c\u6362\u4e3a\u56e0\u5b50\u503c\uff08\u4ed3\u4f4d\uff09\u3002\u5177\u4f53\u65b9\u6cd5\u662f\u4f7f\u7528cdf\uff0c\u8f6c\u6362\u4e3a-1\u52301\u4e4b\u95f4\u7684\u56e0\u5b50\u503c\uff0c\u89c1\u4e66p142\u3002\u8fd9\u6837\u64cd\u4f5c\u540e\uff0c\u6211\u4eec\u5728\u6bcf\u4e2abar\u90fd\u6709\u4e00\u4e2abet size\u3002 \u4f46\u662f\u6bcf\u4e2abet \u90fd\u6709\u4e00\u6bb5\u6301\u7eed\u65f6\u95f4\u3002\u5bf9\u6bcf\u4e2a\u65f6\u523b\uff0c\u6211\u4eec\u9700\u8981\u5c06\u8be5\u65f6\u523b\u4e0a\u7684\u6240\u6709bet\u53d6\u5e73\u5747\u503c\u3002\u7136\u540e\uff0c\u6211\u4eec\u8fd8\u53ef\u4ee5\u8fdb\u884c\u4ed3\u4f4d\u79bb\u6563\u5316\u64cd\u4f5c\u3002\u89c1\u4e66p144\u3002\u6211\u4eec\u8fd8\u53ef\u4ee5\u6839\u636e \u4ef7\u683c\u53d8\u52a8\u52a8\u6001\u8c03\u6574bet size\u3002</li> <li>\u4ed3\u4f4d\u79bb\u6563\u5316 + \u6263\u8d39 \u8fd9\u5957\u7ec4\u5408\u53ef\u80fd\u53ef\u4ee5\u66f4\u597d\u5730\u6539\u5584\u8fde\u7eed\u578b\u56e0\u5b50\u7684\u8d39\u540esharpe\u3002</li> <li>\u9664\u4e86\u81ea\u5df1\u7684\u4e00\u4e9b\u56e0\u5b50\u53ef\u4ee5\u4f5c\u4e3a\u6a21\u578b\u7684\u81ea\u53d8\u91cf\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u901a\u8fc7\u4e00\u4e9b\u7ecf\u5178\u7684\u7279\u5f81\u4f5c\u4e3a\u6a21\u578b\u81ea\u53d8\u91cf\u3002</li> <li>structural break\u7279\u5f81\uff1a\u6211\u4eec\u53ef\u4ee5\u5229\u7528\u8bc6\u522bstructural break\u7684\u65b9\u6cd5\u6765\u6784\u9020\u7279\u5f81\u3002</li> <li>entropy features\uff1a\u5229\u7528\u4fe1\u606f\u71b5\u6784\u9020\u7279\u5f81\u3002</li> <li>Microstructure features\uff1a\u57fa\u4e8e\u5fae\u89c2\u7ed3\u6784\u7684\u7279\u5f81\uff0c\u4f8b\u5982bid-ask spread\u7684\u8bc4\u4ef7\u6307\u6807\u3001\u5e02\u573a\u6d41\u52a8\u6027\u7684\u8861\u91cf\u6307\u6807\u03bb\u3001PIN\u7b49\u90fd\u53ef\u4ee5\u4f5c\u4e3a\u7279\u5f81\u3002</li> </ol>"},{"location":"markdown/daily/current_plan/","title":"\u5b66\u4e60\u8ba1\u5212","text":""},{"location":"markdown/daily/current_plan/#_2","title":"\u5176\u4ed6\u8ba1\u5212","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/","title":"\u5b9e\u6218\u7ae0\u8282\uff1a\u5728Linux\u4e0a\u90e8\u7f72\u5404\u7c7b\u8f6f\u4ef6","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_1","title":"\u524d\u8a00","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#linux_1","title":"\u4e3a\u4ec0\u4e48\u5b66\u4e60\u5404\u7c7b\u8f6f\u4ef6\u5728Linux\u4e0a\u7684\u90e8\u7f72","text":"<p>\u5728\u524d\u9762\uff0c\u6211\u4eec\u5b66\u4e60\u4e86\u8bb8\u591a\u7684Linux\u547d\u4ee4\u548c\u9ad8\u7ea7\u6280\u5de7\uff0c\u8fd9\u4e9b\u77e5\u8bc6\u70b9\u6bd4\u8f83\u96f6\u6563\uff0c\u540c\u5b66\u4eec\u8ddf\u968f\u7740\u8bfe\u7a0b\u7684\u5185\u5bb9\u8fdb\u884c\u7ec3\u4e60\u867d\u7136\u53ef\u4ee5\u57fa\u7840\u638c\u63e1\u8fd9\u4e9b\u547d\u4ee4\u548c\u6280\u5de7\u7684\u4f7f\u7528\uff0c\u4f46\u662f\u5e76\u6ca1\u6709\u4e00\u4e9b\u5177\u4f53\u7684\u5b9e\u64cd\u80fd\u591f\u4e32\u8054\u8d77\u6765\u8fd9\u4e9b\u77e5\u8bc6\u70b9\u3002</p> <p>\u6240\u4ee5\uff0c\u73b0\u5728\u6211\u4eec\u8bbe\u8ba1\u4e86\u5404\u7c7b\u8f6f\u4ef6\u5728Linux\u4e0a\u90e8\u7f72\u5b89\u88c5\u7684\u5b9e\u6218\u7ae0\u8282\uff0c\u53ef\u4ee5\u8ba9\u540c\u5b66\u4eec\uff1a</p> <ul> <li>\u5bf9\u524d\u9762\u5b66\u4e60\u7684\u5404\u7c7b\u64cd\u4f5c\u547d\u4ee4\u8fdb\u884c\u590d\u4e60\u548c\u7ec3\u4e60\uff0c\u4ece\u800c\u6df1\u5ea6\u638c\u63e1\u5b83\u4eec</li> <li>\u672c\u7ae0\u8282\u4e2d\u6f14\u793a\u90e8\u7f72\u7684\u8f6f\u4ef6\uff0c\u5305\u542b\u4e86IT\u884c\u4e1a\u5404\u7c7b\u5c97\u4f4d\u4e2d\u6240\u5fc5\u987b\u4f7f\u7528\u7684\uff0c\u5982\uff1aJava\u540e\u53f0\u3001\u5927\u6570\u636e\u5f00\u53d1\u3001\u8fd0\u7ef4\u5f00\u53d1\u3001\u6d4b\u8bd5\u3001AI\u7b49\u3002\u65e0\u8bba\u5b66\u4e60Linux\u540e\u4ece\u4e8b\u4ec0\u4e48\u5c97\u4f4d\uff0c\u8fd9\u4e9b\u5185\u5bb9\u90fd\u4f1a\u7ed9\u4f60\u5e26\u6765\u5e2e\u52a9</li> </ul> <p>\u5bf9\u4e8e\u96f6\u57fa\u7840\u5b66\u5458\uff0c\u5b9e\u6218\u8bfe\u7a0b\u4e2d\u6240\u8bb2\u89e3\u7684\u8f6f\u4ef6\u5927\u6982\u7387\u591a\u6570\u5927\u5bb6\u5e76\u4e0d\u4e86\u89e3\u3002</p> <p>\u6240\u4ee5\uff0c\u8bfe\u7a0b\u4ec5\u6d89\u53ca\u5230\u5b89\u88c5\u90e8\u7f72\uff0c\u4e0d\u5bf9\u8f6f\u4ef6\u7684\u4f7f\u7528\u505a\u8be6\u7ec6\u8bf4\u660e\u3002</p> <p>\u540c\u5b66\u4eec\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\uff0c\u53ef\u80fd\u4f1a\u9047\u5230\u5404\u79cd\u5404\u6837\u7684\u9519\u8bef\uff0c<code>\u4e0d\u8981\u6015</code>\uff0c\u89e3\u51b3\u5b83\uff0c\u5c06\u4f1a\u7ed9\u4f60\u5e26\u6765\u6781\u5927\u7684\u63d0\u5347\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_2","title":"\u5b66\u4e60\u76ee\u6807","text":"<p>\u5bf9\u4e8e\u672c\u90e8\u5206\u7684\u5185\u5bb9\u5b66\u4e60\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e24\u4e2a\u76ee\u6807\uff1a</p> <ul> <li>\u5bf9\u4e8e\u96f6\u57fa\u7840\u6216\u672a\u4ece\u4e1a\u7684\u5b66\u5458\uff0c\u4e0d\u8981\u6c42\u6df1\u5165\u7406\u89e3\u6240\u5b89\u88c5\u90e8\u7f72\u7684\u8f6f\u4ef6\u662f\u4ec0\u4e48\uff0c\u4ec5\u4ec5\u80fd\u591f\u8ddf\u968f\u8bfe\u7a0b\u6210\u529f\u7684\u5c06\u5176\u90e8\u7f72\u5b89\u88c5\u5e76\u8fd0\u884c\u6210\u529f\u5373\u53ef</li> </ul> <p>\u5728\u8fd9\u4e2a\u8fc7\u7a0b\u4e2d\uff0c\u4e3b\u8981\u953b\u70bc\u5927\u5bb6\u5bf9Linux\u64cd\u4f5c\u7cfb\u7edf\u7684\u719f\u7ec3\u5ea6\uff0c\u6b64\u4e43\u96f6\u57fa\u7840\u672a\u4ece\u4e1a\u5b66\u5458\u7684\u7b2c\u4e00\u5b66\u4e60\u76ee\u6807</p> <ul> <li>\u5bf9\u4e8e\u6709\u57fa\u7840\u6216\u5df2\u4ece\u4e1a\u7684\u5b66\u5458\uff0c\u672c\u7ae0\u8282\u8bb2\u89e3\u7684\u8f6f\u4ef6\u6db5\u76d6\u4e86\u5927\u591a\u6570IT\u4ece\u4e1a\u8005\u6240\u80fd\u63a5\u89e6\u5230\u7684\uff0c\u7279\u522b\u662f\u5927\u6570\u636e\u5f00\u53d1\u3001\u540e\u7aef\u5f00\u53d1\u4e24\u4e2a\u4e3b\u6d41\u65b9\u5411\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u53c2\u8003\u8d44\u6599\uff0c\u4ee5\u4fbf\u5728\u5de5\u4f5c\u4e2d\u6709\u6240\u5e2e\u52a9\u3002</li> </ul> <p>\u672c\u7ae0\u8282\u5185\u7684\u5404\u7c7b\u8f6f\u4ef6\u5b89\u88c5\uff0c\u4e0d\u5f3a\u5236\u8981\u6c42\u5168\u90e8\u5b66\u4e60</p> <ol> <li>\u96f6\u57fa\u7840\u5b66\u5458\uff0c\u5efa\u8bae\u5168\u90e8\u5b66\u4e60\uff0c\u4f5c\u4e3a\u524d\u9762\u5b66\u4e60\u5185\u5bb9\u7684\u603b\u7ed3\u548c\u5b9e\u6218</li> <li>IT\u4ece\u4e1a\u8005\u3001\u6709\u7ecf\u9a8c\u5b66\u5458\uff0c\u53ef\u4ee5\u6309\u9700\u9009\u62e9\uff0c\u9009\u62e9\u5de5\u4f5c\u4e2d\u9700\u8981\u7528\u5230\u7684\u8fdb\u884c\u5b66\u4e60</li> </ol> <p>\u7ae0\u8282\u5185\u5305\u542b\u7684\u8f6f\u4ef6\u5e76\u975e100%\u6db5\u76d6\u4e86IT\u5f00\u53d1\u9886\u57df\u4e2d\u6240\u9700\u8981\u7684\u5185\u5bb9\u3002</p> <p>\u5982\u679c\u60a8\u5bf9\u67d0\u4e9b\u8f6f\u4ef6\u7684\u5b89\u88c5\u6709\u5f3a\u70c8\u9700\u6c42\uff0c\u4e14\u8bfe\u7a0b\u4e2d\u6ca1\u6709\u63d0\u4f9b\u6559\u7a0b\uff0c\u53ef\u4ee5\u79c1\u4fe1B\u7ad9\uff1a\"\u9ed1\u9a6c\u5927\u6570\u636e\u66f9\u8001\u5e08\"\uff0c\u8001\u5e08\u4f1a\u914c\u60c5\u6839\u636e\u65f6\u95f4\u5b89\u6392\u8865\u5145\u4e0a\u53bb\u54e6\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#ppt","title":"\u4e3a\u4ec0\u4e48\u4e0d\u4f7f\u7528PPT\u800c\u662f\u4f7f\u7528\u6587\u6863\u8fdb\u884c\u6388\u8bfe","text":"<p>\u4ece\u73b0\u5728\u5f00\u59cb\uff0c\u5c06\u8981\u8fdb\u5165\u5230Linux\u7684\u5b9e\u64cd\u9636\u6bb5\uff0c\u5728\u8fd9\u4e2a\u9636\u6bb5\u6211\u4eec\u5c06\u4f1a\u6d89\u53ca\u5230\u975e\u5e38\u591a\u7684\u8f6f\u4ef6\u90e8\u7f72\u7b49\u64cd\u4f5c\uff0c\u6d89\u53ca\u5230\uff1a</p> <ul> <li>\u5404\u7c7b\u547d\u4ee4\u7684\u4f7f\u7528</li> <li>\u5404\u79cd\u8fc7\u7a0b\u7684\u7ed3\u679c</li> <li>\u590d\u6742\u7684\u6d41\u7a0b\u6b65\u9aa4</li> <li>\u7b49</li> </ul> <p>\u8fd9\u4e9b\u4fe1\u606f\u7684\u5c55\u793a\uff0c\u5e76\u4e0d\u9002\u5408\u4e8e\u4f7f\u7528PPT\u4f5c\u4e3a\u8f7d\u4f53\u8fdb\u884c\u6388\u8bfe\uff0c\u6240\u4ee5\u4ece\u73b0\u5728\u5f00\u59cb\u6211\u4eec\u5c06\u4f7f\u7528\u64cd\u4f5c\u6587\u6863\u7684\u6a21\u5f0f\u4e3a\u5927\u5bb6\u8fdb\u884c\u8bb2\u89e3\u3002</p> <p>\u4f7f\u7528\u6587\u6863\u6a21\u5f0f\u8fd8\u6709\u4e00\u4e2a\u597d\u5904\uff0c\u9664\u4e86\u5b66\u4e60\u89c6\u9891\u4ee5\u5916\uff0c\u62ff\u5230\u8bfe\u7a0b\u4e2d\u4f7f\u7528\u7684\u64cd\u4f5c\u6587\u6863\uff0c\u540c\u6837\u53ef\u4ee5\u4f5c\u4e3a\u91cd\u8981\u7684\u53c2\u8003\u624b\u518c\u8fdb\u884c\u4f7f\u7528\u3002</p> <p>\u4e00\u4e3e\u4e24\u5f97</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_3","title":"\u524d\u7f6e\u8981\u6c42","text":"<ol> <li>\u5b9e\u6218\u7ae0\u8282\u8981\u6c42\u540c\u5b66\u4eec==\u52a1\u5fc5\u5168\u90e8\u5b66\u4e60\u524d\u9762\u7684\u77e5\u8bc6\u70b9==\uff0c\u5373\uff1a\u521d\u8bc6Linux\u3001Linux\u57fa\u7840\u547d\u4ee4\u3001Linux\u6743\u9650\u7ba1\u7406\u3001Linux\u9ad8\u9636\u6280\u5de7\u8fd94\u4e2a\u7ae0\u8282\uff0c\u8bf7\u52ff\u8df3\u8fc7\u524d\u9762\u7684\u7ae0\u8282\u5b66\u4e60\u5b9e\u6218\u7ae0\u8282\u3002</li> <li>\u5b9e\u6218\u7ae0\u8282\u4e2d\u4f1a\u5f00\u542f\u591a\u53f0\u865a\u62df\u673a\uff0c\u8bf7\u5c3d\u91cf\u786e\u4fdd\u7535\u8111\u7684\u5185\u5b58\u5728\uff1a8GB\uff08\u5305\u542b8GB\uff09\u4ee5\u4e0a\u3002\u5982\u5185\u5b58\u4e0d\u8db3\u53ef\u4ee5\u6269\u5145\u5185\u5b58\u6761\u6216\u8d2d\u4e70\u963f\u91cc\u4e91\u3001UCloud\u7b49\u4e91\u670d\u52a1\u5668\u4e34\u65f6\u4f7f\u7528\uff081\u4e2a\u6708\u591a\u53f0\u4f4e\u914d\u670d\u52a1\u5668\u51e0\u5341\u5757\u5de6\u53f3\uff09</li> </ol> <p>\u5bf9\u4e8e\u4e91\u5e73\u53f0\u4e0a\u8d2d\u4e70\u670d\u52a1\u5668\uff0c\u53ef\u4ee5\u53c2\u9605\u6700\u540e\u7684\u7ae0\u8282\uff08\u4e91\u670d\u52a1\uff09</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_4","title":"\u6ce8\u610f","text":"<p>\u4e0b\u9762\u5168\u90e8\u7684\u8f6f\u4ef6\u5b89\u88c5\u7684\u76f8\u5173\u6d41\u7a0b\uff0c90%\u90fd\u662f\u53d6\u81ea\u8f6f\u4ef6\u81ea\u8eab\u7684\u5b98\u65b9\u7f51\u7ad9\u3002</p> <p>\u4e00\u4e2a\u5408\u683c\u7684\u7a0b\u5e8f\u5458\u8981\u6709\u826f\u597d\u7684\u4fe1\u606f\u6536\u96c6\u80fd\u529b\u54e6</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#mysql","title":"MySQL\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u5b89\u88c5\u90e8\u7f72\u3010\u7b80\u5355\u3011","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_5","title":"\u7b80\u4ecb","text":"<p>MySQL\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\uff08\u540e\u7eed\u7b80\u79f0MySQL\uff09\uff0c\u662f\u4e00\u6b3e\u77e5\u540d\u7684\u6570\u636e\u5e93\u7cfb\u7edf\uff0c\u5176\u7279\u70b9\u662f\uff1a\u8f7b\u91cf\u3001\u7b80\u5355\u3001\u529f\u80fd\u4e30\u5bcc\u3002</p> <p>MySQL\u6570\u636e\u5e93\u53ef\u8c13\u662f\u8f6f\u4ef6\u884c\u4e1a\u7684\u660e\u661f\u4ea7\u54c1\uff0c\u65e0\u8bba\u662f\u540e\u7aef\u5f00\u53d1\u3001\u5927\u6570\u636e\u3001AI\u3001\u8fd0\u7ef4\u3001\u6d4b\u8bd5\u7b49\u5404\u7c7b\u5c97\u4f4d\uff0c\u57fa\u672c\u4e0a\u90fd\u4f1a\u548cMySQL\u6253\u4ea4\u9053\u3002</p> <p>\u8ba9\u6211\u4eec\u4eceMySQL\u5f00\u59cb\uff0c\u8fdb\u884c\u5b9e\u6218\u7684Linux\u8f6f\u4ef6\u5b89\u88c5\u90e8\u7f72\u3002</p> <p>\u672c\u6b21\u8bfe\u7a0b\u5206\u4e3a2\u4e2a\u7248\u672c\u8fdb\u884c\u5b89\u88c5\uff1a</p> <ul> <li>MySQL 5.7\u7248\u672c\u5b89\u88c5</li> <li>MySQL 8.x\u7248\u672c\u5b89\u88c5</li> </ul> <p>\u7531\u4e8eMySQL5.x\u548c8.x\u5404\u81ea\u6709\u8bb8\u591a\u4f7f\u7528\u8005\uff0c\u6240\u4ee5\u8fd9\u4e24\u4e2a\u7248\u672c\u6211\u4eec\u90fd\u6f14\u793a\u5b89\u88c5\u4e00\u904d</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_6","title":"\u6ce8\u610f","text":"<p>MySQL\u7684\u5b89\u88c5\u8fc7\u7a0b\u4e2d\uff0c\u9664\u4e86\u4f1a\u4f7f\u7528Linux\u547d\u4ee4\u5916\uff0c\u8fd8\u4f1a\u4f7f\u7528\u5230\u5c11\u91cf\u7684\u6570\u636e\u5e93\u4e13\u7528\u7684\uff1aSQL\u8bed\u53e5</p> <p>\u5bf9\u4e8eSQL\u8bed\u53e5\u6211\u4eec\u5e76\u672a\u6d89\u53ca\uff0c\u6240\u4ee5\u53ef\u4ee5\u8ddf\u968f\u6559\u7a0b\u7684\u5185\u5bb9\uff0c\u590d\u5236\u7c98\u8d34\u5373\u53ef</p> <p>\u5982\u5bf9MySQL\u611f\u5174\u8da3\uff0c\u53ef\u4ee5\u5b66\u4e60BiliBili\u9ed1\u9a6c\u7a0b\u5e8f\u5458\u89c6\u9891\uff1a2022\u65b0\u7248\u9ed1\u9a6c\u7a0b\u5e8f\u5458MySQL\u77e5\u8bc6\u7cbe\u8bb2+mysql\u5b9e\u6218\u6848\u4f8b_\u96f6\u57fa\u7840mysql\u6570\u636e\u5e93\u5165\u95e8\u5230\u9ad8\u7ea7\u5168\u5957\u6559\u7a0b</p> <p>\u5982\u6709\u65f6\u95f4\uff0c\u5efa\u8bae\u53ef\u4ee5\u5728\u5b66\u4e60\u5b8cLinux\u7cfb\u7edf\u4e4b\u540e\uff0c\u5b66\u4e60\u4e00\u4e0bMySQL\u6570\u636e\u5e93</p> <p>\u65e0\u8bba\u4ece\u4e8b\u4ec0\u4e48\u65b9\u9762\u7684\u5f00\u53d1\uff0cJava\u540e\u7aef\u3001\u5927\u6570\u636e\u3001AI\u3001\u524d\u7aef\u3001Linux\u8fd0\u7ef4\u7b49\uff0c\u90fd\u4f1a\u8981\u6c42\u638c\u63e1MySQL\u6570\u636e\u5e93\u7684</p> <p>\u53ef\u4ee5\u8bf4\uff0cMySQL\u662fIT\u5f00\u53d1\u4ece\u4e1a\u8005\u5fc5\u5907\u7684\u6280\u80fd\u4e86\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#mysql57centos","title":"MySQL5.7\u7248\u672c\u5728CentOS\u7cfb\u7edf\u5b89\u88c5","text":"<p>\u6ce8\u610f\uff1a\u5b89\u88c5\u64cd\u4f5c\u9700\u8981root\u6743\u9650</p> <p>MySQL\u7684\u5b89\u88c5\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u524d\u9762\u5b66\u4e60\u7684yum\u547d\u4ee4\u8fdb\u884c\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_7","title":"\u5b89\u88c5","text":"<ol> <li>\u914d\u7f6eyum\u4ed3\u5e93</li> </ol> <pre><code># \u66f4\u65b0\u5bc6\u94a5\nrpm --import https://repo.mysql.com/RPM-GPG-KEY-mysql-2022\n\n# \u5b89\u88c5Mysql yum\u5e93\uff0c.rpm\u6587\u4ef6\u662fLinux\u7cfb\u7edf\u7684\u4e00\u79cd\u8f6f\u4ef6\u5b89\u88c5\u5305\nrpm -Uvh http://repo.mysql.com//mysql57-community-release-el7-7.noarch.rpm\n</code></pre> <p>\u7531\u4e8eMySQL\u5e76\u4e0d\u5728CentOS\u7684\u5b98\u65b9\u4ed3\u5e93\u4e2d\uff0c\u6240\u4ee5\u6211\u4eec\u901a\u8fc7\u4e0a\u8ff0rpm\u547d\u4ee4\uff1a</p> <ul> <li>\u5bfc\u5165MySQL\u4ed3\u5e93\u7684\u5bc6\u94a5</li> <li>\u914d\u7f6eMySQLQ\u7684yum\u4ed3\u5e93</li> </ul> <ol> <li>\u4f7f\u7528yum\u5b89\u88c5MySQL</li> </ol> <pre><code># yum\u5b89\u88c5Mysql\nyum -y install mysql-community-server\n# fedora\n# fedora\u7684\u5b98\u65b9\u4ed3\u5e93\u4e2d\u81ea\u5e26mysql service\uff0c\u56e0\u6b64\u65e0\u9700\u4e0a\u9762\u7684\u5bfc\u5165\u5bc6\u94a5\u548c\u914d\u7f6e\u4ed3\u5e93\u7684\u6b65\u9aa4\u3002\nyum -y install mariadb-server\n</code></pre> <p></p> <ol> <li>\u5b89\u88c5\u5b8c\u6210\u540e\uff0c\u542f\u52a8MySQL\u5e76\u914d\u7f6e\u5f00\u673a\u81ea\u542f\u52a8</li> </ol> <pre><code>systemctl start mysqld       # \u542f\u52a8\nsystemctl enable mysqld      # \u5f00\u673a\u81ea\u542f\n# fedora\nmariadb.service\n</code></pre> <p>MySQL\u5b89\u88c5\u5b8c\u6210\u540e\uff0c\u4f1a\u81ea\u52a8\u914d\u7f6e\u4e3a\u540d\u79f0\u53eb\u505a\uff1a<code>mysqld</code>\u7684\u670d\u52a1\uff0c\u53ef\u4ee5\u88absystemctl\u6240\u7ba1\u7406</p> <ol> <li>\u68c0\u67e5MySQL\u7684\u8fd0\u884c\u72b6\u6001</li> </ol> <pre><code>systemctl status mysqld\n</code></pre> <p></p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_8","title":"\u914d\u7f6e","text":"<p>\u4e3b\u8981\u914d\u7f6e\u7ba1\u7406\u5458\u7528\u6237root\u7684\u5bc6\u7801\u4ee5\u53ca\u914d\u7f6e\u5141\u8bb8\u8fdc\u7a0b\u767b\u5f55\u7684\u6743\u9650\u3002</p> <ol> <li>\u83b7\u53d6MySQL\u7684\u521d\u59cb\u5bc6\u7801</li> </ol> <pre><code># \u901a\u8fc7grep\u547d\u4ee4\uff0c\u5728/var/log/mysqld.log\u6587\u4ef6\u4e2d\uff0c\u8fc7\u6ee4temporary password\u5173\u952e\u5b57\uff0c\u5f97\u5230\u521d\u59cb\u5bc6\u7801\ngrep 'temporary password' /var/log/mysqld.log\n</code></pre> <p></p> <ol> <li>\u767b\u9646MySQL\u6570\u636e\u5e93\u7cfb\u7edf</li> </ol> <pre><code># \u6267\u884c\nmysql -uroot -p\n# \u89e3\u91ca\n# -u\uff0c\u767b\u9646\u7684\u7528\u6237\uff0cMySQL\u6570\u636e\u5e93\u7684\u7ba1\u7406\u5458\u7528\u6237\u540cLinux\u4e00\u6837\uff0c\u662froot\n# -p\uff0c\u8868\u793a\u4f7f\u7528\u5bc6\u7801\u767b\u9646\n\n# \u6267\u884c\u5b8c\u6bd5\u540e\u8f93\u5165\u521a\u521a\u5f97\u5230\u7684\u521d\u59cb\u5bc6\u7801\uff0c\u5373\u53ef\u8fdb\u5165MySQL\u6570\u636e\u5e93\n</code></pre> <p></p> <ol> <li>\u4fee\u6539root\u7528\u6237\u5bc6\u7801</li> </ol> <pre><code># \u5728MySQL\u63a7\u5236\u53f0\u5185\u6267\u884c\nALTER USER 'root'@'localhost' IDENTIFIED BY '\u5bc6\u7801';    -- \u5bc6\u7801\u9700\u8981\u7b26\u5408\uff1a\u5927\u4e8e8\u4f4d\uff0c\u6709\u5927\u5199\u5b57\u6bcd\uff0c\u6709\u7279\u6b8a\u7b26\u53f7\uff0c\u4e0d\u80fd\u662f\u8fde\u7eed\u7684\u7b80\u5355\u8bed\u53e5\u5982123\uff0cabc\n</code></pre> <ol> <li>[\u6269\u5c55]\uff0c\u914d\u7f6eroot\u7684\u7b80\u5355\u5bc6\u7801</li> </ol> <p>\u6211\u4eec\u53ef\u4ee5\u7ed9root\u8bbe\u7f6e\u7b80\u5355\u5bc6\u7801\uff0c\u5982123456.</p> <p>\u8bf7\u6ce8\u610f\uff0c\u6b64\u914d\u7f6e\u4ec5\u4ec5\u662f\u7528\u4e8e\u6d4b\u8bd5\u73af\u5883\u6216\u5b66\u4e60\u73af\u5883\u7684MySQL\uff0c\u5982\u679c\u662f\u6b63\u5f0f\u4f7f\u7528\uff0c\u8bf7\u52ff\u8bbe\u7f6e\u7b80\u5355\u5bc6\u7801</p> <pre><code># \u5982\u679c\u4f60\u60f3\u8bbe\u7f6e\u7b80\u5355\u5bc6\u7801\uff0c\u9700\u8981\u964d\u4f4eMysql\u7684\u5bc6\u7801\u5b89\u5168\u7ea7\u522b\nset global validate_password_policy=LOW; # \u5bc6\u7801\u5b89\u5168\u7ea7\u522b\u4f4e\nset global validate_password_length=4;    # \u5bc6\u7801\u957f\u5ea6\u6700\u4f4e4\u4f4d\u5373\u53ef\n\n# \u7136\u540e\u5c31\u53ef\u4ee5\u7528\u7b80\u5355\u5bc6\u7801\u4e86\uff08\u8bfe\u7a0b\u4e2d\u4f7f\u7528\u7b80\u5355\u5bc6\u7801\uff0c\u4e3a\u4e86\u65b9\u4fbf\uff0c\u751f\u4ea7\u4e2d\u4e0d\u8981\u8fd9\u6837\uff09\nALTER USER 'root'@'localhost' IDENTIFIED BY '\u7b80\u5355\u5bc6\u7801';\n</code></pre> <ol> <li>[\u6269\u5c55]\uff0c\u914d\u7f6eroot\u8fd0\u884c\u8fdc\u7a0b\u767b\u5f55</li> </ol> <p>\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0croot\u7528\u6237\u662f\u4e0d\u8fd0\u884c\u8fdc\u7a0b\u767b\u5f55\u7684\uff0c\u53ea\u5141\u8bb8\u5728MySQL\u6240\u5728\u7684Linux\u670d\u52a1\u5668\u767b\u9646MySQL\u7cfb\u7edf</p> <p>\u8bf7\u6ce8\u610f\uff0c\u5141\u8bb8root\u8fdc\u7a0b\u767b\u5f55\u4f1a\u5e26\u6765\u5b89\u5168\u98ce\u9669</p> <pre><code># \u6388\u6743root\u8fdc\u7a0b\u767b\u5f55\ngrant all privileges on *.* to root@\"IP\u5730\u5740\" identified by '\u5bc6\u7801' with grant option;  \n# IP\u5730\u5740\u5373\u5141\u8bb8\u767b\u9646\u7684IP\u5730\u5740\uff0c\u4e5f\u53ef\u4ee5\u586b\u5199%\uff0c\u8868\u793a\u5141\u8bb8\u4efb\u4f55\u5730\u5740\n# \u5bc6\u7801\u8868\u793a\u7ed9\u8fdc\u7a0b\u767b\u5f55\u72ec\u7acb\u8bbe\u7f6e\u5bc6\u7801\uff0c\u548c\u672c\u5730\u767b\u9646\u7684\u5bc6\u7801\u53ef\u4ee5\u4e0d\u540c\n\n# \u5237\u65b0\u6743\u9650\uff0c\u751f\u6548\nflush privileges;\n</code></pre> <ol> <li>\u9000\u51faMySQL\u63a7\u5236\u53f0\u9875\u9762</li> </ol> <pre><code># \u9000\u51fa\u547d\u4ee4\nexit\n\n# \u6216\u8005\u901a\u8fc7\u5feb\u6377\u952e\u9000\u51fa\uff1actrl + d\n</code></pre> <ol> <li>\u68c0\u67e5\u7aef\u53e3</li> </ol> <p>MySQL\u9ed8\u8ba4\u7ed1\u5b9a\u4e863306\u7aef\u53e3\uff0c\u53ef\u4ee5\u901a\u8fc7\u7aef\u53e3\u5360\u7528\u68c0\u67e5MySQL\u7684\u7f51\u7edc\u72b6\u6001</p> <pre><code>netstat -anp | grep 3306\n</code></pre> <p></p> <p>\u81f3\u6b64\uff0cMySQL\u5c31\u5b89\u88c5\u5b8c\u6210\u5e76\u53ef\u7528\u4e86\uff0c\u8bf7\u59a5\u5584\u4fdd\u5b58\u597dMySQL\u7684root\u5bc6\u7801\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#mysql80centos","title":"MySQL8.0\u7248\u672c\u5728CentOS\u7cfb\u7edf\u5b89\u88c5","text":"<p>\u6ce8\u610f\uff1a\u5b89\u88c5\u64cd\u4f5c\u9700\u8981root\u6743\u9650</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_9","title":"\u5b89\u88c5","text":"<ol> <li>\u914d\u7f6eyum\u4ed3\u5e93</li> </ol> <pre><code># \u66f4\u65b0\u5bc6\u94a5\nrpm --import https://repo.mysql.com/RPM-GPG-KEY-mysql-2022\n\n# \u5b89\u88c5Mysql8.x\u7248\u672c yum\u5e93\nrpm -Uvh https://dev.mysql.com/get/mysql80-community-release-el7-2.noarch.rpm\n</code></pre> <ol> <li>\u4f7f\u7528yum\u5b89\u88c5MySQL</li> </ol> <pre><code># yum\u5b89\u88c5Mysql\nyum -y install mysql-community-server\n</code></pre> <ol> <li>\u5b89\u88c5\u5b8c\u6210\u540e\uff0c\u542f\u52a8MySQL\u5e76\u914d\u7f6e\u5f00\u673a\u81ea\u542f\u52a8</li> </ol> <pre><code>systemctl start mysqld       # \u542f\u52a8\nsystemctl enable mysqld      # \u5f00\u673a\u81ea\u542f\n</code></pre> <p>MySQL\u5b89\u88c5\u5b8c\u6210\u540e\uff0c\u4f1a\u81ea\u52a8\u914d\u7f6e\u4e3a\u540d\u79f0\u53eb\u505a\uff1a<code>mysqld</code>\u7684\u670d\u52a1\uff0c\u53ef\u4ee5\u88absystemctl\u6240\u7ba1\u7406</p> <ol> <li>\u68c0\u67e5MySQL\u7684\u8fd0\u884c\u72b6\u6001</li> </ol> <pre><code>systemctl status mysqld\n</code></pre>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_10","title":"\u914d\u7f6e","text":"<p>\u4e3b\u8981\u4fee\u6539root\u5bc6\u7801\u548c\u5141\u8bb8root\u8fdc\u7a0b\u767b\u5f55</p> <ol> <li>\u83b7\u53d6MySQL\u7684\u521d\u59cb\u5bc6\u7801</li> </ol> <pre><code># \u901a\u8fc7grep\u547d\u4ee4\uff0c\u5728/var/log/mysqld.log\u6587\u4ef6\u4e2d\uff0c\u8fc7\u6ee4temporary password\u5173\u952e\u5b57\uff0c\u5f97\u5230\u521d\u59cb\u5bc6\u7801\ngrep 'temporary password' /var/log/mysqld.log\n</code></pre> <ol> <li>\u767b\u5f55MySQL\u6570\u636e\u5e93\u7cfb\u7edf</li> </ol> <pre><code># \u6267\u884c\nmysql -uroot -p\n# \u89e3\u91ca\n# -u\uff0c\u767b\u9646\u7684\u7528\u6237\uff0cMySQL\u6570\u636e\u5e93\u7684\u7ba1\u7406\u5458\u7528\u6237\u540cLinux\u4e00\u6837\uff0c\u662froot\n# -p\uff0c\u8868\u793a\u4f7f\u7528\u5bc6\u7801\u767b\u9646\n\n# \u6267\u884c\u5b8c\u6bd5\u540e\u8f93\u5165\u521a\u521a\u5f97\u5230\u7684\u521d\u59cb\u5bc6\u7801\uff0c\u5373\u53ef\u8fdb\u5165MySQL\u6570\u636e\u5e93\n</code></pre> <ol> <li>\u4fee\u6539root\u5bc6\u7801</li> </ol> <pre><code>ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '\u5bc6\u7801'; -- \u5bc6\u7801\u9700\u8981\u7b26\u5408\uff1a\u5927\u4e8e8\u4f4d\uff0c\u6709\u5927\u5199\u5b57\u6bcd\uff0c\u6709\u7279\u6b8a\u7b26\u53f7\uff0c\u4e0d\u80fd\u662f\u8fde\u7eed\u7684\u7b80\u5355\u8bed\u53e5\u5982123\uff0cabc\n</code></pre> <ol> <li>[\u6269\u5c55]\uff0c\u914d\u7f6eroot\u7684\u7b80\u5355\u5bc6\u7801</li> </ol> <p>\u6211\u4eec\u53ef\u4ee5\u7ed9root\u8bbe\u7f6e\u7b80\u5355\u5bc6\u7801\uff0c\u5982123456.</p> <p>\u8bf7\u6ce8\u610f\uff0c\u6b64\u914d\u7f6e\u4ec5\u4ec5\u662f\u7528\u4e8e\u6d4b\u8bd5\u73af\u5883\u6216\u5b66\u4e60\u73af\u5883\u7684MySQL\uff0c\u5982\u679c\u662f\u6b63\u5f0f\u4f7f\u7528\uff0c\u8bf7\u52ff\u8bbe\u7f6e\u7b80\u5355\u5bc6\u7801</p> <pre><code>set global validate_password.policy=0;       # \u5bc6\u7801\u5b89\u5168\u7ea7\u522b\u4f4e\nset global validate_password.length=4;       # \u5bc6\u7801\u957f\u5ea6\u6700\u4f4e4\u4f4d\u5373\u53ef\n</code></pre> <ol> <li>\u5141\u8bb8root\u8fdc\u7a0b\u767b\u5f55\uff0c\u5e76\u8bbe\u7f6e\u8fdc\u7a0b\u767b\u5f55\u5bc6\u7801</li> </ol> <p>\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0croot\u7528\u6237\u662f\u4e0d\u8fd0\u884c\u8fdc\u7a0b\u767b\u5f55\u7684\uff0c\u53ea\u5141\u8bb8\u5728MySQL\u6240\u5728\u7684Linux\u670d\u52a1\u5668\u767b\u9646MySQL\u7cfb\u7edf</p> <p>\u8bf7\u6ce8\u610f\uff0c\u5141\u8bb8root\u8fdc\u7a0b\u767b\u5f55\u4f1a\u5e26\u6765\u5b89\u5168\u98ce\u9669</p> <pre><code># \u7b2c\u4e00\u6b21\u8bbe\u7f6eroot\u8fdc\u7a0b\u767b\u5f55\uff0c\u5e76\u914d\u7f6e\u8fdc\u7a0b\u5bc6\u7801\u4f7f\u7528\u5982\u4e0bSQL\u547d\u4ee4\ncreate user 'root'@'%' IDENTIFIED WITH mysql_native_password BY '\u5bc6\u7801!';   -- \u5bc6\u7801\u9700\u8981\u7b26\u5408\uff1a\u5927\u4e8e8\u4f4d\uff0c\u6709\u5927\u5199\u5b57\u6bcd\uff0c\u6709\u7279\u6b8a\u7b26\u53f7\uff0c\u4e0d\u80fd\u662f\u8fde\u7eed\u7684\u7b80\u5355\u8bed\u53e5\u5982123\uff0cabc\n\n# \u540e\u7eed\u4fee\u6539\u5bc6\u7801\u4f7f\u7528\u5982\u4e0bSQL\u547d\u4ee4\nALTER USER 'root'@'%' IDENTIFIED WITH mysql_native_password BY '\u5bc6\u7801';\n</code></pre> <ol> <li>\u9000\u51faMySQL\u63a7\u5236\u53f0\u9875\u9762</li> </ol> <pre><code># \u9000\u51fa\u547d\u4ee4\nexit\n\n# \u6216\u8005\u901a\u8fc7\u5feb\u6377\u952e\u9000\u51fa\uff1actrl + d\n</code></pre> <ol> <li>\u68c0\u67e5\u7aef\u53e3</li> </ol> <p>MySQL\u9ed8\u8ba4\u7ed1\u5b9a\u4e863306\u7aef\u53e3\uff0c\u53ef\u4ee5\u901a\u8fc7\u7aef\u53e3\u5360\u7528\u68c0\u67e5MySQL\u7684\u7f51\u7edc\u72b6\u6001</p> <pre><code>netstat -anp | grep 3306\n</code></pre> <p></p> <p>\u81f3\u6b64\uff0cMySQL\u5c31\u5b89\u88c5\u5b8c\u6210\u5e76\u53ef\u7528\u4e86\uff0c\u8bf7\u59a5\u5584\u4fdd\u5b58\u597dMySQL\u7684root\u5bc6\u7801\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#mysql57ubuntuwsl","title":"MySQL5.7\u7248\u672c\u5728Ubuntu\uff08WSL\u73af\u5883\uff09\u7cfb\u7edf\u5b89\u88c5","text":"<p>\u8bfe\u7a0b\u4e2d\u914d\u7f6e\u7684WSL\u73af\u5883\u662f\u6700\u65b0\u7684Ubuntu22.04\u7248\u672c\uff0c\u8fd9\u4e2a\u7248\u672c\u7684\u8f6f\u4ef6\u5546\u5e97\u5185\u7f6e\u7684MySQL\u662f8.0\u7248\u672c</p> <p>\u6240\u4ee5\u6211\u4eec\u9700\u8981\u989d\u5916\u7684\u6b65\u9aa4\u624d\u53ef\u4ee5\u5b89\u88c55.7\u7248\u672c\u7684MySQL</p> <p>\u5b89\u88c5\u64cd\u4f5c\u9700root\u6743\u9650\uff0c\u4f60\u53ef\u4ee5\uff1a</p> <ol> <li>\u901a\u8fc7 sudo su -\uff0c\u5207\u6362\u5230root\u7528\u6237</li> </ol> <p>\u8bfe\u7a0b\u4e2d\u9009\u62e9\u8fd9\u79cd\u65b9\u5f0f\u64cd\u4f5c</p> <ol> <li>\u6216\u5728\u6bcf\u4e00\u4e2a\u547d\u4ee4\u524d\uff0c\u52a0\u4e0asudo\uff0c\u7528\u6765\u4e34\u65f6\u63d0\u5347\u6743\u9650</li> </ol>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_11","title":"\u5b89\u88c5","text":"<ol> <li>\u4e0b\u8f7dapt\u4ed3\u5e93\u6587\u4ef6</li> </ol> <pre><code># \u4e0b\u8f7dapt\u4ed3\u5e93\u7684\u5b89\u88c5\u5305\uff0cUbuntu\u7684\u5b89\u88c5\u5305\u662f.deb\u6587\u4ef6\nwget https://dev.mysql.com/get/mysql-apt-config_0.8.12-1_all.deb\n</code></pre> <ol> <li>\u914d\u7f6eapt\u4ed3\u5e93</li> </ol> <pre><code># \u4f7f\u7528dpkg\u547d\u4ee4\u5b89\u88c5\u4ed3\u5e93\ndpkg -i mysql-apt-config_0.8.12-1_all.deb\n</code></pre> <p>\u5f39\u51fa\u6846\u4e2d\u9009\u62e9\uff1a<code>ubuntu bionic</code> \uff08Ubuntu18.04\u7cfb\u7edf\u7684\u4ee3\u53f7\u662fbionic\uff0c\u9009\u62e918.04\u7684\u7248\u672c\u5e93\u7528\u6765\u5b89\u88c5\uff09</p> <p></p> <p>\u5f39\u51fa\u6846\u4e2d\u9009\u62e9\uff1a<code>MySQL Server &amp; Cluster</code></p> <p></p> <p>\u5f39\u51fa\u6846\u4e2d\u9009\u62e9\uff1a<code>mysql-5.7</code></p> <p></p> <p>\u6700\u540e\u9009\u62e9\uff1a<code>ok</code></p> <p></p> <ol> <li>\u66f4\u65b0apt\u4ed3\u5e93\u7684\u4fe1\u606f</li> </ol> <pre><code># \u9996\u5148\u5bfc\u5165\u4ed3\u5e93\u7684\u5bc6\u94a5\u4fe1\u606f\napt-key adv --keyserver keyserver.ubuntu.com --recv-keys 467B942D3A79BD29\n# \u66f4\u65b0\u4ed3\u5e93\u4fe1\u606f\napt update\n</code></pre> <ol> <li>\u68c0\u67e5\u662f\u5426\u6210\u529f\u914d\u7f6eMySQL5.7\u7684\u4ed3\u5e93</li> </ol> <pre><code>apt-cache policy mysql-server\n</code></pre> <p></p> <p>\u770b\u5230\u5982\u56fe\u6240\u793a\u5b57\u6837\uff0c\u5373\u6210\u529f</p> <ol> <li>\u5b89\u88c5MySQL5.7</li> </ol> <pre><code># \u4f7f\u7528apt\u5b89\u88c5mysql\u5ba2\u6237\u7aef\u548cmysql\u670d\u52a1\u7aef\napt install -f -y mysql-client=5.7* mysql-community-server=5.7*\n</code></pre> <p>\u5f39\u51fa\u6846\u4e2d\u8f93\u5165root\u5bc6\u7801\u5e76\u9009\u62e9ok\uff0c\u5bc6\u7801\u4efb\u610f\uff0c\u8bfe\u7a0b\u4e2d\u4ee5123456\u4ee3\u66ff</p> <p></p> <p>\u518d\u6b21\u8f93\u5165root\u5bc6\u7801\u786e\u8ba4</p> <p></p> <ol> <li>\u542f\u52a8MySQL</li> </ol> <pre><code>/etc/init.d/mysql start          # \u542f\u52a8\n/etc/init.d/mysql stop           # \u505c\u6b62\n/etc/init.d/mysql status     # \u67e5\u770b\u72b6\u6001\n</code></pre> <p></p> <ol> <li>\u5bf9MySQL\u8fdb\u884c\u521d\u59cb\u5316</li> </ol> <pre><code># \u6267\u884c\u5982\u4e0b\u547d\u4ee4\uff0c\u6b64\u547d\u4ee4\u662fMySQL\u5b89\u88c5\u540e\u81ea\u5e26\u7684\u914d\u7f6e\u7a0b\u5e8f\nmysql_secure_installation\n# \u53ef\u4ee5\u901a\u8fc7which\u547d\u4ee4\u67e5\u770b\u5230\u8fd9\u4e2a\u81ea\u5e26\u7a0b\u5e8f\u6240\u5728\u7684\u4f4d\u7f6e\nroot@DESKTOP-Q89USRE:~# which mysql_secure_installation\n/usr/bin/mysql_secure_installation\n</code></pre> <ol> <li> <p>\u8f93\u5165\u5bc6\u7801\uff1a</p> <p></p> </li> <li> <p>\u662f\u5426\u5f00\u542f\u5bc6\u7801\u9a8c\u8bc1\u63d2\u4ef6\uff0c\u5982\u679c\u9700\u8981\u589e\u5f3a\u5bc6\u7801\u5b89\u5168\u6027\uff0c\u8f93\u5165<code>y</code>\u5e76\u56de\u8f66\uff0c\u4e0d\u9700\u8981\u76f4\u63a5\u56de\u8f66\uff08\u8bfe\u7a0b\u4e2d\u9009\u62e9\u76f4\u63a5\u56de\u8f66\uff09</p> <p></p> </li> <li> <p>\u662f\u5426\u66f4\u6539root\u5bc6\u7801\uff0c\u9700\u8981\u8f93\u5165<code>y</code>\u56de\u8f66\uff0c\u4e0d\u9700\u8981\u76f4\u63a5\u56de\u8f66\uff08\u8bfe\u7a0b\u4e0d\u66f4\u6539\uff09</p> <p></p> </li> <li> <p>\u662f\u5426\u79fb\u9664\u533f\u540d\u7528\u6237\uff0c\u79fb\u9664\u8f93\u5165<code>y</code>\u56de\u8f66\uff0c\u4e0d\u79fb\u9664\u76f4\u63a5\u56de\u8f66\uff08\u8bfe\u7a0b\u9009\u62e9\u79fb\u9664\uff09</p> <p></p> </li> <li> <p>\u662f\u5426\u8fdb\u5236root\u7528\u6237\u8fdc\u7a0b\u767b\u5f55\uff0c\u7981\u6b62\u8f93\u5165<code>y</code>\u56de\u8f66\uff0c\u4e0d\u7981\u6b62\u76f4\u63a5\u56de\u8f66\uff08\u8bfe\u7a0b\u9009\u62e9\u4e0d\u7981\u6b62\uff09</p> <p></p> </li> <li> <p>\u662f\u5426\u79fb\u9664\u81ea\u5e26\u7684\u6d4b\u8bd5\u6570\u636e\u5e93\uff0c\u79fb\u9664\u8f93\u5165<code>y</code>\u56de\u8f66\uff0c\u4e0d\u79fb\u9664\u76f4\u63a5\u56de\u8f66\uff08\u8bfe\u7a0b\u9009\u62e9\u4e0d\u79fb\u9664\uff09</p> <p></p> </li> <li> <p>\u662f\u5426\u5237\u65b0\u6743\u9650\uff0c\u5237\u65b0\u8f93\u5165<code>y</code>\u56de\u8f66\uff0c\u4e0d\u5237\u65b0\u76f4\u63a5\u56de\u8f66\uff08\u8bfe\u7a0b\u9009\u62e9\u5237\u65b0\uff09</p> <p></p> </li> <li> <p>\u767b\u9646MySQL</p> </li> </ol> <pre><code>mysql -uroot -p\n# \u8f93\u5165\u5bc6\u7801\u5373\u53ef\u767b\u9646\u6210\u529f\n</code></pre> <p></p> <p>\u81f3\u6b64\uff0c\u5728Ubuntu\u4e0a\u5b89\u88c5MySQL5.7\u7248\u672c\u6210\u529f\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#mysql80ubuntuwsl","title":"MySQL8.0\u7248\u672c\u5728Ubuntu\uff08WSL\u73af\u5883\uff09\u7cfb\u7edf\u5b89\u88c5","text":"<p>\u8bfe\u7a0b\u4e2d\u914d\u7f6e\u7684WSL\u73af\u5883\u662f\u6700\u65b0\u7684Ubuntu22.04\u7248\u672c\uff0c\u8fd9\u4e2a\u7248\u672c\u7684\u8f6f\u4ef6\u5546\u5e97\u5185\u7f6e\u7684MySQL\u662f8.0\u7248\u672c</p> <p>\u6240\u4ee5\u76f4\u63a5\u53ef\u4ee5\u901a\u8fc7apt\u5b89\u88c5\u5373\u53ef</p> <p>\u6ce8\u610f\uff0c\u8bfe\u7a0b\u662f\u4ee5WSL\u83b7\u5f97\u7684Ubuntu\u64cd\u4f5c\u7cfb\u7edf\u73af\u5883\u3002</p> <p>\u5982\u679c\u4f60\u901a\u8fc7VMware\u865a\u62df\u673a\u7684\u65b9\u5f0f\u83b7\u5f97\u4e86Ubuntu\u64cd\u4f5c\u7cfb\u7edf\u73af\u5883\uff0c\u64cd\u4f5c\u6b65\u9aa4\u4e0d\u7528\u62c5\u5fc3\uff0c\u548c\u8bfe\u7a0b\u4e2d\u4f7f\u7528WSL\u73af\u5883\u662f==\u5b8c\u5168\u4e00\u81f4\u7684==</p> <p>\u5b89\u88c5\u64cd\u4f5c\u9700root\u6743\u9650\uff0c\u4f60\u53ef\u4ee5\uff1a</p> <ol> <li>\u901a\u8fc7 sudo su -\uff0c\u5207\u6362\u5230root\u7528\u6237</li> </ol> <p>\u8bfe\u7a0b\u4e2d\u9009\u62e9\u8fd9\u79cd\u65b9\u5f0f\u64cd\u4f5c</p> <ol> <li>\u6216\u5728\u6bcf\u4e00\u4e2a\u547d\u4ee4\u524d\uff0c\u52a0\u4e0asudo\uff0c\u7528\u6765\u4e34\u65f6\u63d0\u5347\u6743\u9650</li> </ol>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_12","title":"\u5b89\u88c5","text":"<ol> <li>\u5982\u679c\u5df2\u7ecf\u5b89\u88c5\u8fc7MySQL5.7\u7248\u672c\uff0c\u9700\u8981\u5378\u8f7d\u4ed3\u5e93\u4fe1\u606f\u54e6</li> </ol> <pre><code># \u5378\u8f7dMySQL5.7\u7248\u672c\napt remove -y mysql-client=5.7* mysql-community-server=5.7*\n\n# \u5378\u8f7d5.7\u7684\u4ed3\u5e93\u4fe1\u606f\ndpkg -l | grep mysql | awk '{print $2}' | xargs dpkg -P\n</code></pre> <ol> <li>\u66f4\u65b0apt\u4ed3\u5e93\u4fe1\u606f</li> </ol> <pre><code>apt update\n</code></pre> <ol> <li>\u5b89\u88c5mysql</li> </ol> <pre><code>apt install -y mysql-server\n</code></pre> <ol> <li>\u542f\u52a8MySQL</li> </ol> <pre><code>/etc/init.d/mysql start          # \u542f\u52a8\n/etc/init.d/mysql stop           # \u505c\u6b62\n/etc/init.d/mysql status     # \u67e5\u770b\u72b6\u6001\n</code></pre> <ol> <li>\u767b\u9646MySQL\u8bbe\u7f6e\u5bc6\u7801</li> </ol> <pre><code># \u76f4\u63a5\u6267\u884c\uff1amysql\nmysql\n</code></pre> <ol> <li>\u8bbe\u7f6e\u5bc6\u7801</li> </ol> <pre><code>ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'password';\n</code></pre> <ol> <li>\u9000\u51faMySQL\u63a7\u5236\u53f0</li> </ol> <pre><code>exit\n</code></pre> <ol> <li>\u5bf9MySQL\u8fdb\u884c\u521d\u59cb\u5316</li> </ol> <pre><code># \u6267\u884c\u5982\u4e0b\u547d\u4ee4\uff0c\u6b64\u547d\u4ee4\u662fMySQL\u5b89\u88c5\u540e\u81ea\u5e26\u7684\u914d\u7f6e\u7a0b\u5e8f\nmysql_secure_installation\n# \u53ef\u4ee5\u901a\u8fc7which\u547d\u4ee4\u67e5\u770b\u5230\u8fd9\u4e2a\u81ea\u5e26\u7a0b\u5e8f\u6240\u5728\u7684\u4f4d\u7f6e\nroot@DESKTOP-Q89USRE:~# which mysql_secure_installation\n/usr/bin/mysql_secure_installation\n</code></pre> <ol> <li> <p>\u8f93\u5165\u5bc6\u7801\uff1a</p> <p></p> </li> <li> <p>\u662f\u5426\u5f00\u542f\u5bc6\u7801\u9a8c\u8bc1\u63d2\u4ef6\uff0c\u5982\u679c\u9700\u8981\u589e\u5f3a\u5bc6\u7801\u5b89\u5168\u6027\uff0c\u8f93\u5165<code>y</code>\u5e76\u56de\u8f66\uff0c\u4e0d\u9700\u8981\u76f4\u63a5\u56de\u8f66\uff08\u8bfe\u7a0b\u4e2d\u9009\u62e9\u76f4\u63a5\u56de\u8f66\uff09</p> <p></p> </li> <li> <p>\u662f\u5426\u66f4\u6539root\u5bc6\u7801\uff0c\u9700\u8981\u8f93\u5165<code>y</code>\u56de\u8f66\uff0c\u4e0d\u9700\u8981\u76f4\u63a5\u56de\u8f66\uff08\u8bfe\u7a0b\u4e0d\u66f4\u6539\uff09</p> <p></p> </li> <li> <p>\u662f\u5426\u79fb\u9664\u533f\u540d\u7528\u6237\uff0c\u79fb\u9664\u8f93\u5165<code>y</code>\u56de\u8f66\uff0c\u4e0d\u79fb\u9664\u76f4\u63a5\u56de\u8f66\uff08\u8bfe\u7a0b\u9009\u62e9\u79fb\u9664\uff09</p> <p></p> </li> <li> <p>\u662f\u5426\u8fdb\u5236root\u7528\u6237\u8fdc\u7a0b\u767b\u5f55\uff0c\u7981\u6b62\u8f93\u5165<code>y</code>\u56de\u8f66\uff0c\u4e0d\u7981\u6b62\u76f4\u63a5\u56de\u8f66\uff08\u8bfe\u7a0b\u9009\u62e9\u4e0d\u7981\u6b62\uff09</p> <p></p> </li> <li> <p>\u662f\u5426\u79fb\u9664\u81ea\u5e26\u7684\u6d4b\u8bd5\u6570\u636e\u5e93\uff0c\u79fb\u9664\u8f93\u5165<code>y</code>\u56de\u8f66\uff0c\u4e0d\u79fb\u9664\u76f4\u63a5\u56de\u8f66\uff08\u8bfe\u7a0b\u9009\u62e9\u4e0d\u79fb\u9664\uff09</p> <p></p> </li> <li> <p>\u662f\u5426\u5237\u65b0\u6743\u9650\uff0c\u5237\u65b0\u8f93\u5165<code>y</code>\u56de\u8f66\uff0c\u4e0d\u5237\u65b0\u76f4\u63a5\u56de\u8f66\uff08\u8bfe\u7a0b\u9009\u62e9\u5237\u65b0\uff09</p> <p></p> </li> <li> <p>\u91cd\u65b0\u767b\u9646MySQL\uff08\u7528\u66f4\u6539\u540e\u7684\u5bc6\u7801\uff09</p> </li> </ol> <pre><code>mysql -uroot -p\n</code></pre> <p></p> <p>\u81f3\u6b64\uff0c\u5728Ubuntu\u4e0a\u5b89\u88c5MySQL5.7\u7248\u672c\u6210\u529f\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#tomcat","title":"Tomcat\u5b89\u88c5\u90e8\u7f72\u3010\u7b80\u5355\u3011","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_13","title":"\u7b80\u4ecb","text":"<p>Tomcat \u662f\u7531 Apache \u5f00\u53d1\u7684\u4e00\u4e2a Servlet \u5bb9\u5668\uff0c\u5b9e\u73b0\u4e86\u5bf9 Servlet \u548c JSP \u7684\u652f\u6301\uff0c\u5e76\u63d0\u4f9b\u4e86\u4f5c\u4e3aWeb\u670d\u52a1\u5668\u7684\u4e00\u4e9b\u7279\u6709\u529f\u80fd\uff0c\u5982Tomcat\u7ba1\u7406\u548c\u63a7\u5236\u5e73\u53f0\u3001\u5b89\u5168\u57df\u7ba1\u7406\u548cTomcat\u9600\u7b49\u3002</p> <p>\u7b80\u5355\u6765\u8bf4\uff0cTomcat\u662f\u4e00\u4e2aWEB\u5e94\u7528\u7a0b\u5e8f\u7684\u6258\u7ba1\u5e73\u53f0\uff0c\u53ef\u4ee5\u8ba9\u7528\u6237\u7f16\u5199\u7684WEB\u5e94\u7528\u7a0b\u5e8f\uff0c\u88abTomcat\u6240\u6258\u7ba1\uff0c\u5e76\u63d0\u4f9b\u7f51\u7ad9\u670d\u52a1\u3002</p> <p>\u5373\u8ba9\u7528\u6237\u5f00\u53d1\u7684WEB\u5e94\u7528\u7a0b\u5e8f\uff0c\u53d8\u6210\u53ef\u4ee5\u88ab\u8bbf\u95ee\u7684\u7f51\u9875\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_14","title":"\u5b89\u88c5","text":"<p>Tomcat\u7684\u5b89\u88c5\u975e\u5e38\u7b80\u5355\uff0c\u4e3b\u8981\u5206\u4e3a2\u90e8\u5206\uff1a</p> <ol> <li>\u5b89\u88c5JDK\u73af\u5883</li> <li>\u89e3\u538b\u5e76\u5b89\u88c5Tomcat</li> </ol> <p>\u672c\u6b21\u5b89\u88c5\u4f7f\u7528Tomcat\u7248\u672c\u662f\uff1a10.0.27\u7248\u672c\uff0c\u9700\u8981Java\uff08JDK\uff09\u7248\u672c\u6700\u4f4e\u4e3aJDK8\u6216\u66f4\u9ad8\u7248\u672c</p> <p>\u8bfe\u7a0b\u4e2d\u4f7f\u7528\u7684JDK\u7248\u672c\u662f\uff1aJDK8u351\u7248\u672c</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#jdk","title":"\u5b89\u88c5JDK\u73af\u5883","text":"<ol> <li>\u4e0b\u8f7dJDK\u8f6f\u4ef6</li> </ol> <p>https://www.oracle.com/java/technologies/downloads</p> <p>\u5728\u9875\u9762\u4e0b\u65b9\u627e\u5230\uff1a</p> <p></p> <p>\u4e0b\u8f7d<code>jdk-8u351-linux-x64.tar.gz</code></p> <p></p> <p>\u5728\u5f39\u51fa\u7684\u9875\u9762\u4e2d\u8f93\u5165Oracle\u7684\u8d26\u6237\u5bc6\u7801\u5373\u53ef\u4e0b\u8f7d\uff08\u5982\u65e0\u8d26\u6237\uff0c\u8bf7\u81ea\u884c\u6ce8\u518c\uff0c\u6ce8\u518c\u662f\u514d\u8d39\u7684\uff09</p> <ol> <li>\u767b\u9646Linux\u7cfb\u7edf\uff0c\u5207\u6362\u5230root\u7528\u6237</li> </ol> <p></p> <ol> <li>\u901a\u8fc7FinalShell\uff0c\u4e0a\u4f20\u4e0b\u8f7d\u597d\u7684JDK\u5b89\u88c5\u5305</li> </ol> <p></p> <ol> <li>\u521b\u5efa\u6587\u4ef6\u5939\uff0c\u7528\u6765\u90e8\u7f72JDK\uff0c\u5c06JDK\u548cTomcat\u90fd\u5b89\u88c5\u90e8\u7f72\u5230\uff1a/export/server \u5185</li> </ol> <pre><code>mkdir -p /export/server\n</code></pre> <ol> <li>\u89e3\u538b\u7f29JDK\u5b89\u88c5\u6587\u4ef6</li> </ol> <pre><code>tar -zxvf jdk-8u351-linux-x64.tar.gz -C /export/server\n</code></pre> <ol> <li>\u914d\u7f6eJDK\u7684\u8f6f\u94fe\u63a5</li> </ol> <pre><code>ln -s /export/server/jdk1.8.0_351 /export/server/jdk\n</code></pre> <ol> <li>\u914d\u7f6eJAVA_HOME\u73af\u5883\u53d8\u91cf\uff0c\u4ee5\u53ca\u5c06$JAVA_HOME/bin\u6587\u4ef6\u5939\u52a0\u5165PATH\u73af\u5883\u53d8\u91cf\u4e2d</li> </ol> <pre><code># \u7f16\u8f91/etc/profile\u6587\u4ef6\nexport JAVA_HOME=/export/server/jdk\nexport PATH=$PATH:$JAVA_HOME/bin\n</code></pre> <ol> <li>\u751f\u6548\u73af\u5883\u53d8\u91cf</li> </ol> <pre><code>source /etc/profile\n</code></pre> <ol> <li>\u914d\u7f6ejava\u6267\u884c\u7a0b\u5e8f\u7684\u8f6f\u94fe\u63a5</li> </ol> <pre><code># \u5220\u9664\u7cfb\u7edf\u81ea\u5e26\u7684java\u7a0b\u5e8f\nrm -f /usr/bin/java\n# \u8f6f\u94fe\u63a5\u6211\u4eec\u81ea\u5df1\u5b89\u88c5\u7684java\u7a0b\u5e8f\nln -s /export/server/jdk/bin/java /usr/bin/java\n</code></pre> <ol> <li> <p>\u6267\u884c\u9a8c\u8bc1\uff1a</p> <pre><code>java -version\njavac -version\n</code></pre> </li> </ol>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#tomcat_1","title":"\u89e3\u538b\u5e76\u90e8\u7f72Tomcat","text":"<p>Tomcat\u5efa\u8bae\u4f7f\u7528\u975eRoot\u7528\u6237\u5b89\u88c5\u5e76\u542f\u52a8</p> <p>\u53ef\u4ee5\u521b\u5efa\u4e00\u4e2a\u7528\u6237\uff1atomcat\u7528\u4ee5\u90e8\u7f72</p> <ol> <li>\u9996\u5148\uff0c\u653e\u884ctomcat\u9700\u8981\u4f7f\u7528\u76848080\u7aef\u53e3\u7684\u5916\u90e8\u8bbf\u95ee\u6743\u9650</li> </ol> <p>CentOS\u7cfb\u7edf\u9ed8\u8ba4\u5f00\u542f\u4e86\u9632\u706b\u5899\uff0c\u963b\u6b62\u5916\u90e8\u7f51\u7edc\u6d41\u91cf\u8bbf\u95ee\u7cfb\u7edf\u5185\u90e8</p> <p>\u6240\u4ee5\uff0c\u5982\u679c\u60f3\u8981Tomcat\u53ef\u4ee5\u6b63\u5e38\u4f7f\u7528\uff0c\u9700\u8981\u5bf9Tomcat\u9ed8\u8ba4\u4f7f\u7528\u76848080\u7aef\u53e3\u8fdb\u884c\u653e\u884c</p> <p>\u653e\u884c\u67092\u79cd\u64cd\u4f5c\u65b9\u5f0f\uff1a</p> <ol> <li>\u5173\u95ed\u9632\u706b\u5899</li> <li>\u914d\u7f6e\u9632\u706b\u5899\u89c4\u5219\uff0c\u653e\u884c\u7aef\u53e3</li> </ol> <pre><code># \u4ee5\u4e0b\u64cd\u4f5c2\u9009\u4e00\u5373\u53ef\n# \u65b9\u5f0f1\uff1a\u5173\u95ed\u9632\u706b\u5899\nsystemctl stop firewalld     # \u5173\u95ed\u9632\u706b\u5899\nsystemctl disable firewalld      # \u505c\u6b62\u9632\u706b\u5899\u5f00\u673a\u81ea\u542f\n\n# \u65b9\u5f0f2\uff1a\u653e\u884c8080\u7aef\u53e3\u7684\u5916\u90e8\u8bbf\u95ee\nfirewall-cmd --add-port=8080/tcp --permanent     # --add-port=8080/tcp\u8868\u793a\u653e\u884c8080\u7aef\u53e3\u7684tcp\u8bbf\u95ee\uff0c--permanent\u8868\u793a\u6c38\u4e45\u751f\u6548\nfirewall-cmd --reload                                # \u91cd\u65b0\u8f7d\u5165\u9632\u706b\u5899\u89c4\u5219\u4f7f\u5176\u751f\u6548\n</code></pre> <p>\u65b9\u4fbf\u8d77\u89c1\uff0c\u5efa\u8bae\u540c\u5b66\u4eec\u9009\u62e9\u65b9\u5f0f1\uff0c\u76f4\u63a5\u5173\u95ed\u9632\u706b\u5899\u4e00\u52b3\u6c38\u9038</p> <p>\u9632\u706b\u5899\u7684\u914d\u7f6e\u975e\u5e38\u590d\u6742\uff0c\u540e\u9762\u4f1a\u89c6\u60c5\u51b5\u72ec\u7acb\u51fa\u4e00\u96c6\u9632\u706b\u5899\u914d\u7f6e\u89c4\u5219\u7684\u7ae0\u8282\u3002</p> <ol> <li>\u4ee5root\u7528\u6237\u64cd\u4f5c\uff0c\u521b\u5efatomcat\u7528\u6237</li> </ol> <pre><code># \u4f7f\u7528root\u7528\u6237\u64cd\u4f5c\nuseradd tomcat\n# \u53ef\u9009\uff0c\u4e3atomcat\u7528\u6237\u914d\u7f6e\u5bc6\u7801\npasswd tomcat\n</code></pre> <ol> <li>\u4e0b\u8f7dTomcat\u5b89\u88c5\u5305</li> </ol> <pre><code># \u4f7f\u7528root\u7528\u6237\u64cd\u4f5c\nwget https://dlcdn.apache.org/tomcat/tomcat-10/v10.0.27/bin/apache-tomcat-10.0.27.tar.gz\n# \u5982\u679c\u51fa\u73b0https\u76f8\u5173\u9519\u8bef\uff0c\u53ef\u4ee5\u4f7f\u7528--no-check-certificate\u9009\u9879\nwget --no-check-certificate https://dlcdn.apache.org/tomcat/tomcat-10/v10.0.27/bin/apache-tomcat-10.0.27.tar.gz\n</code></pre> <p>\u5982\u679cLinux\u5185\u4e0b\u8f7d\u8fc7\u6162\uff0c\u53ef\u4ee5\u590d\u5236\u4e0b\u8f7d\u94fe\u63a5\u5728Windows\u7cfb\u7edf\u4e2d\u4f7f\u7528\u8fc5\u96f7\u7b49\u8f6f\u4ef6\u52a0\u901f\u4e0b\u8f7d\u7136\u540e\u4e0a\u4f20\u5230Linux\u5185\u5373\u53ef</p> <p>\u6216\u8005\u4f7f\u7528\u8bfe\u7a0b\u8d44\u6599\u4e2d\u63d0\u4f9b\u7684\u5b89\u88c5\u5305</p> <ol> <li>\u89e3\u538bTomcat\u5b89\u88c5\u5305</li> </ol> <pre><code># \u4f7f\u7528root\u7528\u6237\u64cd\u4f5c\uff0c\u5426\u5219\u65e0\u6743\u9650\u89e3\u538b\u5230/export/server\u5185\uff0c\u9664\u975e\u4fee\u6539\u6b64\u6587\u4ef6\u5939\u6743\u9650\ntar -zxvf apache-tomcat-10.0.27.tar.gz -C /export/server\n</code></pre> <ol> <li>\u521b\u5efaTomcat\u8f6f\u94fe\u63a5</li> </ol> <pre><code># \u4f7f\u7528root\u7528\u6237\u64cd\u4f5c\nln -s /export/server/apache-tomcat-10.0.27 /export/server/tomcat\n</code></pre> <ol> <li>\u4fee\u6539tomcat\u5b89\u88c5\u76ee\u5f55\u6743\u9650</li> </ol> <pre><code># \u4f7f\u7528root\u7528\u6237\u64cd\u4f5c\uff0c\u540c\u65f6\u5bf9\u8f6f\u94fe\u63a5\u548ctomcat\u5b89\u88c5\u6587\u4ef6\u5939\u8fdb\u884c\u4fee\u6539\uff0c\u4f7f\u7528\u901a\u914d\u7b26*\u8fdb\u884c\u5339\u914d\nchown -R tomcat:tomcat /export/server/*tomcat*\n</code></pre> <ol> <li>\u5207\u6362\u5230tomcat\u7528\u6237</li> </ol> <pre><code>su - tomcat\n</code></pre> <ol> <li>\u542f\u52a8tomcat</li> </ol> <pre><code>/export/server/tomcat/bin/startup.sh\n</code></pre> <ol> <li>tomcat\u542f\u52a8\u57288080\u7aef\u53e3\uff0c\u53ef\u4ee5\u68c0\u67e5\u662f\u5426\u6b63\u5e38\u542f\u52a8\u6210\u529f</li> </ol> <pre><code>netstat -anp | grep 8080\n</code></pre> <p></p> <ol> <li> <p>\u6253\u5f00\u6d4f\u89c8\u5668\uff0c\u8f93\u5165\uff1a</p> <p>http://centos:8080\u6216http://192.168.88.130:8080</p> <p>\u4f7f\u7528\u4e3b\u673a\u540d\uff08\u9700\u914d\u7f6e\u597d\u672c\u5730\u7684\u4e3b\u673a\u540d\u6620\u5c04\uff09\u6216IP\u5730\u5740\u8bbf\u95eeTomcat\u7684WEB\u9875\u9762</p> <p></p> </li> </ol> <p>\u81f3\u6b64\uff0cTomcat\u5b89\u88c5\u914d\u7f6e\u5b8c\u6210\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#nginx","title":"Nginx\u5b89\u88c5\u90e8\u7f72\u3010\u7b80\u5355\u3011","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_15","title":"\u7b80\u4ecb","text":"<p>Nginx (engine x) \u662f\u4e00\u4e2a\u9ad8\u6027\u80fd\u7684HTTP\u548c\u53cd\u5411\u4ee3\u7406web\u670d\u52a1\u5668\uff0c\u540c\u65f6\u4e5f\u63d0\u4f9b\u4e86IMAP/POP3/SMTP\u670d\u52a1\u3002</p> <p>\u540cTomcat\u4e00\u6837\uff0cNginx\u53ef\u4ee5\u6258\u7ba1\u7528\u6237\u7f16\u5199\u7684WEB\u5e94\u7528\u7a0b\u5e8f\u6210\u4e3a\u53ef\u8bbf\u95ee\u7684\u7f51\u9875\u670d\u52a1\uff0c\u540c\u65f6\u4e5f\u53ef\u4ee5\u4f5c\u4e3a\u6d41\u91cf\u4ee3\u7406\u670d\u52a1\u5668\uff0c\u63a7\u5236\u6d41\u91cf\u7684\u4e2d\u8f6c\u3002</p> <p>Nginx\u5728WEB\u5f00\u53d1\u9886\u57df\uff0c\u57fa\u672c\u4e0a\u4e5f\u662f\u5fc5\u5907\u7ec4\u4ef6\u4e4b\u4e00\u4e86\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_16","title":"\u5b89\u88c5","text":"<p>Nginx\u540c\u6837\u9700\u8981\u914d\u7f6e\u989d\u5916\u7684yum\u4ed3\u5e93\uff0c\u624d\u53ef\u4ee5\u4f7f\u7528yum\u5b89\u88c5</p> <p>\u5b89\u88c5Nginx\u7684\u64cd\u4f5c\u9700\u8981root\u8eab\u4efd</p> <ol> <li>\u5b89\u88c5yum\u4f9d\u8d56\u7a0b\u5e8f</li> </ol> <pre><code># root\u6267\u884c\nyum install -y yum-utils\n</code></pre> <ol> <li>\u624b\u52a8\u6dfb\u52a0\uff0cnginx\u7684yum\u4ed3\u5e93</li> </ol> <p>yum\u7a0b\u5e8f\u4f7f\u7528\u7684\u4ed3\u5e93\u914d\u7f6e\u6587\u4ef6\uff0c\u5b58\u653e\u5728\uff1a<code>/etc/yum.repo.d</code>\u5185\u3002</p> <pre><code># root\u6267\u884c\n# \u521b\u5efa\u6587\u4ef6\u4f7f\u7528vim\u7f16\u8f91\nvim /etc/yum.repos.d/nginx.repo\n# \u586b\u5165\u5982\u4e0b\u5185\u5bb9\u5e76\u4fdd\u5b58\u9000\u51fa\n[nginx-stable]\nname=nginx stable repo\nbaseurl=http://nginx.org/packages/centos/$releasever/$basearch/\ngpgcheck=1\nenabled=1\ngpgkey=https://nginx.org/keys/nginx_signing.key\nmodule_hotfixes=true\n\n[nginx-mainline]\nname=nginx mainline repo\nbaseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/\ngpgcheck=1\nenabled=0\ngpgkey=https://nginx.org/keys/nginx_signing.key\nmodule_hotfixes=true\n</code></pre> <p>\u901a\u8fc7\u5982\u4e0a\u64cd\u4f5c\uff0c\u6211\u4eec\u624b\u52a8\u6dfb\u52a0\u4e86nginx\u7684yum\u4ed3\u5e93</p> <ol> <li>\u901a\u8fc7yum\u5b89\u88c5\u6700\u65b0\u7a33\u5b9a\u7248\u7684nginx</li> </ol> <pre><code># root\u6267\u884c\nyum install -y nginx\n</code></pre> <ol> <li>\u542f\u52a8</li> </ol> <pre><code># nginx\u81ea\u52a8\u6ce8\u518c\u4e86systemctl\u7cfb\u7edf\u670d\u52a1\nsystemctl start nginx        # \u542f\u52a8\nsystemctl stop nginx     # \u505c\u6b62\nsystemctl status nginx       # \u8fd0\u884c\u72b6\u6001\nsystemctl enable nginx       # \u5f00\u673a\u81ea\u542f\nsystemctl disable nginx      # \u5173\u95ed\u5f00\u673a\u81ea\u542f\n</code></pre> <ol> <li>\u914d\u7f6e\u9632\u706b\u5899\u653e\u884c</li> </ol> <p>nginx\u9ed8\u8ba4\u7ed1\u5b9a80\u7aef\u53e3\uff0c\u9700\u8981\u5173\u95ed\u9632\u706b\u5899\u6216\u653e\u884c80\u7aef\u53e3</p> <pre><code># \u65b9\u5f0f1\uff08\u63a8\u8350\uff09\uff0c\u5173\u95ed\u9632\u706b\u5899\nsystemctl stop firewalld     # \u5173\u95ed\nsystemctl disable firewalld      # \u5173\u95ed\u5f00\u673a\u81ea\u542f\n\n# \u65b9\u5f0f2\uff0c\u653e\u884c80\u7aef\u53e3\nfirewall-cmd --add-port=80/tcp --permanent       # \u653e\u884ctcp\u89c4\u5219\u4e0b\u768480\u7aef\u53e3\uff0c\u6c38\u4e45\u751f\u6548\nfirewall-cmd --reload                            # \u91cd\u65b0\u52a0\u8f7d\u9632\u706b\u5899\u89c4\u5219\n</code></pre> <ol> <li>\u542f\u52a8\u540e\u6d4f\u89c8\u5668\u8f93\u5165Linux\u670d\u52a1\u5668\u7684IP\u5730\u5740\u6216\u4e3b\u673a\u540d\u5373\u53ef\u8bbf\u95ee</li> </ol> <p>http://192.168.88.130 \u6216 http://centos</p> <p>ps\uff1a80\u7aef\u53e3\u662f\u8bbf\u95ee\u7f51\u7ad9\u7684\u9ed8\u8ba4\u7aef\u53e3\uff0c\u6240\u4ee5\u540e\u9762\u65e0\u9700\u8ddf\u968f\u7aef\u53e3\u53f7</p> <p>\u663e\u793a\u7684\u6307\u5b9a\u7aef\u53e3\u4e5f\u662f\u53ef\u4ee5\u7684\u6bd4\u5982\uff1a</p> <ul> <li>http://192.168.88.130:80</li> <li>http://centos:80</li> </ul> <p>\u81f3\u6b64\uff0cNginx\u5b89\u88c5\u914d\u7f6e\u5b8c\u6210\u3002</p> <p></p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#rabbitmq","title":"RabbitMQ\u5b89\u88c5\u90e8\u7f72\u3010\u7b80\u5355\u3011","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_17","title":"\u7b80\u4ecb","text":"<p>RabbitMQ\u4e00\u6b3e\u77e5\u540d\u7684\u5f00\u6e90\u6d88\u606f\u961f\u5217\u7cfb\u7edf\uff0c\u4e3a\u4f01\u4e1a\u63d0\u4f9b\u6d88\u606f\u7684\u53d1\u5e03\u3001\u8ba2\u9605\u3001\u70b9\u5bf9\u70b9\u4f20\u8f93\u7b49\u6d88\u606f\u670d\u52a1\u3002</p> <p>RabbitMQ\u5728\u4f01\u4e1a\u5f00\u53d1\u4e2d\u5341\u5206\u5e38\u89c1\uff0c\u8bfe\u7a0b\u4e3a\u5927\u5bb6\u6f14\u793a\u5feb\u901f\u642d\u5efaRabbitMQ\u73af\u5883\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_18","title":"\u5b89\u88c5","text":"<p>rabbitmq\u5728yum\u4ed3\u5e93\u4e2d\u7684\u7248\u672c\u6bd4\u8f83\u8001\uff0c\u6240\u4ee5\u6211\u4eec\u9700\u8981\u624b\u52a8\u6784\u5efayum\u4ed3\u5e93</p> <ol> <li>\u51c6\u5907yum\u4ed3\u5e93</li> </ol> <pre><code># root\u6267\u884c\n# 1. \u51c6\u5907gpgkey\u5bc6\u94a5\nrpm --import https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc\nrpm --import https://packagecloud.io/rabbitmq/erlang/gpgkey\nrpm --import https://packagecloud.io/rabbitmq/rabbitmq-server/gpgkey\n\n# 2. \u51c6\u5907\u4ed3\u5e93\u6587\u4ef6\nvim /etc/yum.repos.d/rabbitmq.repo\n# \u586b\u5165\u5982\u4e0b\u5185\u5bb9\n##\n## Zero dependency Erlang\n##\n\n[rabbitmq_erlang]\nname=rabbitmq_erlang\nbaseurl=https://packagecloud.io/rabbitmq/erlang/el/7/$basearch\nrepo_gpgcheck=1\ngpgcheck=1\nenabled=1\n# PackageCloud's repository key and RabbitMQ package signing key\ngpgkey=https://packagecloud.io/rabbitmq/erlang/gpgkey\n       https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc\nsslverify=1\nsslcacert=/etc/pki/tls/certs/ca-bundle.crt\nmetadata_expire=300\n\n[rabbitmq_erlang-source]\nname=rabbitmq_erlang-source\nbaseurl=https://packagecloud.io/rabbitmq/erlang/el/7/SRPMS\nrepo_gpgcheck=1\ngpgcheck=0\nenabled=1\n# PackageCloud's repository key and RabbitMQ package signing key\ngpgkey=https://packagecloud.io/rabbitmq/erlang/gpgkey\n       https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc\nsslverify=1\nsslcacert=/etc/pki/tls/certs/ca-bundle.crt\nmetadata_expire=300\n\n##\n## RabbitMQ server\n##\n\n[rabbitmq_server]\nname=rabbitmq_server\nbaseurl=https://packagecloud.io/rabbitmq/rabbitmq-server/el/7/$basearch\nrepo_gpgcheck=1\ngpgcheck=0\nenabled=1\n# PackageCloud's repository key and RabbitMQ package signing key\ngpgkey=https://packagecloud.io/rabbitmq/rabbitmq-server/gpgkey\n       https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc\nsslverify=1\nsslcacert=/etc/pki/tls/certs/ca-bundle.crt\nmetadata_expire=300\n\n[rabbitmq_server-source]\nname=rabbitmq_server-source\nbaseurl=https://packagecloud.io/rabbitmq/rabbitmq-server/el/7/SRPMS\nrepo_gpgcheck=1\ngpgcheck=0\nenabled=1\ngpgkey=https://packagecloud.io/rabbitmq/rabbitmq-server/gpgkey\nsslverify=1\nsslcacert=/etc/pki/tls/certs/ca-bundle.crt\nmetadata_expire=300\n</code></pre> <ol> <li>\u5b89\u88c5RabbitMQ</li> </ol> <pre><code># root\u6267\u884c\nyum install erlang rabbitmq-server -y\n</code></pre> <pre><code>Installed:\n  erlang.x86_64 0:23.3.4.11-1.el7           rabbitmq-server.noarch 0:3.10.0-1.el7\n</code></pre> <ol> <li>\u542f\u52a8</li> </ol> <pre><code># root\u6267\u884c\n# \u4f7f\u7528systemctl\u7ba1\u63a7\uff0c\u670d\u52a1\u540d\uff1arabbitmq-server\nsystemctl enable rabbitmq-server     # \u5f00\u673a\u81ea\u542f\nsystemctl disable rabbitmq-server        # \u5173\u95ed\u5f00\u673a\u81ea\u542f\nsystemctl start rabbitmq-server          # \u542f\u52a8\nsystemctl stop rabbitmq-server           # \u5173\u95ed\nsystemctl status rabbitmq-server     # \u67e5\u770b\u72b6\u6001\n</code></pre> <ol> <li>\u653e\u884c\u9632\u706b\u5899\uff0cRabbitMQ\u4f7f\u75285672\u300115672\u300125672 3\u4e2a\u7aef\u53e3</li> </ol> <pre><code># \u65b9\u5f0f1\uff08\u63a8\u8350\uff09\uff0c\u5173\u95ed\u9632\u706b\u5899\nsystemctl stop firewalld     # \u5173\u95ed\nsystemctl disable firewalld      # \u5173\u95ed\u5f00\u673a\u81ea\u542f\n\n# \u65b9\u5f0f2\uff0c\u653e\u884c5672 25672\u7aef\u53e3\nfirewall-cmd --add-port=5672/tcp --permanent     # \u653e\u884ctcp\u89c4\u5219\u4e0b\u76845672\u7aef\u53e3\uff0c\u6c38\u4e45\u751f\u6548\nfirewall-cmd --add-port=15672/tcp --permanent        # \u653e\u884ctcp\u89c4\u5219\u4e0b\u768415672\u7aef\u53e3\uff0c\u6c38\u4e45\u751f\u6548\nfirewall-cmd --add-port=25672/tcp --permanent        # \u653e\u884ctcp\u89c4\u5219\u4e0b\u768425672\u7aef\u53e3\uff0c\u6c38\u4e45\u751f\u6548\nfirewall-cmd --reload                                # \u91cd\u65b0\u52a0\u8f7d\u9632\u706b\u5899\u89c4\u5219\n</code></pre> <ol> <li>\u542f\u52a8RabbitMQ\u7684WEB\u7ba1\u7406\u63a7\u5236\u53f0</li> </ol> <pre><code>rabbitmq-plugins enable rabbitmq_management\n</code></pre> <ol> <li>\u6dfb\u52a0admin\u7528\u6237\uff0c\u5e76\u8d4b\u4e88\u6743\u9650</li> </ol> <pre><code>rabbitmqctl add_user admin 'Itheima66^'\nrabbitmqctl set_permissions -p \"/\" \"admin\" \".*\" \".*\" \".*\"\nrabbitmqctl set_user_tags admin administrator\n</code></pre> <ol> <li>\u6d4f\u89c8\u5668\u6253\u5f00\u7ba1\u7406\u63a7\u5236\u53f0</li> </ol> <p>http://192.168.88.130:15672</p> <p></p> <p>\u81f3\u6b64\uff0cRabbitMQ\u5df2\u7ecf\u5b89\u88c5\u5b8c\u6210\u4e86\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#redis","title":"Redis\u5b89\u88c5\u90e8\u7f72\u3010\u7b80\u5355\u3011","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_19","title":"\u7b80\u4ecb","text":"<p>redis\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u3001\u4f7f\u7528C\u8bed\u8a00\u7f16\u5199\u7684\u3001\u652f\u6301\u7f51\u7edc\u4ea4\u4e92\u7684\u3001\u53ef\u57fa\u4e8e\u5185\u5b58\u4e5f\u53ef\u6301\u4e45\u5316\u7684Key-Value\u6570\u636e\u5e93\u3002</p> <p>redis\u7684\u7279\u70b9\u5c31\u662f\uff1a<code>\u5feb</code>\uff0c\u53ef\u4ee5\u57fa\u4e8e\u5185\u5b58\u5b58\u50a8\u6570\u636e\u5e76\u63d0\u4f9b\u8d85\u4f4e\u5ef6\u8fdf\u3001\u8d85\u5feb\u7684\u68c0\u7d22\u901f\u5ea6</p> <p>\u4e00\u822c\u7528\u4e8e\u5728\u7cfb\u7edf\u4e2d\u63d0\u4f9b\u5feb\u901f\u7f13\u5b58\u7684\u80fd\u529b\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_20","title":"\u5b89\u88c5","text":"<ol> <li>\u914d\u7f6e<code>EPEL</code>\u4ed3\u5e93</li> </ol> <p>EPEL \u7684\u5168\u79f0\u53eb Extra Packages for Enterprise Linux \u3002EPEL\u662f\u7531 Fedora \u793e\u533a\u6253\u9020\uff0c\u4e3a RHEL \u53ca\u884d\u751f\u53d1\u884c\u7248\u5982 CentOS\u3001Scientific Linux \u7b49\u63d0\u4f9b\u9ad8\u8d28\u91cf\u8f6f\u4ef6\u5305\u7684\u9879\u76ee\u3002\u88c5\u4e0a\u4e86 EPEL\u4e4b\u540e\uff0c\u5c31\u76f8\u5f53\u4e8e\u6dfb\u52a0\u4e86\u4e00\u4e2a\u7b2c\u4e09\u65b9\u6e90\u3002EPEL\u5219\u4e3a\u670d\u52a1\u5668\u7248\u672c\u63d0\u4f9b\u5927\u91cf\u7684rpm\u5305(yum\u7a0b\u5e8f\u6240\u4f7f\u7528\u7684\u7a0b\u5e8f\u5b89\u88c5\u5305\uff0c\u7c7b\u4f3cWindows\u7684exe)\uff0c\u800c\u4e14\u5927\u591a\u6570rpm\u5305\u5728\u5b98\u65b9 repository \u4e2d\u662f\u627e\u4e0d\u5230\u7684\u3002</p> <pre><code># root\u6267\u884c\nyum install -y epel-release\n</code></pre> <ol> <li>\u5b89\u88c5redis</li> </ol> <pre><code># root\u6267\u884c\nyum install -y redis\n</code></pre> <ol> <li>\u542f\u52a8redis</li> </ol> <pre><code># root\u6267\u884c\n# \u4f7f\u7528systemctl\u7ba1\u63a7\uff0c\u670d\u52a1\u540d\uff1aredis\nsystemctl enable redis       # \u5f00\u673a\u81ea\u542f\nsystemctl disable redis      # \u5173\u95ed\u5f00\u673a\u81ea\u542f\nsystemctl start redis        # \u542f\u52a8\nsystemctl stop redis     # \u5173\u95ed\nsystemctl status redis       # \u67e5\u770b\u72b6\u6001\n</code></pre> <ol> <li>\u653e\u884c\u9632\u706b\u5899\uff0credis\u4f7f\u7528\u7aef\u53e36379</li> </ol> <pre><code># \u65b9\u5f0f1\uff08\u63a8\u8350\uff09\uff0c\u5173\u95ed\u9632\u706b\u5899\nsystemctl stop firewalld     # \u5173\u95ed\nsystemctl disable firewalld      # \u5173\u95ed\u5f00\u673a\u81ea\u542f\n\n# \u65b9\u5f0f2\uff0c\u653e\u884c6379\u7aef\u53e3\nfirewall-cmd --add-port=6379/tcp --permanent     # \u653e\u884ctcp\u89c4\u5219\u4e0b\u76846379\u7aef\u53e3\uff0c\u6c38\u4e45\u751f\u6548\nfirewall-cmd --reload    \n</code></pre> <ol> <li>\u8fdb\u5165redis\u670d\u52a1</li> </ol> <pre><code># \u6267\u884credis-cli\n[root@centos ~]# redis-cli\n127.0.0.1:6379&gt; set mykey hello\nOK\n127.0.0.1:6379&gt; get mykey\n\"hello\"\n127.0.0.1:6379&gt; \n</code></pre> <p>\u81f3\u6b64\uff0credis\u5b89\u88c5\u5b8c\u6210\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#elasticsearch","title":"ElasticSearch\u5b89\u88c5\u90e8\u7f72","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_21","title":"\u7b80\u4ecb","text":"<p>\u5168\u6587\u641c\u7d22\u5c5e\u4e8e\u6700\u5e38\u89c1\u7684\u9700\u6c42\uff0c\u5f00\u6e90\u7684 Elasticsearch \uff08\u4ee5\u4e0b\u7b80\u79f0 es\uff09\u662f\u76ee\u524d\u5168\u6587\u641c\u7d22\u5f15\u64ce\u7684\u9996\u9009\u3002</p> <p>\u5b83\u53ef\u4ee5\u5feb\u901f\u5730\u50a8\u5b58\u3001\u641c\u7d22\u548c\u5206\u6790\u6d77\u91cf\u6570\u636e\u3002\u7ef4\u57fa\u767e\u79d1\u3001Stack Overflow\u3001Github \u90fd\u91c7\u7528\u5b83\u3002</p> <p>Elasticsearch\u7b80\u79f0es\uff0c\u5728\u4f01\u4e1a\u5185\u540c\u6837\u662f\u4e00\u6b3e\u5e94\u7528\u975e\u5e38\u5e7f\u6cdb\u7684\u641c\u7d22\u5f15\u64ce\u670d\u52a1\u3002</p> <p>\u5f88\u591a\u670d\u52a1\u4e2d\u7684\u641c\u7d22\u529f\u80fd\uff0c\u90fd\u662f\u57fa\u4e8ees\u6765\u5b9e\u73b0\u7684\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_22","title":"\u5b89\u88c5","text":"<ol> <li>\u6dfb\u52a0yum\u4ed3\u5e93</li> </ol> <pre><code># root\u6267\u884c\n# \u5bfc\u5165\u4ed3\u5e93\u5bc6\u94a5\nrpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch\n\n# \u6dfb\u52a0yum\u6e90\n# \u7f16\u8f91\u6587\u4ef6 \nvim /etc/yum.repos.d/elasticsearch.repo\n\n[elasticsearch-7.x]\nname=Elasticsearch repository for 7.x packages\nbaseurl=https://artifacts.elastic.co/packages/7.x/yum\ngpgcheck=1\ngpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch\nenabled=1\nautorefresh=1\ntype=rpm-md\n\n\n# \u66f4\u65b0yum\u7f13\u5b58\nyum makecache\n</code></pre> <ol> <li>\u5b89\u88c5es</li> </ol> <pre><code>yum install -y elasticsearch\n</code></pre> <ol> <li>\u914d\u7f6ees</li> </ol> <pre><code>vim /etc/elasticsearch/elasticsearch.yml\n\n# 17\u884c\uff0c\u8bbe\u7f6e\u96c6\u7fa4\u540d\u79f0\ncluster.name: my-cluster\n\n# 23\u884c\uff0c\u8bbe\u7f6e\u8282\u70b9\u540d\u79f0\nnode.name: node-1\n\n# 56\u884c\uff0c\u5141\u8bb8\u5916\u7f51\u8bbf\u95ee\nnetwork.host: 0.0.0.0\n\n# 74\u884c\uff0c\u914d\u7f6e\u96c6\u7fa4master\u8282\u70b9\ncluster.initial_master_nodes: [\"node-1\"]\n</code></pre> <ol> <li>\u542f\u52a8es</li> </ol> <pre><code>systemctl start | stop | status | enable | disable elasticsearch\n</code></pre> <ol> <li>\u5173\u95ed\u9632\u706b\u5899</li> </ol> <pre><code>systemctl stop firewalld\nsystemctl disable firewalld\n</code></pre> <ol> <li>\u6d4b\u8bd5</li> </ol> <p>\u6d4f\u89c8\u5668\u6253\u5f00\uff1ahttp://ip:9200/?pretty</p> <p></p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_23","title":"\u96c6\u7fa4\u5316\u73af\u5883\u524d\u7f6e\u51c6\u5907","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_24","title":"\u4ecb\u7ecd","text":"<p>\u5728\u524d\u9762\uff0c\u6211\u4eec\u6240\u5b66\u4e60\u5b89\u88c5\u7684\u8f6f\u4ef6\uff0c\u90fd\u662f\u4ee5\u5355\u673a\u6a21\u5f0f\u8fd0\u884c\u7684\u3002</p> <p>\u540e\u7eed\uff0c\u6211\u4eec\u5c06\u8981\u5b66\u4e60\u5927\u6570\u636e\u76f8\u5173\u7684\u8f6f\u4ef6\u90e8\u7f72\uff0c\u6240\u4ee5\u540e\u7eed\u6211\u4eec\u6240\u5b89\u88c5\u7684\u8f6f\u4ef6\u670d\u52a1\uff0c\u5927\u591a\u6570\u90fd\u662f\u4ee5\u96c6\u7fa4\u5316\uff08\u591a\u53f0\u670d\u52a1\u5668\u5171\u540c\u5de5\u4f5c\uff09\u6a21\u5f0f\u8fd0\u884c\u7684\u3002</p> <p>\u6240\u4ee5\uff0c\u5728\u5f53\u524d\u5c0f\u8282\uff0c\u6211\u4eec\u9700\u8981\u5b8c\u6210\u96c6\u7fa4\u5316\u73af\u5883\u7684\u524d\u7f6e\u51c6\u5907\uff0c\u5305\u62ec\u521b\u5efa\u591a\u53f0\u865a\u62df\u673a\uff0c\u914d\u7f6e\u4e3b\u673a\u540d\u6620\u5c04\uff0cSSH\u514d\u5bc6\u767b\u5f55\u7b49\u7b49\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_25","title":"\u90e8\u7f72","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#linux_2","title":"\u914d\u7f6e\u591a\u53f0Linux\u865a\u62df\u673a","text":"<p>\u5b89\u88c5\u96c6\u7fa4\u5316\u8f6f\u4ef6\uff0c\u9996\u8981\u6761\u4ef6\u5c31\u662f\u8981\u6709\u591a\u53f0Linux\u670d\u52a1\u5668\u53ef\u7528\u3002</p> <p>\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528VMware\u63d0\u4f9b\u7684\u514b\u9686\u529f\u80fd\uff0c\u5c06\u6211\u4eec\u7684\u865a\u62df\u673a\u989d\u5916\u514b\u9686\u51fa3\u53f0\u6765\u4f7f\u7528\u3002</p> <ol> <li> <p>\u9996\u5148\uff0c\u5173\u673a\u5f53\u524dCentOS\u7cfb\u7edf\u865a\u62df\u673a\uff08\u53ef\u4ee5\u4f7f\u7528root\u7528\u6237\u6267\u884c<code>init 0</code>\u6765\u5feb\u901f\u5173\u673a\uff09</p> </li> <li> <p>\u65b0\u5efa\u6587\u4ef6\u5939</p> </li> </ol> <p></p> <p>\u6587\u4ef6\u5939\u8d77\u540d\u4e3a\uff1a<code>\u865a\u62df\u673a\u96c6\u7fa4</code></p> <ol> <li>\u514b\u9686</li> </ol> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <p></p> <ol> <li>\u540c\u6837\u7684\u64cd\u4f5c\u514b\u9686\u51fa\uff1anode2\u548cnode3</li> </ol> <p></p> <ol> <li>\u5f00\u542fnode1\uff0c\u4fee\u6539\u4e3b\u673a\u540d\u4e3anode1\uff0c\u5e76\u4fee\u6539\u56fa\u5b9aip\u4e3a\uff1a192.168.88.131</li> </ol> <pre><code># \u4fee\u6539\u4e3b\u673a\u540d\nhostnamectl set-hostname node1\n\n# \u4fee\u6539IP\u5730\u5740\nvim /etc/sysconfig/network-scripts/ifcfg-ens33\nIPADDR=\"192.168.88.131\"\n\n# \u91cd\u542f\u7f51\u5361\nsystemctl stop network\nsystemctl start network\n# \u6216\u8005\u76f4\u63a5\nsystemctl restart network\n</code></pre> <ol> <li>\u540c\u6837\u7684\u64cd\u4f5c\u542f\u52a8node2\u548cnode3,</li> </ol> <p>\u4fee\u6539node2\u4e3b\u673a\u540d\u4e3anode2\uff0c\u8bbe\u7f6eip\u4e3a192.168.88.132</p> <p>\u4fee\u6539node2\u4e3b\u673a\u540d\u4e3anode3\uff0c\u8bbe\u7f6eip\u4e3a192.168.88.133</p> <ol> <li>\u914d\u7f6eFinalShell\uff0c\u914d\u7f6e\u8fde\u63a5\u5230node1\u3001node2\u3001node3\u7684\u8fde\u63a5</li> </ol> <p>\u4e3a\u4e86\u7b80\u5355\u8d77\u89c1\uff0c\u5efa\u8bae\u914d\u7f6eroot\u7528\u6237\u767b\u5f55</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_26","title":"\u51c6\u5907\u4e3b\u673a\u540d\u6620\u5c04","text":"<ol> <li>\u5728Windows\u7cfb\u7edf\u4e2d\u4fee\u6539hosts\u6587\u4ef6\uff0c\u586b\u5165\u5982\u4e0b\u5185\u5bb9\uff1a</li> </ol> <p>\u5982\u679c\u540c\u5b66\u4eec\u4f7f\u7528MacOS\u7cfb\u7edf\uff0c\u8bf7\uff1a</p> <ol> <li>sudo su -\uff0c\u5207\u6362\u5230root</li> <li>\u4fee\u6539/etc/hosts\u6587\u4ef6</li> </ol> <pre><code>192.168.88.131 node1\n192.168.88.132 node2\n192.168.88.133 node3\n</code></pre> <ol> <li>\u57283\u53f0Linux\u7684/etc/hosts\u6587\u4ef6\u4e2d\uff0c\u586b\u5165\u5982\u4e0b\u5185\u5bb9\uff083\u53f0\u90fd\u8981\u6dfb\u52a0\uff09</li> </ol> <pre><code>192.168.88.131 node1\n192.168.88.132 node2\n192.168.88.133 node3\n</code></pre>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#ssh","title":"\u914d\u7f6eSSH\u514d\u5bc6\u767b\u5f55","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_27","title":"\u7b80\u4ecb","text":"<p>SSH\u670d\u52a1\u662f\u4e00\u79cd\u7528\u4e8e\u8fdc\u7a0b\u767b\u5f55\u7684\u5b89\u5168\u8ba4\u8bc1\u534f\u8bae\u3002</p> <p>\u6211\u4eec\u901a\u8fc7FinalShell\u8fdc\u7a0b\u8fde\u63a5\u5230Linux\uff0c\u5c31\u662f\u4f7f\u7528\u7684SSH\u670d\u52a1\u3002</p> <p>SSH\u670d\u52a1\u652f\u6301\uff1a</p> <ol> <li>\u901a\u8fc7\u8d26\u6237+\u5bc6\u7801\u7684\u8ba4\u8bc1\u65b9\u5f0f\u6765\u505a\u7528\u6237\u8ba4\u8bc1</li> <li>\u901a\u8fc7\u8d26\u6237+\u79d8\u94a5\u6587\u4ef6\u7684\u65b9\u5f0f\u505a\u7528\u6237\u8ba4\u8bc1</li> </ol> <p>SSH\u53ef\u4ee5\u8ba9\u6211\u4eec\u901a\u8fc7SSH\u547d\u4ee4\uff0c\u8fdc\u7a0b\u7684\u767b\u9646\u5230\u5176\u5b83\u7684\u4e3b\u673a\u4e0a\uff0c\u6bd4\u5982\uff1a</p> <p>\u5728node1\u6267\u884c\uff1assh root@node2\uff0c\u5c06\u4ee5root\u7528\u6237\u767b\u5f55node2\u670d\u52a1\u5668\uff0c\u8f93\u5165\u5bc6\u7801\u5373\u53ef\u6210\u529f\u767b\u9646</p> <p>\u6216\u8005ssh node2\uff0c\u5c06\u4ee5\u5f53\u524d\u7528\u6237\u76f4\u63a5\u767b\u9646\u5230node2\u670d\u52a1\u5668\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#ssh_1","title":"SSH\u514d\u5bc6\u914d\u7f6e","text":"<p>\u540e\u7eed\u5b89\u88c5\u7684\u96c6\u7fa4\u5316\u8f6f\u4ef6\uff0c\u591a\u6570\u9700\u8981\u8fdc\u7a0b\u767b\u5f55\u4ee5\u53ca\u8fdc\u7a0b\u6267\u884c\u547d\u4ee4\uff0c\u6211\u4eec\u53ef\u4ee5\u7b80\u5355\u8d77\u89c1\uff0c\u914d\u7f6e\u4e09\u53f0Linux\u670d\u52a1\u5668\u4e4b\u95f4\u7684\u514d\u5bc6\u7801\u4e92\u76f8SSH\u767b\u9646</p> <ol> <li> <p>\u5728\u6bcf\u4e00\u53f0\u673a\u5668\u90fd\u6267\u884c\uff1a<code>ssh-keygen -t rsa -b 4096</code>\uff0c\u4e00\u8def\u56de\u8f66\u5230\u5e95\u5373\u53ef</p> </li> <li> <p>\u5728\u6bcf\u4e00\u53f0\u673a\u5668\u90fd\u6267\u884c\uff1a</p> </li> </ol> <pre><code>ssh-copy-id node1\nssh-copy-id node2\nssh-copy-id node3\n</code></pre> <ol> <li>\u6267\u884c\u5b8c\u6bd5\u540e\uff0cnode1\u3001node2\u3001node3\u4e4b\u95f4\u5c06\u5b8c\u6210root\u7528\u6237\u4e4b\u95f4\u7684\u514d\u5bc6\u4e92\u901a</li> </ol>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#jdk_1","title":"\u914d\u7f6eJDK\u73af\u5883","text":"<p>\u540e\u7eed\u7684\u5927\u6570\u636e\u96c6\u7fa4\u8f6f\u4ef6\uff0c\u591a\u6570\u662f\u9700\u8981Java\u8fd0\u884c\u73af\u5883\u7684\uff0c\u6240\u4ee5\u6211\u4eec\u4e3a==\u6bcf\u4e00\u53f0==\u673a\u5668\u90fd\u914d\u7f6eJDK\u73af\u5883\u3002</p> <p>JDK\u914d\u7f6e\u53c2\u9605\uff1a<code>Tomcat</code>\u5b89\u88c5\u90e8\u7f72\u73af\u8282\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#selinux","title":"\u5173\u95ed\u9632\u706b\u5899\u548cSELinux","text":"<p>\u96c6\u7fa4\u5316\u8f6f\u4ef6\u4e4b\u95f4\u9700\u8981\u901a\u8fc7\u7aef\u53e3\u4e92\u76f8\u901a\u8baf\uff0c\u4e3a\u4e86\u907f\u514d\u51fa\u73b0\u7f51\u7edc\u4e0d\u901a\u7684\u95ee\u9898\uff0c\u6211\u4eec\u53ef\u4ee5\u7b80\u5355\u7684\u5728\u96c6\u7fa4\u5185\u90e8\u5173\u95ed\u9632\u706b\u5899\u3002</p> <p>\u5728\u6bcf\u4e00\u53f0\u673a\u5668\u90fd\u6267\u884c</p> <pre><code>systemctl stop firewalld\nsystemctl disable firewalld\n</code></pre> <p>Linux\u6709\u4e00\u4e2a\u5b89\u5168\u6a21\u5757\uff1aSELinux\uff0c\u7528\u4ee5\u9650\u5236\u7528\u6237\u548c\u7a0b\u5e8f\u7684\u76f8\u5173\u6743\u9650\uff0c\u6765\u786e\u4fdd\u7cfb\u7edf\u7684\u5b89\u5168\u7a33\u5b9a\u3002</p> <p>SELinux\u7684\u914d\u7f6e\u540c\u9632\u706b\u5899\u4e00\u6837\uff0c\u975e\u5e38\u590d\u6742\uff0c\u8bfe\u7a0b\u4e2d\u4e0d\u591a\u6d89\u53ca\uff0c\u540e\u7eed\u89c6\u60c5\u51b5\u53ef\u4ee5\u51fa\u4e00\u7ae0SELinux\u7684\u914d\u7f6e\u8bfe\u7a0b\u3002</p> <p>\u5728\u5f53\u524d\uff0c\u6211\u4eec\u53ea\u9700\u8981\u5173\u95edSELinux\u529f\u80fd\uff0c\u907f\u514d\u5bfc\u81f4\u540e\u9762\u7684\u8f6f\u4ef6\u8fd0\u884c\u51fa\u73b0\u95ee\u9898\u5373\u53ef\uff0c</p> <p>\u5728\u6bcf\u4e00\u53f0\u673a\u5668\u90fd\u6267\u884c</p> <pre><code>vim /etc/sysconfig/selinux\n\n# \u5c06\u7b2c\u4e03\u884c\uff0cSELINUX=enforcing \u6539\u4e3a\nSELINUX=disabled\n# \u4fdd\u5b58\u9000\u51fa\u540e\uff0c\u91cd\u542f\u865a\u62df\u673a\u5373\u53ef\uff0c\u5343\u4e07\u8981\u6ce8\u610fdisabled\u5355\u8bcd\u4e0d\u8981\u5199\u9519\uff0c\u4e0d\u7136\u65e0\u6cd5\u542f\u52a8\u7cfb\u7edf\n</code></pre>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_28","title":"\u6dfb\u52a0\u5feb\u7167","text":"<p>\u4e3a\u4e86\u907f\u514d\u540e\u7eed\u51fa\u73b0\u95ee\u9898\uff0c\u5728\u5b8c\u6210\u4e0a\u8ff0\u8bbe\u7f6e\u540e\uff0c\u4e3a==\u6bcf\u4e00\u53f0\u865a\u62df\u673a==\u90fd\u5236\u4f5c\u5feb\u7167\uff0c\u7559\u5f85\u4f7f\u7528\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#-scp","title":"\u8865\u5145\u547d\u4ee4 - scp","text":"<p>\u540e\u7eed\u7684\u5b89\u88c5\u90e8\u7f72\u64cd\u4f5c\uff0c\u6211\u4eec\u5c06\u4f1a\u9891\u7e41\u7684\u5728\u591a\u53f0\u670d\u52a1\u5668\u4e4b\u95f4\u76f8\u4e92\u4f20\u8f93\u6570\u636e\u3002</p> <p>\u4e3a\u4e86\u66f4\u52a0\u65b9\u9762\u7684\u4e92\u76f8\u4f20\u8f93\uff0c\u6211\u4eec\u8865\u5145\u4e00\u4e2a\u547d\u4ee4\uff1ascp</p> <p>scp\u547d\u4ee4\u662fcp\u547d\u4ee4\u7684\u5347\u7ea7\u7248\uff0c\u5373\uff1assh cp\uff0c\u901a\u8fc7SSH\u534f\u8bae\u5b8c\u6210\u6587\u4ef6\u7684\u590d\u5236\u3002</p> <p>\u5176\u4e3b\u8981\u7684\u529f\u80fd\u5c31\u662f\uff1a\u5728\u4e0d\u540c\u7684Linux\u670d\u52a1\u5668\u4e4b\u95f4\uff0c\u901a\u8fc7<code>SSH</code>\u534f\u8bae\u4e92\u76f8\u4f20\u8f93\u6587\u4ef6\u3002</p> <p>\u53ea\u8981\u77e5\u6653\u670d\u52a1\u5668\u7684\u8d26\u6237\u548c\u5bc6\u7801\uff08\u6216\u5bc6\u94a5\uff09\uff0c\u5373\u53ef\u901a\u8fc7SCP\u4e92\u4f20\u6587\u4ef6\u3002</p> <p>\u8bed\u6cd5\uff1a</p> <pre><code>scp [-r] \u53c2\u65701 \u53c2\u65702\n- -r\u9009\u9879\u7528\u4e8e\u590d\u5236\u6587\u4ef6\u5939\u4f7f\u7528\uff0c\u5982\u679c\u590d\u5236\u6587\u4ef6\u5939\uff0c\u5fc5\u987b\u4f7f\u7528-r\n- \u53c2\u65701\uff1a\u672c\u673a\u8def\u5f84 \u6216 \u8fdc\u7a0b\u76ee\u6807\u8def\u5f84\n- \u53c2\u65702\uff1a\u8fdc\u7a0b\u76ee\u6807\u8def\u5f84 \u6216 \u672c\u673a\u8def\u5f84\n\n\u5982\uff1a\nscp -r /export/server/jdk root@node2:/export/server/\n\u5c06\u672c\u673a\u4e0a\u7684jdk\u6587\u4ef6\u5939\uff0c \u4ee5root\u7684\u8eab\u4efd\u590d\u5236\u5230node2\u7684/export/server/\u5185\n\u540cSSH\u767b\u9646\u4e00\u6837\uff0c\u8d26\u6237\u540d\u53ef\u4ee5\u7701\u7565\uff08\u4f7f\u7528\u672c\u673a\u5f53\u524d\u7684\u540c\u540d\u8d26\u6237\u767b\u9646\uff09\n\n\u5982\uff1a\nscp -r node2:/export/server/jdk /export/server/\n\u5c06\u8fdc\u7a0bnode2\u7684jdk\u6587\u4ef6\u5939\uff0c\u590d\u5236\u5230\u672c\u673a\u7684/export/server/\u5185\n\n\n# scp\u547d\u4ee4\u7684\u9ad8\u7ea7\u7528\u6cd5\ncd /export/server\nscp -r jdk node2:`pwd`/    # \u5c06\u672c\u673a\u5f53\u524d\u8def\u5f84\u7684jdk\u6587\u4ef6\u5939\uff0c\u590d\u5236\u5230node2\u670d\u52a1\u5668\u7684\u540c\u540d\u8def\u5f84\u4e0b\nscp -r jdk node2:$PWD      # \u5c06\u672c\u673a\u5f53\u524d\u8def\u5f84\u7684jdk\u6587\u4ef6\u5939\uff0c\u590d\u5236\u5230node2\u670d\u52a1\u5668\u7684\u540c\u540d\u8def\u5f84\u4e0b\n</code></pre>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#zookeeper","title":"Zookeeper\u96c6\u7fa4\u5b89\u88c5\u90e8\u7f72","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_29","title":"\u7b80\u4ecb","text":"<p>ZooKeeper\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u7684\uff0c\u5f00\u653e\u6e90\u7801\u7684\u5206\u5e03\u5f0f\u5e94\u7528\u7a0b\u5e8f\u534f\u8c03\u670d\u52a1\uff0c\u662fHadoop\u548cHbase\u7684\u91cd\u8981\u7ec4\u4ef6\u3002\u5b83\u662f\u4e00\u4e2a\u4e3a\u5206\u5e03\u5f0f\u5e94\u7528\u63d0\u4f9b\u4e00\u81f4\u6027\u670d\u52a1\u7684\u8f6f\u4ef6\uff0c\u63d0\u4f9b\u7684\u529f\u80fd\u5305\u62ec\uff1a\u914d\u7f6e\u7ef4\u62a4\u3001\u57df\u540d\u670d\u52a1\u3001\u5206\u5e03\u5f0f\u540c\u6b65\u3001\u7ec4\u670d\u52a1\u7b49\u3002</p> <p>\u9664\u4e86\u4e3aHadoop\u548cHBase\u63d0\u4f9b\u534f\u8c03\u670d\u52a1\u5916\uff0cZookeeper\u4e5f\u88ab\u5176\u5b83\u8bb8\u591a\u8f6f\u4ef6\u91c7\u7528\u4f5c\u4e3a\u5176\u5206\u5e03\u5f0f\u72b6\u6001\u4e00\u81f4\u6027\u7684\u4f9d\u8d56\uff0c\u6bd4\u5982Kafka\uff0c\u53c8\u6216\u8005\u4e00\u4e9b\u8f6f\u4ef6\u9879\u76ee\u4e2d\uff0c\u4e5f\u7ecf\u5e38\u80fd\u89c1\u5230Zookeeper\u4f5c\u4e3a\u4e00\u81f4\u6027\u534f\u8c03\u670d\u52a1\u5b58\u5728\u3002</p> <p>Zookeeper\u4e0d\u8bba\u662f\u5927\u6570\u636e\u9886\u57df\u4ea6\u6216\u662f\u5176\u5b83\u670d\u52a1\u5668\u5f00\u53d1\u9886\u57df\uff0c\u6d89\u53ca\u5230\u5206\u5e03\u5f0f\u72b6\u6001\u4e00\u81f4\u6027\u7684\u573a\u666f\uff0c\u603b\u6709\u5b83\u7684\u8eab\u5f71\u5b58\u5728\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_30","title":"\u5b89\u88c5","text":"<p>Zookeeper\u662f\u4e00\u6b3e\u5206\u5e03\u5f0f\u7684\u96c6\u7fa4\u5316\u8f6f\u4ef6\uff0c\u53ef\u4ee5\u5728\u591a\u53f0\u670d\u52a1\u5668\u4e0a\u90e8\u7f72\uff0c\u5e76\u534f\u540c\u7ec4\u6210\u5206\u5e03\u5f0f\u96c6\u7fa4\u4e00\u8d77\u5de5\u4f5c\u3002</p> <ol> <li> <p>\u9996\u5148\uff0c\u8981\u786e\u4fdd\u5df2\u7ecf\u5b8c\u6210\u4e86<code>\u96c6\u7fa4\u5316\u73af\u5883\u524d\u7f6e\u51c6\u5907</code>\u73af\u8282\u7684\u5168\u90e8\u5185\u5bb9</p> </li> <li> <p>\u3010node1\u4e0a\u64cd\u4f5c\u3011\u4e0b\u8f7dZookeeper\u5b89\u88c5\u5305\uff0c\u5e76\u89e3\u538b</p> </li> </ol> <pre><code># \u4e0b\u8f7d\nwget http://archive.apache.org/dist/zookeeper/zookeeper-3.5.9/apache-zookeeper-3.5.9-bin.tar.gz\n\n# \u786e\u4fdd\u5982\u4e0b\u76ee\u5f55\u5b58\u5728\uff0c\u4e0d\u5b58\u5728\u5c31\u521b\u5efa\nmkdir -p /export/server\n\n# \u89e3\u538b\ntar -zxvf apache-zookeeper-3.5.9-bin.tar.gz -C /export/server\n</code></pre> <ol> <li>\u3010node1\u4e0a\u64cd\u4f5c\u3011\u521b\u5efa\u8f6f\u94fe\u63a5</li> </ol> <pre><code>ln -s /export/server/apache-zookeeper-3.5.9 /export/server/zookeeper\n</code></pre> <ol> <li>\u3010node1\u4e0a\u64cd\u4f5c\u3011\u4fee\u6539\u914d\u7f6e\u6587\u4ef6</li> </ol> <pre><code>vim /export/server/zookeeper/conf/zoo.cfg\n\ntickTime=2000\n# zookeeper\u6570\u636e\u5b58\u50a8\u76ee\u5f55\ndataDir=/export/server/zookeeper/data\nclientPort=2181\ninitLimit=5\nsyncLimit=2\nserver.1=node1:2888:3888\nserver.2=node2:2888:3888\nserver.3=node3:2888:3888\n</code></pre> <ol> <li>\u3010node1\u4e0a\u64cd\u4f5c\u3011\u914d\u7f6e<code>myid</code></li> </ol> <pre><code># 1. \u521b\u5efaZookeeper\u7684\u6570\u636e\u76ee\u5f55\nmkdir /export/server/zookeeper/data\n\n# 2. \u521b\u5efa\u6587\u4ef6\uff0c\u5e76\u586b\u51651\nvim /export/server/zookeeper/data/myid\n# \u5728\u6587\u4ef6\u5185\u586b\u51651\u5373\u53ef\n</code></pre> <ol> <li>\u3010\u5728node2\u548cnode3\u4e0a\u64cd\u4f5c\u3011\uff0c\u521b\u5efa\u6587\u4ef6\u5939</li> </ol> <pre><code>mkdir -p /export/server\n</code></pre> <ol> <li>\u3010node1\u4e0a\u64cd\u4f5c\u3011\u5c06Zookeeper \u590d\u5236\u5230node2\u548cnode3</li> </ol> <pre><code>cd /export/server\n\nscp -r apache-zookeeper-3.5.9 node2:`pwd`/\nscp -r apache-zookeeper-3.5.9 node3:`pwd`/\n</code></pre> <ol> <li>\u3010\u5728node2\u4e0a\u64cd\u4f5c\u3011</li> </ol> <pre><code># 1. \u521b\u5efa\u8f6f\u94fe\u63a5\nln -s /export/server/apache-zookeeper-3.5.9 /export/server/zookeeper\n\n# 2. \u4fee\u6539myid\u6587\u4ef6\nvim /export/server/zookeeper/data/myid\n# \u4fee\u6539\u5185\u5bb9\u4e3a2\n</code></pre> <ol> <li>\u3010\u5728node3\u4e0a\u64cd\u4f5c\u3011</li> </ol> <pre><code># 1. \u521b\u5efa\u8f6f\u94fe\u63a5\nln -s /export/server/apache-zookeeper-3.5.9 /export/server/zookeeper\n\n# 2. \u4fee\u6539myid\u6587\u4ef6\nvim /export/server/zookeeper/data/myid\n# \u4fee\u6539\u5185\u5bb9\u4e3a3\n</code></pre> <ol> <li> <p>\u3010\u5728node1\u3001node2\u3001node3\u4e0a\u5206\u522b\u6267\u884c\u3011\u542f\u52a8Zookeeper</p> <pre><code># \u542f\u52a8\u547d\u4ee4\n/export/server/zookeeper/bin/zkServer.sh start      # \u542f\u52a8Zookeeper\n</code></pre> </li> <li> <p>\u3010\u5728node1\u3001node2\u3001node3\u4e0a\u5206\u522b\u6267\u884c\u3011\u68c0\u67e5Zookeeper\u8fdb\u7a0b\u662f\u5426\u542f\u52a8</p> <pre><code>jps\n\n# \u7ed3\u679c\u4e2d\u627e\u5230\u6709\uff1aQuorumPeerMain \u8fdb\u7a0b\u5373\u53ef\n</code></pre> </li> <li> <p>\u3010node1\u4e0a\u64cd\u4f5c\u3011\u9a8c\u8bc1Zookeeper</p> <pre><code>/export/server/zookeeper/zkCli.sh\n\n# \u8fdb\u5165\u5230Zookeeper\u63a7\u5236\u53f0\u4e2d\u540e\uff0c\u6267\u884c\nls /\n\n# \u5982\u65e0\u62a5\u9519\u5373\u914d\u7f6e\u6210\u529f\n</code></pre> </li> </ol> <p>\u81f3\u6b64Zookeeper\u5b89\u88c5\u5b8c\u6210</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#kafka","title":"Kafka\u96c6\u7fa4\u5b89\u88c5\u90e8\u7f72","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_31","title":"\u7b80\u4ecb","text":"<p>Kafka\u662f\u4e00\u6b3e<code>\u5206\u5e03\u5f0f\u7684\u3001\u53bb\u4e2d\u5fc3\u5316\u7684\u3001\u9ad8\u541e\u5410\u4f4e\u5ef6\u8fdf\u3001\u8ba2\u9605\u6a21\u5f0f</code>\u7684\u6d88\u606f\u961f\u5217\u7cfb\u7edf\u3002</p> <p>\u540cRabbitMQ\u4e00\u6837\uff0cKafka\u4e5f\u662f\u6d88\u606f\u961f\u5217\u3002\u4e0d\u8fc7RabbitMQ\u591a\u7528\u4e8e\u540e\u7aef\u7cfb\u7edf\uff0c\u56e0\u5176\u66f4\u52a0\u4e13\u6ce8\u4e8e\u6d88\u606f\u7684\u5ef6\u8fdf\u548c\u5bb9\u9519\u3002</p> <p>Kafka\u591a\u7528\u4e8e\u5927\u6570\u636e\u4f53\u7cfb\uff0c\u56e0\u5176\u66f4\u52a0\u4e13\u6ce8\u4e8e\u6570\u636e\u7684\u541e\u5410\u80fd\u529b\u3002</p> <p>Kafka\u591a\u6570\u90fd\u662f\u8fd0\u884c\u5728\u5206\u5e03\u5f0f\uff08\u96c6\u7fa4\u5316\uff09\u6a21\u5f0f\u4e0b\uff0c\u6240\u4ee5\u8bfe\u7a0b\u5c06\u4ee53\u53f0\u670d\u52a1\u5668\uff0c\u6765\u5b8c\u6210Kafka\u96c6\u7fa4\u7684\u5b89\u88c5\u90e8\u7f72\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_32","title":"\u5b89\u88c5","text":"<ol> <li>\u786e\u4fdd\u5df2\u7ecf\u8ddf\u968f\u524d\u9762\u7684\u89c6\u9891\uff0c\u5b89\u88c5\u5e76\u90e8\u7f72\u4e86JDK\u548cZookeeper\u670d\u52a1</li> </ol> <p>Kafka\u7684\u8fd0\u884c\u4f9d\u8d56JDK\u73af\u5883\u548cZookeeper\u8bf7\u786e\u4fdd\u5df2\u7ecf\u6709\u4e86JDK\u73af\u5883\u548cZookeeper</p> <ol> <li>\u3010\u5728node1\u64cd\u4f5c\u3011\u4e0b\u8f7d\u5e76\u4e0a\u4f20Kafka\u7684\u5b89\u88c5\u5305</li> </ol> <pre><code># \u4e0b\u8f7d\u5b89\u88c5\u5305\nwget http://archive.apache.org/dist/kafka/2.4.1/kafka_2.12-2.4.1.tgz\n</code></pre> <ol> <li>\u3010\u5728node1\u64cd\u4f5c\u3011\u89e3\u538b</li> </ol> <pre><code>mkdir -p /export/server          # \u6b64\u6587\u4ef6\u5939\u5982\u679c\u4e0d\u5b58\u5728\u9700\u5148\u521b\u5efa\n\n# \u89e3\u538b\ntar -zxvf kafka_2.12-2.4.1.tgz -C /export/server/\n\n# \u521b\u5efa\u8f6f\u94fe\u63a5\nln -s /export/server/kafka_2.12-2.4.1 /export/server/kafka\n</code></pre> <ol> <li>\u3010\u5728node1\u64cd\u4f5c\u3011\u4fee\u6539Kafka\u76ee\u5f55\u5185\u7684config\u76ee\u5f55\u5185\u7684<code>server.properties</code>\u6587\u4ef6</li> </ol> <pre><code>cd /export/server/kafka/config\n# \u6307\u5b9abroker\u7684id\nbroker.id=1\n# \u6307\u5b9a kafka\u7684\u7ed1\u5b9a\u76d1\u542c\u7684\u5730\u5740\nlisteners=PLAINTEXT://node1:9092\n# \u6307\u5b9aKafka\u6570\u636e\u7684\u4f4d\u7f6e\nlog.dirs=/export/server/kafka/data\n# \u6307\u5b9aZookeeper\u7684\u4e09\u4e2a\u8282\u70b9\nzookeeper.connect=node1:2181,node2:2181,node3:2181\n</code></pre> <ol> <li>\u3010\u5728node1\u64cd\u4f5c\u3011\u5c06node1\u7684kafka\u590d\u5236\u5230node2\u548cnode3</li> </ol> <pre><code>cd /export/server\n\n# \u590d\u5236\u5230node2\u540c\u540d\u6587\u4ef6\u5939\nscp -r kafka_2.12-2.4.1 node2:`pwd`/\n# \u590d\u5236\u5230node3\u540c\u540d\u6587\u4ef6\u5939\nscp -r kafka_2.12-2.4.1 node3:$PWD\n</code></pre> <ol> <li>\u3010\u5728node2\u64cd\u4f5c\u3011</li> </ol> <pre><code># \u521b\u5efa\u8f6f\u94fe\u63a5\nln -s /export/server/kafka_2.12-2.4.1 /export/server/kafka\n\ncd /export/server/kafka/config\n# \u6307\u5b9abroker\u7684id\nbroker.id=2\n# \u6307\u5b9a kafka\u7684\u7ed1\u5b9a\u76d1\u542c\u7684\u5730\u5740\nlisteners=PLAINTEXT://node2:9092\n# \u6307\u5b9aKafka\u6570\u636e\u7684\u4f4d\u7f6e\nlog.dirs=/export/server/kafka/data\n# \u6307\u5b9aZookeeper\u7684\u4e09\u4e2a\u8282\u70b9\nzookeeper.connect=node1:2181,node2:2181,node3:2181\n</code></pre> <ol> <li>\u3010\u5728node3\u64cd\u4f5c\u3011</li> </ol> <pre><code># \u521b\u5efa\u8f6f\u94fe\u63a5\nln -s /export/server/kafka_2.12-2.4.1 /export/server/kafka\n\ncd /export/server/kafka/config\n# \u6307\u5b9abroker\u7684id\nbroker.id=3\n# \u6307\u5b9a kafka\u7684\u7ed1\u5b9a\u76d1\u542c\u7684\u5730\u5740\nlisteners=PLAINTEXT://node3:9092\n# \u6307\u5b9aKafka\u6570\u636e\u7684\u4f4d\u7f6e\nlog.dirs=/export/server/kafka/data\n# \u6307\u5b9aZookeeper\u7684\u4e09\u4e2a\u8282\u70b9\nzookeeper.connect=node1:2181,node2:2181,node3:2181\n</code></pre> <ol> <li>\u542f\u52a8kafka</li> </ol> <pre><code># \u8bf7\u5148\u786e\u4fddZookeeper\u5df2\u7ecf\u542f\u52a8\u4e86\n\n# \u65b9\u5f0f1\uff1a\u3010\u524d\u53f0\u542f\u52a8\u3011\u5206\u522b\u5728node1\u30012\u30013\u4e0a\u6267\u884c\u5982\u4e0b\u8bed\u53e5\n/export/server/kafka/bin/kafka-server-start.sh /export/server/kafka/config/server.properties\n\n# \u65b9\u5f0f2\uff1a\u3010\u540e\u53f0\u542f\u52a8\u3011\u5206\u522b\u5728node1\u30012\u30013\u4e0a\u6267\u884c\u5982\u4e0b\u8bed\u53e5\nnohup /export/server/kafka/bin/kafka-server-start.sh /export/server/kafka/config/server.properties 2&gt;&amp;1 &gt;&gt; /export/server/kafka/kafka-server.log &amp;\n</code></pre> <ol> <li>\u9a8c\u8bc1Kafka\u542f\u52a8</li> </ol> <pre><code># \u5728\u6bcf\u4e00\u53f0\u670d\u52a1\u5668\u6267\u884c\njps\n</code></pre> <p></p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#kafka_1","title":"\u6d4b\u8bd5Kafka\u80fd\u5426\u6b63\u5e38\u4f7f\u7528","text":"<ol> <li>\u521b\u5efa\u6d4b\u8bd5\u4e3b\u9898</li> </ol> <pre><code># \u5728node1\u6267\u884c\uff0c\u521b\u5efa\u4e00\u4e2a\u4e3b\u9898\n/export/server/kafka_2.12-2.4.1/bin/kafka-topics.sh --create --zookeeper node1:2181 --replication-factor 1 --partitions 3 --topic test\n</code></pre> <ol> <li>\u8fd0\u884c\u6d4b\u8bd5\uff0c\u8bf7\u5728FinalShell\u4e2d\u6253\u5f002\u4e2anode1\u7684\u7ec8\u7aef\u9875\u9762</li> </ol> <pre><code># \u6253\u5f00\u4e00\u4e2a\u7ec8\u7aef\u9875\u9762\uff0c\u542f\u52a8\u4e00\u4e2a\u6a21\u62df\u7684\u6570\u636e\u751f\u4ea7\u8005\n/export/server/kafka_2.12-2.4.1/bin/kafka-console-producer.sh --broker-list node1:9092 --topic test\n# \u518d\u6253\u5f00\u4e00\u4e2a\u65b0\u7684\u7ec8\u7aef\u9875\u9762\uff0c\u5728\u542f\u52a8\u4e00\u4e2a\u6a21\u62df\u7684\u6570\u636e\u6d88\u8d39\u8005\n/export/server/kafka_2.12-2.4.1/bin/kafka-console-consumer.sh --bootstrap-server node1:9092 --topic test --from-beginning\n</code></pre>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#hadoop","title":"\u5927\u6570\u636e\u96c6\u7fa4\uff08Hadoop\u751f\u6001\uff09\u5b89\u88c5\u90e8\u7f72","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_33","title":"\u7b80\u4ecb","text":"<p>1\uff09Hadoop\u662f\u4e00\u4e2a\u7531Apache\u57fa\u91d1\u4f1a\u6240\u5f00\u53d1\u7684\u5206\u5e03\u5f0f\u7cfb\u7edf\u57fa\u7840\u67b6\u6784\u3002 2\uff09\u4e3b\u8981\u89e3\u51b3\uff0c\u6d77\u91cf\u6570\u636e\u7684\u5b58\u50a8\u548c\u6d77\u91cf\u6570\u636e\u7684\u5206\u6790\u8ba1\u7b97\u95ee\u9898\u3002</p> <p>Hadoop HDFS \u63d0\u4f9b\u5206\u5e03\u5f0f\u6d77\u91cf\u6570\u636e\u5b58\u50a8\u80fd\u529b</p> <p>Hadoop YARN \u63d0\u4f9b\u5206\u5e03\u5f0f\u96c6\u7fa4\u8d44\u6e90\u7ba1\u7406\u80fd\u529b</p> <p>Hadoop MapReduce \u63d0\u4f9b\u5206\u5e03\u5f0f\u6d77\u91cf\u6570\u636e\u8ba1\u7b97\u80fd\u529b</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_34","title":"\u524d\u7f6e\u8981\u6c42","text":"<ul> <li>\u8bf7\u786e\u4fdd\u5b8c\u6210\u4e86\u96c6\u7fa4\u5316\u73af\u5883\u524d\u7f6e\u51c6\u5907\u7ae0\u8282\u7684\u5185\u5bb9</li> <li>\u5373\uff1aJDK\u3001SSH\u514d\u5bc6\u3001\u5173\u95ed\u9632\u706b\u5899\u3001\u914d\u7f6e\u4e3b\u673a\u540d\u6620\u5c04\u7b49\u524d\u7f6e\u64cd\u4f5c</li> </ul>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#hadoop_1","title":"Hadoop\u96c6\u7fa4\u89d2\u8272","text":"<p>Hadoop\u751f\u6001\u4f53\u7cfb\u4e2d\u603b\u5171\u4f1a\u51fa\u73b0\u5982\u4e0b\u8fdb\u7a0b\u89d2\u8272\uff1a</p> <ol> <li>Hadoop HDFS\u7684\u7ba1\u7406\u89d2\u8272\uff1aNamenode\u8fdb\u7a0b\uff08<code>\u4ec5\u97001\u4e2a\u5373\u53ef\uff08\u7ba1\u7406\u8005\u4e00\u4e2a\u5c31\u591f\uff09</code>\uff09</li> <li>Hadoop HDFS\u7684\u5de5\u4f5c\u89d2\u8272\uff1aDatanode\u8fdb\u7a0b\uff08<code>\u9700\u8981\u591a\u4e2a\uff08\u5de5\u4eba\uff0c\u8d8a\u591a\u8d8a\u597d\uff0c\u4e00\u4e2a\u673a\u5668\u542f\u52a8\u4e00\u4e2a\uff09</code>\uff09</li> <li>Hadoop YARN\u7684\u7ba1\u7406\u89d2\u8272\uff1aResourceManager\u8fdb\u7a0b\uff08<code>\u4ec5\u97001\u4e2a\u5373\u53ef\uff08\u7ba1\u7406\u8005\u4e00\u4e2a\u5c31\u591f\uff09</code>\uff09</li> <li>Hadoop YARN\u7684\u5de5\u4f5c\u89d2\u8272\uff1aNodeManager\u8fdb\u7a0b\uff08<code>\u9700\u8981\u591a\u4e2a\uff08\u5de5\u4eba\uff0c\u8d8a\u591a\u8d8a\u597d\uff0c\u4e00\u4e2a\u673a\u5668\u542f\u52a8\u4e00\u4e2a\uff09</code>\uff09</li> <li>Hadoop \u5386\u53f2\u8bb0\u5f55\u670d\u52a1\u5668\u89d2\u8272\uff1aHistoryServer\u8fdb\u7a0b\uff08<code>\u4ec5\u97001\u4e2a\u5373\u53ef\uff08\u529f\u80fd\u8fdb\u7a0b\u65e0\u9700\u592a\u591a1\u4e2a\u8db3\u591f\uff09</code>\uff09</li> <li>Hadoop \u4ee3\u7406\u670d\u52a1\u5668\u89d2\u8272\uff1aWebProxyServer\u8fdb\u7a0b\uff08<code>\u4ec5\u97001\u4e2a\u5373\u53ef\uff08\u529f\u80fd\u8fdb\u7a0b\u65e0\u9700\u592a\u591a1\u4e2a\u8db3\u591f\uff09</code>\uff09</li> <li>Zookeeper\u7684\u8fdb\u7a0b\uff1aQuorumPeerMain\u8fdb\u7a0b\uff08<code>\u4ec5\u97001\u4e2a\u5373\u53ef\uff08Zookeeper\u7684\u5de5\u4f5c\u8005\uff0c\u8d8a\u591a\u8d8a\u597d\uff09</code>\uff09</li> </ol>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_35","title":"\u89d2\u8272\u548c\u8282\u70b9\u5206\u914d","text":"<p>\u89d2\u8272\u5206\u914d\u5982\u4e0b\uff1a</p> <ol> <li>node1:Namenode\u3001Datanode\u3001ResourceManager\u3001NodeManager\u3001HistoryServer\u3001WebProxyServer\u3001QuorumPeerMain</li> <li>node2:Datanode\u3001NodeManager\u3001QuorumPeerMain</li> <li>node3:Datanode\u3001NodeManager\u3001QuorumPeerMain</li> </ol> <p></p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_36","title":"\u5b89\u88c5","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_37","title":"\u8c03\u6574\u865a\u62df\u673a\u5185\u5b58","text":"<p>\u5982\u4e0a\u56fe\uff0c\u53ef\u4ee5\u770b\u51fanode1\u627f\u8f7d\u4e86\u592a\u591a\u7684\u538b\u529b\u3002\u540c\u65f6node2\u548cnode3\u4e5f\u540c\u65f6\u8fd0\u884c\u4e86\u4e0d\u5c11\u7a0b\u5e8f</p> <p>\u4e3a\u4e86\u786e\u4fdd\u96c6\u7fa4\u7684\u7a33\u5b9a\uff0c\u9700\u8981\u5bf9\u865a\u62df\u673a\u8fdb\u884c\u5185\u5b58\u8bbe\u7f6e\u3002</p> <p>\u8bf7\u5728VMware\u4e2d\uff0c\u5bf9\uff1a</p> <ol> <li>node1\u8bbe\u7f6e4GB\u6216\u4ee5\u4e0a\u5185\u5b58</li> <li>node2\u548cnode3\u8bbe\u7f6e2GB\u6216\u4ee5\u4e0a\u5185\u5b58</li> </ol> <p>\u5927\u6570\u636e\u7684\u8f6f\u4ef6\u672c\u8eab\u5c31\u662f\u96c6\u7fa4\u5316\uff08\u4e00\u5806\u670d\u52a1\u5668\uff09\u4e00\u8d77\u8fd0\u884c\u7684\u3002</p> <p>\u73b0\u5728\u6211\u4eec\u5728\u4e00\u53f0\u7535\u8111\u4e2d\u4ee5\u591a\u53f0\u865a\u62df\u673a\u6765\u6a21\u62df\u96c6\u7fa4\uff0c\u786e\u5b9e\u4f1a\u6709\u5f88\u5927\u7684\u5185\u5b58\u538b\u529b\u54e6\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#zookeeper_1","title":"Zookeeper\u96c6\u7fa4\u90e8\u7f72","text":"<p>\u7565</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#hadoop_2","title":"Hadoop\u96c6\u7fa4\u90e8\u7f72","text":"<ol> <li>\u4e0b\u8f7dHadoop\u5b89\u88c5\u5305\u3001\u89e3\u538b\u3001\u914d\u7f6e\u8f6f\u94fe\u63a5</li> </ol> <pre><code># 1. \u4e0b\u8f7d\nwget http://archive.apache.org/dist/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz\n\n# 2. \u89e3\u538b\n# \u8bf7\u786e\u4fdd\u76ee\u5f55/export/server\u5b58\u5728\ntar -zxvf hadoop-3.3.0.tar.gz -C /export/server/\n\n# 3. \u6784\u5efa\u8f6f\u94fe\u63a5\nln -s /export/server/hadoop-3.3.0 /export/server/hadoop\n</code></pre> <ol> <li>\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\uff1a<code>hadoop-env.sh</code></li> </ol> <p>Hadoop\u7684\u914d\u7f6e\u6587\u4ef6\u8981\u4fee\u6539\u7684\u5730\u65b9\u5f88\u591a\uff0c\u8bf7\u7ec6\u5fc3</p> <p>cd \u8fdb\u5165\u5230/export/server/hadoop/etc/hadoop\uff0c\u6587\u4ef6\u5939\u4e2d\uff0c\u914d\u7f6e\u6587\u4ef6\u90fd\u5728\u8fd9\u91cc</p> <p>\u4fee\u6539hadoop-env.sh\u6587\u4ef6</p> <p>\u6b64\u6587\u4ef6\u662f\u914d\u7f6e\u4e00\u4e9bHadoop\u7528\u5230\u7684\u73af\u5883\u53d8\u91cf</p> <p>\u8fd9\u4e9b\u662f\u4e34\u65f6\u53d8\u91cf\uff0c\u5728Hadoop\u8fd0\u884c\u65f6\u6709\u7528</p> <p>\u5982\u679c\u8981\u6c38\u4e45\u751f\u6548\uff0c\u9700\u8981\u5199\u5230/etc/profile\u4e2d</p> <pre><code># \u5728\u6587\u4ef6\u5f00\u5934\u52a0\u5165\uff1a\n# \u914d\u7f6eJava\u5b89\u88c5\u8def\u5f84\nexport JAVA_HOME=/export/server/jdk\n# \u914d\u7f6eHadoop\u5b89\u88c5\u8def\u5f84\nexport HADOOP_HOME=/export/server/hadoop\n# Hadoop hdfs\u914d\u7f6e\u6587\u4ef6\u8def\u5f84\nexport HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop\n# Hadoop YARN\u914d\u7f6e\u6587\u4ef6\u8def\u5f84\nexport YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop\n# Hadoop YARN \u65e5\u5fd7\u6587\u4ef6\u5939\nexport YARN_LOG_DIR=$HADOOP_HOME/logs/yarn\n# Hadoop hdfs \u65e5\u5fd7\u6587\u4ef6\u5939\nexport HADOOP_LOG_DIR=$HADOOP_HOME/logs/hdfs\n\n# Hadoop\u7684\u4f7f\u7528\u542f\u52a8\u7528\u6237\u914d\u7f6e\nexport HDFS_NAMENODE_USER=root\nexport HDFS_DATANODE_USER=root\nexport HDFS_SECONDARYNAMENODE_USER=root\nexport YARN_RESOURCEMANAGER_USER=root\nexport YARN_NODEMANAGER_USER=root\nexport YARN_PROXYSERVER_USER=root\n</code></pre> <ol> <li>\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\uff1a<code>core-site.xml</code></li> </ol> <p>\u5982\u4e0b\uff0c\u6e05\u7a7a\u6587\u4ef6\uff0c\u586b\u5165\u5982\u4e0b\u5185\u5bb9</p> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?&gt;\n&lt;!--\n  Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License. See accompanying LICENSE file.\n--&gt;\n\n&lt;!-- Put site-specific property overrides in this file. --&gt;\n&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;fs.defaultFS&lt;/name&gt;\n    &lt;value&gt;hdfs://node1:8020&lt;/value&gt;\n    &lt;description&gt;&lt;/description&gt;\n  &lt;/property&gt;\n\n  &lt;property&gt;\n    &lt;name&gt;io.file.buffer.size&lt;/name&gt;\n    &lt;value&gt;131072&lt;/value&gt;\n    &lt;description&gt;&lt;/description&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre> <ol> <li>\u914d\u7f6e\uff1a<code>hdfs-site.xml</code>\u6587\u4ef6</li> </ol> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?&gt;\n&lt;!--\n  Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License. See accompanying LICENSE file.\n--&gt;\n\n&lt;!-- Put site-specific property overrides in this file. --&gt;\n\n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.datanode.data.dir.perm&lt;/name&gt;\n        &lt;value&gt;700&lt;/value&gt;\n    &lt;/property&gt;\n\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n    &lt;value&gt;/data/nn&lt;/value&gt;\n    &lt;description&gt;Path on the local filesystem where the NameNode stores the namespace and transactions logs persistently.&lt;/description&gt;\n  &lt;/property&gt;\n\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.hosts&lt;/name&gt;\n    &lt;value&gt;node1,node2,node3&lt;/value&gt;\n    &lt;description&gt;List of permitted DataNodes.&lt;/description&gt;\n  &lt;/property&gt;\n\n  &lt;property&gt;\n    &lt;name&gt;dfs.blocksize&lt;/name&gt;\n    &lt;value&gt;268435456&lt;/value&gt;\n    &lt;description&gt;&lt;/description&gt;\n  &lt;/property&gt;\n\n\n  &lt;property&gt;\n    &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt;\n    &lt;value&gt;100&lt;/value&gt;\n    &lt;description&gt;&lt;/description&gt;\n  &lt;/property&gt;\n\n  &lt;property&gt;\n    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n    &lt;value&gt;/data/dn&lt;/value&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre> <ol> <li>\u914d\u7f6e\uff1a<code>mapred-env.sh</code>\u6587\u4ef6</li> </ol> <pre><code># \u5728\u6587\u4ef6\u7684\u5f00\u5934\u52a0\u5165\u5982\u4e0b\u73af\u5883\u53d8\u91cf\u8bbe\u7f6e\nexport JAVA_HOME=/export/server/jdk\nexport HADOOP_JOB_HISTORYSERVER_HEAPSIZE=1000\nexport HADOOP_MAPRED_ROOT_LOGGER=INFO,RFA\n</code></pre> <ol> <li>\u914d\u7f6e\uff1a<code>mapred-site.xml</code>\u6587\u4ef6</li> </ol> <pre><code>&lt;?xml version=\"1.0\"?&gt;\n&lt;?xml-stylesheet type=\"text/xsl\" href=\"configuration.xsl\"?&gt;\n&lt;!--\n  Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License. See accompanying LICENSE file.\n--&gt;\n\n&lt;!-- Put site-specific property overrides in this file. --&gt;\n\n&lt;configuration&gt;\n  &lt;property&gt;\n    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n    &lt;value&gt;yarn&lt;/value&gt;\n    &lt;description&gt;&lt;/description&gt;\n  &lt;/property&gt;\n\n  &lt;property&gt;\n    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;\n    &lt;value&gt;node1:10020&lt;/value&gt;\n    &lt;description&gt;&lt;/description&gt;\n  &lt;/property&gt;\n\n\n  &lt;property&gt;\n    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;\n    &lt;value&gt;node1:19888&lt;/value&gt;\n    &lt;description&gt;&lt;/description&gt;\n  &lt;/property&gt;\n\n\n  &lt;property&gt;\n    &lt;name&gt;mapreduce.jobhistory.intermediate-done-dir&lt;/name&gt;\n    &lt;value&gt;/data/mr-history/tmp&lt;/value&gt;\n    &lt;description&gt;&lt;/description&gt;\n  &lt;/property&gt;\n\n\n  &lt;property&gt;\n    &lt;name&gt;mapreduce.jobhistory.done-dir&lt;/name&gt;\n    &lt;value&gt;/data/mr-history/done&lt;/value&gt;\n    &lt;description&gt;&lt;/description&gt;\n  &lt;/property&gt;\n&lt;property&gt;\n  &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;\n  &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n  &lt;name&gt;mapreduce.map.env&lt;/name&gt;\n  &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;\n&lt;/property&gt;\n&lt;property&gt;\n  &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;\n  &lt;value&gt;HADOOP_MAPRED_HOME=$HADOOP_HOME&lt;/value&gt;\n&lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre> <ol> <li>\u914d\u7f6e\uff1a<code>yarn-env.sh</code>\u6587\u4ef6</li> </ol> <pre><code># \u5728\u6587\u4ef6\u7684\u5f00\u5934\u52a0\u5165\u5982\u4e0b\u73af\u5883\u53d8\u91cf\u8bbe\u7f6e\nexport JAVA_HOME=/export/server/jdk\nexport HADOOP_HOME=/export/server/hadoop\nexport HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop\nexport YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop\nexport YARN_LOG_DIR=$HADOOP_HOME/logs/yarn\nexport HADOOP_LOG_DIR=$HADOOP_HOME/logs/hdfs\n</code></pre> <ol> <li>\u914d\u7f6e\uff1a<code>yarn-site.xml</code>\u6587\u4ef6</li> </ol> <pre><code>&lt;?xml version=\"1.0\"?&gt;\n&lt;!--\n  Licensed under the Apache License, Version 2.0 (the \"License\");\n  you may not use this file except in compliance with the License.\n  You may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\n  Unless required by applicable law or agreed to in writing, software\n  distributed under the License is distributed on an \"AS IS\" BASIS,\n  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n  See the License for the specific language governing permissions and\n  limitations under the License. See accompanying LICENSE file.\n--&gt;\n&lt;configuration&gt;\n\n&lt;!-- Site specific YARN configuration properties --&gt;\n&lt;property&gt;\n    &lt;name&gt;yarn.log.server.url&lt;/name&gt;\n    &lt;value&gt;http://node1:19888/jobhistory/logs&lt;/value&gt;\n    &lt;description&gt;&lt;/description&gt;\n&lt;/property&gt;\n\n  &lt;property&gt;\n    &lt;name&gt;yarn.web-proxy.address&lt;/name&gt;\n    &lt;value&gt;node1:8089&lt;/value&gt;\n    &lt;description&gt;proxy server hostname and port&lt;/description&gt;\n  &lt;/property&gt;\n\n\n  &lt;property&gt;\n    &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;\n    &lt;value&gt;true&lt;/value&gt;\n    &lt;description&gt;Configuration to enable or disable log aggregation&lt;/description&gt;\n  &lt;/property&gt;\n\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt;\n    &lt;value&gt;/tmp/logs&lt;/value&gt;\n    &lt;description&gt;Configuration to enable or disable log aggregation&lt;/description&gt;\n  &lt;/property&gt;\n\n\n&lt;!-- Site specific YARN configuration properties --&gt;\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;\n    &lt;value&gt;node1&lt;/value&gt;\n    &lt;description&gt;&lt;/description&gt;\n  &lt;/property&gt;\n\n  &lt;property&gt;\n    &lt;name&gt;yarn.resourcemanager.scheduler.class&lt;/name&gt;\n    &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler&lt;/value&gt;\n    &lt;description&gt;&lt;/description&gt;\n  &lt;/property&gt;\n\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.local-dirs&lt;/name&gt;\n    &lt;value&gt;/data/nm-local&lt;/value&gt;\n    &lt;description&gt;Comma-separated list of paths on the local filesystem where intermediate data is written.&lt;/description&gt;\n  &lt;/property&gt;\n\n\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.log-dirs&lt;/name&gt;\n    &lt;value&gt;/data/nm-log&lt;/value&gt;\n    &lt;description&gt;Comma-separated list of paths on the local filesystem where logs are written.&lt;/description&gt;\n  &lt;/property&gt;\n\n\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.log.retain-seconds&lt;/name&gt;\n    &lt;value&gt;10800&lt;/value&gt;\n    &lt;description&gt;Default time (in seconds) to retain log files on the NodeManager Only applicable if log-aggregation is disabled.&lt;/description&gt;\n  &lt;/property&gt;\n\n\n\n  &lt;property&gt;\n    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;\n    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;\n    &lt;description&gt;Shuffle service that needs to be set for Map Reduce applications.&lt;/description&gt;\n  &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre> <ol> <li>\u4fee\u6539workers\u6587\u4ef6</li> </ol> <pre><code># \u5168\u90e8\u5185\u5bb9\u5982\u4e0b\nnode1\nnode2\nnode3\n</code></pre> <ol> <li>\u5206\u53d1hadoop\u5230\u5176\u5b83\u673a\u5668</li> </ol> <pre><code># \u5728node1\u6267\u884c\ncd /export/server\n\nscp -r hadoop-3.3.0 node2:`pwd`/\nscp -r hadoop-3.3.0 node2:`pwd`/\n</code></pre> <ol> <li> <p>\u5728node2\u3001node3\u6267\u884c</p> <pre><code># \u521b\u5efa\u8f6f\u94fe\u63a5\nln -s /export/server/hadoop-3.3.0 /export/server/hadoop\n</code></pre> </li> <li> <p>\u521b\u5efa\u6240\u9700\u76ee\u5f55</p> <ul> <li>\u5728node1\u6267\u884c\uff1a</li> </ul> <pre><code>mkdir -p /data/nn\nmkdir -p /data/dn\nmkdir -p /data/nm-log\nmkdir -p /data/nm-local\n</code></pre> <ul> <li>\u5728node2\u6267\u884c\uff1a</li> </ul> <pre><code>mkdir -p /data/dn\nmkdir -p /data/nm-log\nmkdir -p /data/nm-local\n</code></pre> <ul> <li>\u5728node3\u6267\u884c\uff1a</li> </ul> <pre><code>mkdir -p /data/dn\nmkdir -p /data/nm-log\nmkdir -p /data/nm-local\n</code></pre> </li> <li> <p>\u914d\u7f6e\u73af\u5883\u53d8\u91cf</p> <p>\u5728node1\u3001node2\u3001node3\u4fee\u6539/etc/profile</p> <pre><code>export HADOOP_HOME=/export/server/hadoop\nexport PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\n</code></pre> <p>\u6267\u884c<code>source /etc/profile</code>\u751f\u6548</p> </li> <li> <p>\u683c\u5f0f\u5316NameNode\uff0c\u5728node1\u6267\u884c</p> <pre><code>hadoop namenode -format\n</code></pre> <p>hadoop\u8fd9\u4e2a\u547d\u4ee4\u6765\u81ea\u4e8e\uff1a$HADOOP_HOME/bin\u4e2d\u7684\u7a0b\u5e8f</p> <p>\u7531\u4e8e\u914d\u7f6e\u4e86\u73af\u5883\u53d8\u91cfPATH\uff0c\u6240\u4ee5\u53ef\u4ee5\u5728\u4efb\u610f\u4f4d\u7f6e\u6267\u884chadoop\u547d\u4ee4\u54e6</p> </li> <li> <p>\u542f\u52a8hadoop\u7684hdfs\u96c6\u7fa4\uff0c\u5728node1\u6267\u884c\u5373\u53ef</p> <pre><code>start-dfs.sh\n\n# \u5982\u9700\u505c\u6b62\u53ef\u4ee5\u6267\u884c\nstop-dfs.sh\n</code></pre> <p>start-dfs.sh\u8fd9\u4e2a\u547d\u4ee4\u6765\u81ea\u4e8e\uff1a$HADOOP_HOME/sbin\u4e2d\u7684\u7a0b\u5e8f</p> <p>\u7531\u4e8e\u914d\u7f6e\u4e86\u73af\u5883\u53d8\u91cfPATH\uff0c\u6240\u4ee5\u53ef\u4ee5\u5728\u4efb\u610f\u4f4d\u7f6e\u6267\u884cstart-dfs.sh\u547d\u4ee4\u54e6</p> </li> <li> <p>\u542f\u52a8hadoop\u7684yarn\u96c6\u7fa4\uff0c\u5728node1\u6267\u884c\u5373\u53ef</p> <pre><code>start-yarn.sh\n\n# \u5982\u9700\u505c\u6b62\u53ef\u4ee5\u6267\u884c\nstop-yarn.sh\n</code></pre> </li> <li> <p>\u542f\u52a8\u5386\u53f2\u670d\u52a1\u5668</p> <pre><code>mapred --daemon start historyserver\n\n# \u5982\u9700\u505c\u6b62\u5c06start\u66f4\u6362\u4e3astop\n</code></pre> </li> <li> <p>\u542f\u52a8web\u4ee3\u7406\u670d\u52a1\u5668</p> <pre><code>yarn-daemon.sh start proxyserver\n\n# \u5982\u9700\u505c\u6b62\u5c06start\u66f4\u6362\u4e3astop\n</code></pre> </li> </ol>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#hadoop_3","title":"\u9a8c\u8bc1Hadoop\u96c6\u7fa4\u8fd0\u884c\u60c5\u51b5","text":"<ol> <li> <p>\u5728node1\u3001node2\u3001node3\u4e0a\u901a\u8fc7jps\u9a8c\u8bc1\u8fdb\u7a0b\u662f\u5426\u90fd\u542f\u52a8\u6210\u529f</p> </li> <li> <p>\u9a8c\u8bc1HDFS\uff0c\u6d4f\u89c8\u5668\u6253\u5f00\uff1ahttp://node1:9870</p> </li> </ol> <p>\u521b\u5efa\u6587\u4ef6test.txt\uff0c\u968f\u610f\u586b\u5165\u5185\u5bb9\uff0c\u5e76\u6267\u884c\uff1a</p> <pre><code>hadoop fs -put test.txt /test.txt\n\nhadoop fs -cat /test.txt\n</code></pre> <ol> <li>\u9a8c\u8bc1YARN\uff0c\u6d4f\u89c8\u5668\u6253\u5f00\uff1ahttp://node1:8088</li> </ol> <p>\u6267\u884c\uff1a</p> <pre><code># \u521b\u5efa\u6587\u4ef6words.txt\uff0c\u586b\u5165\u5982\u4e0b\u5185\u5bb9\nitheima itcast hadoop\nitheima hadoop hadoop\nitheima itcast\n\n# \u5c06\u6587\u4ef6\u4e0a\u4f20\u5230HDFS\u4e2d\nhadoop fs -put words.txt /words.txt\n\n# \u6267\u884c\u5982\u4e0b\u547d\u4ee4\u9a8c\u8bc1YARN\u662f\u5426\u6b63\u5e38\nhadoop jar /export/server/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.0.jar wordcount -Dmapred.job.queue.name=root.root /words.txt /output\n</code></pre>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#nosqlhbase","title":"\u5927\u6570\u636eNoSQL\u6570\u636e\u5e93HBase\u96c6\u7fa4\u90e8\u7f72","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_38","title":"\u7b80\u4ecb","text":"<p>HBase \u662f\u4e00\u79cd\u5206\u5e03\u5f0f\u3001\u53ef\u6269\u5c55\u3001\u652f\u6301\u6d77\u91cf\u6570\u636e\u5b58\u50a8\u7684 NoSQL \u6570\u636e\u5e93\u3002</p> <p>\u548cRedis\u4e00\u6837\uff0cHBase\u662f\u4e00\u6b3eKeyValue\u578b\u5b58\u50a8\u7684\u6570\u636e\u5e93\u3002</p> <p>\u4e0d\u8fc7\u548cRedis\u8bbe\u8ba1\u65b9\u5411\u4e0d\u540c</p> <ul> <li>Redis\u8bbe\u8ba1\u4e3a\u5c11\u91cf\u6570\u636e\uff0c\u8d85\u5feb\u68c0\u7d22</li> <li>HBase\u8bbe\u8ba1\u4e3a\u6d77\u91cf\u6570\u636e\uff0c\u5feb\u901f\u68c0\u7d22</li> </ul> <p>HBase\u5728\u5927\u6570\u636e\u9886\u57df\u5e94\u7528\u5341\u5206\u5e7f\u6cdb\uff0c\u73b0\u5728\u6211\u4eec\u6765\u5728node1\u3001node2\u3001node3\u4e0a\u90e8\u7f72HBase\u96c6\u7fa4\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_39","title":"\u5b89\u88c5","text":"<ol> <li> <p>HBase\u4f9d\u8d56Zookeeper\u3001JDK\u3001Hadoop\uff08HDFS\uff09\uff0c\u8bf7\u786e\u4fdd\u5df2\u7ecf\u5b8c\u6210\u524d\u9762</p> </li> <li> <p>\u96c6\u7fa4\u5316\u8f6f\u4ef6\u524d\u7f6e\u51c6\u5907\uff08JDK\uff09</p> </li> <li>Zookeeper</li> <li>Hadoop</li> <li> <p>\u8fd9\u4e9b\u73af\u8282\u7684\u8f6f\u4ef6\u5b89\u88c5</p> </li> <li> <p>\u3010node1\u6267\u884c\u3011\u4e0b\u8f7dHBase\u5b89\u88c5\u5305</p> </li> </ol> <pre><code># \u4e0b\u8f7d\nwget http://archive.apache.org/dist/hbase/2.1.0/hbase-2.1.0-bin.tar.gz\n\n# \u89e3\u538b\ntar -zxvf hbase-2.1.0-bin.tar.gz -C /export/server\n\n# \u914d\u7f6e\u8f6f\u94fe\u63a5\nln -s /export/server/hbase-2.1.0 /export/server/hbase\n</code></pre> <ol> <li>\u3010node1\u6267\u884c\u3011\uff0c\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\uff0c\u4fee\u6539<code>conf/hbase-env.sh</code>\u6587\u4ef6</li> </ol> <pre><code># \u572828\u884c\u914d\u7f6eJAVA_HOME\nexport JAVA_HOME=/export/server/jdk\n# \u5728126\u884c\u914d\u7f6e\uff1a\n# \u610f\u601d\u8868\u793a\uff0c\u4e0d\u4f7f\u7528HBase\u81ea\u5e26\u7684Zookeeper\uff0c\u800c\u662f\u7528\u72ec\u7acbZookeeper\nexport HBASE_MANAGES_ZK=false\n# \u5728\u4efb\u610f\u884c\uff0c\u6bd4\u598226\u884c\uff0c\u6dfb\u52a0\u5982\u4e0b\u5185\u5bb9\uff1a\nexport HBASE_DISABLE_HADOOP_CLASSPATH_LOOKUP=\"true\"\n</code></pre> <ol> <li>\u3010node1\u6267\u884c\u3011\uff0c\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\uff0c\u4fee\u6539<code>conf/hbase-site.xml</code>\u6587\u4ef6</li> </ol> <pre><code># \u5c06\u6587\u4ef6\u7684\u5168\u90e8\u5185\u5bb9\u66ff\u6362\u6210\u5982\u4e0b\u5185\u5bb9\uff1a\n&lt;configuration&gt;\n        &lt;!-- HBase\u6570\u636e\u5728HDFS\u4e2d\u7684\u5b58\u653e\u7684\u8def\u5f84 --&gt;\n        &lt;property&gt;\n            &lt;name&gt;hbase.rootdir&lt;/name&gt;\n            &lt;value&gt;hdfs://node1:8020/hbase&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;!-- Hbase\u7684\u8fd0\u884c\u6a21\u5f0f\u3002false\u662f\u5355\u673a\u6a21\u5f0f\uff0ctrue\u662f\u5206\u5e03\u5f0f\u6a21\u5f0f\u3002\u82e5\u4e3afalse,Hbase\u548cZookeeper\u4f1a\u8fd0\u884c\u5728\u540c\u4e00\u4e2aJVM\u91cc\u9762 --&gt;\n        &lt;property&gt;\n            &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;\n            &lt;value&gt;true&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;!-- ZooKeeper\u7684\u5730\u5740 --&gt;\n        &lt;property&gt;\n            &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;\n            &lt;value&gt;node1,node2,node3&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;!-- ZooKeeper\u5feb\u7167\u7684\u5b58\u50a8\u4f4d\u7f6e --&gt;\n        &lt;property&gt;\n            &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt;\n            &lt;value&gt;/export/server/apache-zookeeper-3.6.0-bin/data&lt;/value&gt;\n        &lt;/property&gt;\n        &lt;!--  V2.1\u7248\u672c\uff0c\u5728\u5206\u5e03\u5f0f\u60c5\u51b5\u4e0b, \u8bbe\u7f6e\u4e3afalse --&gt;\n        &lt;property&gt;\n            &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;\n            &lt;value&gt;false&lt;/value&gt;\n        &lt;/property&gt;\n&lt;/configuration&gt;\n</code></pre> <ol> <li>\u3010node1\u6267\u884c\u3011\uff0c\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\uff0c\u4fee\u6539<code>conf/regionservers</code>\u6587\u4ef6</li> </ol> <pre><code># \u586b\u5165\u5982\u4e0b\u5185\u5bb9\nnode1\nnode2\nnode3\n</code></pre> <ol> <li>\u3010node1\u6267\u884c\u3011\uff0c\u5206\u53d1hbase\u5230\u5176\u5b83\u673a\u5668</li> </ol> <pre><code>scp -r /export/server/hbase-2.1.0 node2:/export/server/\nscp -r /export/server/hbase-2.1.0 node3:/export/server/\n</code></pre> <ol> <li>\u3010node2\u3001node3\u6267\u884c\u3011\uff0c\u914d\u7f6e\u8f6f\u94fe\u63a5</li> </ol> <pre><code>ln -s /export/server/hbase-2.1.0 /export/server/hbase\n</code></pre> <ol> <li>\u3010node1\u3001node2\u3001node3\u6267\u884c\u3011\uff0c\u914d\u7f6e\u73af\u5883\u53d8\u91cf</li> </ol> <pre><code># \u914d\u7f6e\u5728/etc/profile\u5185\uff0c\u8ffd\u52a0\u5982\u4e0b\u4e24\u884c\nexport HBASE_HOME=/export/server/hbase\nexport PATH=$HBASE_HOME/bin:$PATH\n\nsource /etc/profile\n</code></pre> <ol> <li>\u3010node1\u6267\u884c\u3011\u542f\u52a8HBase</li> </ol> <p>\u8bf7\u786e\u4fdd\uff1aHadoop HDFS\u3001Zookeeper\u662f\u5df2\u7ecf\u542f\u52a8\u4e86\u7684</p> <pre><code>start-hbase.sh\n\n# \u5982\u9700\u505c\u6b62\u53ef\u4f7f\u7528\nstop-hbase.sh\n</code></pre> <p>\u7531\u4e8e\u6211\u4eec\u914d\u7f6e\u4e86\u73af\u5883\u53d8\u91cfexport PATH=\\(PATH:\\)HBASE_HOME/bin</p> <p>start-hbase.sh\u5373\u5728$HBASE_HOME/bin\u5185\uff0c\u6240\u4ee5\u53ef\u4ee5\u65e0\u8bba\u5f53\u524d\u76ee\u5f55\u5728\u54ea\uff0c\u5747\u53ef\u76f4\u63a5\u6267\u884c</p> <ol> <li> <p>\u9a8c\u8bc1HBase</p> <p>\u6d4f\u89c8\u5668\u6253\u5f00\uff1ahttp://node1:16010\uff0c\u5373\u53ef\u770b\u5230HBase\u7684WEB UI\u9875\u9762</p> </li> <li> <p>\u7b80\u5355\u6d4b\u8bd5\u4f7f\u7528HBase</p> <p>\u3010node1\u6267\u884c\u3011</p> <pre><code>hbase shell\n\n# \u521b\u5efa\u8868\ncreate 'test', 'cf'\n\n# \u63d2\u5165\u6570\u636e\nput 'test', 'rk001', 'cf:info', 'itheima'\n\n# \u67e5\u8be2\u6570\u636e\nget 'test', 'rk001'\n\n# \u626b\u63cf\u8868\u6570\u636e\nscan 'test'\n</code></pre> </li> </ol>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#spark","title":"\u5206\u5e03\u5f0f\u5185\u5b58\u8ba1\u7b97Spark\u73af\u5883\u90e8\u7f72","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_40","title":"\u6ce8\u610f","text":"<p>\u672c\u5c0f\u8282\u7684\u64cd\u4f5c\uff0c\u57fa\u4e8e\uff1a<code>\u5927\u6570\u636e\u96c6\u7fa4\uff08Hadoop\u751f\u6001\uff09\u5b89\u88c5\u90e8\u7f72</code>\u73af\u8282\u4e2d\u6240\u6784\u5efa\u7684Hadoop\u96c6\u7fa4</p> <p>\u5982\u679c\u6ca1\u6709Hadoop\u96c6\u7fa4\uff0c\u8bf7\u53c2\u9605\u524d\u7f6e\u5185\u5bb9\uff0c\u90e8\u7f72\u597d\u73af\u5883\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_41","title":"\u7b80\u4ecb","text":"<p>Spark\u662f\u4e00\u6b3e\u5206\u5e03\u5f0f\u5185\u5b58\u8ba1\u7b97\u5f15\u64ce\uff0c\u53ef\u4ee5\u652f\u6491\u6d77\u91cf\u6570\u636e\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u3002</p> <p>Spark\u5728\u5927\u6570\u636e\u4f53\u7cfb\u662f\u660e\u661f\u4ea7\u54c1\uff0c\u4f5c\u4e3a\u6700\u65b0\u4e00\u4ee3\u7684\u7efc\u5408\u8ba1\u7b97\u5f15\u64ce\uff0c\u652f\u6301\u79bb\u7ebf\u8ba1\u7b97\u548c\u5b9e\u65f6\u8ba1\u7b97\u3002</p> <p>\u5728\u5927\u6570\u636e\u9886\u57df\u5e7f\u6cdb\u5e94\u7528\uff0c\u662f\u76ee\u524d\u4e16\u754c\u4e0a\u4f7f\u7528\u6700\u591a\u7684\u5927\u6570\u636e\u5206\u5e03\u5f0f\u8ba1\u7b97\u5f15\u64ce\u3002</p> <p>\u6211\u4eec\u5c06\u57fa\u4e8e\u524d\u9762\u6784\u5efa\u7684Hadoop\u96c6\u7fa4\uff0c\u90e8\u7f72Spark Standalone\u96c6\u7fa4\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_42","title":"\u5b89\u88c5","text":"<ol> <li>\u3010node1\u6267\u884c\u3011\u4e0b\u8f7d\u5e76\u89e3\u538b</li> </ol> <pre><code>wget https://archive.apache.org/dist/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n\n# \u89e3\u538b\ntar -zxvf spark-2.4.5-bin-hadoop2.7.tgz -C /export/server/\n\n# \u8f6f\u94fe\u63a5\nln -s /export/server/spark-2.4.5-bin-hadoop2.7 /export/server/spark\n</code></pre> <ol> <li>\u3010node1\u6267\u884c\u3011\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\u540d\u79f0</li> </ol> <pre><code># \u6539\u540d\ncd /export/server/spark/conf\nmv spark-env.sh.template spark-env.sh\nmv slaves.template slaves\n</code></pre> <ol> <li>\u3010node1\u6267\u884c\u3011\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\uff0c<code>spark-env.sh</code></li> </ol> <pre><code>## \u8bbe\u7f6eJAVA\u5b89\u88c5\u76ee\u5f55\nJAVA_HOME=/export/server/jdk\n\n## HADOOP\u8f6f\u4ef6\u914d\u7f6e\u6587\u4ef6\u76ee\u5f55\uff0c\u8bfb\u53d6HDFS\u4e0a\u6587\u4ef6\u548c\u8fd0\u884cYARN\u96c6\u7fa4\nHADOOP_CONF_DIR=/export/server/hadoop/etc/hadoop\nYARN_CONF_DIR=/export/server/hadoop/etc/hadoop\n\n## \u6307\u5b9aspark\u8001\u5927Master\u7684IP\u548c\u63d0\u4ea4\u4efb\u52a1\u7684\u901a\u4fe1\u7aef\u53e3\nexport SPARK_MASTER_HOST=node1\nexport SPARK_MASTER_PORT=7077\n\nSPARK_MASTER_WEBUI_PORT=8080\nSPARK_WORKER_CORES=1\nSPARK_WORKER_MEMORY=1g\n</code></pre> <ol> <li>\u3010node1\u6267\u884c\u3011\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\uff0c<code>slaves</code></li> </ol> <pre><code>node1\nnode2\nnode3\n</code></pre> <ol> <li>\u3010node1\u6267\u884c\u3011\u5206\u53d1</li> </ol> <pre><code>scp -r spark-2.4.5-bin-hadoop2.7 node2:$PWD\nscp -r spark-2.4.5-bin-hadoop2.7 node3:$PWD\n</code></pre> <ol> <li>\u3010node2\u3001node3\u6267\u884c\u3011\u8bbe\u7f6e\u8f6f\u94fe\u63a5</li> </ol> <pre><code>ln -s /export/server/spark-2.4.5-bin-hadoop2.7 /export/server/spark\n</code></pre> <ol> <li>\u3010node1\u6267\u884c\u3011\u542f\u52a8Spark\u96c6\u7fa4</li> </ol> <pre><code>/export/server/spark/sbin/start-all.sh\n\n# \u5982\u9700\u505c\u6b62\uff0c\u53ef\u4ee5\n/export/server/spark/sbin/stop-all.sh\n</code></pre> <ol> <li> <p>\u6253\u5f00Spark\u76d1\u63a7\u9875\u9762\uff0c\u6d4f\u89c8\u5668\u6253\u5f00\uff1ahttp://node1:8081</p> </li> <li> <p>\u3010node1\u6267\u884c\u3011\u63d0\u4ea4\u6d4b\u8bd5\u4efb\u52a1</p> </li> </ol> <pre><code>/export/server/spark/bin/spark-submit --master spark://node1:7077 --class org.apache.spark.examples.SparkPi /export/server/spark/examples/jars/spark-examples_2.11-2.4.5.jar\n</code></pre>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#flink","title":"\u5206\u5e03\u5f0f\u5185\u5b58\u8ba1\u7b97Flink\u73af\u5883\u90e8\u7f72","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_43","title":"\u6ce8\u610f","text":"<p>\u672c\u5c0f\u8282\u7684\u64cd\u4f5c\uff0c\u57fa\u4e8e\uff1a<code>\u5927\u6570\u636e\u96c6\u7fa4\uff08Hadoop\u751f\u6001\uff09\u5b89\u88c5\u90e8\u7f72</code>\u73af\u8282\u4e2d\u6240\u6784\u5efa\u7684Hadoop\u96c6\u7fa4</p> <p>\u5982\u679c\u6ca1\u6709Hadoop\u96c6\u7fa4\uff0c\u8bf7\u53c2\u9605\u524d\u7f6e\u5185\u5bb9\uff0c\u90e8\u7f72\u597d\u73af\u5883\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_44","title":"\u7b80\u4ecb","text":"<p>Flink\u540cSpark\u4e00\u6837\uff0c\u662f\u4e00\u6b3e\u5206\u5e03\u5f0f\u5185\u5b58\u8ba1\u7b97\u5f15\u64ce\uff0c\u53ef\u4ee5\u652f\u6491\u6d77\u91cf\u6570\u636e\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u3002</p> <p>Flink\u5728\u5927\u6570\u636e\u4f53\u7cfb\u540c\u6837\u662f\u660e\u661f\u4ea7\u54c1\uff0c\u4f5c\u4e3a\u6700\u65b0\u4e00\u4ee3\u7684\u7efc\u5408\u8ba1\u7b97\u5f15\u64ce\uff0c\u652f\u6301\u79bb\u7ebf\u8ba1\u7b97\u548c\u5b9e\u65f6\u8ba1\u7b97\u3002</p> <p>\u5728\u5927\u6570\u636e\u9886\u57df\u5e7f\u6cdb\u5e94\u7528\uff0c\u662f\u76ee\u524d\u4e16\u754c\u4e0a\u9664\u53bbSpark\u4ee5\u5916\uff0c\u5e94\u7528\u6700\u4e3a\u5e7f\u6cdb\u7684\u5206\u5e03\u5f0f\u8ba1\u7b97\u5f15\u64ce\u3002</p> <p>\u6211\u4eec\u5c06\u57fa\u4e8e\u524d\u9762\u6784\u5efa\u7684Hadoop\u96c6\u7fa4\uff0c\u90e8\u7f72Flink Standalone\u96c6\u7fa4</p> <p>Spark\u66f4\u52a0\u504f\u5411\u4e8e\u79bb\u7ebf\u8ba1\u7b97\u800cFlink\u66f4\u52a0\u504f\u5411\u4e8e\u5b9e\u65f6\u8ba1\u7b97\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_45","title":"\u5b89\u88c5","text":"<ol> <li>\u3010node1\u64cd\u4f5c\u3011\u4e0b\u8f7d\u5b89\u88c5\u5305</li> </ol> <pre><code>wget https://archive.apache.org/dist/flink/flink-1.10.0/flink-1.10.0-bin-scala_2.11.tgz\n\n# \u89e3\u538b\ntar -zxvf flink-1.10.0-bin-scala_2.11.tgz -C /export/server/\n\n# \u8f6f\u94fe\u63a5\nln -s /export/server/flink-1.10.0 /export/server/flink\n</code></pre> <ol> <li>\u3010node1\u64cd\u4f5c\u3011\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\uff0c<code>conf/flink-conf.yaml</code></li> </ol> <pre><code># jobManager \u7684IP\u5730\u5740\njobmanager.rpc.address: node1\n# JobManager \u7684\u7aef\u53e3\u53f7\njobmanager.rpc.port: 6123\n# JobManager JVM heap \u5185\u5b58\u5927\u5c0f\njobmanager.heap.size: 1024m\n# TaskManager JVM heap \u5185\u5b58\u5927\u5c0f\ntaskmanager.heap.size: 1024m\n# \u6bcf\u4e2a TaskManager \u63d0\u4f9b\u7684\u4efb\u52a1 slots \u6570\u91cf\u5927\u5c0f\ntaskmanager.numberOfTaskSlots: 2\n#\u662f\u5426\u8fdb\u884c\u9884\u5206\u914d\u5185\u5b58\uff0c\u9ed8\u8ba4\u4e0d\u8fdb\u884c\u9884\u5206\u914d\uff0c\u8fd9\u6837\u5728\u6211\u4eec\u4e0d\u4f7f\u7528flink\u96c6\u7fa4\u65f6\u5019\u4e0d\u4f1a\u5360\u7528\u96c6\u7fa4\u8d44\u6e90\ntaskmanager.memory.preallocate: false\n# \u7a0b\u5e8f\u9ed8\u8ba4\u5e76\u884c\u8ba1\u7b97\u7684\u4e2a\u6570\nparallelism.default: 1\n#JobManager\u7684Web\u754c\u9762\u7684\u7aef\u53e3\uff08\u9ed8\u8ba4\uff1a8081\uff09\njobmanager.web.port: 8081\n</code></pre> <ol> <li>\u3010node1\u64cd\u4f5c\u3011\uff0c\u4fee\u6539\u914d\u7f6e\u6587\u4ef6\uff0c<code>conf/slaves</code></li> </ol> <pre><code>node1\nnode2\nnode3\n</code></pre> <ol> <li>\u3010node1\u64cd\u4f5c\u3011\u5206\u53d1Flink\u5b89\u88c5\u5305\u5230\u5176\u5b83\u673a\u5668</li> </ol> <pre><code>cd /export/server\nscp -r flink-1.10.0 node2:`pwd`/\nscp -r flink-1.10.0 node3:`pwd`/\n</code></pre> <ol> <li>\u3010node2\u3001node3\u64cd\u4f5c\u3011</li> </ol> <pre><code># \u914d\u7f6e\u8f6f\u94fe\u63a5\nln -s /export/server/flink-1.10.0 /export/server/flink\n</code></pre> <ol> <li>\u3010node1\u64cd\u4f5c\u3011\uff0c\u542f\u52a8Flink</li> </ol> <pre><code>/export/server/flink/bin/start-cluster.sh\n</code></pre> <ol> <li>\u9a8c\u8bc1Flink\u542f\u52a8</li> </ol> <pre><code># \u6d4f\u89c8\u5668\u6253\u5f00\nhttp://node1:8081\n</code></pre> <ol> <li>\u63d0\u4ea4\u6d4b\u8bd5\u4efb\u52a1</li> </ol> <p>\u3010node1\u6267\u884c\u3011</p> <pre><code>/export/server/flink/bin/flink run /export/server/flink-1.10.0/examples/batch/WordCount.jar\n</code></pre>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#zabbix","title":"\u8fd0\u7ef4\u76d1\u63a7Zabbix\u90e8\u7f72","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_46","title":"\u7b80\u4ecb","text":"<p>Zabbix \u7531 Alexei Vladishev \u521b\u5efa\uff0c\u76ee\u524d\u7531\u5176\u6210\u7acb\u7684\u516c\u53f8\u2014\u2014 Zabbix SIA \u79ef\u6781\u7684\u6301\u7eed\u5f00\u53d1\u66f4\u65b0\u7ef4\u62a4\uff0c \u5e76\u4e3a\u7528\u6237\u63d0\u4f9b\u6280\u672f\u652f\u6301\u670d\u52a1\u3002</p> <p>Zabbix \u662f\u4e00\u4e2a==\u4f01\u4e1a\u7ea7\u5206\u5e03\u5f0f\u5f00\u6e90\u76d1\u63a7\u89e3\u51b3\u65b9\u6848==\u3002</p> <p>Zabbix \u8f6f\u4ef6\u80fd\u591f==\u76d1\u63a7==\u4f17\u591a\u7f51\u7edc\u53c2\u6570\u548c\u670d\u52a1\u5668\u7684==\u5065\u5eb7\u5ea6\u3001\u5b8c\u6574\u6027==\u3002Zabbix \u4f7f\u7528\u7075\u6d3b\u7684\u544a\u8b66\u673a\u5236\uff0c\u5141\u8bb8\u7528\u6237\u4e3a\u51e0\u4e4e\u4efb\u4f55\u4e8b\u4ef6\u914d\u7f6e\u57fa\u4e8e\u90ae\u4ef6\u7684\u544a\u8b66\u3002\u8fd9\u6837\u7528\u6237\u53ef\u4ee5\u5feb\u901f\u54cd\u5e94\u670d\u52a1\u5668\u95ee\u9898\u3002Zabbix \u57fa\u4e8e\u5b58\u50a8\u7684\u6570\u636e\u63d0\u4f9b\u51fa\u8272\u7684\u62a5\u8868\u548c\u6570\u636e\u53ef\u89c6\u5316\u529f\u80fd\u3002\u8fd9\u4e9b\u529f\u80fd\u4f7f\u5f97 Zabbix \u6210\u4e3a\u5bb9\u91cf\u89c4\u5212\u7684\u7406\u60f3\u9009\u62e9\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_47","title":"\u5b89\u88c5","text":"<p>\u5b89\u88c5\u6574\u4f53\u6b65\u9aa4:</p> <ol> <li>\u51c6\u5907Linux \u670d\u52a1\u5668(\u865a\u62df\u673a)</li> <li>\u5b89\u88c5Mysql</li> <li>\u5b89\u88c5zabbix( \u5305\u542b server  agent  web)</li> <li>\u914d\u7f6e mysql, \u4e3azabbix\u521b\u5efa\u8868\u7ed3\u6784</li> <li>\u914d\u7f6ezabbix server</li> <li>\u542f\u52a8\u5e76\u5f00\u542f\u5f00\u673a\u81ea\u542f\u52a8</li> </ol> <p></p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#-mysql","title":"\u5b89\u88c5\u524d\u51c6\u5907 - Mysql","text":"<p>\u5b89\u88c5ZabbixServer\u9700\u8981\u5148\u5b89\u88c5\u597d<code>Mysql</code>\u6570\u636e\u5e93</p> <p>\u8bfe\u7a0b\u4f7f\u7528<code>Mysql 5.7</code></p> <p>\u5b89\u88c5\u6b65\u9aa4\uff1a</p> <pre><code># \u5b89\u88c5Mysql yum\u5e93\nrpm -Uvh http://repo.mysql.com//mysql57-community-release-el7-7.noarch.rpm\n\n# yum\u5b89\u88c5Mysql\nyum -y install mysql-community-server\n\n# \u542f\u52a8Mysql\u8bbe\u7f6e\u5f00\u673a\u542f\u52a8\nsystemctl start mysqld\nsystemctl enable mysqld\n\n# \u68c0\u67e5Mysql\u670d\u52a1\u72b6\u6001\nsystemctl status mysqld\n\n# \u7b2c\u4e00\u6b21\u542f\u52a8mysql\uff0c\u4f1a\u5728\u65e5\u5fd7\u6587\u4ef6\u4e2d\u751f\u6210root\u7528\u6237\u7684\u4e00\u4e2a\u968f\u673a\u5bc6\u7801\uff0c\u4f7f\u7528\u4e0b\u9762\u547d\u4ee4\u67e5\u770b\u8be5\u5bc6\u7801\ngrep 'temporary password' /var/log/mysqld.log\n\n# \u4fee\u6539root\u7528\u6237\u5bc6\u7801\nmysql -u root -p -h localhost\nEnter password:\n\nmysql&gt; ALTER USER 'root'@'localhost' IDENTIFIED BY 'Root!@#$';\n\n# \u5982\u679c\u4f60\u60f3\u8bbe\u7f6e\u7b80\u5355\u5bc6\u7801\uff0c\u9700\u8981\u964d\u4f4eMysql\u7684\u5bc6\u7801\u5b89\u5168\u7ea7\u522b\nset global validate_password_policy=LOW; # \u5bc6\u7801\u5b89\u5168\u7ea7\u522b\u4f4e\nset global validate_password_length=4;   # \u5bc6\u7801\u957f\u5ea6\u6700\u4f4e4\u4f4d\u5373\u53ef\n\n# \u7136\u540e\u5c31\u53ef\u4ee5\u7528\u7b80\u5355\u5bc6\u7801\u4e86\uff08\u8bfe\u7a0b\u4e2d\u4f7f\u7528\u7b80\u5355\u5bc6\u7801\uff0c\u4e3a\u4e86\u65b9\u4fbf\uff0c\u751f\u4ea7\u4e2d\u4e0d\u8981\u8fd9\u6837\uff09\nALTER USER 'root'@'localhost' IDENTIFIED BY 'root';\nmysql&gt; grant all privileges on *.* to root@'%' identified by 'root';\n</code></pre>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#zabbix-server-zabbix-agent","title":"\u5b89\u88c5Zabbix Server \u548c Zabbix Agent","text":"<p>\u521d\u59cb\u5b89\u88c5\uff0c\u6211\u4eec\u5148\u5b89\u88c5ZabbixServer\u4ee5\u53ca\u5728Server\u672c\u673a\u5b89\u88c5Agent\u3002</p> <p>\u6253\u5f00\u5b98\u7f51\u4e0b\u8f7d\u9875\u9762\uff1ahttps://www.zabbix.com/download?zabbix=4.0&amp;os_distribution=centos&amp;os_version=7&amp;db=mysql</p> <p></p> <p>\u9009\u62e9\u5bf9\u5e94\u7684\u7248\u672c\uff0c\u7136\u540e\u518d\u4e0b\u9762\u5b98\u7f51\u7ed9\u51fa\u4e86\u5177\u4f53\u7684\u5b89\u88c5\u547d\u4ee4\uff0c\u4f7f\u7528<code>rpm</code>\u548c<code>yum</code>\u6765\u8fdb\u884c\u5b89\u88c5\u3002</p> <p>\u9700\u8981\u6709\u7f51\u7edc\u3002</p> <p><code>\u4ee5\u4e0b\u5185\u5bb9\u6765\u81ea\u5b98\u65b9\u9875\u9762</code></p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#a-zabbix-yum","title":"a. \u5b89\u88c5Zabbix yum\u5e93","text":"<p>documentation</p> <pre><code>rpm -Uvh https://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-2.el7.noarch.rpm\nyum clean all\n</code></pre>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#b-zabbix-serveragent","title":"b. \u5b89\u88c5Zabbix Server\u3001\u524d\u7aef\u3001Agent","text":"<pre><code>yum -y install zabbix-server-mysql zabbix-web-mysql zabbix-agent\n# \u5982\u679c\u53ea\u9700\u8981\u5b89\u88c5Agent\u7684\u8bdd\nyum -y install zabbix-agent\n</code></pre>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#c-mysql","title":"c. \u521d\u59cb\u5316Mysql\u6570\u636e\u5e93","text":"<p>documentation</p> <p>\u5728Mysql\u4e2d\u64cd\u4f5c</p> <pre><code># \u767b\u5f55Mysql \u6570\u636e\u5e93\nmysql -uroot -pYourPassword\nmysql&gt; create database zabbix character set utf8 collate utf8_bin;\nmysql&gt; grant all privileges on zabbix.* to zabbix@localhost identified by 'zabbix';\n# \u6216\u8005: grant all privileges on zabbix.* to zabbix@'%' identified by 'zabbix';\nmysql&gt; quit;\n</code></pre> <p>\u6d4b\u8bd5\u5728Zabbix Server\u670d\u52a1\u5668\u4e0a\u80fd\u5426\u8fdc\u7a0b\u767b\u5f55Mysql\uff0c\u5982\u679c\u53ef\u4ee5\u767b\u5f55\u7ee7\u7eed\u5411\u4e0b\u8d70\u3002</p> <p>Import initial schema and data. You will be prompted to enter your newly created password.</p> <pre><code># zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix\n</code></pre>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#d-zabbix-server","title":"d. \u4e3aZabbix Server\u914d\u7f6e\u6570\u636e\u5e93","text":"<p>Edit file /etc/zabbix/zabbix_server.conf</p> <pre><code>DBPassword=password\nDBHost=mysql-host-ip-or-hostname\n</code></pre>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#e-zabbixphp","title":"e. \u914d\u7f6eZabbix\u7684PHP\u524d\u7aef","text":"<p>Edit file <code>/etc/httpd/conf.d/zabbix.conf</code>, uncomment and set the right timezone for you.<code># php_value date.timezone Asia/Shanghai</code></p> <p>Start Zabbix server and agent processes and make it start at system boot:</p> <pre><code>systemctl restart zabbix-server zabbix-agent httpd # \u542f\u52a8\u3001\u91cd\u542f\nsystemctl enable zabbix-server zabbix-agent httpd  # \u5f00\u673a\u81ea\u542f\n</code></pre> <p>Now your Zabbix server is up and running!</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#zabbix-web-ui","title":"\u914d\u7f6ezabbix \u524d\u7aef\uff08WEB UI\uff09","text":"<p>\u6253\u5f00:<code>http://192.168.88.131/zabbix</code></p> <p>\u5373\u53ef\u8fdb\u5165Zabbix\u9875\u9762\uff0c\u5728\u9996\u6b21\u6253\u5f00\u7684\u65f6\u5019\uff0c\u4f1a\u8fdb\u5165\u8bbe\u7f6e\u9875\u9762\uff0c\u5982\u56fe\uff1a</p> <p></p> <p>\u70b9\u51fb\u4e0b\u4e00\u6b65\uff0c\u4f1a\u68c0\u67e5\u76f8\u5e94\u7684\u8bbe\u7f6e\u662f\u5426\u90fd\u6b63\u5e38</p> <p></p> <p>\u5982\u679c\u4e00\u5207\u6b63\u5e38\uff0c\u70b9\u51fb\u4e0b\u4e00\u6b65\u3002</p> <p>\u914d\u7f6eDB\u8fde\u63a5</p> <p></p> <p>\u6309\u5177\u4f53\u60c5\u51b5\u586b\u5199\u5373\u53ef</p> <p>\u914d\u7f6eServer\u7ec6\u8282</p> <p></p> <p>\u5177\u4f53\u914d\u7f6e\u5373\u53ef\uff0cName\u8868\u793a\u8fd9\u4e2aZabbix\u670d\u52a1\u7684\u540d\u5b57\uff0c\u8fd9\u91cc\u8d77\u540d\u53eb<code>ITHEIMA-TEST</code></p> <p>\u5b89\u88c5\u524d\u603b\u7ed3\u9884\u89c8</p> <p>\u68c0\u67e5\u786e\u8ba4\u6ca1\u6709\u95ee\u9898\u5c31\u4e0b\u4e00\u6b65</p> <p></p> <p>\u914d\u7f6e\u5b8c\u6210</p> <p></p> <p>\u521d\u59cb\u7ba1\u7406\u5458\u8d26\u6237Admin\u5bc6\u7801zabbix</p> <p>\u8f93\u5165\u8d26\u6237\u5bc6\u7801\u540e\uff0c\u5c31\u80fd\u8fdb\u5165zabbix\u9875\u9762\u4e86\u3002</p> <p>\u5982\u4e0b\u56fe\uff1a</p> <p></p> <p>\u73b0\u5728\u662f\u4e00\u4e2a\u5d2d\u65b0\u7684zabbix\u7b49\u5f85\u6211\u4eec\u53bb\u63a2\u7d22\u3002</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#grafana","title":"\u8fd0\u7ef4\u76d1\u63a7Grafana\u90e8\u7f72","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_48","title":"\u7b80\u4ecb","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_49","title":"\u5b89\u88c5","text":""},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_50","title":"\u90e8\u7f72\u5f62\u5f0f","text":"<p><code>Grafana</code>\u652f\u6301\u4e24\u79cd\u90e8\u7f72\u5f62\u5f0f</p> <ol> <li>\u81ea\u884c\u90e8\u7f72, \u53ef\u4ee5\u90e8\u7f72\u5728\u64cd\u4f5c\u7cfb\u7edf\u4e4b\u4e0a. \u81ea\u884c\u63d0\u4f9b\u670d\u52a1\u5668, \u57df\u540d\u7b49.</li> <li><code>Grafana</code>\u5b98\u65b9\u6258\u7ba1. \u65e0\u9700\u5b89\u88c5, \u5728\u7ebf\u6ce8\u518c\u5373\u53ef\u5f97\u5230\u4e00\u4e2a\u4e13\u5c5e\u4e8e\u81ea\u5df1\u7684<code>Grafana</code>, \u4f46\u662f\u8981\u82b1\u94b1\u7684. \u662f\u4e00\u79cd<code>SaaS</code>\u670d\u52a1</li> </ol> <p>\u6211\u4eec\u8bfe\u7a0b\u9009\u62e9\u65b9\u5f0f1</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_51","title":"\u5b89\u88c5","text":"<p><code>Grafana</code>\u652f\u6301\u5e38\u89c1\u7684\u7edd\u5927\u591a\u6570\u64cd\u4f5c\u7cfb\u7edf, \u5982<code>windows</code> <code>mac</code> <code>linux</code> \u540c\u65f6\u4e5f\u652f\u6301\u90e8\u7f72\u5728<code>docker</code>\u4e2d.</p> <p>\u5927\u591a\u6570\u60c5\u51b5\u4e0b, <code>Grafana</code>\u90fd\u662f\u90e8\u7f72\u5728<code>linux</code>\u670d\u52a1\u5668\u4e4b\u4e0a. \u6240\u4ee5\u672c\u8bfe\u7a0b\u4e5f\u662f\u57fa\u4e8e<code>Linux</code>\u7cfb\u7edf\u6765\u8bb2\u89e3.</p> <p>\u5bf9<code>windows</code> <code>mac</code>\u7cfb\u7edf \u6216 <code>docker</code>\u90e8\u7f72\u6709\u5174\u8da3\u7684\u540c\u5b66, \u8bf7\u53c2\u8003:  https://grafana.com/grafana/download</p> <p>\u6211\u4eec\u90e8\u7f72<code>Grafana</code>\u53ef\u4ee5\u4f7f\u7528<code>YUM</code>\u6765\u8fdb\u884c\u90e8\u7f72.</p> <pre><code># \u521b\u5efa\u4e00\u4e2a\u6587\u4ef6\nvim /etc/yum.repos.d/grafana.repo\n\n# \u5c06\u4e0b\u9762\u7684\u5185\u5bb9\u590d\u5236\u8fdb\u53bb\n[grafana]\nname=grafana\nbaseurl=https://packages.grafana.com/oss/rpm\nrepo_gpgcheck=1\nenabled=1\ngpgcheck=1\ngpgkey=https://packages.grafana.com/gpg.key\nsslverify=1\nsslcacert=/etc/pki/tls/certs/ca-bundle.crt\n\n# \u6700\u540e\u5b89\u88c5\nyum install grafana\n</code></pre>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_52","title":"\u914d\u7f6e\u8bf4\u660e","text":"<p><code>grafana-server</code>\u5177\u6709\u8bb8\u591a\u914d\u7f6e\u9009\u9879\uff0c\u8fd9\u4e9b\u9009\u9879\u53ef\u4ee5\u5728<code>.ini</code>\u914d\u7f6e\u6587\u4ef6\u4e2d\u6307\u5b9a\uff0c\u4e5f\u53ef\u4ee5\u4f7f\u7528\u73af\u5883\u53d8\u91cf\u6307\u5b9a\u3002</p> <p>Note. <code>Grafana</code> needs to be restarted for any configuration changes to take effect. </p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_53","title":"\u914d\u7f6e\u6587\u4ef6\u6ce8\u91ca","text":"<p><code>;</code>\u7b26\u53f7\u5728<code>.ini</code>\u6587\u4ef6\u4e2d\u5168\u5c40\u8868\u793a\u6ce8\u91ca ()</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_54","title":"\u914d\u7f6e\u6587\u4ef6\u8def\u5f84","text":"<p>\u5982\u679c\u662f\u81ea\u5df1\u89e3\u538b\u5b89\u88c5, \u6216\u8005\u81ea\u884c\u7f16\u8bd1\u7684\u65b9\u5f0f\u5b89\u88c5, \u914d\u7f6e\u6587\u4ef6\u5728:</p> <ul> <li>\u9ed8\u8ba4: <code>$WORKING_DIR/conf/defaults.ini</code></li> <li>\u81ea\u5b9a\u4e49:<code>$WORKING_DIR/conf/custom.ini</code></li> <li>\u81ea\u5b9a\u4e49\u914d\u7f6e\u6587\u4ef6\u8def\u5f84\u53ef\u4ee5\u88ab\u53c2\u6570<code>--config</code>\u8986\u76d6</li> </ul> <p>\u5bf9\u4e8e<code>YUM</code> <code>RPM</code> \u5b89\u88c5\u7684\u65b9\u5f0f, \u914d\u7f6e\u6587\u4ef6\u5728: <code>/etc/grafana/grafana.ini</code></p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_55","title":"\u4f7f\u7528\u73af\u5883\u53d8\u91cf","text":"<p>\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u8bed\u6cd5\u4f7f\u7528\u73af\u5883\u53d8\u91cf\u6765\u8986\u76d6\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u6240\u6709\u9009\u9879\uff1a</p> <pre><code>GF_&lt;SectionName&gt;_&lt;KeyName&gt;\n</code></pre> <p>\u5176\u4e2d<code>SectionName</code>\u662f\u65b9\u62ec\u53f7\u5185\u7684\u6587\u672c\u3002\u4e00\u5207\u90fd\u5e94\u4e3a\u5927\u5199\uff0c<code>.</code>\u5e94\u66ff\u6362\u4e3a<code>_</code> \u4f8b\u5982\uff0c\u7ed9\u5b9a\u4ee5\u4e0b\u914d\u7f6e\u8bbe\u7f6e\uff1a</p> <pre><code># default section\ninstance_name = ${HOSTNAME}\n\n[security]\nadmin_user = admin\n\n[auth.google]\nclient_secret = 0ldS3cretKey\n</code></pre> <p>Then you can override them using:</p> <pre><code>export GF_DEFAULT_INSTANCE_NAME=my-instance\nexport GF_SECURITY_ADMIN_USER=true  # GF_ \u56fa\u5b9a SECURITY \u662fSectionName ADMIN_USER \u662f\u914d\u7f6e\u7684key \u8f6c\u5927\u5199 . \u8f6c _\nexport GF_AUTH_GOOGLE_CLIENT_SECRET=newS3cretKey\n</code></pre>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_56","title":"\u5f00\u59cb\u914d\u7f6e","text":"<p><code>Grafana</code>\u652f\u6301\u4f7f\u7528<code>Sqlite3</code> <code>Postgresql</code> <code>Mysql</code>\u8fd9\u4e09\u79cd\u6570\u636e\u5e93\u4f5c\u4e3a\u5176<code>\u5143\u6570\u636e</code>\u7684\u5b58\u50a8.</p> <p>\u6211\u4eec\u8bfe\u7a0b\u4f7f\u7528<code>Mysql</code>. \u548c<code>zabbix</code>\u7684\u5143\u6570\u636emysql\u5171\u7528\u4e00\u4e2a\u5b9e\u4f8b</p> <p>\u53ea\u9700\u8981\u914d\u7f6e\u5982\u4e0b\u5185\u5bb9\u5373\u53ef:</p> <p></p> <p>\u5e76\u767b\u9646mysql, \u6267\u884c:</p> <p><code>create database grafana CHARACTER SET utf8 COLLATE utf8_general_ci;</code></p> <p>\u521b\u5efa<code>Grafana</code>\u4f7f\u7528\u7684\u6570\u636e\u5e93\u4f5c\u4e3a\u5143\u6570\u636e\u5b58\u50a8.</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/#_57","title":"\u542f\u52a8","text":"<pre><code>systemctl daemon-reload\nsystemctl start grafana-server\nsystemctl enable grafana-server\n</code></pre> <p>\u6d4f\u89c8\u5668\u6253\u5f00\uff1ahttp://node1:3000</p> <p>\u9ed8\u8ba4\u8d26\u6237\u5bc6\u7801\uff1aadmin/admin</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/","title":"\u914d\u7f6eLinux\u7cfb\u7edf","text":"<p>\u603b\u4f53\u6d41\u7a0b\uff1a\u5b89\u88c5\u865a\u62df\u673a\u7ba1\u7406\u8f6f\u4ef6 Vmware fusion ---&gt; \u5b89\u88c5centos ---&gt; \u914d\u7f6ecentos</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/#1-vmware-fusion","title":"1. \u5b89\u88c5 Vmware fusion","text":"<p>/Users/wenglongao/\u7814\u7a76\u751f\u5b66\u4e60/Linux\u8bfe\u7a0b\u8d44\u6599/\u76f8\u5173\u5b89\u88c5\u6587\u4ef6/VMWare-Fusion-Pro-13.0.2(21581413)_[kitdown].dmg</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/#2-centos","title":"2. \u5b89\u88c5 centos","text":"<p>/Users/wenglongao/\u7814\u7a76\u751f\u5b66\u4e60/Linux\u8bfe\u7a0b\u8d44\u6599/\u76f8\u5173\u5b89\u88c5\u6587\u4ef6/CentOS-7-aarch64-08191738.iso \u6ce8\u610f\u70b9\uff1a\u5728\u5b89\u88c5\u7684\u65f6\u5019\u9009\u62e9\u56fe\u5f62\u754c\u9762gnome\uff0c\u4e0d\u8981\u9009\u62e9mini\u5b89\u88c5\u5f62\u5f0f\uff0c\u5426\u5219\u53ea\u6709\u547d\u4ee4\u884c\u7a97\u53e3</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/#3-centos","title":"3. \u914d\u7f6e centos","text":"<p>\u53c2\u8003\u6587\u7ae0</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/#4-final-shell","title":"4. \u5b89\u88c5 final shell","text":"<p>\u7528\u4e8e\u8fdc\u7a0b\u64cd\u4f5cLinux\u7cfb\u7edf /Users/wenglongao/\u7814\u7a76\u751f\u5b66\u4e60/Linux\u8bfe\u7a0b\u8d44\u6599/\u8f6f\u4ef6\u5305/MacOS\u8f6f\u4ef6/finalshell_install.pkg</p>"},{"location":"markdown/development_utils/Linux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/#5-ubuntu","title":"5. \u8865\u5145\uff1a\u53ef\u4ee5\u5b89\u88c5ubuntu","text":"<p>Ubuntu\u53ef\u4ee5\u901a\u8fc7parallel\u5b89\u88c5\uff0c\u5f88\u65b9\u4fbf\u3002 arm\u7248\u672c\u7684\u5b98\u7f51\u5730\u5740 \u53c2\u8003\u6587\u7ae0 /Users/wenglongao/\u7814\u7a76\u751f\u5b66\u4e60/Linux\u8bfe\u7a0b\u8d44\u6599/\u76f8\u5173\u5b89\u88c5\u6587\u4ef6/ubuntu-22.04.3-live-server-arm64.iso</p>"},{"location":"markdown/development_utils/docker%E9%85%8D%E7%BD%AE/","title":"\u914d\u7f6edocker","text":"<p>docker\u6559\u7a0b</p>"},{"location":"markdown/development_utils/docker%E9%85%8D%E7%BD%AE/#docker_1","title":"docker\u4f7f\u7528\u6b65\u9aa4","text":""},{"location":"markdown/development_utils/docker%E9%85%8D%E7%BD%AE/#docker_2","title":"\u5b89\u88c5docker","text":"<p>\u5177\u4f53\u53ef\u4ee5\u53c2\u8003docker\u6559\u7a0b </p>"},{"location":"markdown/development_utils/docker%E9%85%8D%E7%BD%AE/#docker_3","title":"\u4fee\u6539docker\u955c\u50cf\u6e90","text":"<p>\u4fee\u6539docker\u955c\u50cf\u6e90 * \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0cmacos\u4e0adocker\u7684daemon.json\u7684\u8def\u5f84\u5e94\u8be5\u5728\uff1a/Users//.docker/daemon.json * \u627e\u5230daemon.json\u540e\uff0c\u4f7f\u7528\u4fee\u6539docker\u955c\u50cf\u6e90\u6559\u7a0b\u7684\u65b9\u6cd5\u6dfb\u52a0\u591a\u4e2a\u955c\u50cf\u6e90\u5373\u53ef\u3002 * \u76ee\u524d\u6211\u4f7f\u7528\u7684\u955c\u50cf\u6e90\uff1a \"registry-mirrors\": [     \"http://hub-mirror.c.163.com\",     \"https://mirror.ccs.tencentyun.com\",     \"https://docker.m.daocloud.io\",     \"https://docker.imgdb.de\",     \"https://docker-0.unsee.tech\",     \"https://docker.hlmirror.com\",     \"https://docker.1ms.run\",     \"https://func.ink\",     \"https://lispy.org\",     \"https://docker.xiaogenban1993.com\"   ] * \u6216\u8005\uff0c\u5728Docker Desktop\u4e2d\uff0c\u6253\u5f00Setting-Docker Engine\uff0c\u6dfb\u52a0\u4e0a\u8ff0registry-mirrors\u5230\u914d\u7f6e\u6587\u4ef6\u4e2d\u4e5f\u53ef\u4ee5"},{"location":"markdown/development_utils/docker%E9%85%8D%E7%BD%AE/#deeprec","title":"\u5b9e\u6218\uff1aDeepRec\u7684\u90e8\u7f72","text":"<p>DeepRec DeepRec\u7684\u90e8\u7f72\u9700\u8981\u7528\u5230docker\u3002\u5728\u6211\u81ea\u5df1\u7684MacBook m1\u4e0a\u5c1d\u8bd5\u90e8\u7f72\u3002\u90e8\u7f72\u6709\u4e24\u79cd\u65b9\u5f0f\uff1a\u901a\u8fc7Docker\u90e8\u7f72\uff08\u63a8\u8350\uff09\u3001\u624b\u52a8\u90e8\u7f72\u3002 \u9996\u5148\uff0c\u4ecb\u7ecd\u7b2c\u4e00\u79cd\u65b9\u5f0f\uff1a\u901a\u8fc7docker\u90e8\u7f72\uff1a</p>"},{"location":"markdown/development_utils/docker%E9%85%8D%E7%BD%AE/#docker_4","title":"\u5b89\u88c5docker","text":""},{"location":"markdown/development_utils/docker%E9%85%8D%E7%BD%AE/#_1","title":"\u62c9\u53d6\u955c\u50cf","text":"<p>\u62c9\u53d6\u9002\u914darm64\u7248\u672c\u4e14\u4f7f\u7528cpu\u7684DeepRec\u955c\u50cf <code>docker pull alideeprec/deeprec-release:deeprec2302-cpu-py38-ubuntu22.04-arm64</code></p>"},{"location":"markdown/development_utils/docker%E9%85%8D%E7%BD%AE/#_2","title":"\u521b\u5efa\u5bb9\u5668","text":"<p>\u57fa\u4e8e\u62c9\u53d6\u7684\u955c\u50cf\uff0c\u521b\u5efadocker\u5bb9\u5668\uff0c\u53ef\u901a\u8fc7--name\u81ea\u5b9a\u4e49\u540d\u79f0<code>docker run -it --name deeprec-dev alideeprec/deeprec-release:deeprec2302-cpu-py38-ubuntu22.04-arm64 /bin/bash</code></p>"},{"location":"markdown/development_utils/docker%E9%85%8D%E7%BD%AE/#clone-code","title":"clone code","text":"<p>\u5728\u7ec8\u7aef\u8fd0\u884cdocker\u76ee\u5f55\uff0c\u7136\u540e\u5728docker\u5185\uff0c\u8fd0\u884c<code>git clone https://github.com/alibaba/DeepRec</code> \u76ee\u7684\u662f\u5c06DeepRec\u7684\u4ee3\u7801clone\u5230docker\u5bb9\u5668\u4e2d\uff0c\u7136\u540e\u5728docker\u5bb9\u5668\u4e2d\u76f4\u63a5\u8fd0\u884c\u4ee3\u7801 * \u7406\u89e3\uff1a\u6211\u4eec\u62c9\u53d6\u4e86\u4ee3\u7801\u7684\u955c\u50cf\uff0c\u7136\u540e\u4f7f\u7528\u8fd9\u4e2a\u955c\u50cf\uff0c\u521b\u5efa\u4e86\u4e00\u4e2adocker\u5bb9\u5668\u3002\u8fd9\u6837\uff0c\u5728\u5bb9\u5668\u4e2d\u5c31\u6709\u4ee3\u7801\u8fd0\u884c\u6240\u9700\u7684\u73af\u5883\u3002\u53ea\u9700\u8981\u5728\u5bb9\u5668\u4e2d\u8fd0\u884c\u4ee3\u7801\u5373\u53ef\u3002</p>"},{"location":"markdown/development_utils/docker%E9%85%8D%E7%BD%AE/#_3","title":"\u8fd0\u884c\u8bad\u7ec3\u4ee3\u7801","text":"<p>\u4ee5Wide &amp; Deep\u6a21\u578b\u4e3a\u4f8b\u3002 * \u9996\u5148\uff0ccd\u5230\u6a21\u578b\u6570\u636e\u76ee\u5f55\uff1a<code>cd /home/workdir/DeepRec/modelzoo/wide_and_deep/data</code>\uff0c\u5e76\u4e14\u4e0b\u8f7d\u6570\u636e\u96c6\uff1a <code>wget https://storage.googleapis.com/dataset-uploader/criteo-kaggle/large_version/train.csv</code> <code>wget https://storage.googleapis.com/dataset-uploader/criteo-kaggle/large_version/eval.csv</code> * \u7136\u540e\uff0ccd\u5230\u6a21\u578b\u76ee\u5f55\uff1a<code>cd /home/workdir/DeepRec/modelzoo/wide_and_deep</code> * \u8fd0\u884c\u8bad\u7ec3\u811a\u672c<code>python train.py --parquet_dataset False</code>\uff08\u4f7f\u7528\u7684\u662fcsv data\uff0c\u4e0d\u662fparquet data\uff09 \u987a\u5229\u7684\u8bdd\uff0c\u6a21\u578b\u5c31\u53ef\u4ee5\u5f00\u59cb\u8bad\u7ec3\u4e86\u3002</p> <p> \u53e6\u5916\uff0c\u4e5f\u53ef\u4ee5\u624b\u52a8\u90e8\u7f72\u3002\u624b\u52a8\u90e8\u7f72\u662f\u5728\u672c\u5730python\u73af\u5883\u4e2d\u4f7f\u7528<code>pip install $DEEPREC_WHL</code>\u5b89\u88c5DeepRec\u8fd0\u884c\u4f9d\u8d56\u7684package\uff0c\u7136\u540e\u624b\u52a8\u4e0b\u8f7d\u6570\u636e\u96c6\uff0c\u5728\u73af\u5883\u4e2d\u8fd0\u884c<code>python train.py</code>\u5373\u53ef\u3002</p>"},{"location":"markdown/development_utils/mongo_test/","title":"Mongo test","text":"In\u00a0[1]: Copied! <pre>from pymongo import MongoClient\nimport pandas as pd\n</pre> from pymongo import MongoClient import pandas as pd <p>\u9047\u5230\u95ee\u9898\uff0c\u53ef\u4ee5\u5148\u53bb\u770b\u770bmonngodb\u7684log\uff1a/opt/homebrew/var/log/mongodb/output.log</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <ul> <li>\u9996\u5148\uff0c\u5728\u7ec8\u7aef\u542f\u52a8mongodb <code>brew services start mongodb-community@7.0</code> <code>brew services stop mongodb-community@7.0</code> <code>brew services restart mongodb-community@7.0</code></li> </ul> In\u00a0[10]: Copied! <pre>#  \u521b\u5efa\u6570\u636e\u5e93\u8fde\u63a5\u5bf9\u8c61\nclient = MongoClient(\"mongodb://localhost:27017\")\n \n#  \u9009\u62e9\u4e00\u4e2a\u6570\u636e\u5e93\ndb = client['admin']\n#  \u6570\u636e\u5e93\u4e2d\u5f00\u4e86\u6743\u9650\u8ba4\u8bc1\u540e\uff0c\u9700\u8981\u4e0b\u4e00\u884c\u4ee3\u7801\n#  \u8f93\u5165\u8d85\u7ea7\u7ba1\u7406\u5458\u8d26\u53f7\u548c\u5bc6\u7801\n# db.authenticate('python', 'python')\n# #  \u9009\u62e9\u4e00\u4e2a\u96c6\u5408,\u6ca1\u6709\u7684\u8bdd\u4f1a\u65b0\u5efa\u7684\ncol = client['pydata']['test']\n</pre> #  \u521b\u5efa\u6570\u636e\u5e93\u8fde\u63a5\u5bf9\u8c61 client = MongoClient(\"mongodb://localhost:27017\")   #  \u9009\u62e9\u4e00\u4e2a\u6570\u636e\u5e93 db = client['admin'] #  \u6570\u636e\u5e93\u4e2d\u5f00\u4e86\u6743\u9650\u8ba4\u8bc1\u540e\uff0c\u9700\u8981\u4e0b\u4e00\u884c\u4ee3\u7801 #  \u8f93\u5165\u8d85\u7ea7\u7ba1\u7406\u5458\u8d26\u53f7\u548c\u5bc6\u7801 # db.authenticate('python', 'python') # #  \u9009\u62e9\u4e00\u4e2a\u96c6\u5408,\u6ca1\u6709\u7684\u8bdd\u4f1a\u65b0\u5efa\u7684 col = client['pydata']['test']  In\u00a0[4]: Copied! <pre># \u65b0\u5efa\u4e00\u4e2a\u6570\u636e\u5e93\uff0c\u5728\u65b0\u5efa\u6570\u636e\u5e93\u4e4b\u4e0b\u65b0\u5efa\u4e00\u4e2acollection\nmydb = client[\"mydatabase\"]\nmycol = mydb[\"customers\"]\nmycol.delete_many({})\nmycol.insert_one({\"name\": \"John\", \"age\": 30})\nmycol.insert_one({\"name\": \"Leo\", \"age\": 22})\nclient.list_database_names()\n</pre> # \u65b0\u5efa\u4e00\u4e2a\u6570\u636e\u5e93\uff0c\u5728\u65b0\u5efa\u6570\u636e\u5e93\u4e4b\u4e0b\u65b0\u5efa\u4e00\u4e2acollection mydb = client[\"mydatabase\"] mycol = mydb[\"customers\"] mycol.delete_many({}) mycol.insert_one({\"name\": \"John\", \"age\": 30}) mycol.insert_one({\"name\": \"Leo\", \"age\": 22}) client.list_database_names() Out[4]: <pre>['admin', 'config', 'local', 'mydatabase']</pre> In\u00a0[5]: Copied! <pre># \u67e5\u770b\u6570\u636e\u5e93\u4e2d\u7684\u6240\u6709collection\nmydb.list_collection_names()\n</pre> # \u67e5\u770b\u6570\u636e\u5e93\u4e2d\u7684\u6240\u6709collection mydb.list_collection_names() Out[5]: <pre>['customers']</pre> In\u00a0[6]: Copied! <pre>list(mycol.find({}))\n</pre> list(mycol.find({})) Out[6]: <pre>[{'_id': ObjectId('6555d59ca88aed77b6e3c137'), 'name': 'John', 'age': 30},\n {'_id': ObjectId('6555d59ca88aed77b6e3c138'), 'name': 'Leo', 'age': 22}]</pre> In\u00a0[7]: Copied! <pre># \u4e0d\u8f93\u51fa_id\nlist(mycol.find({}, {\"_id\": False}))\n</pre> # \u4e0d\u8f93\u51fa_id list(mycol.find({}, {\"_id\": False})) Out[7]: <pre>[{'name': 'John', 'age': 30}, {'name': 'Leo', 'age': 22}]</pre> In\u00a0[8]: Copied! <pre>list(mycol.find({}, {\"_id\": False, 'name': False}))\n</pre> list(mycol.find({}, {\"_id\": False, 'name': False})) Out[8]: <pre>[{'age': 30}, {'age': 22}]</pre> In\u00a0[9]: Copied! <pre>list(mycol.find_one())\n</pre> list(mycol.find_one()) Out[9]: <pre>['_id', 'name', 'age']</pre> In\u00a0[10]: Copied! <pre># \u5c06\u7ed3\u679c\u8f93\u51fa\u4e3adf\npd.DataFrame(list(mycol.find({}, {\"_id\": False})))\n</pre> # \u5c06\u7ed3\u679c\u8f93\u51fa\u4e3adf pd.DataFrame(list(mycol.find({}, {\"_id\": False}))) Out[10]: name age 0 John 30 1 Leo 22 In\u00a0[11]: Copied! <pre>df_new = pd.DataFrame(data={'name': ['lucy', 'jack'], 'age': ['21', '23']})\ndf_new\n</pre> df_new = pd.DataFrame(data={'name': ['lucy', 'jack'], 'age': ['21', '23']}) df_new Out[11]: name age 0 lucy 21 1 jack 23 In\u00a0[12]: Copied! <pre>records = df_new.to_dict(orient='records')\nrecords\n</pre> records = df_new.to_dict(orient='records') records Out[12]: <pre>[{'name': 'lucy', 'age': '21'}, {'name': 'jack', 'age': '23'}]</pre> In\u00a0[13]: Copied! <pre>mycol.insert_many(records)\n</pre> mycol.insert_many(records) Out[13]: <pre>InsertManyResult([ObjectId('6555d59ca88aed77b6e3c139'), ObjectId('6555d59ca88aed77b6e3c13a')], acknowledged=True)</pre> In\u00a0[14]: Copied! <pre>list(mycol.find({}, {\"_id\": False}))\n</pre> list(mycol.find({}, {\"_id\": False})) Out[14]: <pre>[{'name': 'John', 'age': 30},\n {'name': 'Leo', 'age': 22},\n {'name': 'lucy', 'age': '21'},\n {'name': 'jack', 'age': '23'}]</pre> In\u00a0[15]: Copied! <pre>mycol.insert_one({\"hobby\": 'sleep'})\n</pre> mycol.insert_one({\"hobby\": 'sleep'}) Out[15]: <pre>InsertOneResult(ObjectId('6555d59ca88aed77b6e3c13b'), acknowledged=True)</pre> In\u00a0[16]: Copied! <pre>list(mycol.find({}, {\"_id\": False}))\n</pre> list(mycol.find({}, {\"_id\": False})) Out[16]: <pre>[{'name': 'John', 'age': 30},\n {'name': 'Leo', 'age': 22},\n {'name': 'lucy', 'age': '21'},\n {'name': 'jack', 'age': '23'},\n {'hobby': 'sleep'}]</pre> In\u00a0[17]: Copied! <pre># mycol.drop()\n</pre> # mycol.drop() <p>\u5728\u672c\u5730\u7684 MongoDB \u4e2d\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u6b65\u9aa4\u6765\u6dfb\u52a0\u7528\u6237\uff1a</p> <ol> <li><p>\u542f\u7528\u8bbf\u95ee\u63a7\u5236\uff1a</p> <ul> <li>\u5728 <code>mongod.conf</code> \u914d\u7f6e\u6587\u4ef6\u4e2d\uff0c\u786e\u4fdd <code>security.authorization</code> \u8bbe\u7f6e\u4e3a <code>enabled</code>\u3002</li> <li>\u91cd\u542f MongoDB \u670d\u52a1\u4ee5\u5e94\u7528\u66f4\u6539\u3002</li> </ul> </li> <li><p>\u8fde\u63a5\u5230 MongoDB\uff1a</p> <ul> <li>\u6253\u5f00\u7ec8\u7aef\u6216\u547d\u4ee4\u884c\u7a97\u53e3\u3002</li> <li>\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u4ee5\u8fde\u63a5\u5230 MongoDB\uff1a</li> </ul> <pre>mongo\n</pre> </li> <li><p>\u5207\u6362\u5230 admin \u6570\u636e\u5e93\uff1a</p> <ul> <li>\u5728 MongoDB \u4e2d\uff0c\u7528\u6237\u4fe1\u606f\u5b58\u50a8\u5728 <code>admin</code> \u6570\u636e\u5e93\u4e2d\u3002</li> <li>\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u4ee5\u5207\u6362\u5230 <code>admin</code> \u6570\u636e\u5e93\uff1a</li> </ul> <pre>use admin\n</pre> </li> <li><p>\u521b\u5efa\u7528\u6237\uff1a</p> <ul> <li>\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u4ee5\u521b\u5efa\u4e00\u4e2a\u7528\u6237\uff1a</li> </ul> <pre>db.createUser({\n    user: \"myuser\",\n    pwd: \"mypassword\",\n    roles: [\"readWrite\", \"dbAdmin\"]\n})\n</pre> <ul> <li>\u8fd9\u5c06\u521b\u5efa\u4e00\u4e2a\u540d\u4e3a <code>myuser</code> \u7684\u7528\u6237\uff0c\u5bc6\u7801\u4e3a <code>mypassword</code>\uff0c\u5e76\u8d4b\u4e88\u4e86 <code>readWrite</code> \u548c <code>dbAdmin</code> \u89d2\u8272\u3002</li> </ul> </li> <li><p>\u9a8c\u8bc1\u7528\u6237\uff1a</p> <ul> <li>\u8fd0\u884c\u4ee5\u4e0b\u547d\u4ee4\u4ee5\u9a8c\u8bc1\u7528\u6237\uff1a</li> </ul> <pre>db.auth(\"myuser\", \"mypassword\")\n</pre> <ul> <li>\u5982\u679c\u8fd4\u56de <code>1</code>\uff0c\u8868\u793a\u9a8c\u8bc1\u6210\u529f\u3002</li> </ul> </li> </ol> <p>\u73b0\u5728\uff0c\u4f60\u5df2\u7ecf\u6210\u529f\u5728\u672c\u5730\u7684 MongoDB \u6570\u636e\u5e93\u4e2d\u521b\u5efa\u4e86\u4e00\u4e2a\u7528\u6237\uff0c\u53ef\u4ee5\u4f7f\u7528\u7528\u6237\u540d\u548c\u5bc6\u7801\u767b\u5f55\u5230\u6570\u636e\u5e93\u4e86\uff01\ud83d\udc4d</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/16 (1) Create a User \u2014 MongoDB Manual. https://www.mongodb.com/docs/manual/tutorial/create-users/. (2) How to Add a New User to a MongoDB Database - Medium. https://mhagemann.medium.com/how-to-add-a-new-user-to-a-mongodb-database-d896776b5362. (3) How to create users and define their permissions in MongoDB?. https://stackoverflow.com/questions/58158830/how-to-create-users-and-define-their-permissions-in-mongodb. (4) Add Users \u2014 MongoDB Manual. https://www.mongodb.com/docs/v4.4/tutorial/create-users/.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>\u5728 MongoDB Compass \u4e2d\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u6b65\u9aa4\u6765\u8bbf\u95ee\u4e00\u4e2a\u6709\u5bc6\u7801\u7684\u7528\u6237\uff1a</p> <ol> <li><p>\u6253\u5f00 MongoDB Compass \u5e76\u8fde\u63a5\u5230\u4f60\u7684 MongoDB \u5b9e\u4f8b\uff0c\u4f7f\u7528\u5177\u6709\u7ba1\u7406\u5458\u6743\u9650\u7684\u7528\u6237\u3002</p> </li> <li><p>\u5728 Compass \u4e2d\uff0c\u70b9\u51fb\u5de6\u4e0a\u89d2\u7684 \u201cNew Connection\u201d \u6309\u94ae\uff0c\u6216\u8005\u5728\u5df2\u6709\u7684\u8fde\u63a5\u5217\u8868\u4e2d\u70b9\u51fb \u201cConnect\u201d\u3002</p> </li> <li><p>\u5728\u8fde\u63a5\u8bbe\u7f6e\u4e2d\uff0c\u586b\u5199\u4ee5\u4e0b\u4fe1\u606f\uff1a</p> <ul> <li>Hostname\uff1aMongoDB \u670d\u52a1\u5668\u7684\u4e3b\u673a\u540d\u6216 IP \u5730\u5740\u3002</li> <li>Port\uff1aMongoDB \u670d\u52a1\u5668\u7684\u7aef\u53e3\u53f7\uff08\u901a\u5e38\u662f 27017\uff09\u3002</li> <li>Authentication\uff1a\u9009\u62e9 Username / Password\u3002</li> <li>Username\uff1a\u4f60\u8981\u8bbf\u95ee\u7684\u6570\u636e\u5e93\u7684\u7528\u6237\u540d\u3002</li> <li>Password\uff1a\u5bf9\u5e94\u7528\u6237\u540d\u7684\u5bc6\u7801\u3002</li> <li>Authentication Database\uff1a\u901a\u5e38\u662f <code>admin</code>\uff0c\u56e0\u4e3a\u8fd9\u662f\u7ba1\u7406\u7528\u6237\u7684\u9ed8\u8ba4\u6570\u636e\u5e93\u3002</li> </ul> </li> <li><p>\u70b9\u51fb \u201cConnect\u201d \u6309\u94ae\uff0cCompass \u5c06\u4f7f\u7528\u63d0\u4f9b\u7684\u7528\u6237\u540d\u548c\u5bc6\u7801\u8fde\u63a5\u5230 MongoDB \u5b9e\u4f8b\u3002</p> </li> </ol> <p>\u8bf7\u6ce8\u610f\uff0c\u5982\u679c\u4f60\u7684\u5bc6\u7801\u4e2d\u5305\u542b\u7279\u6b8a\u5b57\u7b26\uff08\u5982 <code>@</code>\uff09\uff0c\u4f60\u53ef\u4ee5\u4f7f\u7528 URL \u7f16\u7801\u6765\u8868\u793a\u5bc6\u7801\u3002\u4f8b\u5982\uff0c\u5982\u679c\u5bc6\u7801\u662f <code>myP@ssw0rd</code>\uff0c\u5219\u53ef\u4ee5\u5728\u8fde\u63a5\u5b57\u7b26\u4e32\u4e2d\u4f7f\u7528 <code>myP%40ssw0rd</code> \u6765\u8868\u793a\u00b9\u00b2\u00b3\u3002</p> <p>\u5982\u679c\u4f60\u4f7f\u7528 MongoDB Atlas\uff0c\u4f60\u53ef\u4ee5\u4ece Atlas \u63a7\u5236\u53f0\u83b7\u53d6\u8fde\u63a5\u5b57\u7b26\u4e32\uff0c\u7136\u540e\u5c06\u5176\u7c98\u8d34\u5230 Compass \u4e2d\u3002\u8fde\u63a5\u5b57\u7b26\u4e32\u5c06\u5305\u542b\u7528\u6237\u540d\u3001\u5bc6\u7801\u548c\u5176\u4ed6\u5fc5\u8981\u7684\u4fe1\u606f\u3002</p> <p>\u5e0c\u671b\u8fd9\u5bf9\u4f60\u6709\u6240\u5e2e\u52a9\uff01\ud83d\udd11\ud83d\udd12</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/16 (1) See / setup a user with MongoDB Compass? - Stack Overflow. https://stackoverflow.com/questions/46972695/see-setup-a-user-with-mongodb-compass. (2) How can you specify the mongodb username and password using a Server .... https://stackoverflow.com/questions/14045509/how-can-you-specify-the-mongodb-username-and-password-using-a-server-instance. (3) Authentication Connection Tab \u2014 MongoDB Compass. https://www.mongodb.com/docs/compass/master/connect/advanced-connection-options/authentication-connection/. (4) Connect to MongoDB \u2014 MongoDB Compass. https://www.mongodb.com/docs/compass/current/connect/. (5) node.js - MongoDB password with \"@\" in it - Stack Overflow. https://stackoverflow.com/questions/7486623/mongodb-password-with-in-it. (6) How to connect MongoDB with MongoDB Compass \u2013 Webuzo. https://webuzo.com/docs/how-tos/how-to-connect-mongodb-with-mongodb-compass/. (7) Connection Strings \u2014 MongoDB Manual. https://www.mongodb.com/docs/manual/reference/connection-string/.</p> In\u00a0[18]: Copied! <pre>db = client[\"admin\"]\n</pre> db = client[\"admin\"] <p>\u521b\u5efa\u62e5\u6709root\u6743\u9650\u7684\u65b0\u7528\u6237leo</p> <p>https://blog.csdn.net/zhanghongshuang/article/details/117461225</p> <p>\u5728\u7ec8\u7aef\u8fd0\u884c\u5982\u4e0b\u547d\u4ee4</p> <p><code>mongosh</code> <code>use admin</code></p> <p><code>db.createUser({         user: 'leo',         pwd: '240103',         roles: ['root']     })</code></p> In\u00a0[6]: Copied! <pre>#  \u521b\u5efa\u6570\u636e\u5e93\u8fde\u63a5\u5bf9\u8c61\n# url\u7684\u683c\u5f0f\uff1amongodb://username:password@ip:port\n# \u767b\u5f55\u4e4b\u540e\u64cd\u4f5c\u5b8c\u5168\u4e00\u6837\nleo = MongoClient('mongodb://leo:240103@127.0.0.1:27017')\nleo.list_database_names()\n# #  \u9009\u62e9\u4e00\u4e2a\u6570\u636e\u5e93\n# db = client['admin']\n# #  \u6570\u636e\u5e93\u4e2d\u5f00\u4e86\u6743\u9650\u8ba4\u8bc1\u540e\uff0c\u9700\u8981\u4e0b\u4e00\u884c\u4ee3\u7801\n# #  \u8f93\u5165\u8d85\u7ea7\u7ba1\u7406\u5458\u8d26\u53f7\u548c\u5bc6\u7801\n# # db.authenticate('python', 'python')\n# # #  \u9009\u62e9\u4e00\u4e2a\u96c6\u5408,\u6ca1\u6709\u7684\u8bdd\u4f1a\u65b0\u5efa\u7684\n# col = client['pydata']['test']\n</pre> #  \u521b\u5efa\u6570\u636e\u5e93\u8fde\u63a5\u5bf9\u8c61 # url\u7684\u683c\u5f0f\uff1amongodb://username:password@ip:port # \u767b\u5f55\u4e4b\u540e\u64cd\u4f5c\u5b8c\u5168\u4e00\u6837 leo = MongoClient('mongodb://leo:240103@127.0.0.1:27017') leo.list_database_names() # #  \u9009\u62e9\u4e00\u4e2a\u6570\u636e\u5e93 # db = client['admin'] # #  \u6570\u636e\u5e93\u4e2d\u5f00\u4e86\u6743\u9650\u8ba4\u8bc1\u540e\uff0c\u9700\u8981\u4e0b\u4e00\u884c\u4ee3\u7801 # #  \u8f93\u5165\u8d85\u7ea7\u7ba1\u7406\u5458\u8d26\u53f7\u548c\u5bc6\u7801 # # db.authenticate('python', 'python') # # #  \u9009\u62e9\u4e00\u4e2a\u96c6\u5408,\u6ca1\u6709\u7684\u8bdd\u4f1a\u65b0\u5efa\u7684 # col = client['pydata']['test']  <pre>\n---------------------------------------------------------------------------\nServerSelectionTimeoutError               Traceback (most recent call last)\nCell In[6], line 5\n      1 #  \u521b\u5efa\u6570\u636e\u5e93\u8fde\u63a5\u5bf9\u8c61\n      2 # url\u7684\u683c\u5f0f\uff1amongodb://username:password@ip:port\n      3 # \u767b\u5f55\u4e4b\u540e\u64cd\u4f5c\u5b8c\u5168\u4e00\u6837\n      4 leo = MongoClient('mongodb://leo:240103@127.0.0.1:27017')\n----&gt; 5 leo.list_database_names()\n\nFile ~/anaconda3/envs/leoweng4.1/lib/python3.9/site-packages/pymongo/mongo_client.py:1952, in MongoClient.list_database_names(self, session, comment)\n   1934 def list_database_names(\n   1935     self,\n   1936     session: Optional[client_session.ClientSession] = None,\n   1937     comment: Optional[Any] = None,\n   1938 ) -&gt; list[str]:\n   1939     \"\"\"Get a list of the names of all databases on the connected server.\n   1940 \n   1941     :Parameters:\n   (...)\n   1950     .. versionadded:: 3.6\n   1951     \"\"\"\n-&gt; 1952     return [doc[\"name\"] for doc in self.list_databases(session, nameOnly=True, comment=comment)]\n\nFile ~/anaconda3/envs/leoweng4.1/lib/python3.9/site-packages/pymongo/mongo_client.py:1925, in MongoClient.list_databases(self, session, comment, **kwargs)\n   1923     cmd[\"comment\"] = comment\n   1924 admin = self._database_default_options(\"admin\")\n-&gt; 1925 res = admin._retryable_read_command(cmd, session=session)\n   1926 # listDatabases doesn't return a cursor (yet). Fake one.\n   1927 cursor = {\n   1928     \"id\": 0,\n   1929     \"firstBatch\": res[\"databases\"],\n   1930     \"ns\": \"admin.$cmd\",\n   1931 }\n\nFile ~/anaconda3/envs/leoweng4.1/lib/python3.9/site-packages/pymongo/database.py:1026, in Database._retryable_read_command(self, command, session)\n   1013 def _cmd(\n   1014     session: Optional[ClientSession],\n   1015     _server: Server,\n   1016     conn: Connection,\n   1017     read_preference: _ServerMode,\n   1018 ) -&gt; dict[str, Any]:\n   1019     return self._command(\n   1020         conn,\n   1021         command,\n   1022         read_preference=read_preference,\n   1023         session=session,\n   1024     )\n-&gt; 1026 return self.__client._retryable_read(_cmd, read_preference, session)\n\nFile ~/anaconda3/envs/leoweng4.1/lib/python3.9/site-packages/pymongo/mongo_client.py:1492, in MongoClient._retryable_read(self, func, read_pref, session, address, retryable)\n   1487 # Ensure that the client supports retrying on reads and there is no session in\n   1488 # transaction, otherwise, we will not support retry behavior for this call.\n   1489 retryable = bool(\n   1490     retryable and self.options.retry_reads and not (session and session.in_transaction)\n   1491 )\n-&gt; 1492 return self._retry_internal(\n   1493     func,\n   1494     session,\n   1495     None,\n   1496     is_read=True,\n   1497     address=address,\n   1498     read_pref=read_pref,\n   1499     retryable=retryable,\n   1500 )\n\nFile ~/anaconda3/envs/leoweng4.1/lib/python3.9/site-packages/pymongo/_csot.py:107, in apply.&lt;locals&gt;.csot_wrapper(self, *args, **kwargs)\n    105         with _TimeoutContext(timeout):\n    106             return func(self, *args, **kwargs)\n--&gt; 107 return func(self, *args, **kwargs)\n\nFile ~/anaconda3/envs/leoweng4.1/lib/python3.9/site-packages/pymongo/mongo_client.py:1453, in MongoClient._retry_internal(self, func, session, bulk, is_read, address, read_pref, retryable)\n   1428 @_csot.apply\n   1429 def _retry_internal(\n   1430     self,\n   (...)\n   1437     retryable: bool = False,\n   1438 ) -&gt; T:\n   1439     \"\"\"Internal retryable helper for all client transactions.\n   1440 \n   1441     :Parameters:\n   (...)\n   1451       Output of the calling func()\n   1452     \"\"\"\n-&gt; 1453     return _ClientConnectionRetryable(\n   1454         mongo_client=self,\n   1455         func=func,\n   1456         bulk=bulk,\n   1457         is_read=is_read,\n   1458         session=session,\n   1459         read_pref=read_pref,\n   1460         address=address,\n   1461         retryable=retryable,\n   1462     ).run()\n\nFile ~/anaconda3/envs/leoweng4.1/lib/python3.9/site-packages/pymongo/mongo_client.py:2315, in _ClientConnectionRetryable.run(self)\n   2313 self._check_last_error(check_csot=True)\n   2314 try:\n-&gt; 2315     return self._read() if self._is_read else self._write()\n   2316 except ServerSelectionTimeoutError:\n   2317     # The application may think the write was never attempted\n   2318     # if we raise ServerSelectionTimeoutError on the retry\n   2319     # attempt. Raise the original exception instead.\n   2320     self._check_last_error()\n\nFile ~/anaconda3/envs/leoweng4.1/lib/python3.9/site-packages/pymongo/mongo_client.py:2436, in _ClientConnectionRetryable._read(self)\n   2430 def _read(self) -&gt; T:\n   2431     \"\"\"Wrapper method for read-type retryable client executions\n   2432 \n   2433     :Returns:\n   2434         Output for func()'s call\n   2435     \"\"\"\n-&gt; 2436     self._server = self._get_server()\n   2437     assert self._read_pref is not None, \"Read Preference required on read calls\"\n   2438     with self._client._conn_from_server(self._read_pref, self._server, self._session) as (\n   2439         conn,\n   2440         read_pref,\n   2441     ):\n\nFile ~/anaconda3/envs/leoweng4.1/lib/python3.9/site-packages/pymongo/mongo_client.py:2399, in _ClientConnectionRetryable._get_server(self)\n   2393 def _get_server(self) -&gt; Server:\n   2394     \"\"\"Retrieves a server object based on provided object context\n   2395 \n   2396     :Returns:\n   2397         Abstraction to connect to server\n   2398     \"\"\"\n-&gt; 2399     return self._client._select_server(\n   2400         self._server_selector, self._session, address=self._address\n   2401     )\n\nFile ~/anaconda3/envs/leoweng4.1/lib/python3.9/site-packages/pymongo/mongo_client.py:1303, in MongoClient._select_server(self, server_selector, session, address)\n   1301             raise AutoReconnect(\"server %s:%s no longer available\" % address)  # noqa: UP031\n   1302     else:\n-&gt; 1303         server = topology.select_server(server_selector)\n   1304     return server\n   1305 except PyMongoError as exc:\n   1306     # Server selection errors in a transaction are transient.\n\nFile ~/anaconda3/envs/leoweng4.1/lib/python3.9/site-packages/pymongo/topology.py:302, in Topology.select_server(self, selector, server_selection_timeout, address)\n    295 def select_server(\n    296     self,\n    297     selector: Callable[[Selection], Selection],\n    298     server_selection_timeout: Optional[float] = None,\n    299     address: Optional[_Address] = None,\n    300 ) -&gt; Server:\n    301     \"\"\"Like select_servers, but choose a random server if several match.\"\"\"\n--&gt; 302     server = self._select_server(selector, server_selection_timeout, address)\n    303     if _csot.get_timeout():\n    304         _csot.set_rtt(server.description.min_round_trip_time)\n\nFile ~/anaconda3/envs/leoweng4.1/lib/python3.9/site-packages/pymongo/topology.py:286, in Topology._select_server(self, selector, server_selection_timeout, address)\n    280 def _select_server(\n    281     self,\n    282     selector: Callable[[Selection], Selection],\n    283     server_selection_timeout: Optional[float] = None,\n    284     address: Optional[_Address] = None,\n    285 ) -&gt; Server:\n--&gt; 286     servers = self.select_servers(selector, server_selection_timeout, address)\n    287     if len(servers) == 1:\n    288         return servers[0]\n\nFile ~/anaconda3/envs/leoweng4.1/lib/python3.9/site-packages/pymongo/topology.py:237, in Topology.select_servers(self, selector, server_selection_timeout, address)\n    234     server_timeout = server_selection_timeout\n    236 with self._lock:\n--&gt; 237     server_descriptions = self._select_servers_loop(selector, server_timeout, address)\n    239     return [\n    240         cast(Server, self.get_server_by_address(sd.address)) for sd in server_descriptions\n    241     ]\n\nFile ~/anaconda3/envs/leoweng4.1/lib/python3.9/site-packages/pymongo/topology.py:259, in Topology._select_servers_loop(self, selector, timeout, address)\n    256 while not server_descriptions:\n    257     # No suitable servers.\n    258     if timeout == 0 or now &gt; end_time:\n--&gt; 259         raise ServerSelectionTimeoutError(\n    260             f\"{self._error_message(selector)}, Timeout: {timeout}s, Topology Description: {self.description!r}\"\n    261         )\n    263     self._ensure_opened()\n    264     self._request_check_all()\n\nServerSelectionTimeoutError: 127.0.0.1:27017: [Errno 61] Connection refused (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms), Timeout: 30s, Topology Description: &lt;TopologyDescription id: 65cef41aef2ba24e00135c0c, topology_type: Unknown, servers: [&lt;ServerDescription ('127.0.0.1', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('127.0.0.1:27017: [Errno 61] Connection refused (configured timeouts: socketTimeoutMS: 20000.0ms, connectTimeoutMS: 20000.0ms)')&gt;]&gt;</pre> In\u00a0[23]: Copied! <pre>leo\n</pre> leo Out[23]: <pre>MongoClient(host=['127.0.0.1:27017'], document_class=dict, tz_aware=False, connect=True)</pre> In\u00a0[30]: Copied! <pre>c = leo['mydatabase']['customers']\n</pre> c = leo['mydatabase']['customers'] In\u00a0[33]: Copied! <pre>c.insert_one({\"name\": \"cate\", \"age\": 30})\n</pre> c.insert_one({\"name\": \"cate\", \"age\": 30}) Out[33]: <pre>InsertOneResult(ObjectId('6555d98da88aed77b6e3c13e'), acknowledged=True)</pre> In\u00a0[34]: Copied! <pre>list(c.find())\n</pre> list(c.find()) Out[34]: <pre>[{'_id': ObjectId('6555d59ca88aed77b6e3c137'), 'name': 'John', 'age': 30},\n {'_id': ObjectId('6555d59ca88aed77b6e3c138'), 'name': 'Leo', 'age': 22},\n {'_id': ObjectId('6555d59ca88aed77b6e3c139'), 'name': 'lucy', 'age': '21'},\n {'_id': ObjectId('6555d59ca88aed77b6e3c13a'), 'name': 'jack', 'age': '23'},\n {'_id': ObjectId('6555d59ca88aed77b6e3c13b'), 'hobby': 'sleep'},\n {'_id': ObjectId('6555d903a88aed77b6e3c13d'), 'name': 'John', 'age': 30},\n {'_id': ObjectId('6555d98da88aed77b6e3c13e'), 'name': 'cate', 'age': 30}]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>\u914d\u7f6emongodb https://blog.csdn.net/weixin_46019681/article/details/125491883?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-125491883-blog-129079258.235^v38^pc_relevant_sort_base2&amp;spm=1001.2101.3001.4242.1&amp;utm_relevant_index=3</p>"},{"location":"markdown/development_utils/mongo_test/#leo","title":"\u4f7f\u7528leo\u767b\u5f55\u00b6","text":""},{"location":"markdown/development_utils/plotly%E7%9A%84%E9%85%8D%E7%BD%AE/","title":"plotly\u7684\u914d\u7f6e","text":"<ol> <li>plotly\u7684\u914d\u7f6e\u53ef\u80fd\u4f1a\u9047\u5230ipywidgets\u5b89\u88c5\u540e\u5bfc\u81f4jupyter notebook server error \u89e3\u51b3\u529e\u6cd5\uff1a</li> <li><code>conda install -c conda-forge widgetsnbextension</code></li> <li><code>jupyter nbextension enable --py widgetsnbextension</code></li> <li><code>jupyter nbextension enable --py --sys-prefix widgetsnbextension</code></li> </ol> <p>\u76ee\u524d\u8fd8\u6ca1\u641e\u5b9a</p>"},{"location":"markdown/development_utils/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B/","title":"\u5f00\u53d1\u73af\u5883\u914d\u7f6e\u53ca\u5f00\u53d1\u6d41\u7a0b","text":"<p>\u5229\u7528pycharm\u548canaconda\u642d\u5efa\u5f00\u53d1\u73af\u5883</p>"},{"location":"markdown/development_utils/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B/#1","title":"1. \u6d4b\u8bd5\u73af\u5883","text":"<p>\u5728anaconda\u4e2d\u521b\u5efa\u6d4b\u8bd5\u73af\u5883leoweng_test\uff0c\u7136\u540e\u5728jupyter notebook\u7684kernel\u4e2d\u52a0\u5165\u6d4b\u8bd5\u73af\u5883\uff0c\u547d\u540d\u4e3aleoweng_test\uff0c \u8fd9\u6837\u5c31\u53ef\u4ee5\u5728notebook\u4e2d\u5bf9\u73af\u5883\u8fdb\u884c\u6d4b\u8bd5\u540c\u65f6\u5b8c\u6210\u5f00\u53d1\u3002</p>"},{"location":"markdown/development_utils/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B/#2","title":"2. \u751f\u4ea7\u73af\u5883","text":"<p>\u540c\u6837\u7684\u6b65\u9aa4\u521b\u5efaleowengx.x\uff0c\u76ee\u524d\u4e3a4.1\u7248\u672c(leoweng4.1)</p> <p> <code>conda install ipykernel</code> \u5b89\u88c5ipykernel  <code>sudo python -m ipykernel install --name tf</code> \u5728ipykernel\u4e2d\u5b89\u88c5\u5f53\u524d\u73af\u5883  \u2003\u2003\u6ce8\u610f\uff1a\u4ee5\u4e0a\u901a\u8fc7python -m ipykernel install \u547d\u4ee4\u624b\u52a8\u5c06jupyter notebook\u7684kernel\u8fde\u63a5\u5230\u865a\u62df\u73af\u5883\uff0c\u53ef\u80fd\u4f1a\u5931\u6548\uff0c \u5efa\u8bae\u76f4\u63a5conda install nb_conda\uff0c\u7136\u540e\u91cd\u542fnotebook\uff0cnotebook\u7684kernel\u5c31\u4f1a\u81ea\u52a8\u8fde\u63a5\u865a\u62df\u73af\u5883\u3002conda env:\u5f00\u5934\u7684\u5c31\u662f\u81ea\u52a8\u8fde\u63a5\u7684\uff0c \u6709\u591a\u5c11\u7684\u865a\u62df\u73af\u5883\u90fd\u4f1a\u81ea\u52a8\u521b\u5efa\u5bf9\u5e94\u4e2a\u6570\u7684notebook kernel\u3002 </p> <p>\u9644 1. \u5b89\u88c5tensorflow\u65b9\u6cd5 2. Mac\u5b89\u88c5\u5e26\u6709MPS\u52a0\u901f\u7684torch\u7684\u65b9\u6cd5</p>"},{"location":"markdown/development_utils/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B/#3-pycharm","title":"3. pycharm\u73af\u5883\u914d\u7f6e","text":"<p>\u2003\u2003\u5728pycharm\u4e2d\uff0c\u9009\u53d6anaconda\u4e2d\u7684python interpreter\uff0c\u7136\u540e\u5c31\u53ef\u4ee5\u901a\u8fc7pycharm\u7684terminal\u6765\u7ba1\u7406\u548c\u64cd\u4f5canaconda\u4e2d\u521b\u5efa\u7684\u73af\u5883\u3002 check\u4ee5\u4e0b\u5f00\u5934\u662f\u5426\u4e3a\u865a\u62df\u73af\u5883\u540d\u79f0\uff1a  \u5728existing environment\u4e2d\u6dfb\u52a0\u521b\u5efa\u597d\u7684\u865a\u62df\u73af\u5883\uff08\u5982leoweng_test\uff09 </p>"},{"location":"markdown/development_utils/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B/#4package","title":"4.\u5728\u672c\u5730\u53d1\u5e03package","text":"<ol> <li>\u6253\u5f00pycharm\uff0c\u5728site-package\u8def\u5f84\u4e2d\u521b\u5efa\u65b0\u7684project\uff0c\u547d\u540d\u4e3a\u81ea\u5df1\u60f3\u8981\u7684\u5305\u540d\u79f0\u3002\u8fd9\u91cc\u6307\u5b9asite-package\u8def\u5f84\u662f\u4e3a\u4e86\u80fd\u8ba9site-package\u8def\u5f84\u4e2d\u5177\u6709 py\u6587\u4ef6\uff0c\u548c\u5176\u4ed6package\u7edf\u4e00\u3002\u521b\u5efa\u597d\u81f3\u5c11\u4e09\u4e2apy\u6587\u4ef6\uff0c\u5177\u4f53\u7ed3\u6784\u53c2\u8003\u4e0b\u56fe\u3001psapmdata\u4ee5\u53camypackage1\u3002\u5176\u4e2dinit\u6587\u4ef6\u7684\u4f5c\u7528\u662f\u4f7f\u5f97 python interpreter\u77e5\u9053\u8fd9\u4e2a\u8def\u5f84\u4e0b\u662fpython package\uff0c\u56e0\u6b64\u9700\u8981\u5728\u6bcf\u4e2apy\u7684\u540c\u7ea7\u76ee\u5f55\u4e0b\u90fd\u653e\u4e00\u4e2ainit\u6587\u4ef6\uff0cinit\u6587\u4ef6\u53ef\u4ee5\u4e3a\u7a7a\uff08\u4f46\u662f\u6700\u597d\u6709import\uff0c \u5177\u4f53\u53c2\u8003\u5305\u548c\u6a21\u5757\u7684\u8bf4\u660e\uff09\u3002setup\u6587\u4ef6\u7684\u53c2\u6570\u7b49\u53c2\u8003\u4e0b\u8868  \u4ee5\u53ca \u8fd9\u7bc7blog\u3002</li> <li>\u786e\u4fddpycharm\u73af\u5883\u5207\u6362\u81f3\u60f3\u8981\u53d1\u5e03package\u7684\u73af\u5883\uff0c\u5728pycharm terminal\u4e2d\u8f93\u5165python -m build\uff08\u6216\u8005python setup.py bdist_wheel sdist\uff09\uff0c\u7136\u540e\u4f1a\u770b\u5230\u751f\u6210\u4e00\u4e9b\u6587\u4ef6\uff0c\u5173\u6ce8dist\u6587\u4ef6\u5939\u4e2d\u7684.tar.gz\u6587\u4ef6\uff0c\u4ee3\u8868\u7740\u6e90\u7801\u5206\u53d1\u5305\uff0c\u6211\u4eec\u901a\u5e38\u5229\u7528\u8fd9\u4e2a\u6587\u4ef6\u6765install package\u3002</li> <li>\u9009\u62e9\u6587\u4ef6\u540d\u79f0\uff0c\u8fd0\u884cpip install dist/mypackage1-0.0.4.tar.gz\uff0c\u6b64\u65f6package\u5df2\u7ecf\u53d1\u5e03\u5728\u672c\u5730\uff0c\u5e76\u4e14\u53ef\u4ee5\u88abpip\u8bc6\u522b\u3002\uff08pip list or pip show can be used for test.\uff09</li> <li>\u5982\u679c\u8fed\u4ee3\u7248\u672c\uff0c\u90a3\u4e48\u9700\u8981\u5728setup.py\u4e2d\u4fee\u6539\u7248\u672c\u53f7\uff0c\u7136\u540e\u518d\u6b21\u91cd\u590d\u6b65\u9aa4\u53d1\u5e03package\u3002 </li> <li>\u6ce8\u610f\uff1a\u8fd9\u7bc7\u6587\u7ae0\u6709\u90e8\u5206\u4e0d\u591f\u5b8c\u5584\u7684\u5730\u65b9\uff0c\u5177\u4f53package\u7684\u7ed3\u6784\u8bf7\u53c2\u8003lwpackage\uff0c\u540c\u65f6\u9700\u8981\u6ce8\u610f__init__.py\u6587\u4ef6 5.git\u914d\u7f6e\u53ca\u5229\u7528git\u5f00\u53d1\u7684\u6d41\u7a0b</li> <li> <p>\u6982\u8ff0\u5047\u8bbe\u6211\u4eec\u4ece\u96f6\u5f00\u59cb\u5f00\u53d1\uff0c\u90a3\u4e48\u6700\u597d\u7684\u6b65\u9aa4\u662f\u5148\u5728\u8fdc\u7a0b\u521b\u5efa\u4e00\u4e2a\u4ed3\u5e93\uff0c\u7136\u540e\u514b\u9686\u5230\u672c\u5730\uff0c\u5728\u672c\u5730\u5b8c\u6210\u5f00\u53d1\u540epush\u5230\u8fdc\u7a0b\u5e76\u4e14\u5408\u5e76\u8fdc\u7a0b\u5206\u652f\u3002</p> </li> <li> <p>\u5177\u4f53\u6d41\u7a0b 1.\u5728\u8fdc\u7a0b\u624b\u52a8\u521b\u5efa\u4e00\u4e2a\u4ed3\u5e93\uff0c\u6dfb\u52a0README\u7b49\u6587\u4ef6\u3002 2.\u521b\u5efagit\u672c\u5730\u4ed3\u5e93\uff08repo\uff09\u8def\u5f84 ~/work_repo\u3002 3.\u5728pycharm clone \u8fdc\u7a0b\u4ed3\u5e93\uff0c\u9009\u62e9\u672c\u5730\u4ed3\u5e93\uff08directory\uff09\u8def\u5f84\uff0c\u914d\u7f6epython interpreter, checkout\u65b0\u7684\u5206\u652f\u5f00\u59cb\u5f00\u53d1\u3002 </p> </li> </ol> <p>4.\u5f00\u53d1\u5b8c\u6210\u540e\u5728pycharm\u4e2dpush\uff0c\u540c\u65f6\u5728gitee\u63d0\u4ea4pull request\u3002 </p> <p>5.\u5ba1\u67e5\u548c\u6d4b\u8bd5\u4eba\u5458\u5ba1\u6838merge request, \u5e76\u4e14\u5408\u5e76\u5206\u652f\u3002 </p> <p>6.\u5728pycharm\u672c\u5730pull\u6700\u65b0\u7684\u8fdc\u7a0bmain\uff0c\u672c\u5730main\u4e5f\u88ab\u66f4\u65b0\uff0c\u5b8c\u6210\u8fdc\u7aef\u4ed3\u5e93\u548c\u672c\u5730\u4ed3\u5e93\u7684\u66f4\u65b0\u3002 7.\u76ee\u524d\u4e3a\u6b62\uff0c\u672c\u5730\u7684\u64cd\u4f5c\u90fd\u662f\u5728repo\u4e2d\u8fdb\u884c\u7684\uff0c\u800c\u672c\u5730\u73af\u5883\u4e2d\u7684\u76f8\u5173package\u5e76\u6ca1\u6709\u66f4\u65b0\u3002\u56e0\u6b64\uff0c\u6700\u540e\u6211\u4eec\u66f4\u65b0\u672c\u5730\u73af\u5883\u4e2d\u7684package\u3002\u9996\u5148\uff0cpython -m build\u751f\u6210.tar.gz\u6587\u4ef6\uff0c\u7136\u540e\u5728\u672c\u5730\u73af\u5883\u4e0binstall\u3002\u4f8b\u5982\uff0c pip install file://Users/wenglongao/work_repo/mypackage1/dist/mypackage1-0.0.5.tar.gz</p>"},{"location":"markdown/development_utils/%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%BC%80%E5%8F%91%E6%B5%81%E7%A8%8B/#anaconda","title":"Anaconda\u865a\u62df\u73af\u5883\u7ba1\u7406\u8bf4\u660e","text":"<p>\u5728Anaconda\u4e2d\uff0c<code>\u6bcf\u4e2a\u865a\u62df\u73af\u5883\u4e0b\u90fd\u4f1a\u521b\u5efa\u4e00\u4e2a\u81ea\u8eab\u7684python\u89e3\u91ca\u5668</code>\u3002\u4f8b\u5982\uff0c\u5728torch\u73af\u5883\u4e0b\u7684python\u89e3\u91ca\u5668\u5c31\u5728<code>/Users/wenglongao/anaconda3/envs/torch/bin</code>\u8def\u5f84\u4e0b\u3002 \u5728bin\u76ee\u5f55\u4e0b\uff0c\u6709\u5f88\u591a\u4e2apython\u6587\u4ef6\uff0c\u5176\u4e2d\u4e00\u4e9b\u662f\u66ff\u8eab\uff0c\u4e00\u4e9b\u662f\u6587\u7a3f\u3002  \u76ee\u524d\u53d1\u73b0\u7684\u89c4\u5f8b\u662f\uff0c\u4f7f\u7528<code>conda create -n torch python=3.10</code>\u521b\u5efa\u65b0\u865a\u62df\u73af\u5883\uff0c\u5219python3.10\u4e3a\u6587\u7a3f\uff0c\u5176\u5b83\u7684python\u6587\u4ef6\u4e3a\u66ff\u8eab\uff0c\u66ff\u8eab\u5b9e\u9645\u4e0a\u662f\u4e00\u4e2a\u7b26\u53f7\u94fe\u63a5\uff0c \u94fe\u63a5\u6307\u5411\u771f\u6b63\u7684python\u89e3\u91ca\u5668(python3.10)\u3002\u5982\u679c\u5728\u6b64\u8def\u5f84\u4e0b\u4f7f\u7528<code>readlink -f ./python</code>\u6765\u67e5\u770b\u7b26\u53f7\u94fe\u63a5\u6307\u5411\u7684\u8def\u5f84\uff0c\u5c31\u4f1a\u53d1\u73b0\u8fd4\u56de\u7684\u8def\u5f84\u662f<code>/Users/wenglongao/anaconda3/envs/torch/bin/python3.10</code>\uff0c \u4ee3\u8868\u771f\u6b63\u7684python\u89e3\u91ca\u5668\u8def\u5f84\u3002</p> <p>Anaconda\u901a\u8fc7\u81ea\u52a8\u521b\u5efa\u591a\u4e2a\u66ff\u8eab\u6587\u4ef6\uff0c\u4f7f\u5f97\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528python\u8fd0\u884c\u547d\u4ee4\uff0c\u5373python test.py\u3001python3.10 test.py\u662f\u7b49\u4ef7\u7684\u3002</p> <p>\u53c2\u8003\u6587\u7ae0  https://blog.csdn.net/weixin_42345113/article/details/106444312</p> <p>https://blog.csdn.net/xx_xjm/article/details/128762190</p> <p>https://blog.csdn.net/lslxdx/article/details/73131664</p> <p>debug\uff1a https://blog.csdn.net/donaldsy/article/details/103515752</p> <p>\u53d1\u5e03package &amp; setup.py reference\uff1a https://blog.csdn.net/weixin_43940314/article/details/128349554</p> <p>https://blog.csdn.net/weixin_49891576/article/details/129745519</p> <p>\u5305\u548c\u6a21\u5757\u7684\u8bf4\u660e https://blog.csdn.net/a15608445683/article/details/127926233</p> <p>http://www.ujiuye.com/wenda/2023/72725.html</p>"},{"location":"markdown/development_utils/%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97/","title":"\u66f4\u65b0\u65e5\u5fd7","text":""},{"location":"markdown/development_utils/%E6%9B%B4%E6%96%B0%E6%97%A5%E5%BF%97/#20231031","title":"20231031","text":"<ul> <li>\u66f4\u65b0leoweng4.0\u73af\u5883\uff0c\u5176\u4e2d\u5305\u542bleoweng3.0.2\u7684\u6240\u6709package\u548c\u914d\u7f6e</li> <li>\u5728leoweng4.0\u4e2d\u6dfb\u52a0lwutils package\uff0c\u5176\u4e2d\u5305\u62ec\u672c\u5730\u7684\u6240\u6709\u6709\u7528\u7684\u65b9\u6cd5\u7b49</li> </ul>"},{"location":"markdown/development_utils/%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%A0%81/","title":"\u914d\u7f6e\u4ee3\u7801","text":"<pre><code>conda create -n leoweng3.0 python--3.9\npip install pandas numpy matplotlib mkdocs mkdocs-material ipympl\n</code></pre>"},{"location":"markdown/information_material/red_and_green_books/","title":"\u7ea2\u7eff\u5b9d\u4e66","text":""},{"location":"markdown/information_material/red_and_green_books/#_2","title":"\u7eff\u5b9d\u4e66","text":"<p>\u7eff\u5b9d\u4e66.pdf</p>"},{"location":"markdown/information_material/red_and_green_books/#_3","title":"\u7ea2\u5b9d\u4e66","text":"<p>\u7ea2\u5b9d\u4e66.pdf</p>"},{"location":"markdown/information_material/useful_books/","title":"useful books","text":""},{"location":"markdown/information_material/useful_books/#fluent-python","title":"fluent python","text":"<p>fluent_python.pdf</p>"},{"location":"markdown/interview_utils/interview_puzzles/brain_teasers/","title":"Brain teaser","text":""},{"location":"markdown/interview_utils/interview_puzzles/brain_teasers/#_1","title":"\u8d5b\u9a6c\u95ee\u9898","text":"<p>25\u5339\u9a6c\uff0c\u6bcf\u53ea\u9a6c\u7684\u901f\u5ea6\u90fd\u4e0d\u540c\u3002\u73b0\u5728\u67095\u6761\u8d5b\u9053\uff0c\u6bcf\u6b21\u6bd4\u8d5b\u53ef\u4ee5\u51b3\u5b9a\u9a6c\u7684\u76f8\u5bf9\u540d\u6b21\uff0c\u95ee\u6700\u5c11\u9700\u8981\u51e0\u6b21\u6bd4\u8d5b\u53ef\u4ee5\u627e\u5230\u6700\u5feb\u76845\u5339\u9a6c\u3002 - \u9996\u5148\uff0c\u5c0625\u5339\u9a6c\u5206\u62105\u7ec4\u6bd4\u8d5b\uff0c\u5171\u4e94\u6b21\u3002\u5c06\u6bcf\u7ec4\u6392\u540d\u6700\u540e\u7684\u4e24\u5339\u9a6c\u6392\u9664\u3002\u6b64\u65f6\u5269\u4e0b3 * 5 = 15\u5339 - \u5c06\u6bcf\u7ec4\u7684\u7b2c\u4e00\u540d\u6bd4\u8d5b\uff0c\u6392\u9664\u6700\u540e\u4e24\u540d\u6240\u5728\u7ec4\u7684\u5168\u90e8\u9a6c\uff0c\u4e14\u524d\u4e09\u540d\u6240\u5728\u7ec4\u4e2d\uff0c\u7b2c\u4e8c\u7ec4\u7684\u7ec4\u5185\u7b2c\u4e09\u540d\u53ef\u4ee5\u6392\u9664\uff0c\u7b2c\u4e09\u7ec4\u7684\u7ec4\u51852\u30013\u540d\u53ef\u4ee5\u6392\u9664\u3002\u6b64\u65f6\u5269\u4e0b 3 + 2 + 1 = 6\u5339\u9a6c\uff0c\u8fd9\u662f\u7b2c\u516d\u6b21\u6bd4\u8d5b\u3002 - \u7b2c\u516d\u6b21\u6bd4\u8d5b\u4e2d\u6392\u540d\u7b2c\u4e00\u7684\u9a6c\u4e00\u5b9a\u662f\u6700\u5feb\u7684\uff0c\u5219\u6211\u4eec\u9700\u8981\u4ece6 - 1 = 5\u5339\u9a6c\u4e2d\u9009\u51fa2\u5339\u6700\u5feb\u7684\uff0c\u6b64\u65f6\u8fdb\u884c\u7b2c\u4e03\u6b21\u6bd4\u8d5b\u3002 - \u5219\u603b\u5171\u8fdb\u884c\u4e865 + 1 + 1 = 7\u6b21\u6bd4\u8d5b\u3002</p>"},{"location":"markdown/interview_utils/interview_puzzles/brain_teasers/#_2","title":"\u5de7\u514b\u529b\u5757","text":"<p>\u7ed9\u5b9a\u4e00\u4e2aN * M \u7684\u5de7\u514b\u529b\u5757\uff0c\u95ee\u6700\u5c11\u591a\u5c11\u5200\u53ef\u4ee5\u5207\u62101*1\u7684\u5c0f\u5757\uff1f\u6ce8\u610f\u6bcf\u6b21\u53ea\u80fd\u5c06\u4e00\u5757\u5207\u6210\u4e24\u5757\u3002 \u65e0\u8bba\u5982\u4f55\u5207\u5272\uff0c\u603b\u5171\u9700\u8981\u7684\u5200\u6570\u4e3a NM - 1 12\u3002\u8fd9\u662f\u56e0\u4e3a\u6bcf\u4e00\u5200\u90fd\u4f1a\u589e\u52a0\u4e00\u4e2a\u65b0\u7684\u5c0f\u5757\uff0c\u800c\u6211\u4eec\u5e0c\u671b\u6700\u7ec8\u5f97\u5230\u7684\u662f NM \u4e2a\u5c0f\u5757\u3002\u56e0\u6b64\uff0c\u7b54\u6848\u662f\uff1a\u6700\u5c11\u9700\u8981 NM - 1 \u5200\u6765\u5c06\u5de7\u514b\u529b\u5757\u5207\u6210 1 \u00d7 1 \u7684\u5c0f\u5757\u3002</p>"},{"location":"markdown/interview_utils/interview_puzzles/brain_teasers/#_3","title":"\u65e5\u671f\u95ee\u9898","text":"<p>\u4eca\u5929\u7684180\u5929\u540e\u662f\u661f\u671f\u51e0\uff1f 180 / 7 = 25.....5\uff0c\u5219\u6211\u4eec\u5c06\u4eca\u5929\u7684\u661f\u671f\u5f80\u540e\u63a8\u4e94\u5929\u5373\u53ef\u3002</p>"},{"location":"markdown/interview_utils/interview_puzzles/brain_teasers/#_4","title":"\u4e09\u67aa\u624b","text":"<p>\u7532\u4e59\u4e19\u4e09\u4e2a\u67aa\u624b\u8fdb\u884c\u5bf9\u51b3\uff0c\u7532\u7684\u547d\u4e2d\u7387\u662f8/10\uff0c\u4e59\u662f6/10\uff0c\u4e19\u662f4/10\uff0c\u4ed6\u4eec\u90fd\u77e5\u9053\u5f7c\u6b64\u7684\u547d\u4e2d\u7387\u3002\u73b0\u5728\u5f00\u59cb\u591a\u8f6e\u5bf9\u51b3\u3002 \u6bcf\u8f6e\u5bf9\u51b3\u4e2d\u4ed6\u4eec\u90fd\u9700\u8981\u5411\u53e6\u5916\u4e00\u4e2a\u4eba\u5f00\u67aa\uff0c\u76f4\u5230\u6709\u4e00\u4e2a\u4eba\u6d3b\u7740\uff0c\u5bf9\u51b3\u7ed3\u675f\u3002\u95ee\u54ea\u4e2a\u4eba\u5b58\u6d3b\u7684\u6982\u7387\u6700\u5927\u3002</p>"},{"location":"markdown/interview_utils/interview_puzzles/brain_teasers/#_5","title":"\u76f8\u5173\u7cfb\u6570","text":"<p>\u6709\u4e09\u4e2a\u968f\u673a\u53d8\u91cfx, y, z\uff0c\u4ed6\u4eec\u4e24\u4e24\u4e4b\u95f4\u76f8\u5173\u7cfb\u6570\u76f8\u540c\uff0c\u95ee\u4ed6\u4eec\u4e4b\u95f4\u76f8\u5173\u7cfb\u6570\u7684\u53d6\u503c\u8303\u56f4\uff1f\u5982\u679c\u662f\u56db\u4e2a\u968f\u673a\u53d8\u91cf\u5462\uff1f</p>"},{"location":"markdown/interview_utils/interview_puzzles/brain_teasers/#_6","title":"\u586b\u6ee1\u957f\u65b9\u5f62","text":"<p>500900\u7684\u5927\u957f\u65b9\u5f62\u80fd\u5426\u88ab58\u7684\u5c0f\u957f\u65b9\u5f62\u586b\u6ee1\uff1f</p>"},{"location":"markdown/interview_utils/interview_puzzles/brain_teasers/#_7","title":"\u6843\u82b1\u6e38\u620f","text":"<p>\u5c06\u7ea2\u6843A\u52306\u548c\u9ed1\u6843A\u52306\u603b\u517112\u5f20\u6251\u514b\u724c\u6d17\u6df7\u653e\u5728\u4e00\u8d77\uff0c\u7136\u540e\u968f\u673a\u5730\u4ece\u4e2d\u4e00\u5f20\u5f20\u5730\u62bd\u724c\u3002\u5982\u679c\u624b\u4e2d\u6709\u4e24\u5f20\u6570\u5b57\u76f8\u540c\u7684\u724c\uff0c \u90a3\u4e48\u5c31\u5f03\u7f6e\u8fd9\u4e24\u5f20\u724c\u653e\u5230\u4e00\u8fb9\uff0c\u5982\u679c\u624b\u4e2d\u6709\u4e09\u5f20\u4e24\u4e24\u4e0d\u80fd\u6d88\u53bb\u7684\u724c\uff0c\u90a3\u4e48\u5c31\u8f93\u6389\u8fd9\u4e2a\u6e38\u620f\u3002\u95ee\u8fd9\u4e2a\u6e38\u620f\u7684\u80dc\u7387\u662f\u591a\u5c11\uff1f</p>"},{"location":"markdown/interview_utils/interview_puzzles/brain_teasers/#_8","title":"\u624b\u7535\u7b52\u7535\u6c60","text":"<p>\u6709\u4e00\u4e2a\u624b\u7535\u7b52\uff0c\u9700\u8981\u4e24\u8282\u597d\u7684\u7535\u6c60\u624d\u80fd\u6b63\u5e38\u53d1\u5149\u3002\u73b0\u5728\u67096\u8282\u597d\u7535\u6c60\u548c6\u8282\u574f\u7535\u6c60\u88ab\u6253\u4e71\u653e\u5728\u4e00\u8d77\u3002 \u8bf7\u95ee\u6700\u591a\u5c1d\u8bd5\u591a\u5c11\u6b21\u4e4b\u540e\u53ef\u4ee5\u4fdd\u8bc1\u627e\u5230\u4e24\u8282\u4f7f\u5f97\u624b\u7535\u7b52\u53ef\u4ee5\u6b63\u5e38\u4f7f\u7528\u7684\u7535\u6c60\uff08\u5305\u62ec\u6700\u540e\u4e00\u6b21\u4f7f\u5f97\u624b\u7535\u7b52\u4eae\u8d77\u6765\u7684\u5c1d\u8bd5\uff09\uff0c \u8bf7\u8bc1\u660e\u7ed3\u8bba\uff0c\u5e76\u4e14\u7ed9\u51fa\u4e00\u4e2a\u5c1d\u8bd5\u7684\u987a\u5e8f</p>"},{"location":"markdown/interview_utils/interview_puzzles/brain_teasers/#_9","title":"\u4e8c\u5143\u7ec4\u5206\u5272","text":"<p>\u7ed9\u5b9a\u6b63\u6574\u6570\u7ec41\u4e00\u76f4\u523022\uff0c\u95ee\u6709\u591a\u5c11\u79cd\u65b9\u6cd5\u53ef\u4ee5\u5c06\u8fd9\u4e2a\u6b63\u6574\u6570\u6570\u7ec4\u5207\u5206\u621011\u4e2a\u4e8c\u5143\u7ec4\uff0c\u5176\u4e2d\u6bcf\u4e2a\u4e8c\u5143\u7ec4\u4e2d\u7684\u6570\u5b57\u7684\u7edd\u5bf9\u503c\u5dee\u503c\u53ea\u80fd\u4e3a1\u6216\u800511\uff1f</p>"},{"location":"markdown/interview_utils/interview_puzzles/brain_teasers/#_10","title":"\u901a\u52e4\u7684\u6559\u6388","text":"<p>\u6559\u6388\u6bcf\u5929\u5728\u5bb6\u548c\u5b66\u6821\u4e4b\u95f4\u901a\u52e4\uff0c\u65e9\u4e0a\u4ece\u5bb6\u53bb\u5b66\u6821\uff0c\u665a\u4e0a\u4ece\u5b66\u6821\u56de\u5bb6\u3002\u6bcf\u5929\u7684\u65e9\u4e0a\u548c\u665a\u4e0a\u90fd\u6709p\u7684\u6982\u7387\u4f1a\u4e0b\u96e8\uff0c\u800c\u6559\u6388\u53ea\u6709\u4e00\u628a\u4f1e\u3002 \u5bf9\u4e8e\u6bcf\u4e00\u7a0b\u6765\u8bf4\uff0c\u5982\u679c\u51fa\u53d1\u7684\u65f6\u5019\u5916\u9762\u4e0d\u4e0b\u96e8\uff0c\u5219\u6559\u6388\u4e0d\u4f1a\u5e26\u7740\u4f1e\uff0c\u5982\u679c\u4e0b\u7740\u96e8\uff0c\u5e76\u4e14\u6559\u6388\u51fa\u53d1\u5730\u6709\u4f1e\uff0c\u90a3\u4e48\u4ed6\u4f1a\u5e26\u7740\u4f1e\u53bb\u4e0a\u73ed\u6216\u56de\u5bb6\uff0c \u800c\u5982\u679c\u5916\u9762\u4e0b\u96e8\u5e76\u4e14\u6559\u6388\u51fa\u53d1\u5730\u6ca1\u6709\u4f1e\uff0c\u90a3\u4e48\u5c31\u53ea\u80fd\u6dcb\u6e7f\u4e86\u3002\u95ee\u957f\u671f\u6765\u8bf4\uff0c\u6559\u6388\u4f1a\u6709\u591a\u5c11\u6bd4\u4f8b\u7684\u65f6\u5019\u88ab\u6dcb\u6e7f\uff1f</p>"},{"location":"markdown/interview_utils/interview_puzzles/brain_teasers/#_11","title":"\u7b2c\u4e8c\u5927\u7684\u6570","text":"<p>\u7ed9\u5b9a\u4e00\u4e2a\u957f\u5ea6\u4e3an\u7684\u672a\u6392\u5e8f\u6570\u7ec4\uff0c\u8bf7\u95ee\u81f3\u5c11\u9700\u8981\u591a\u5c11\u6b21\u6bd4\u8f83\uff0c\u624d\u53ef\u4ee5\u786e\u4fdd\u627e\u5230\u6570\u7ec4\u4e2d\u7b2c\u4e8c\u5927\u7684\u6570\uff1f\u5373\u5728\u6700\u574f\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u591a\u5c11\u6b21\u6bd4\u8f83\uff1f</p>"},{"location":"markdown/interview_utils/python_algorithm_puzzles/Alternating%20Prime%20Sequence/","title":"Alternating Prime Sequence","text":"<p>\u601d\u8def\u5f88\u7b80\u5355\uff0c\u76f4\u63a5\u8ba1\u7b97\u8d28\u6570\u548c\u975e\u8d28\u6570\u7684\u4e2a\u6570\uff0c\u7136\u540e\u8ba1\u7b97\u8d28\u6570\u6216\u8005\u975e\u8d28\u6570\u4e2d\u9700\u8981\u51cf\u53bb\u7684\u6570\u5b57\u4e2a\u6570\uff0c\u6392\u5e8f\u540e\u53d6\u51fa\u6700\u5c0f\u7684\u51e0\u4e2a\u5c31\u53ef</p> In\u00a0[1]: Copied! <pre>from typing import List\n</pre> from typing import List In\u00a0[44]: Copied! <pre>def minPenalty(arr: List[int]):\n    prime_subseq = [i for i in arr if is_prime(i)]\n    non_prime_subseq = [i for i in arr if not is_prime(i)]\n    \n    if abs(len(non_prime_subseq) - len(prime_subseq)) &lt;= 1:\n        return 0\n    \n    if len(prime_subseq) &gt; len(non_prime_subseq):\n        longer = prime_subseq\n        num_drop = len(prime_subseq) - len(non_prime_subseq) - 1\n    else:\n        longer = non_prime_subseq\n        num_drop = len(non_prime_subseq) - len(prime_subseq) - 1\n    \n    return sum(sorted(longer)[:num_drop])\n</pre> def minPenalty(arr: List[int]):     prime_subseq = [i for i in arr if is_prime(i)]     non_prime_subseq = [i for i in arr if not is_prime(i)]          if abs(len(non_prime_subseq) - len(prime_subseq)) &lt;= 1:         return 0          if len(prime_subseq) &gt; len(non_prime_subseq):         longer = prime_subseq         num_drop = len(prime_subseq) - len(non_prime_subseq) - 1     else:         longer = non_prime_subseq         num_drop = len(non_prime_subseq) - len(prime_subseq) - 1          return sum(sorted(longer)[:num_drop]) In\u00a0[45]: Copied! <pre>def is_prime(n: int):\n    if n &lt; 2:\n        return False\n    \n    for i in range(2, int(n ** 0.5) + 1):\n        if n % i == 0:\n            return False\n        \n    return True\n</pre> def is_prime(n: int):     if n &lt; 2:         return False          for i in range(2, int(n ** 0.5) + 1):         if n % i == 0:             return False              return True In\u00a0[46]: Copied! <pre>arr = [3, 7, 1, 4, 6, 6]\n</pre> arr = [3, 7, 1, 4, 6, 6] In\u00a0[47]: Copied! <pre>minPenalty(arr)\n</pre> minPenalty(arr) Out[47]: <pre>1</pre> In\u00a0[51]: Copied! <pre>arr =  [1, 2, 4, 3, 6, 5, 7, 7]\nminPenalty(arr)\n</pre> arr =  [1, 2, 4, 3, 6, 5, 7, 7] minPenalty(arr) Out[51]: <pre>2</pre> In\u00a0[50]: Copied! <pre>arr =  [1, 2, 4, 3, 6, 5, 7, 7, 7, 7, 7, 7]\nminPenalty(arr)\n</pre> arr =  [1, 2, 4, 3, 6, 5, 7, 7, 7, 7, 7, 7] minPenalty(arr) Out[50]: <pre>24</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[6]: Copied! <pre>is_prime(7)\n</pre> is_prime(7) Out[6]: <pre>True</pre> In\u00a0[8]: Copied! <pre>arr = [3, 7, 1, 4, 6, 6]\n</pre> arr = [3, 7, 1, 4, 6, 6] In\u00a0[10]: Copied! <pre>prime_subseq = [i for i in arr if is_prime(i)]\nprime_subseq\n</pre> prime_subseq = [i for i in arr if is_prime(i)] prime_subseq Out[10]: <pre>[3, 7]</pre> In\u00a0[11]: Copied! <pre>non_prime_subseq = [i for i in arr if not is_prime(i)]\nnon_prime_subseq\n</pre> non_prime_subseq = [i for i in arr if not is_prime(i)] non_prime_subseq Out[11]: <pre>[1, 4, 6, 6]</pre> In\u00a0[12]: Copied! <pre>abs(-1)\n</pre> abs(-1) Out[12]: <pre>1</pre> In\u00a0[14]: Copied! <pre>sorted([1, 3, 2, 7, 6])\n</pre> sorted([1, 3, 2, 7, 6]) Out[14]: <pre>[1, 2, 3, 6, 7]</pre> In\u00a0[15]: Copied! <pre>sorted([1, 3, 2, 7, 6])[:3]\n</pre> sorted([1, 3, 2, 7, 6])[:3] Out[15]: <pre>[1, 2, 3]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/interview_utils/python_algorithm_puzzles/Delivery%20Management%20System/","title":"Delivery Management System","text":"In\u00a0[121]: Copied! <pre>from typing import List\nfrom collections import deque\n</pre> from typing import List from collections import deque In\u00a0[169]: Copied! <pre>def order(cityNodes: int, cityFrom: List[int], cityTo: List[int], company: int):\n    \n    # initialize dc which contains the neighborhood cities of every city\n    dc = {}\n    for i in range(1, cityNodes + 1):\n        dc[i] = []\n        \n    for x, y in list(zip(cityFrom, cityTo)):\n        if y not in dc[x]:\n           dc[x].append(y)\n        if x not in dc[y]:\n            dc[y].append(x)\n\n    # bfs\n    # initialize\n    result = []\n    delivered = [False] * cityNodes\n    delivered[company - 1] = True\n    for city in dc[company]:\n        delivered[city - 1] = True\n    d = deque(sorted(dc[company]))\n    result += sorted(dc[company])\n    while d:\n        # \u961f\u5217\u7528\u4e8ebfs\n        current = d.popleft()\n\n        # \u5bf9\u4e8e\u5f53\u524d\u8282\u70b9\u7684\u76f8\u90bb\u57ce\u5e02\uff0c\u90fd\u662f\u4e0b\u4e00\u5708deliver\u7684\u57ce\u5e02\n        next_delivery_series = []\n        for city in dc[current]:\n            if not delivered[city - 1]:\n                next_delivery_series.append(city)\n                delivered[city - 1] = True\n        ## \u52a0\u4e0a\u8fd9\u4e00\u5708\u7684\u7ed3\u679c\n        result += sorted(next_delivery_series)\n\n        ## \u5c06\u8fd9\u4e00\u5708\u57ce\u5e02\u52a0\u5165\u961f\u5217\n        for city in next_delivery_series:\n            d.append(city)\n            \n    return result\n</pre> def order(cityNodes: int, cityFrom: List[int], cityTo: List[int], company: int):          # initialize dc which contains the neighborhood cities of every city     dc = {}     for i in range(1, cityNodes + 1):         dc[i] = []              for x, y in list(zip(cityFrom, cityTo)):         if y not in dc[x]:            dc[x].append(y)         if x not in dc[y]:             dc[y].append(x)      # bfs     # initialize     result = []     delivered = [False] * cityNodes     delivered[company - 1] = True     for city in dc[company]:         delivered[city - 1] = True     d = deque(sorted(dc[company]))     result += sorted(dc[company])     while d:         # \u961f\u5217\u7528\u4e8ebfs         current = d.popleft()          # \u5bf9\u4e8e\u5f53\u524d\u8282\u70b9\u7684\u76f8\u90bb\u57ce\u5e02\uff0c\u90fd\u662f\u4e0b\u4e00\u5708deliver\u7684\u57ce\u5e02         next_delivery_series = []         for city in dc[current]:             if not delivered[city - 1]:                 next_delivery_series.append(city)                 delivered[city - 1] = True         ## \u52a0\u4e0a\u8fd9\u4e00\u5708\u7684\u7ed3\u679c         result += sorted(next_delivery_series)          ## \u5c06\u8fd9\u4e00\u5708\u57ce\u5e02\u52a0\u5165\u961f\u5217         for city in next_delivery_series:             d.append(city)                  return result In\u00a0[170]: Copied! <pre>cityNodes = 7\ncompany = 1\ncityFrom = [1, 1, 2, 1, 2, 2, 3, 4]\ncityTo = [3, 2, 3, 4, 4, 5, 6, 7]\n</pre> cityNodes = 7 company = 1 cityFrom = [1, 1, 2, 1, 2, 2, 3, 4] cityTo = [3, 2, 3, 4, 4, 5, 6, 7] In\u00a0[171]: Copied! <pre>result = order(cityNodes, cityFrom, cityTo, company)\nresult\n</pre> result = order(cityNodes, cityFrom, cityTo, company) result Out[171]: <pre>[2, 3, 4, 5, 6, 7]</pre> In\u00a0[172]: Copied! <pre>cityNodes = 4\ncompany = 1\ncityFrom = [1, 2, 2]\ncityTo = [2, 3, 4]\n</pre> cityNodes = 4 company = 1 cityFrom = [1, 2, 2] cityTo = [2, 3, 4] In\u00a0[173]: Copied! <pre>result = order(cityNodes, cityFrom, cityTo, company)\nresult\n</pre> result = order(cityNodes, cityFrom, cityTo, company) result Out[173]: <pre>[2, 3, 4]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[18]: Copied! <pre>delivered = [False] * cityNodes\n</pre> delivered = [False] * cityNodes In\u00a0[19]: Copied! <pre>delivered[company - 1] = True\n</pre> delivered[company - 1] = True In\u00a0[\u00a0]: Copied! <pre>for i in range(len(cityFrom)):\n    current = cityFrom[i]\n    \n    if not delivered[cityFrom[i]]\n</pre> for i in range(len(cityFrom)):     current = cityFrom[i]          if not delivered[cityFrom[i]] In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[21]: Copied! <pre># \u77e5\u9053\u601d\u8def\u4f46\u662f\u4ee3\u7801\u5199\u4e0d\u51fa\u6765\u3002\u3002\u3002\n</pre> # \u77e5\u9053\u601d\u8def\u4f46\u662f\u4ee3\u7801\u5199\u4e0d\u51fa\u6765\u3002\u3002\u3002 In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[48]: Copied! <pre>delivered = [False] * cityNodes\nresult = []\n</pre> delivered = [False] * cityNodes result = [] In\u00a0[47]: Copied! <pre>delivered\n</pre> delivered Out[47]: <pre>[False, False, False, False, False, False, False]</pre> In\u00a0[40]: Copied! <pre>dc = {}\nfor i in range(1, cityNodes + 1):\n    dc[i] = []\ndc\n</pre> dc = {} for i in range(1, cityNodes + 1):     dc[i] = [] dc Out[40]: <pre>{1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: []}</pre> In\u00a0[41]: Copied! <pre>for x, y in list(zip(cityFrom, cityTo)):\n    if y not in dc[x]:\n       dc[x].append(y)\n    if x not in dc[y]:\n        dc[y].append(x)\n</pre> for x, y in list(zip(cityFrom, cityTo)):     if y not in dc[x]:        dc[x].append(y)     if x not in dc[y]:         dc[y].append(x) In\u00a0[119]: Copied! <pre># initialize\nresult = []\ndelivered = [False] * cityNodes\ndelivered[company - 1] = True\nfor city in dc[company]:\n    delivered[city - 1] = True\nd = deque(sorted(dc[company]))\nresult += sorted(dc[company])\nprint('result_before', result)\nwhile d:\n    # \u961f\u5217\u7528\u4e8ebfs\n    current = d.popleft()\n    \n    # \u5bf9\u4e8e\u5f53\u524d\u8282\u70b9\u7684\u76f8\u90bb\u57ce\u5e02\uff0c\u90fd\u662f\u4e0b\u4e00\u5708deliver\u7684\u57ce\u5e02\n    next_delivery_series = []\n#     print(dc[current])\n    for city in dc[current]:\n        if not delivered[city - 1]:\n            next_delivery_series.append(city)\n            delivered[city - 1] = True\n    ## \u52a0\u4e0a\u8fd9\u4e00\u5708\u7684\u7ed3\u679c\n    print('nds', next_delivery_series)\n    print('hello', sorted(next_delivery_series))\n    result += sorted(next_delivery_series)\n    \n    print('result', result)\n    ## \u5c06\u8fd9\u4e00\u5708\u57ce\u5e02\u52a0\u5165\u961f\u5217\n    for city in next_delivery_series:\n        d.append(city)\n    print('d:', d)\n    \n    \n         \n</pre> # initialize result = [] delivered = [False] * cityNodes delivered[company - 1] = True for city in dc[company]:     delivered[city - 1] = True d = deque(sorted(dc[company])) result += sorted(dc[company]) print('result_before', result) while d:     # \u961f\u5217\u7528\u4e8ebfs     current = d.popleft()          # \u5bf9\u4e8e\u5f53\u524d\u8282\u70b9\u7684\u76f8\u90bb\u57ce\u5e02\uff0c\u90fd\u662f\u4e0b\u4e00\u5708deliver\u7684\u57ce\u5e02     next_delivery_series = [] #     print(dc[current])     for city in dc[current]:         if not delivered[city - 1]:             next_delivery_series.append(city)             delivered[city - 1] = True     ## \u52a0\u4e0a\u8fd9\u4e00\u5708\u7684\u7ed3\u679c     print('nds', next_delivery_series)     print('hello', sorted(next_delivery_series))     result += sorted(next_delivery_series)          print('result', result)     ## \u5c06\u8fd9\u4e00\u5708\u57ce\u5e02\u52a0\u5165\u961f\u5217     for city in next_delivery_series:         d.append(city)     print('d:', d)                     <pre>result_before [2, 3, 4]\nnds [5]\nhello [5]\nresult [2, 3, 4, 5]\nd: deque([3, 4, 5])\nnds [6]\nhello [6]\nresult [2, 3, 4, 5, 6]\nd: deque([4, 5, 6])\nnds [7]\nhello [7]\nresult [2, 3, 4, 5, 6, 7]\nd: deque([5, 6, 7])\nnds []\nhello []\nresult [2, 3, 4, 5, 6, 7]\nd: deque([6, 7])\nnds []\nhello []\nresult [2, 3, 4, 5, 6, 7]\nd: deque([7])\nnds []\nhello []\nresult [2, 3, 4, 5, 6, 7]\nd: deque([])\n</pre> In\u00a0[117]: Copied! <pre>result = [2, 3, 4]\nresult += sorted([5])\nresult\n</pre> result = [2, 3, 4] result += sorted([5]) result Out[117]: <pre>[2, 3, 4, 5]</pre> In\u00a0[120]: Copied! <pre>result\n</pre> result Out[120]: <pre>[2, 3, 4, 5, 6, 7]</pre> In\u00a0[67]: Copied! <pre>delivered\n</pre> delivered Out[67]: <pre>[True, True, True, True, False, False, False]</pre> In\u00a0[62]: Copied! <pre>d\n</pre> d Out[62]: <pre>deque([2, 3, 4])</pre> In\u00a0[53]: Copied! <pre>sorted(dc[company])\n</pre> sorted(dc[company]) Out[53]: <pre>[2, 3, 4]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[45]: Copied! <pre>for key, value in dc.items():\n    print(key, value)\n</pre> for key, value in dc.items():     print(key, value) <pre>1 [3, 2, 4]\n2 [1, 3, 4, 5]\n3 [1, 2, 6]\n4 [1, 2, 7]\n5 [2]\n6 [3]\n7 [4]\n</pre> In\u00a0[42]: Copied! <pre>dc\n</pre> dc Out[42]: <pre>{1: [3, 2, 4],\n 2: [1, 3, 4, 5],\n 3: [1, 2, 6],\n 4: [1, 2, 7],\n 5: [2],\n 6: [3],\n 7: [4]}</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/interview_utils/python_algorithm_puzzles/Document%20Chunking/","title":"Document Chunking","text":"In\u00a0[71]: Copied! <pre>import math\nfrom typing import List\nfrom functools import reduce\n</pre> import math from typing import List from functools import reduce In\u00a0[72]: Copied! <pre>def minimumChunkRequired(totalPackets: int, uploadedChunk: List[List[int]]):\n    result = 0\n    uploaded_number = reduce(lambda x, y: x + y, [list(range(i[0], i[-1] + 1)) for i in uploadedChunk])\n    continuous_packets = extract_continuous_packets(list(range(1, totalPackets + 1)), uploaded_number)\n    \n    for packets in continuous_packets:\n        result += minimum_number_of_chunks(len(packets))\n        \n    return result\n</pre> def minimumChunkRequired(totalPackets: int, uploadedChunk: List[List[int]]):     result = 0     uploaded_number = reduce(lambda x, y: x + y, [list(range(i[0], i[-1] + 1)) for i in uploadedChunk])     continuous_packets = extract_continuous_packets(list(range(1, totalPackets + 1)), uploaded_number)          for packets in continuous_packets:         result += minimum_number_of_chunks(len(packets))              return result In\u00a0[70]: Copied! <pre>def extract_continuous_packets(lst, uploaded_number):\n    result = []\n    seq = []\n    for i in lst:\n        if i not in uploaded_number:\n            if not seq:\n                seq.append(i)\n            elif i == seq[-1] + 1:\n                seq.append(i)\n            else:\n                result.append(seq)\n                seq = [i]\n    if seq:\n        result.append(seq)\n        \n    return result\n</pre> def extract_continuous_packets(lst, uploaded_number):     result = []     seq = []     for i in lst:         if i not in uploaded_number:             if not seq:                 seq.append(i)             elif i == seq[-1] + 1:                 seq.append(i)             else:                 result.append(seq)                 seq = [i]     if seq:         result.append(seq)              return result In\u00a0[63]: Copied! <pre>def minimum_number_of_chunks(l: int):\n    \"\"\"\n    calculate the minimum number of chunks that a document of length l can be divided into.\n    \"\"\"\n    remain_length = l\n    number_chunks = 0\n    while remain_length &gt; 0:\n        n = math.floor(math.log(remain_length, 2))\n        remain_length -= pow(2, n)\n        number_chunks += 1\n    \n    return number_chunks\n</pre> def minimum_number_of_chunks(l: int):     \"\"\"     calculate the minimum number of chunks that a document of length l can be divided into.     \"\"\"     remain_length = l     number_chunks = 0     while remain_length &gt; 0:         n = math.floor(math.log(remain_length, 2))         remain_length -= pow(2, n)         number_chunks += 1          return number_chunks In\u00a0[64]: Copied! <pre>minimumChunkRequired(totalPackets=10, uploadedChunk = [[1, 2], [4, 4], [7, 8]])\n</pre> minimumChunkRequired(totalPackets=10, uploadedChunk = [[1, 2], [4, 4], [7, 8]]) Out[64]: <pre>3</pre> In\u00a0[67]: Copied! <pre>minimumChunkRequired(totalPackets=5, uploadedChunk = [[1, 2]])\n</pre> minimumChunkRequired(totalPackets=5, uploadedChunk = [[1, 2]]) Out[67]: <pre>2</pre> In\u00a0[68]: Copied! <pre>minimumChunkRequired(totalPackets=10, uploadedChunk = [[1, 2], [9, 10]])\n</pre> minimumChunkRequired(totalPackets=10, uploadedChunk = [[1, 2], [9, 10]]) Out[68]: <pre>2</pre> In\u00a0[69]: Copied! <pre>minimumChunkRequired(totalPackets=18, uploadedChunk = [[9, 17]])\n</pre> minimumChunkRequired(totalPackets=18, uploadedChunk = [[9, 17]]) Out[69]: <pre>2</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[55]: Copied! <pre>totalPackets = 10\nuploadedChunk = [[1, 2], [9, 10]]\n</pre> totalPackets = 10 uploadedChunk = [[1, 2], [9, 10]] In\u00a0[60]: Copied! <pre>extract_continuous_sequences(list(range(1, 11)), uploaded_number)\n</pre> extract_continuous_sequences(list(range(1, 11)), uploaded_number) Out[60]: <pre>[[3, 4, 5, 6, 7, 8]]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[56]: Copied! <pre>uploaded_number = [list(range(i[0], i[-1] + 1)) for i in uploadedChunk]\n</pre> uploaded_number = [list(range(i[0], i[-1] + 1)) for i in uploadedChunk] In\u00a0[57]: Copied! <pre>uploaded_number = reduce(lambda x, y: x + y, uploaded_number)\n</pre> uploaded_number = reduce(lambda x, y: x + y, uploaded_number) In\u00a0[58]: Copied! <pre>uploaded_number\n</pre> uploaded_number Out[58]: <pre>[1, 2, 9, 10]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[22]: Copied! <pre>document\n</pre> document Out[22]: <pre>[0, 1, 2, 3, 4]</pre> In\u00a0[19]: Copied! <pre>document = list(range(totalPackets))\nchunks = []\nfor i in range(totalPackets):\n    \n</pre> document = list(range(totalPackets)) chunks = [] for i in range(totalPackets):      Out[19]: <pre>[0, 1, 2, 3, 4]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[21]: Copied! <pre>5 in range(1, 10)\n</pre> 5 in range(1, 10) Out[21]: <pre>True</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[2]: Copied! <pre>math.log(100, 2)\n</pre> math.log(100, 2) Out[2]: <pre>6.643856189774725</pre> In\u00a0[5]: Copied! <pre>math.ceil(math.log(100, 2))\n</pre> math.ceil(math.log(100, 2)) Out[5]: <pre>7</pre> In\u00a0[6]: Copied! <pre>math.floor(math.log(100, 2))\n</pre> math.floor(math.log(100, 2)) Out[6]: <pre>6</pre> In\u00a0[10]: Copied! <pre>math.floor(math.log(4, 2))\n</pre> math.floor(math.log(4, 2)) Out[10]: <pre>2</pre> In\u00a0[9]: Copied! <pre>pow(2, 6)\n</pre> pow(2, 6) Out[9]: <pre>64</pre> In\u00a0[8]: Copied! <pre>math.log(2, 2)\n</pre> math.log(2, 2) Out[8]: <pre>1.0</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/interview_utils/python_algorithm_puzzles/Extraordinary%20Substrings/","title":"Extraordinary Substrings","text":"In\u00a0[18]: Copied! <pre>def countSubstrings(input_str: str):\n    # create word-to-number mapper\n    mapper = {}\n    for i in range(97, 123):\n        mapper[chr(i)] = (i - 96) // 3 + 1\n        \n    result = 0\n    for i in range(len(input_str)):\n        for j in range(i + 1, len(input_str) + 1):\n            substring = input_str[i: j]\n            # total sum of mapped value\n            value = 0\n            for x in substring:\n                value += mapper[x]\n            # check divisible or not\n            if value % len(substring) == 0:\n                result += 1\n                \n    return result\n</pre> def countSubstrings(input_str: str):     # create word-to-number mapper     mapper = {}     for i in range(97, 123):         mapper[chr(i)] = (i - 96) // 3 + 1              result = 0     for i in range(len(input_str)):         for j in range(i + 1, len(input_str) + 1):             substring = input_str[i: j]             # total sum of mapped value             value = 0             for x in substring:                 value += mapper[x]             # check divisible or not             if value % len(substring) == 0:                 result += 1                      return result In\u00a0[1]: Copied! <pre>input_str = 'asdf'\n</pre> input_str = 'asdf' In\u00a0[19]: Copied! <pre>countSubstrings(input_str)\n</pre> countSubstrings(input_str) Out[19]: <pre>6</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>mapper = {}\nfor i in range(97, 123):\n    mapper[chr(i)] = (i - 96) // 3 + 1\n</pre> mapper = {} for i in range(97, 123):     mapper[chr(i)] = (i - 96) // 3 + 1 In\u00a0[17]: Copied! <pre>result = 0\nfor i in range(len(input_str)):\n    for j in range(i + 1, len(input_str) + 1):\n        substring = input_str[i: j]\n        # total sum of mapped value\n        value = 0\n        for x in substring:\n            value += mapper[x]\n        if value % len(substring) == 0:\n            result += 1\nresult\n</pre> result = 0 for i in range(len(input_str)):     for j in range(i + 1, len(input_str) + 1):         substring = input_str[i: j]         # total sum of mapped value         value = 0         for x in substring:             value += mapper[x]         if value % len(substring) == 0:             result += 1 result Out[17]: <pre>6</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[13]: Copied! <pre>mapper = {}\nfor i in range(97, 123):\n    mapper[chr(i)] = (i - 96) // 3 + 1\nmapper\n</pre> mapper = {} for i in range(97, 123):     mapper[chr(i)] = (i - 96) // 3 + 1 mapper Out[13]: <pre>{'a': 1,\n 'b': 1,\n 'c': 2,\n 'd': 2,\n 'e': 2,\n 'f': 3,\n 'g': 3,\n 'h': 3,\n 'i': 4,\n 'j': 4,\n 'k': 4,\n 'l': 5,\n 'm': 5,\n 'n': 5,\n 'o': 6,\n 'p': 6,\n 'q': 6,\n 'r': 7,\n 's': 7,\n 't': 7,\n 'u': 8,\n 'v': 8,\n 'w': 8,\n 'x': 9,\n 'y': 9,\n 'z': 9}</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/interview_utils/python_algorithm_puzzles/Frequency%20Sort/","title":"Frequency Sort","text":"In\u00a0[41]: Copied! <pre>from collections import Counter\nfrom functools import reduce\nfrom typing import List\n</pre> from collections import Counter from functools import reduce from typing import List In\u00a0[42]: Copied! <pre>def itemsSort(items: List[int]):\n    ctr = Counter(items)\n    sorted_value = sorted(ctr.items(), key=lambda x: (x[1], x[0]))\n    return reduce(lambda x, y: x + y, [[x[0]] * x[1] for x in sorted_value])\n</pre> def itemsSort(items: List[int]):     ctr = Counter(items)     sorted_value = sorted(ctr.items(), key=lambda x: (x[1], x[0]))     return reduce(lambda x, y: x + y, [[x[0]] * x[1] for x in sorted_value]) In\u00a0[43]: Copied! <pre>items = [8, 5, 5, 5, 5, 1, 1, 1, 4, 4]\n</pre> items = [8, 5, 5, 5, 5, 1, 1, 1, 4, 4] In\u00a0[44]: Copied! <pre>itemsSort(items)\n</pre> itemsSort(items) Out[44]: <pre>[8, 4, 4, 1, 1, 1, 5, 5, 5, 5]</pre> In\u00a0[45]: Copied! <pre>items = [3, 1, 2, 2, 4]\n</pre> items = [3, 1, 2, 2, 4] In\u00a0[46]: Copied! <pre>itemsSort(items)\n</pre> itemsSort(items) Out[46]: <pre>[1, 3, 4, 2, 2]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[32]: Copied! <pre>ctr = Counter(items)\n</pre> ctr = Counter(items) In\u00a0[34]: Copied! <pre>sorted_value = sorted(ctr.items(), key=lambda x: (x[1], x[0]))\nsorted_value\n</pre> sorted_value = sorted(ctr.items(), key=lambda x: (x[1], x[0])) sorted_value Out[34]: <pre>[(1, 1), (3, 1), (4, 1), (2, 2)]</pre> In\u00a0[35]: Copied! <pre>reduce(lambda x, y: x + y, [[x[0]] * x[1] for x in sorted_value])\n</pre> reduce(lambda x, y: x + y, [[x[0]] * x[1] for x in sorted_value]) Out[35]: <pre>[1, 3, 4, 2, 2]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[12]: Copied! <pre>ctr\n</pre> ctr Out[12]: <pre>Counter({8: 1, 5: 4, 1: 3, 4: 2})</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/interview_utils/python_algorithm_puzzles/K%20Smallest%20Substring/","title":"K Smallest Substring","text":"In\u00a0[68]: Copied! <pre>def getSubstring(input_str: str, k: int):\n    count = 0\n    left_pointer, right_pointer = 0, 0\n    min_length = float('inf')\n    result = None\n    while right_pointer &lt; len(input_str):\n        if input_str[right_pointer] == '1':\n            count += 1\n\n        if count == k:\n            while left_pointer &lt; len(input_str):\n                if input_str[left_pointer] == '1' and (left_pointer == 0 or left_pointer == len(input_str) - 1):\n                    break\n                left_pointer += 1\n                if input_str[left_pointer] == '1':\n                    break\n            count -= 1\n\n            if (right_pointer - left_pointer) &lt; min_length:\n                result = input_str[left_pointer: right_pointer + 1]\n            min_length = right_pointer - left_pointer\n\n        right_pointer += 1\n    \n    if result:\n        return result\n</pre> def getSubstring(input_str: str, k: int):     count = 0     left_pointer, right_pointer = 0, 0     min_length = float('inf')     result = None     while right_pointer &lt; len(input_str):         if input_str[right_pointer] == '1':             count += 1          if count == k:             while left_pointer &lt; len(input_str):                 if input_str[left_pointer] == '1' and (left_pointer == 0 or left_pointer == len(input_str) - 1):                     break                 left_pointer += 1                 if input_str[left_pointer] == '1':                     break             count -= 1              if (right_pointer - left_pointer) &lt; min_length:                 result = input_str[left_pointer: right_pointer + 1]             min_length = right_pointer - left_pointer          right_pointer += 1          if result:         return result In\u00a0[80]: Copied! <pre>input_str = '0101101'\nk = 1\n</pre> input_str = '0101101' k = 1 In\u00a0[76]: Copied! <pre>input_str = '10101'\nk = 2\n</pre> input_str = '10101' k = 2 In\u00a0[72]: Copied! <pre>input_str = '010100011'\nk = 2\n</pre> input_str = '010100011' k = 2 In\u00a0[81]: Copied! <pre>getSubstring(input_str, k)\n</pre> getSubstring(input_str, k) Out[81]: <pre>'1'</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[48]: Copied! <pre>input_str = '0101101'\nk = 1\n</pre> input_str = '0101101' k = 1 In\u00a0[51]: Copied! <pre>input_str = '10101'\nk = 2\n</pre> input_str = '10101' k = 2 In\u00a0[65]: Copied! <pre>input_str = '010100011'\nk = 2\n</pre> input_str = '010100011' k = 2 In\u00a0[67]: Copied! <pre>count = 0\nleft_pointer, right_pointer = 0, 0\nmin_length = float('inf')\nwhile right_pointer &lt; len(input_str):\n    if input_str[right_pointer] == '1':\n        count += 1\n        \n    if count == k:\n        while left_pointer &lt; len(input_str):\n            if input_str[left_pointer] == '1' and (left_pointer == 0 or left_pointer == len(input_str) - 1):\n                break\n            left_pointer += 1\n            if input_str[left_pointer] == '1':\n                break\n        count -= 1\n        \n        if (right_pointer - left_pointer) &lt; min_length:\n            result = input_str[left_pointer: right_pointer + 1]\n        min_length = right_pointer - left_pointer\n        \n    right_pointer += 1\n    \nresult\n</pre> count = 0 left_pointer, right_pointer = 0, 0 min_length = float('inf') while right_pointer &lt; len(input_str):     if input_str[right_pointer] == '1':         count += 1              if count == k:         while left_pointer &lt; len(input_str):             if input_str[left_pointer] == '1' and (left_pointer == 0 or left_pointer == len(input_str) - 1):                 break             left_pointer += 1             if input_str[left_pointer] == '1':                 break         count -= 1                  if (right_pointer - left_pointer) &lt; min_length:             result = input_str[left_pointer: right_pointer + 1]         min_length = right_pointer - left_pointer              right_pointer += 1      result Out[67]: <pre>'11'</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[18]: Copied! <pre>def find_subarray_with_sum(arr, k):\n    prefix_sum = 0\n    prefix_sum_map = {}\n    for i in range(len(arr)):\n        prefix_sum += arr[i]\n        if prefix_sum == k:\n            return arr[:i+1]\n        if prefix_sum - k in prefix_sum_map:\n            return arr[prefix_sum_map[prefix_sum - k] + 1:i+1]\n        prefix_sum_map[prefix_sum] = i\n    return None\n</pre> def find_subarray_with_sum(arr, k):     prefix_sum = 0     prefix_sum_map = {}     for i in range(len(arr)):         prefix_sum += arr[i]         if prefix_sum == k:             return arr[:i+1]         if prefix_sum - k in prefix_sum_map:             return arr[prefix_sum_map[prefix_sum - k] + 1:i+1]         prefix_sum_map[prefix_sum] = i     return None In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[29]: Copied! <pre>arr = [0, 1, 0, 1, 1, 0, 1]\nk = 3\n</pre> arr = [0, 1, 0, 1, 1, 0, 1] k = 3 In\u00a0[28]: Copied! <pre>find_subarray_with_sum(arr, k)\n</pre> find_subarray_with_sum(arr, k) Out[28]: <pre>[0, 0, 0, 1, 1, 0, 1]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/interview_utils/python_algorithm_puzzles/K%20Smallest%20Substring/#two-pointer-method","title":"two pointer method\u00b6","text":""},{"location":"markdown/interview_utils/python_algorithm_puzzles/Keyboard/","title":"Keyboard","text":"In\u00a0[60]: Copied! <pre>from typing import List\n</pre> from typing import List In\u00a0[61]: Copied! <pre>from itertools import product\n</pre> from itertools import product In\u00a0[62]: Copied! <pre>def entryTime(s: str, keypad: str):\n    dc = {}\n    pointer = 0\n    for i, j in product(range(3), range(3)):\n            dc[keypad[pointer]] = [i, j]\n            pointer += 1\n\n    total_time = 0\n    for i in range(1, len(s)): \n        total_time += calculate_time(dc[s[i]], dc[s[i - 1]])\n\n    return total_time\n\ndef calculate_time(pos1: List, pos2: List):\n    distance = max([abs(i - j) for i, j in list(zip(pos1, pos2))])\n    if distance == 0:\n        return 0\n    elif distance &lt; 2:\n        return 1\n    else:\n        return 2\n</pre> def entryTime(s: str, keypad: str):     dc = {}     pointer = 0     for i, j in product(range(3), range(3)):             dc[keypad[pointer]] = [i, j]             pointer += 1      total_time = 0     for i in range(1, len(s)):          total_time += calculate_time(dc[s[i]], dc[s[i - 1]])      return total_time  def calculate_time(pos1: List, pos2: List):     distance = max([abs(i - j) for i, j in list(zip(pos1, pos2))])     if distance == 0:         return 0     elif distance &lt; 2:         return 1     else:         return 2 In\u00a0[63]: Copied! <pre>s = '423692'\nkeypad = '923857614'\n</pre> s = '423692' keypad = '923857614' In\u00a0[64]: Copied! <pre>entryTime(s, keypad)\n</pre> entryTime(s, keypad) Out[64]: <pre>8</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[3]: Copied! <pre>l = [[1, 2], [3, 4]]\n</pre> l = [[1, 2], [3, 4]] In\u00a0[33]: Copied! <pre>dc = {}\npointer = 0\nfor i in range(3):\n    for j in range(3):\n        dc[keypad[pointer]] = [i, j]\n        pointer += 1\n\ntotal_time = 0\nfor i in range(1, len(s)): \n    total_time += calculate_time(dc[s[i]], dc[s[i - 1]])\n\nprint(total_time)\n</pre> dc = {} pointer = 0 for i in range(3):     for j in range(3):         dc[keypad[pointer]] = [i, j]         pointer += 1  total_time = 0 for i in range(1, len(s)):      total_time += calculate_time(dc[s[i]], dc[s[i - 1]])  print(total_time)   <pre>8\n</pre> In\u00a0[32]: Copied! <pre>dc\n</pre> dc Out[32]: <pre>{'9': [0, 0],\n '2': [0, 1],\n '3': [0, 2],\n '8': [1, 0],\n '5': [1, 1],\n '7': [1, 2],\n '6': [2, 0],\n '1': [2, 1],\n '4': [2, 2]}</pre> In\u00a0[23]: Copied! <pre>dc[1]\n</pre> dc[1] Out[23]: <pre>[2, 1]</pre> In\u00a0[25]: Copied! <pre>pos1 = [0, 0]\npos2 = [0, 1]\n</pre> pos1 = [0, 0] pos2 = [0, 1] In\u00a0[28]: Copied! <pre>[abs(i - j) for i, j in list(zip(pos1, pos2))]\n</pre> [abs(i - j) for i, j in list(zip(pos1, pos2))] Out[28]: <pre>[0, 1]</pre> In\u00a0[40]: Copied! <pre>for i, j in product(range(3), range(3)):\n    print(i, j)\n</pre> for i, j in product(range(3), range(3)):     print(i, j) <pre>0 0\n0 1\n0 2\n1 0\n1 1\n1 2\n2 0\n2 1\n2 2\n</pre> In\u00a0[44]: Copied! <pre>dc\n</pre> dc Out[44]: <pre>{'9': [0, 0],\n '2': [0, 1],\n '3': [0, 2],\n '8': [1, 0],\n '5': [1, 1],\n '7': [1, 2],\n '6': [2, 0],\n '1': [2, 1],\n '4': [2, 2]}</pre> In\u00a0[47]: Copied! <pre>'11' in dc\n</pre> '11' in dc Out[47]: <pre>False</pre> In\u00a0[48]: Copied! <pre>'9' in dc\n</pre> '9' in dc Out[48]: <pre>True</pre> In\u00a0[49]: Copied! <pre>dc\n</pre> dc Out[49]: <pre>{'9': [0, 0],\n '2': [0, 1],\n '3': [0, 2],\n '8': [1, 0],\n '5': [1, 1],\n '7': [1, 2],\n '6': [2, 0],\n '1': [2, 1],\n '4': [2, 2]}</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/interview_utils/python_algorithm_puzzles/Minimum%20Swaps/","title":"Minimum Swaps","text":"In\u00a0[24]: Copied! <pre>from typing import List\n</pre> from typing import List In\u00a0[91]: Copied! <pre>def minimumSwaps(popularity: List):\n    # using cycle sort\n    num_swaps = 0\n    for i in range(len(popularity)):\n        count = 0\n        for j in range(len(popularity)):\n            if popularity[j] &gt; popularity[i]:\n                count += 1\n\n        while count != i:\n            if popularity.index(popularity[i]) == count:\n                continue\n            else:\n                popularity[i], popularity[count] = popularity[count], popularity[i]\n                num_swaps += 1\n\n            count = 0\n            for j in range(len(popularity)):\n                if popularity[j] &gt; popularity[i]:\n                    count += 1\n    return num_swaps\n</pre> def minimumSwaps(popularity: List):     # using cycle sort     num_swaps = 0     for i in range(len(popularity)):         count = 0         for j in range(len(popularity)):             if popularity[j] &gt; popularity[i]:                 count += 1          while count != i:             if popularity.index(popularity[i]) == count:                 continue             else:                 popularity[i], popularity[count] = popularity[count], popularity[i]                 num_swaps += 1              count = 0             for j in range(len(popularity)):                 if popularity[j] &gt; popularity[i]:                     count += 1     return num_swaps In\u00a0[70]: Copied! <pre>def minimumSwaps(popularity: List):\n    # using cycle sort\n    num_swaps = 0\n    for i in range(len(popularity)):\n        \n        t_index = true_index(i, popularity)\n        while t_index != i:\n            \n            if popularity.index(popularity[i]) == t_index:\n                continue\n            else:\n                popularity[i], popularity[t_index] = popularity[t_index], popularity[i]\n                num_swaps += 1\n                \n            t_index = true_index(i, popularity)\n            \n    return num_swaps\n</pre> def minimumSwaps(popularity: List):     # using cycle sort     num_swaps = 0     for i in range(len(popularity)):                  t_index = true_index(i, popularity)         while t_index != i:                          if popularity.index(popularity[i]) == t_index:                 continue             else:                 popularity[i], popularity[t_index] = popularity[t_index], popularity[i]                 num_swaps += 1                              t_index = true_index(i, popularity)                  return num_swaps In\u00a0[84]: Copied! <pre>def true_index(idx: int, arr: List):\n    \"\"\"\n    find the true index of the element with index idx in arr\n    \"\"\"\n    count = 0\n    for j in range(len(popularity)):\n        if popularity[j] &gt; popularity[idx]:\n            count += 1\n            \n    return count\n</pre> def true_index(idx: int, arr: List):     \"\"\"     find the true index of the element with index idx in arr     \"\"\"     count = 0     for j in range(len(popularity)):         if popularity[j] &gt; popularity[idx]:             count += 1                  return count In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[92]: Copied! <pre>popularity = [6, 2, 4, 1, 5, 9]\n</pre> popularity = [6, 2, 4, 1, 5, 9] In\u00a0[93]: Copied! <pre>minimumSwaps(popularity)\n</pre> minimumSwaps(popularity) Out[93]: <pre>5</pre> In\u00a0[94]: Copied! <pre>popularity = [3, 1, 2]\n</pre> popularity = [3, 1, 2] In\u00a0[95]: Copied! <pre>minimumSwaps(popularity)\n</pre> minimumSwaps(popularity) Out[95]: <pre>1</pre> In\u00a0[96]: Copied! <pre>popularity = [3, 4, 1, 2]\n</pre> popularity = [3, 4, 1, 2] In\u00a0[97]: Copied! <pre>minimumSwaps(popularity)\n</pre> minimumSwaps(popularity) Out[97]: <pre>2</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[49]: Copied! <pre>num_swap = 0\nfor i in range(len(popularity)):\n    count = 0\n    for j in range(len(popularity)):\n        if popularity[j] &gt; popularity[i]:\n            count += 1\n    \n    while count != i:\n        if popularity.index(popularity[i]) == count:\n            continue\n        else:\n            popularity[i], popularity[count] = popularity[count], popularity[i]\n            print('hello')\n            num_swap += 1\n        \n        count = 0\n        for j in range(len(popularity)):\n            if popularity[j] &gt; popularity[i]:\n                count += 1\n    \n    \n    \n</pre> num_swap = 0 for i in range(len(popularity)):     count = 0     for j in range(len(popularity)):         if popularity[j] &gt; popularity[i]:             count += 1          while count != i:         if popularity.index(popularity[i]) == count:             continue         else:             popularity[i], popularity[count] = popularity[count], popularity[i]             print('hello')             num_swap += 1                  count = 0         for j in range(len(popularity)):             if popularity[j] &gt; popularity[i]:                 count += 1                 <pre>hello\nhello\nhello\nhello\nhello\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/interview_utils/python_algorithm_puzzles/Minimum%20Swaps/#version1","title":"version1\u00b6","text":""},{"location":"markdown/interview_utils/python_algorithm_puzzles/Minimum%20Swaps/#version2","title":"version2\u00b6","text":""},{"location":"markdown/interview_utils/python_algorithm_puzzles/Special%20Sequence/","title":"Special Sequence","text":"In\u00a0[57]: Copied! <pre>from typing import List\n</pre> from typing import List In\u00a0[79]: Copied! <pre>def sumOfTheDIgits(q: List[int]):\n    # combined result is a list with the sum of special sequence in index order.\n    l, combined_result = [1], [1]\n    # we iterate from first sequence to the max element of q\n    for i in range(max(q) - 1):\n        count = 0\n        number = l[0]\n        result = []\n        for j in range(len(l)):\n\n            if l[j] != number:\n                result += [count, number]\n\n                count = 0\n                number = l[j]\n\n            count += 1\n\n            if j == len(l) - 1:\n                result += [count, number]\n\n        l = result\n\n        combined_result.append(sum(l))\n        \n    return [combined_result[i - 1] for i in q]\n</pre> def sumOfTheDIgits(q: List[int]):     # combined result is a list with the sum of special sequence in index order.     l, combined_result = [1], [1]     # we iterate from first sequence to the max element of q     for i in range(max(q) - 1):         count = 0         number = l[0]         result = []         for j in range(len(l)):              if l[j] != number:                 result += [count, number]                  count = 0                 number = l[j]              count += 1              if j == len(l) - 1:                 result += [count, number]          l = result          combined_result.append(sum(l))              return [combined_result[i - 1] for i in q] In\u00a0[80]: Copied! <pre>sumOfTheDIgits([1, 2, 3])\n</pre> sumOfTheDIgits([1, 2, 3]) Out[80]: <pre>[1, 2, 3]</pre> In\u00a0[81]: Copied! <pre>sumOfTheDIgits([1, 2, 5])\n</pre> sumOfTheDIgits([1, 2, 5]) Out[81]: <pre>[1, 2, 8]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[82]: Copied! <pre># \u6ca1\u627e\u5230\n</pre> # \u6ca1\u627e\u5230 In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[59]: Copied! <pre>n = 10\n</pre> n = 10 In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[60]: Copied! <pre># l is the appearance array\nl = [1]\ncombined_result = [l]\nfor i in range(n - 1):\n    count = 0\n    number = l[0]\n    result = []\n    for j in range(len(l)):\n\n        if l[j] != number:\n            result += [count, number]\n\n            count = 0\n            number = l[j]\n\n        count += 1\n\n        if j == len(l) - 1:\n            result += [count, number]\n\n    l = result\n    \n    combined_result.append(l)\n\n[sum(i) for i in combined_result]\n</pre> # l is the appearance array l = [1] combined_result = [l] for i in range(n - 1):     count = 0     number = l[0]     result = []     for j in range(len(l)):          if l[j] != number:             result += [count, number]              count = 0             number = l[j]          count += 1          if j == len(l) - 1:             result += [count, number]      l = result          combined_result.append(l)  [sum(i) for i in combined_result]  Out[60]: <pre>[1, 2, 3, 5, 8, 10, 13, 16, 23, 32]</pre> In\u00a0[67]: Copied! <pre>countAndSay(7)\n</pre> countAndSay(7) <pre>[1, 1]\n[2, 1]\n[1, 2, 1, 1]\n[1, 1, 1, 2, 2, 1]\n[3, 1, 2, 2, 1, 1]\n[1, 3, 1, 1, 2, 2, 2, 1]\n</pre> Out[67]: <pre>[1, 3, 1, 1, 2, 2, 2, 1]</pre> In\u00a0[68]: Copied! <pre>from collections import Counter\n</pre> from collections import Counter In\u00a0[70]: Copied! <pre>c = Counter([3, 1, 2, 2, 1, 1])\nc\n</pre> c = Counter([3, 1, 2, 2, 1, 1]) c Out[70]: <pre>Counter({3: 1, 1: 3, 2: 2})</pre> In\u00a0[71]: Copied! <pre>sum([1, 3, 1, 1, 2, 2, 2, 1])\n</pre> sum([1, 3, 1, 1, 2, 2, 2, 1]) Out[71]: <pre>13</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[44]: Copied! <pre>seq = [1]\n\nall_result = []\n\nfor i in range(n):\n    result = []\n    prev = seq[0]\n    count = 1\n    for j in range(len(seq)):\n        if j == len(seq) - 1:\n            if seq[j] != prev:\n                result += [count , prev]\n                result += [1, seq[j]]\n            else:\n                result += [count, prev]\n                \n            continue\n            \n        elif seq[j] != prev:\n            result += [count - 1, prev]\n            count = 0\n            prev = seq[j]\n            \n        else:\n            count += 1\n            prev = seq[j]\n        \n    print('result', result)\n    all_result.append(result)\n    \n    seq = result\n    print('seq', seq)\n</pre> seq = [1]  all_result = []  for i in range(n):     result = []     prev = seq[0]     count = 1     for j in range(len(seq)):         if j == len(seq) - 1:             if seq[j] != prev:                 result += [count , prev]                 result += [1, seq[j]]             else:                 result += [count, prev]                              continue                      elif seq[j] != prev:             result += [count - 1, prev]             count = 0             prev = seq[j]                      else:             count += 1             prev = seq[j]              print('result', result)     all_result.append(result)          seq = result     print('seq', seq) <pre>result [1, 1]\nseq [1, 1]\nresult [2, 1]\nseq [2, 1]\nresult [1, 2, 1, 1]\nseq [1, 2, 1, 1]\nresult [1, 1, -1, 2, 0, 1]\nseq [1, 1, -1, 2, 0, 1]\nresult [2, 1, -1, -1, -1, 2, -1, 0, 1, 1]\nseq [2, 1, -1, -1, -1, 2, -1, 0, 1, 1]\n</pre> In\u00a0[22]: Copied! <pre>result = []\nresult += [1] * 2\nresult\n</pre> result = [] result += [1] * 2 result Out[22]: <pre>[1, 1]</pre> In\u00a0[24]: Copied! <pre>result\n</pre> result Out[24]: <pre>[]</pre> In\u00a0[36]: Copied! <pre>all_result\n</pre> all_result Out[36]: <pre>[[1, 1], [2, 1], [2, 2], [2, 2], [2, 2]]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/interview_utils/python_algorithm_puzzles/Special%20Sequence/","title":"\u6709\u6ca1\u6709\u66f4\u5feb\u7684\u65b9\u6cd5\uff1f\u00b6","text":""},{"location":"markdown/interview_utils/python_algorithm_puzzles/Statistic%20Indicators/","title":"Statistic Indicators","text":"In\u00a0[1]: Copied! <pre>from typing import List\n</pre> from typing import List In\u00a0[87]: Copied! <pre>def difference_calculator(N: int, arr: List):\n    return abs(calculator_indicator_1(arr, N) - calculate_indicator_2(arr))\n</pre> def difference_calculator(N: int, arr: List):     return abs(calculator_indicator_1(arr, N) - calculate_indicator_2(arr)) In\u00a0[88]: Copied! <pre>def calculator_indicator_1(arr, N):\n    pointer = 0\n    dc = {}\n    indicator_1 = 0\n    while pointer &lt; N:\n\n        # current group\n        if (pointer == 0) or (arr[pointer - 1] == arr[pointer]):\n            if arr[pointer] not in dc:\n                dc[arr[pointer]] = 1\n            else:\n                dc[arr[pointer]] += 1\n\n        # next group\n        else: # (pointer &gt; 0) and arr[pointer - 1] != arr[pointer]\n\n            # every time entering into next group, we calculate the number of indicator1 in current dc and \n            # initialize dc\n            indicator_1 += sum([1 for i, j in dc.items() if i == j])\n            dc = {}\n\n            # add a new key\n            dc[arr[pointer]] = 1\n\n        pointer += 1\n\n    indicator_1 += calculate_indicator_1(dc)\n\n    return indicator_1\n</pre> def calculator_indicator_1(arr, N):     pointer = 0     dc = {}     indicator_1 = 0     while pointer &lt; N:          # current group         if (pointer == 0) or (arr[pointer - 1] == arr[pointer]):             if arr[pointer] not in dc:                 dc[arr[pointer]] = 1             else:                 dc[arr[pointer]] += 1          # next group         else: # (pointer &gt; 0) and arr[pointer - 1] != arr[pointer]              # every time entering into next group, we calculate the number of indicator1 in current dc and              # initialize dc             indicator_1 += sum([1 for i, j in dc.items() if i == j])             dc = {}              # add a new key             dc[arr[pointer]] = 1          pointer += 1      indicator_1 += calculate_indicator_1(dc)      return indicator_1 In\u00a0[89]: Copied! <pre>def calculate_indicator_2(arr: List):\n    indicator_2 = 0\n    for number in list(set(arr)):\n        check = True\n        for i in range(number - 1, 2 * number - 1):\n            if arr[i] != number:\n                check = False\n                break\n\n        if check and (2 * number - 1 == N or arr[2 * number - 1] != number):\n            indicator_2 += 1\n            \n    return indicator_2\n</pre> def calculate_indicator_2(arr: List):     indicator_2 = 0     for number in list(set(arr)):         check = True         for i in range(number - 1, 2 * number - 1):             if arr[i] != number:                 check = False                 break          if check and (2 * number - 1 == N or arr[2 * number - 1] != number):             indicator_2 += 1                  return indicator_2 In\u00a0[98]: Copied! <pre>arr = [3, 3, 2, 2, 5, 5, 5, 5, 5, 3, 3, 3, 2, 2]\nN = 14\n</pre> arr = [3, 3, 2, 2, 5, 5, 5, 5, 5, 3, 3, 3, 2, 2] N = 14 In\u00a0[99]: Copied! <pre>difference_calculator(N, arr)\n</pre> difference_calculator(N, arr) Out[99]: <pre>3</pre> In\u00a0[100]: Copied! <pre>arr = [1, 2, 2, 2, 2, 3, 3, 3, 1, 1, 2, 2]\nN = 12\n</pre> arr = [1, 2, 2, 2, 2, 3, 3, 3, 1, 1, 2, 2] N = 12 In\u00a0[101]: Copied! <pre>difference_calculator(N, arr)\n</pre> difference_calculator(N, arr) Out[101]: <pre>2</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[96]: Copied! <pre>arr = [1, 2, 2, 4, 4, 4, 4, 3, 4, 4, 4]\nN = 11\n</pre> arr = [1, 2, 2, 4, 4, 4, 4, 3, 4, 4, 4] N = 11 In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[46]: Copied! <pre>indicator_1\n</pre> indicator_1 Out[46]: <pre>3</pre> In\u00a0[50]: Copied! <pre>list(set(arr))\n</pre> list(set(arr)) Out[50]: <pre>[1, 2, 3, 4]</pre> In\u00a0[61]: Copied! <pre>number = 3\n</pre> number = 3 In\u00a0[63]: Copied! <pre>for i in range(number - 1, 2 * number - 1):\n    print(i)\n</pre> for i in range(number - 1, 2 * number - 1):     print(i) <pre>2\n3\n4\n</pre> In\u00a0[64]: Copied! <pre>arr[2] != number\n</pre> arr[2] != number Out[64]: <pre>True</pre> In\u00a0[79]: Copied! <pre>dc = {1: 1, 2: 3, 4: 4}\n</pre> dc = {1: 1, 2: 3, 4: 4} In\u00a0[84]: Copied! <pre>sum([1 for i, j in dc.items() if i == j])\n</pre> sum([1 for i, j in dc.items() if i == j]) Out[84]: <pre>2</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/interview_utils/python_algorithm_puzzles/backtrader/","title":"Backtrader","text":"In\u00a0[\u00a0]: Copied! <pre>import shutil\nimport os\n</pre> import shutil import os In\u00a0[\u00a0]: Copied! <pre>shutil.rmtree('/Users/wenglongao/Downloads/\u672a\u547d\u540d\u6587\u4ef6\u5939 3')\nos.mkdir('/Users/wenglongao/Downloads/\u672a\u547d\u540d\u6587\u4ef6\u5939 3')\n</pre> shutil.rmtree('/Users/wenglongao/Downloads/\u672a\u547d\u540d\u6587\u4ef6\u5939 3') os.mkdir('/Users/wenglongao/Downloads/\u672a\u547d\u540d\u6587\u4ef6\u5939 3') In\u00a0[\u00a0]: Copied! <pre>from lwpackage.lwutils.file_processor import move_file, make_path, clear_path\n</pre> from lwpackage.lwutils.file_processor import move_file, make_path, clear_path In\u00a0[\u00a0]: Copied! <pre>from lwpackage.lwutils.lwpath import PREPROCESS_PHOTO_PATH, POSTPROCESS_PHOTO_PATH, FOLDER_TO_ALBUM_MAP\n</pre> from lwpackage.lwutils.lwpath import PREPROCESS_PHOTO_PATH, POSTPROCESS_PHOTO_PATH, FOLDER_TO_ALBUM_MAP  In\u00a0[\u00a0]: Copied! <pre>clear_path(PREPROCESS_PHOTO_PATH)\n</pre> clear_path(PREPROCESS_PHOTO_PATH) In\u00a0[\u00a0]: Copied! <pre>import akshare as ak\n</pre> import akshare as ak  In\u00a0[\u00a0]: Copied! <pre>import akshare as ak\n\nstock_zh_a_hist_df = ak.stock_zh_a_hist(symbol=\"000001\", start_date=\"20210101\", end_date=\"20211231\", adjust=\"\")\nprint(stock_zh_a_hist_df)\n</pre> import akshare as ak  stock_zh_a_hist_df = ak.stock_zh_a_hist(symbol=\"000001\", start_date=\"20210101\", end_date=\"20211231\", adjust=\"\") print(stock_zh_a_hist_df)  In\u00a0[\u00a0]: Copied! <pre>stock_zh_a_hist_df\n</pre> stock_zh_a_hist_df In\u00a0[\u00a0]: Copied! <pre>df = ak.stock_zh_a_tick_tx(symbol=\"000001\", trade_date=\"20211101\")\ndf\n</pre> df = ak.stock_zh_a_tick_tx(symbol=\"000001\", trade_date=\"20211101\") df In\u00a0[\u00a0]: Copied! <pre>stock_zh_a_minute_df = ak.stock_zh_a_hist(symbol='600751', period='1', adjust=\"qfq\")\nstock_zh_a_minute_df\n</pre> stock_zh_a_minute_df = ak.stock_zh_a_hist(symbol='600751', period='1', adjust=\"qfq\") stock_zh_a_minute_df In\u00a0[\u00a0]: Copied! <pre>stock_zh_a_minute_df\n</pre> stock_zh_a_minute_df In\u00a0[\u00a0]: Copied! <pre>df_stock = ak.stock_zh_a_spot_em()\n</pre> df_stock = ak.stock_zh_a_spot_em() In\u00a0[\u00a0]: Copied! <pre>ak.stock_zh_a_minute(symbol='sz000001', period='1', adjust=\"qfq\")\n</pre> ak.stock_zh_a_minute(symbol='sz000001', period='1', adjust=\"qfq\") In\u00a0[\u00a0]: Copied! <pre>df_stock\n</pre> df_stock In\u00a0[\u00a0]: Copied! <pre>import akshare as ak\n\n# \u83b7\u53d6\u5e73\u5b89\u94f6\u884c(000001)\u7684\u80a1\u7968\u4ee3\u7801\ndf = ak.stock_zh_a_spot_em()\nsymbol = df[df['\u540d\u79f0'] == '\u5e73\u5b89\u94f6\u884c']['\u4ee3\u7801'].values[0]\nprint(symbol)\n</pre> import akshare as ak  # \u83b7\u53d6\u5e73\u5b89\u94f6\u884c(000001)\u7684\u80a1\u7968\u4ee3\u7801 df = ak.stock_zh_a_spot_em() symbol = df[df['\u540d\u79f0'] == '\u5e73\u5b89\u94f6\u884c']['\u4ee3\u7801'].values[0] print(symbol) In\u00a0[\u00a0]: Copied! <pre>df = ak.stock_zh_a_hist(symbol=\"000001\", period=\"daily\", start_date=\"20170301\", end_date='20210907', adjust=\"\")\ndf\n</pre> df = ak.stock_zh_a_hist(symbol=\"000001\", period=\"daily\", start_date=\"20170301\", end_date='20210907', adjust=\"\") df In\u00a0[\u00a0]: Copied! <pre># \u4e0d\u52a0symbol\u9ed8\u8ba4\u8fd4\u56de\u4e2d\u56fd\u5e73\u5b89\ndf = ak.stock_zh_a_hist(period=\"daily\", start_date=\"20170301\", end_date='20210907', adjust=\"\")\ndf\n</pre> # \u4e0d\u52a0symbol\u9ed8\u8ba4\u8fd4\u56de\u4e2d\u56fd\u5e73\u5b89 df = ak.stock_zh_a_hist(period=\"daily\", start_date=\"20170301\", end_date='20210907', adjust=\"\") df In\u00a0[\u00a0]: Copied! <pre>df = ak.stock_zh_a_hist(symbol=\"000001\", period=\"daily\", start_date=\"20170301\", end_date='20210907', adjust=\"\")\ndf\n</pre> df = ak.stock_zh_a_hist(symbol=\"000001\", period=\"daily\", start_date=\"20170301\", end_date='20210907', adjust=\"\") df In\u00a0[\u00a0]: Copied! <pre>import akshare as ak\n\n# \u6ce8\u610f\uff1a\u8be5\u63a5\u53e3\u8fd4\u56de\u7684\u6570\u636e\u53ea\u6709\u6700\u8fd1\u4e00\u4e2a\u4ea4\u6613\u65e5\u7684\u6709\u5f00\u76d8\u4ef7\uff0c\u5176\u4ed6\u65e5\u671f\u5f00\u76d8\u4ef7\u4e3a 0\nstock_zh_a_hist_min_em_df = ak.stock_zh_a_hist_min_em(symbol=\"300429\", start_date=\"2023-11-01 09:32:00\", end_date=\"2023-11-02 09:32:00\", period='1', adjust='')\nstock_zh_a_hist_min_em_df\n</pre> import akshare as ak  # \u6ce8\u610f\uff1a\u8be5\u63a5\u53e3\u8fd4\u56de\u7684\u6570\u636e\u53ea\u6709\u6700\u8fd1\u4e00\u4e2a\u4ea4\u6613\u65e5\u7684\u6709\u5f00\u76d8\u4ef7\uff0c\u5176\u4ed6\u65e5\u671f\u5f00\u76d8\u4ef7\u4e3a 0 stock_zh_a_hist_min_em_df = ak.stock_zh_a_hist_min_em(symbol=\"300429\", start_date=\"2023-11-01 09:32:00\", end_date=\"2023-11-02 09:32:00\", period='1', adjust='') stock_zh_a_hist_min_em_df In\u00a0[\u00a0]: Copied! <pre># \u6ce8\u610f\uff0cakshare\u4e2d\u7684\u4e00\u4e9b\u51fd\u6570\u9700\u8981\u8f93\u5165\u5e26\u6709\u5e02\u573a\u6807\u8bc6\u7684\u80a1\u7968\n</pre> # \u6ce8\u610f\uff0cakshare\u4e2d\u7684\u4e00\u4e9b\u51fd\u6570\u9700\u8981\u8f93\u5165\u5e26\u6709\u5e02\u573a\u6807\u8bc6\u7684\u80a1\u7968 In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>df_stock[df_stock['\u4ee3\u7801'] == '000001']\n</pre> df_stock[df_stock['\u4ee3\u7801'] == '000001'] In\u00a0[\u00a0]: Copied! <pre>def add_market_prefix(code: str) -&gt; str:\n    if code.startswith(('0', '3')):\n        return 'sz' + code\n    elif code.startswith('6'):\n        return 'sh' + code\n    else:\n        raise ValueError(f\"Invalid A\u80a1\u80a1\u7968\u4ee3\u7801: {code}\")\n</pre> def add_market_prefix(code: str) -&gt; str:     if code.startswith(('0', '3')):         return 'sz' + code     elif code.startswith('6'):         return 'sh' + code     else:         raise ValueError(f\"Invalid A\u80a1\u80a1\u7968\u4ee3\u7801: {code}\")  In\u00a0[\u00a0]: Copied! <pre>add_market_prefix('300269')\n</pre> add_market_prefix('300269') In\u00a0[\u00a0]: Copied! <pre>ak.stock_zh_a_minute(symbol='sz300269', period='1', adjust=\"qfq\")\n</pre> ak.stock_zh_a_minute(symbol='sz300269', period='1', adjust=\"qfq\") In\u00a0[\u00a0]: Copied! <pre>from __future__ import (absolute_import, division, print_function,\n                        unicode_literals)\n\nimport backtrader as bt\n\nif __name__ == '__main__':\n    \n    # \u521b\u5efaCerebro\u5b9e\u4f8b\n    cerebro = bt.Cerebro()\n#     cerebro.broker.setcash(100000.0)\n\n    # \u8f93\u51faCerebro\u5f15\u64ce\u9ed8\u8ba4\u672c\u91d1\n    print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())\n\n    # \u8fd0\u884c\u5f15\u64ce\n    cerebro.run()\n\n    # \u8f93\u51faCerebro\u5f15\u64ce\u8fd0\u884c\u4e4b\u540e\u672c\u91d1\u60c5\u51b5\n    print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue())\n</pre> from __future__ import (absolute_import, division, print_function,                         unicode_literals)  import backtrader as bt  if __name__ == '__main__':          # \u521b\u5efaCerebro\u5b9e\u4f8b     cerebro = bt.Cerebro() #     cerebro.broker.setcash(100000.0)      # \u8f93\u51faCerebro\u5f15\u64ce\u9ed8\u8ba4\u672c\u91d1     print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())      # \u8fd0\u884c\u5f15\u64ce     cerebro.run()      # \u8f93\u51faCerebro\u5f15\u64ce\u8fd0\u884c\u4e4b\u540e\u672c\u91d1\u60c5\u51b5     print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue())  In\u00a0[\u00a0]: Copied! <pre>from __future__ import (absolute_import, division, print_function,\n                        unicode_literals)\n\nimport backtrader as bt\n\nif __name__ == '__main__':\n    cerebro = bt.Cerebro()\n    cerebro.broker.setcash(100000.0) # \u8bbe\u7f6e\u672c\u91d1\n\n    print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())\n\n    cerebro.run()\n\n    print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue())\n</pre> from __future__ import (absolute_import, division, print_function,                         unicode_literals)  import backtrader as bt  if __name__ == '__main__':     cerebro = bt.Cerebro()     cerebro.broker.setcash(100000.0) # \u8bbe\u7f6e\u672c\u91d1      print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())      cerebro.run()      print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue())  In\u00a0[\u00a0]: Copied! <pre>os.path.abspath(sys.argv[0])\n</pre> os.path.abspath(sys.argv[0]) In\u00a0[\u00a0]: Copied! <pre>sys.argv[0]\n</pre> sys.argv[0] In\u00a0[\u00a0]: Copied! <pre>modpath = os.path.dirname(os.path.abspath(sys.argv[0]))\ndatapath = os.path.join(modpath, '../../datas/orcl-1995-2014.txt')\n</pre> modpath = os.path.dirname(os.path.abspath(sys.argv[0])) datapath = os.path.join(modpath, '../../datas/orcl-1995-2014.txt') In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>datapath\n</pre> datapath In\u00a0[\u00a0]: Copied! <pre>data = bt.feeds.YahooFinanceCSVData(\n       dataname=datapath,\n       # Do not pass values before this date\n       fromdate=datetime.datetime(2000, 1, 1),\n       # Do not pass values after this date\n       todate=datetime.datetime(2000, 12, 31),\n       reverse=False)\n</pre> data = bt.feeds.YahooFinanceCSVData(        dataname=datapath,        # Do not pass values before this date        fromdate=datetime.datetime(2000, 1, 1),        # Do not pass values after this date        todate=datetime.datetime(2000, 12, 31),        reverse=False)  In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[61]: Copied! <pre>import os\nimport sys\nfrom datetime import datetime\nimport pandas as pd\nimport akshare as ak\n</pre> import os import sys from datetime import datetime import pandas as pd import akshare as ak In\u00a0[62]: Copied! <pre>df = ak.stock_zh_a_minute(symbol='sz000001', period='1', adjust=\"qfq\")\n</pre> df = ak.stock_zh_a_minute(symbol='sz000001', period='1', adjust=\"qfq\") In\u00a0[63]: Copied! <pre>df = df.rename(columns={'day': 'datetime'})\n</pre> df = df.rename(columns={'day': 'datetime'}) In\u00a0[64]: Copied! <pre>df['volume'] = df['volume'].astype(int)\n</pre> df['volume'] = df['volume'].astype(int) In\u00a0[65]: Copied! <pre>df['datetime'] = pd.to_datetime(df['datetime'])\n</pre> df['datetime'] = pd.to_datetime(df['datetime']) In\u00a0[66]: Copied! <pre>df.dtypes\n</pre> df.dtypes Out[66]: <pre>datetime    datetime64[ns]\nopen               float64\nhigh               float64\nlow                float64\nclose              float64\nvolume               int64\ndtype: object</pre> In\u00a0[67]: Copied! <pre>df\n</pre> df Out[67]: datetime open high low close volume 0 2023-10-24 13:53:00 10.55 10.59 10.55 10.58 1562200 1 2023-10-24 13:54:00 10.57 10.60 10.57 10.60 1539663 2 2023-10-24 13:55:00 10.59 10.60 10.59 10.59 338000 3 2023-10-24 13:56:00 10.59 10.61 10.58 10.61 1019300 4 2023-10-24 13:57:00 10.60 10.60 10.58 10.59 216600 ... ... ... ... ... ... ... 1965 2023-11-03 14:54:00 10.46 10.46 10.45 10.46 282200 1966 2023-11-03 14:55:00 10.45 10.47 10.45 10.46 722900 1967 2023-11-03 14:56:00 10.46 10.47 10.45 10.46 137400 1968 2023-11-03 14:57:00 10.46 10.47 10.46 10.46 411500 1969 2023-11-03 15:00:00 10.48 10.48 10.48 10.48 1529300 <p>1970 rows \u00d7 6 columns</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p><code>bt.Strategy</code>\u7c7b\u662fBacktrader\u4e2d\u7528\u4e8e\u5236\u5b9a\u56de\u6d4b\u7b56\u7565\u7684\u6838\u5fc3\u7c7b\u3002\u4ee5\u4e0b\u662f\u4e00\u4e9b\u5e38\u7528\u7684\u5c5e\u6027\uff1a</p> <ol> <li><p><code>self.datas</code>\uff1a\u5305\u542b\u6240\u6709\u6570\u636e\u6e90\u7684\u5217\u8868\u3002\u6bcf\u4e2a\u6570\u636e\u6e90\u90fd\u662f\u4e00\u4e2a<code>bt.feeds</code>\u5bf9\u8c61\uff0c\u5305\u542b\u6709\u5173\u6570\u636e\u7684\u4fe1\u606f\uff0c\u4f8b\u5982\u5f00\u76d8\u4ef7\u3001\u6536\u76d8\u4ef7\u7b49\u3002</p> </li> <li><p><code>self.params</code>\uff1a\u5305\u542b\u7b56\u7565\u53c2\u6570\u7684\u5b57\u5178\u3002\u8fd9\u4e9b\u53c2\u6570\u53ef\u4ee5\u5728\u5b9e\u4f8b\u5316\u7b56\u7565\u65f6\u4f20\u9012\uff0c\u5e76\u5728\u7b56\u7565\u4e2d\u4f7f\u7528\u3002</p> </li> <li><p><code>self.position</code>\uff1a\u5305\u542b\u5f53\u524d\u6301\u4ed3\u7684\u4fe1\u606f\u3002\u8fd9\u662f\u4e00\u4e2a<code>bt.Position</code>\u5bf9\u8c61\uff0c\u5176\u4e2d\u5305\u542b\u6709\u5173\u6301\u4ed3\u6570\u91cf\u3001\u5e73\u5747\u6210\u672c\u7b49\u7684\u4fe1\u606f\u3002</p> </li> <li><p><code>self.broker</code>\uff1a\u5305\u542b\u6709\u5173\u7ecf\u7eaa\u4eba\u7684\u4fe1\u606f\u3002\u8fd9\u662f\u4e00\u4e2a<code>bt.broker</code>\u5bf9\u8c61\uff0c\u5176\u4e2d\u5305\u542b\u6709\u5173\u73b0\u91d1\u4f59\u989d\u3001\u624b\u7eed\u8d39\u7b49\u7684\u4fe1\u606f\u3002</p> </li> <li><p><code>self.order</code>\uff1a\u5305\u542b\u6709\u5173\u5f53\u524d\u8ba2\u5355\u7684\u4fe1\u606f\u3002\u8fd9\u662f\u4e00\u4e2a<code>bt.Order</code>\u5bf9\u8c61\uff0c\u5176\u4e2d\u5305\u542b\u6709\u5173\u8ba2\u5355\u7c7b\u578b\u3001\u6570\u91cf\u7b49\u7684\u4fe1\u606f\u3002</p> </li> <li><p><code>self.trade</code>\uff1a\u5305\u542b\u6709\u5173\u5f53\u524d\u4ea4\u6613\u7684\u4fe1\u606f\u3002\u8fd9\u662f\u4e00\u4e2a<code>bt.Trade</code>\u5bf9\u8c61\uff0c\u5176\u4e2d\u5305\u542b\u6709\u5173\u4ea4\u6613\u7c7b\u578b\u3001\u6570\u91cf\u7b49\u7684\u4fe1\u606f\u3002</p> </li> <li><p><code>self.analyzers</code>\uff1a\u5305\u542b\u6240\u6709\u5206\u6790\u5668\u7684\u5217\u8868\u3002\u6bcf\u4e2a\u5206\u6790\u5668\u90fd\u662f\u4e00\u4e2a<code>bt.analyzers</code>\u5bf9\u8c61\uff0c\u7528\u4e8e\u8ba1\u7b97\u7b56\u7565\u6027\u80fd\u6307\u6807\uff0c\u4f8b\u5982\u6536\u76ca\u7387\u3001\u590f\u666e\u6bd4\u7387\u7b49\u3002</p> </li> </ol> <p>\u5e0c\u671b\u8fd9\u53ef\u4ee5\u5e2e\u52a9\u60a8\u89e3\u51b3\u95ee\u9898\u3002\u5982\u679c\u60a8\u9700\u8981\u66f4\u591a\u5e2e\u52a9\uff0c\u8bf7\u544a\u8bc9\u6211\u3002</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/2 (1) Strategy - Backtrader. https://www.backtrader.com/docu/strategy/. (2) Python\u91cf\u5316\u4ea4\u6613\u5b66\u4e60\u7b14\u8bb0\uff0823\uff09\u2014\u2014backtrader\u7684Strategy\u7c7b .... https://blog.csdn.net/m0_46603114/article/details/105488437. (3) Can you add parameters to backtrader strategy? - Stack Overflow. https://stackoverflow.com/questions/72273407/can-you-add-parameters-to-backtrader-strategy.</p> In\u00a0[93]: Copied! <pre>from __future__ import (absolute_import, division, print_function,\n                       unicode_literals)\n\nimport os.path  # To manage paths\nimport sys  # To find out the script name (in argv[0])\n\n# Import the backtrader platform\nimport backtrader as bt\n\n# Create a Strategy\nclass TestStrategy(bt.Strategy):\n\n    def log(self, txt, dt=None):\n        ''' Logging function for this strategy'''\n        dt = self.datas[0].datetime.date()\n        print('%s, %s' % (dt.isoformat(), txt))\n\n    def __init__(self):\n        # Keep a reference to the \"close\" line in the data[0] dataseries\n        self.dataclose = self.datas[0].close\n    \n    # \u5728\u56de\u6d4b\u8fc7\u7a0b\u4e2d\uff0cnext()\u65b9\u6cd5\u5c06\u5728\u6bcf\u4e2a\u6570\u636e\u70b9\u4e0a\u88ab\u8c03\u7528\u4e00\u6b21\uff0c\u4ee5\u4fbf\u7b56\u7565\u53ef\u4ee5\u8bc4\u4f30\u65b0\u6570\u636e\u5e76\u6267\u884c\u4ea4\u6613\u3002\n    def next(self):\n        # Simply log the closing price of the series from the reference\n        self.log('Close, %.2f' % self.dataclose[0])\n\n\nclass MyStrategy(bt.Strategy):\n    def __init__(self):\n        self.sma = bt.indicators.SimpleMovingAverage(self.data, period=15)\n\n    def next(self):\n        if self.data.close &gt; self.sma:\n            self.buy()\n            # \u6211\u4eec\u53ea\u4f20\u5165\u4e86\u4e00\u4e2a\u6570\u636e\u6e90df\uff0c\u56e0\u6b64self.datas\u53ea\u6709\u4e00\u4e2a\u5143\u7d20\u3002\n            print(f'type of self.datas is {type(self.datas)}')  # self.datas\u662f\u4e00\u4e2alist\n            print(f'type of self.datas[0] is {type(self.datas[0])}') # self.datas[0]\u662f\u4e00\u4e2abt.feeds\n            print(self.datas[0].datetime.datetime())\n            print(f'{self.datas[0].close[0]}, {self.datas[0].close[-1]}, {self.datas[0].close[-2]}, {self.sma[0]}')\n        elif self.data.close &lt; self.sma:\n            self.sell()\n            \n# Create a Strategy\nclass TestStrategy1(bt.Strategy):\n\n    def log(self, txt, dt=None):\n        ''' Logging function fot this strategy'''\n        dt = self.datas[0].datetime.date(0)\n        print('%s, %s' % (dt.isoformat(), txt))\n\n    def __init__(self):\n        # Keep a reference to the \"close\" line in the data[0] dataseries\n        self.dataclose = self.datas[0].close\n\n    def next(self):\n        # Simply log the closing price of the series from the reference\n        self.log('Close, %.2f' % self.dataclose[0])\n\n        if self.dataclose[0] &lt; self.dataclose[-1]:\n            # current close less than previous close\n\n            if self.dataclose[-1] &lt; self.dataclose[-2]:\n                # previous close less than the previous close\n\n                # BUY, BUY, BUY!!! (with all possible default parameters)\n                self.log(f'BUY CREATE, {self.dataclose[0]}')\n                # \u8ba2\u5355\u662f\u5728\u201c\u5e02\u573a\u4e0a\u201d\u6267\u884c\u7684\uff0c\u4ee3\u7406(Cerebro\u5b9e\u4f8b)\u4f7f\u7528\u4e0b\u4e00\u4e2abar\u7684\u5f00\u76d8\u4ef7\u6267\u884c\u4e70\u64cd\u4f5c\uff0c\n                # \u56e0\u4e3a\u5b83\u662f\u5f53\u524d\u68c0\u67e5bar\u4e4b\u540e\u7684\u7b2c\u4e00\u4e2atick\uff08\u6ee1\u8db3\u4e0b\u5355\u6761\u4ef6\u4e4b\u540e\u7684\u4e0b\u4e00\u4e2abar\u4e2d\u7684\u5f00\u76d8\u4ef7-\u5f3a\u8c03\u4e00\u4e0b\uff0c\n                # \u8fd9\u91cc\u672a\u5fc5\u662f\u4e0b\u4e00\u4e2a\u5f00\u76d8\u65e5\uff0c\u56e0\u4e3abacktrader\u6ca1\u6709\u5047\u8bbe\u4f60\u7684\u6570\u636e\u91c7\u6837\u95f4\u9694\u662fD\uff09\n                self.buy()\n                \n\nclass TestStrategy2(bt.Strategy):\n    \n    # log\u51fd\u6570\u4e3b\u8981\u76ee\u7684\u5c31\u662f\u8f93\u51fa\u65f6\u95f4\n    def log(self, txt, dt=None):\n        ''' Logging function fot this strategy'''\n        dt = dt or self.datas[0].datetime.datetime(0)\n        print('%s, %s' % (dt.isoformat(), txt))\n\n    def __init__(self):\n        # Keep a reference to the \"close\" line in the data[0] dataseries\n        self.dataclose = self.datas[0].close\n\n        # To keep track of pending orders\n        self.order = None\n\n    def notify_order(self, order):\n        if order.status in [order.Submitted, order.Accepted]:\n            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n            return\n\n        # Check if an order has been completed\n        # Attention: broker could reject order if not enough cash\n        if order.status in [order.Completed]:\n            if order.isbuy():\n                self.log('BUY EXECUTED, %.2f' % order.executed.price)\n            elif order.issell():\n                self.log('SELL EXECUTED, %.2f' % order.executed.price)\n\n            self.bar_executed = len(self)\n\n        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n            self.log('Order Canceled/Margin/Rejected')\n\n        # Write down: no pending order\n        self.order = None\n\n    def next(self):\n        # Simply log the closing price of the series from the reference\n        self.log('Close, %.2f' % self.dataclose[0])\n\n        # Check if an order is pending ... if yes, we cannot send a 2nd one\n        if self.order:\n            return\n#         print(self.position)\n        # Check if we are in the market\n        if not self.position:\n\n            # Not yet ... we MIGHT BUY if ...\n            if self.dataclose[0] &lt; self.dataclose[-1]:\n                    # current close less than previous close\n\n                    if self.dataclose[-1] &lt; self.dataclose[-2]:\n                        # previous close less than the previous close\n\n                        # BUY, BUY, BUY!!! (with default parameters)\n                        self.log('BUY CREATE, %.2f' % self.dataclose[0])\n\n                        # Keep track of the created order to avoid a 2nd order\n                        self.order = self.buy()\n\n        else:\n\n            # Already in the market ... we might sell\n            if len(self) &gt;= (self.bar_executed + 5):\n                print('lenself:', len(self))\n                print('bar:', self.bar_executed)\n                # SELL, SELL, SELL!!! (with all possible default parameters)\n                self.log('SELL CREATE, %.2f' % self.dataclose[0])\n\n                # Keep track of the created order to avoid a 2nd order\n                self.order = self.sell(size=100)\n\n\n# Create a Stratey\nclass TestStrategy3(bt.Strategy):\n\n    def log(self, txt, dt=None):\n        ''' Logging function fot this strategy'''\n        dt = self.datas[0].datetime.datetime(0)\n        print('%s, %s' % (dt.isoformat(), txt))\n\n    def __init__(self):\n        # Keep a reference to the \"close\" line in the data[0] dataseries\n        self.dataclose = self.datas[0].close\n            \n        # \u6ce8\u610f\uff0c\u672c\u8eabbt.Strategy\u6ca1\u6709order\u5c5e\u6027\u3002\u8fd9\u91cc\u7684self.order\u662f\u6211\u4eec\u81ea\u5df1\u5b9a\u4e49\u7684\n        # To keep track of pending orders and buy price/commission\n        self.order = None\n        self.buyprice = None\n        self.buycomm = None\n\n    def notify_order(self, order):\n        # \u6ce8\u610f\u5230\u5728\u4f20\u5165\u6570\u636e\u7684\u6bcf\u4e00\u4e2atick\uff0cnotify_order\u53ef\u80fd\u4f1a\u88ab\u8c03\u7528\u591a\u6b21\uff0c\u5373\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u4e00\u6b21\uff0cnotify_order\u5c31\u4f1a\u88ab\u8c03\u7528\u4e00\u6b21\n        print('\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570')\n        print('order.status:', order.status, order.getstatusname())\n        if order.status in [order.Submitted, order.Accepted]:\n            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n            return\n\n        # Check if an order has been completed\uff0c\u6b64\u65f6order.getstatusname() = Completed\n        # Attention: broker could reject order if not enough cash\n        if order.status in [order.Completed]:\n            if order.isbuy():  # \u5982\u679c\u662f\u4e70\u5355\uff0c\u8f93\u51faBUY EXECUTED\u7684log\n                self.log(\n                    'BUY EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %\n                    (order.executed.price,\n                     order.executed.value,\n                     order.executed.comm))\n\n                self.buyprice = order.executed.price\n                self.buycomm = order.executed.comm\n            else:  # \u5982\u679c\u662f\u5356\u5355\uff0c\u8f93\u51faSELL EXECUTED\u7684log\n                self.log('SELL EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %\n                         (order.executed.price,\n                          order.executed.value,\n                          order.executed.comm))\n\n            self.bar_executed = len(self)\n\n        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n            self.log('Order Canceled/Margin/Rejected')\n\n        self.order = None\n\n    def notify_trade(self, trade):\n        print('\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570')\n        if not trade.isclosed:\n            return\n        \n        self.log('OPERATION PROFIT: GROSS %.2f, NET %.2f' %\n                 (trade.pnl, trade.pnlcomm))\n\n    def next(self):\n        # Simply log the closing price of the series from the reference\n        self.log('Close, %.2f' % self.dataclose[0])\n        print('self.order: ', self.order)\n        # Check if an order is pending ... if yes, we cannot send a 2nd one\n        if self.order:\n            return\n\n        # Check if we are in the market\n        if not self.position:\n\n            # Not yet ... we MIGHT BUY if ...\n            if self.dataclose[0] &lt; self.dataclose[-1]:\n                    # current close less than previous close\n\n                    if self.dataclose[-1] &lt; self.dataclose[-2]:\n                        # previous close less than the previous close\n\n                        # BUY, BUY, BUY!!! (with default parameters)\n                        self.log('BUY CREATE, %.2f' % self.dataclose[0])\n\n                        # Keep track of the created order to avoid a 2nd order\n                        self.order = self.buy()\n\n        else:\n\n            # Already in the market ... we might sell\n            if len(self) &gt;= (self.bar_executed + 5):\n                # SELL, SELL, SELL!!! (with all possible default parameters)\n                self.log('SELL CREATE, %.2f' % self.dataclose[0])\n\n                # Keep track of the created order to avoid a 2nd order\n                self.order = self.sell()\n\n    \nif __name__ == '__main__':\n   # Create a cerebro entity\n    cerebro = bt.Cerebro()\n    \n    # Add a strategy\n#     cerebro.addstrategy(TestStrategy)\n#     cerebro.addstrategy(MyStrategy)\n#     cerebro.addstrategy(TestStrategy1)\n#     cerebro.addstrategy(TestStrategy2)\n    cerebro.addstrategy(TestStrategy3)\n\n    data = bt.feeds.PandasData(dataname=df, datetime=-1)\n\n    # Add the Data Feed to Cerebro\n    # \u6bcf\u6b21\u4f20\u5165\u7684\u6570\u636e\u4fdd\u5b58\u5728Strategy\u7684data\u4e2d,\u4f7f\u7528self.datas\u8c03\u7528\u3002\n    # \u6211\u4eec\u53ea\u4f20\u5165\u4e86\u4e00\u6b21\u6570\u636e\uff0c\u5219self.datas\u53ea\u5305\u542b\u4e00\u4e2a\u5143\u7d20\uff0c\u8c03\u7528\u7684\u65f6\u5019\u4f7f\u7528self.datas[0]\n    cerebro.adddata(data)\n\n    # Set our desired cash start\n    cerebro.broker.setcash(100000.0)\n    \n    # \u8bbe\u7f6e\u4f63\u91d1\uff0c\u6211\u4eec\u8981\u5728\u6bcf\u6b21\u4e70\u5356\u64cd\u4f5c\u7684\u65f6\u5019\u7ed90.1%\u7684\u4f63\u91d1\u7387\n    # 0.1% ... divide by 100 to remove the %\n    cerebro.broker.setcommission(commission=0.001)\n\n    \n    # Print out the starting conditions\n    print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())\n\n    # Run over everything\n    cerebro.run()\n\n    # Print out the final result\n    print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue())\n#     cerebro.plot(style='bar')\n</pre> from __future__ import (absolute_import, division, print_function,                        unicode_literals)  import os.path  # To manage paths import sys  # To find out the script name (in argv[0])  # Import the backtrader platform import backtrader as bt  # Create a Strategy class TestStrategy(bt.Strategy):      def log(self, txt, dt=None):         ''' Logging function for this strategy'''         dt = self.datas[0].datetime.date()         print('%s, %s' % (dt.isoformat(), txt))      def __init__(self):         # Keep a reference to the \"close\" line in the data[0] dataseries         self.dataclose = self.datas[0].close          # \u5728\u56de\u6d4b\u8fc7\u7a0b\u4e2d\uff0cnext()\u65b9\u6cd5\u5c06\u5728\u6bcf\u4e2a\u6570\u636e\u70b9\u4e0a\u88ab\u8c03\u7528\u4e00\u6b21\uff0c\u4ee5\u4fbf\u7b56\u7565\u53ef\u4ee5\u8bc4\u4f30\u65b0\u6570\u636e\u5e76\u6267\u884c\u4ea4\u6613\u3002     def next(self):         # Simply log the closing price of the series from the reference         self.log('Close, %.2f' % self.dataclose[0])   class MyStrategy(bt.Strategy):     def __init__(self):         self.sma = bt.indicators.SimpleMovingAverage(self.data, period=15)      def next(self):         if self.data.close &gt; self.sma:             self.buy()             # \u6211\u4eec\u53ea\u4f20\u5165\u4e86\u4e00\u4e2a\u6570\u636e\u6e90df\uff0c\u56e0\u6b64self.datas\u53ea\u6709\u4e00\u4e2a\u5143\u7d20\u3002             print(f'type of self.datas is {type(self.datas)}')  # self.datas\u662f\u4e00\u4e2alist             print(f'type of self.datas[0] is {type(self.datas[0])}') # self.datas[0]\u662f\u4e00\u4e2abt.feeds             print(self.datas[0].datetime.datetime())             print(f'{self.datas[0].close[0]}, {self.datas[0].close[-1]}, {self.datas[0].close[-2]}, {self.sma[0]}')         elif self.data.close &lt; self.sma:             self.sell()              # Create a Strategy class TestStrategy1(bt.Strategy):      def log(self, txt, dt=None):         ''' Logging function fot this strategy'''         dt = self.datas[0].datetime.date(0)         print('%s, %s' % (dt.isoformat(), txt))      def __init__(self):         # Keep a reference to the \"close\" line in the data[0] dataseries         self.dataclose = self.datas[0].close      def next(self):         # Simply log the closing price of the series from the reference         self.log('Close, %.2f' % self.dataclose[0])          if self.dataclose[0] &lt; self.dataclose[-1]:             # current close less than previous close              if self.dataclose[-1] &lt; self.dataclose[-2]:                 # previous close less than the previous close                  # BUY, BUY, BUY!!! (with all possible default parameters)                 self.log(f'BUY CREATE, {self.dataclose[0]}')                 # \u8ba2\u5355\u662f\u5728\u201c\u5e02\u573a\u4e0a\u201d\u6267\u884c\u7684\uff0c\u4ee3\u7406(Cerebro\u5b9e\u4f8b)\u4f7f\u7528\u4e0b\u4e00\u4e2abar\u7684\u5f00\u76d8\u4ef7\u6267\u884c\u4e70\u64cd\u4f5c\uff0c                 # \u56e0\u4e3a\u5b83\u662f\u5f53\u524d\u68c0\u67e5bar\u4e4b\u540e\u7684\u7b2c\u4e00\u4e2atick\uff08\u6ee1\u8db3\u4e0b\u5355\u6761\u4ef6\u4e4b\u540e\u7684\u4e0b\u4e00\u4e2abar\u4e2d\u7684\u5f00\u76d8\u4ef7-\u5f3a\u8c03\u4e00\u4e0b\uff0c                 # \u8fd9\u91cc\u672a\u5fc5\u662f\u4e0b\u4e00\u4e2a\u5f00\u76d8\u65e5\uff0c\u56e0\u4e3abacktrader\u6ca1\u6709\u5047\u8bbe\u4f60\u7684\u6570\u636e\u91c7\u6837\u95f4\u9694\u662fD\uff09                 self.buy()                   class TestStrategy2(bt.Strategy):          # log\u51fd\u6570\u4e3b\u8981\u76ee\u7684\u5c31\u662f\u8f93\u51fa\u65f6\u95f4     def log(self, txt, dt=None):         ''' Logging function fot this strategy'''         dt = dt or self.datas[0].datetime.datetime(0)         print('%s, %s' % (dt.isoformat(), txt))      def __init__(self):         # Keep a reference to the \"close\" line in the data[0] dataseries         self.dataclose = self.datas[0].close          # To keep track of pending orders         self.order = None      def notify_order(self, order):         if order.status in [order.Submitted, order.Accepted]:             # Buy/Sell order submitted/accepted to/by broker - Nothing to do             return          # Check if an order has been completed         # Attention: broker could reject order if not enough cash         if order.status in [order.Completed]:             if order.isbuy():                 self.log('BUY EXECUTED, %.2f' % order.executed.price)             elif order.issell():                 self.log('SELL EXECUTED, %.2f' % order.executed.price)              self.bar_executed = len(self)          elif order.status in [order.Canceled, order.Margin, order.Rejected]:             self.log('Order Canceled/Margin/Rejected')          # Write down: no pending order         self.order = None      def next(self):         # Simply log the closing price of the series from the reference         self.log('Close, %.2f' % self.dataclose[0])          # Check if an order is pending ... if yes, we cannot send a 2nd one         if self.order:             return #         print(self.position)         # Check if we are in the market         if not self.position:              # Not yet ... we MIGHT BUY if ...             if self.dataclose[0] &lt; self.dataclose[-1]:                     # current close less than previous close                      if self.dataclose[-1] &lt; self.dataclose[-2]:                         # previous close less than the previous close                          # BUY, BUY, BUY!!! (with default parameters)                         self.log('BUY CREATE, %.2f' % self.dataclose[0])                          # Keep track of the created order to avoid a 2nd order                         self.order = self.buy()          else:              # Already in the market ... we might sell             if len(self) &gt;= (self.bar_executed + 5):                 print('lenself:', len(self))                 print('bar:', self.bar_executed)                 # SELL, SELL, SELL!!! (with all possible default parameters)                 self.log('SELL CREATE, %.2f' % self.dataclose[0])                  # Keep track of the created order to avoid a 2nd order                 self.order = self.sell(size=100)   # Create a Stratey class TestStrategy3(bt.Strategy):      def log(self, txt, dt=None):         ''' Logging function fot this strategy'''         dt = self.datas[0].datetime.datetime(0)         print('%s, %s' % (dt.isoformat(), txt))      def __init__(self):         # Keep a reference to the \"close\" line in the data[0] dataseries         self.dataclose = self.datas[0].close                      # \u6ce8\u610f\uff0c\u672c\u8eabbt.Strategy\u6ca1\u6709order\u5c5e\u6027\u3002\u8fd9\u91cc\u7684self.order\u662f\u6211\u4eec\u81ea\u5df1\u5b9a\u4e49\u7684         # To keep track of pending orders and buy price/commission         self.order = None         self.buyprice = None         self.buycomm = None      def notify_order(self, order):         # \u6ce8\u610f\u5230\u5728\u4f20\u5165\u6570\u636e\u7684\u6bcf\u4e00\u4e2atick\uff0cnotify_order\u53ef\u80fd\u4f1a\u88ab\u8c03\u7528\u591a\u6b21\uff0c\u5373\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u4e00\u6b21\uff0cnotify_order\u5c31\u4f1a\u88ab\u8c03\u7528\u4e00\u6b21         print('\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570')         print('order.status:', order.status, order.getstatusname())         if order.status in [order.Submitted, order.Accepted]:             # Buy/Sell order submitted/accepted to/by broker - Nothing to do             return          # Check if an order has been completed\uff0c\u6b64\u65f6order.getstatusname() = Completed         # Attention: broker could reject order if not enough cash         if order.status in [order.Completed]:             if order.isbuy():  # \u5982\u679c\u662f\u4e70\u5355\uff0c\u8f93\u51faBUY EXECUTED\u7684log                 self.log(                     'BUY EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %                     (order.executed.price,                      order.executed.value,                      order.executed.comm))                  self.buyprice = order.executed.price                 self.buycomm = order.executed.comm             else:  # \u5982\u679c\u662f\u5356\u5355\uff0c\u8f93\u51faSELL EXECUTED\u7684log                 self.log('SELL EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %                          (order.executed.price,                           order.executed.value,                           order.executed.comm))              self.bar_executed = len(self)          elif order.status in [order.Canceled, order.Margin, order.Rejected]:             self.log('Order Canceled/Margin/Rejected')          self.order = None      def notify_trade(self, trade):         print('\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570')         if not trade.isclosed:             return                  self.log('OPERATION PROFIT: GROSS %.2f, NET %.2f' %                  (trade.pnl, trade.pnlcomm))      def next(self):         # Simply log the closing price of the series from the reference         self.log('Close, %.2f' % self.dataclose[0])         print('self.order: ', self.order)         # Check if an order is pending ... if yes, we cannot send a 2nd one         if self.order:             return          # Check if we are in the market         if not self.position:              # Not yet ... we MIGHT BUY if ...             if self.dataclose[0] &lt; self.dataclose[-1]:                     # current close less than previous close                      if self.dataclose[-1] &lt; self.dataclose[-2]:                         # previous close less than the previous close                          # BUY, BUY, BUY!!! (with default parameters)                         self.log('BUY CREATE, %.2f' % self.dataclose[0])                          # Keep track of the created order to avoid a 2nd order                         self.order = self.buy()          else:              # Already in the market ... we might sell             if len(self) &gt;= (self.bar_executed + 5):                 # SELL, SELL, SELL!!! (with all possible default parameters)                 self.log('SELL CREATE, %.2f' % self.dataclose[0])                  # Keep track of the created order to avoid a 2nd order                 self.order = self.sell()       if __name__ == '__main__':    # Create a cerebro entity     cerebro = bt.Cerebro()          # Add a strategy #     cerebro.addstrategy(TestStrategy) #     cerebro.addstrategy(MyStrategy) #     cerebro.addstrategy(TestStrategy1) #     cerebro.addstrategy(TestStrategy2)     cerebro.addstrategy(TestStrategy3)      data = bt.feeds.PandasData(dataname=df, datetime=-1)      # Add the Data Feed to Cerebro     # \u6bcf\u6b21\u4f20\u5165\u7684\u6570\u636e\u4fdd\u5b58\u5728Strategy\u7684data\u4e2d,\u4f7f\u7528self.datas\u8c03\u7528\u3002     # \u6211\u4eec\u53ea\u4f20\u5165\u4e86\u4e00\u6b21\u6570\u636e\uff0c\u5219self.datas\u53ea\u5305\u542b\u4e00\u4e2a\u5143\u7d20\uff0c\u8c03\u7528\u7684\u65f6\u5019\u4f7f\u7528self.datas[0]     cerebro.adddata(data)      # Set our desired cash start     cerebro.broker.setcash(100000.0)          # \u8bbe\u7f6e\u4f63\u91d1\uff0c\u6211\u4eec\u8981\u5728\u6bcf\u6b21\u4e70\u5356\u64cd\u4f5c\u7684\u65f6\u5019\u7ed90.1%\u7684\u4f63\u91d1\u7387     # 0.1% ... divide by 100 to remove the %     cerebro.broker.setcommission(commission=0.001)           # Print out the starting conditions     print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())      # Run over everything     cerebro.run()      # Print out the final result     print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue()) #     cerebro.plot(style='bar')  <pre>Starting Portfolio Value: 100000.00\n2023-10-24T13:53:00, Close, 10.58\nself.order:  None\n2023-10-24T13:54:00, Close, 10.60\nself.order:  None\n2023-10-24T13:55:00, Close, 10.59\nself.order:  None\n2023-10-24T13:56:00, Close, 10.61\nself.order:  None\n2023-10-24T13:57:00, Close, 10.59\nself.order:  None\n2023-10-24T13:58:00, Close, 10.57\nself.order:  None\n2023-10-24T13:58:00, BUY CREATE, 10.57\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-24T13:59:00, BUY EXECUTED, Price: 10.57, Cost: 10.57, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-24T13:59:00, Close, 10.56\nself.order:  None\n2023-10-24T14:00:00, Close, 10.57\nself.order:  None\n2023-10-24T14:01:00, Close, 10.58\nself.order:  None\n2023-10-24T14:02:00, Close, 10.59\nself.order:  None\n2023-10-24T14:03:00, Close, 10.61\nself.order:  None\n2023-10-24T14:04:00, Close, 10.60\nself.order:  None\n2023-10-24T14:04:00, SELL CREATE, 10.60\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-24T14:05:00, SELL EXECUTED, Price: 10.61, Cost: 10.57, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-24T14:05:00, OPERATION PROFIT: GROSS 0.04, NET 0.02\n2023-10-24T14:05:00, Close, 10.61\nself.order:  None\n2023-10-24T14:06:00, Close, 10.59\nself.order:  None\n2023-10-24T14:07:00, Close, 10.60\nself.order:  None\n2023-10-24T14:08:00, Close, 10.61\nself.order:  None\n2023-10-24T14:09:00, Close, 10.60\nself.order:  None\n2023-10-24T14:10:00, Close, 10.59\nself.order:  None\n2023-10-24T14:10:00, BUY CREATE, 10.59\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-24T14:11:00, BUY EXECUTED, Price: 10.59, Cost: 10.59, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-24T14:11:00, Close, 10.59\nself.order:  None\n2023-10-24T14:12:00, Close, 10.60\nself.order:  None\n2023-10-24T14:13:00, Close, 10.60\nself.order:  None\n2023-10-24T14:14:00, Close, 10.60\nself.order:  None\n2023-10-24T14:15:00, Close, 10.61\nself.order:  None\n2023-10-24T14:16:00, Close, 10.59\nself.order:  None\n2023-10-24T14:16:00, SELL CREATE, 10.59\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-24T14:17:00, SELL EXECUTED, Price: 10.59, Cost: 10.59, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-24T14:17:00, OPERATION PROFIT: GROSS 0.00, NET -0.02\n2023-10-24T14:17:00, Close, 10.59\nself.order:  None\n2023-10-24T14:18:00, Close, 10.59\nself.order:  None\n2023-10-24T14:19:00, Close, 10.58\nself.order:  None\n2023-10-24T14:20:00, Close, 10.58\nself.order:  None\n2023-10-24T14:21:00, Close, 10.58\nself.order:  None\n2023-10-24T14:22:00, Close, 10.59\nself.order:  None\n2023-10-24T14:23:00, Close, 10.59\nself.order:  None\n2023-10-24T14:24:00, Close, 10.58\nself.order:  None\n2023-10-24T14:25:00, Close, 10.59\nself.order:  None\n2023-10-24T14:26:00, Close, 10.59\nself.order:  None\n2023-10-24T14:27:00, Close, 10.58\nself.order:  None\n2023-10-24T14:28:00, Close, 10.57\nself.order:  None\n2023-10-24T14:28:00, BUY CREATE, 10.57\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-24T14:29:00, BUY EXECUTED, Price: 10.57, Cost: 10.57, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-24T14:29:00, Close, 10.57\nself.order:  None\n2023-10-24T14:30:00, Close, 10.58\nself.order:  None\n2023-10-24T14:31:00, Close, 10.57\nself.order:  None\n2023-10-24T14:32:00, Close, 10.57\nself.order:  None\n2023-10-24T14:33:00, Close, 10.57\nself.order:  None\n2023-10-24T14:34:00, Close, 10.56\nself.order:  None\n2023-10-24T14:34:00, SELL CREATE, 10.56\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-24T14:35:00, SELL EXECUTED, Price: 10.56, Cost: 10.57, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-24T14:35:00, OPERATION PROFIT: GROSS -0.01, NET -0.03\n2023-10-24T14:35:00, Close, 10.56\nself.order:  None\n2023-10-24T14:36:00, Close, 10.56\nself.order:  None\n2023-10-24T14:37:00, Close, 10.56\nself.order:  None\n2023-10-24T14:38:00, Close, 10.56\nself.order:  None\n2023-10-24T14:39:00, Close, 10.56\nself.order:  None\n2023-10-24T14:40:00, Close, 10.57\nself.order:  None\n2023-10-24T14:41:00, Close, 10.56\nself.order:  None\n2023-10-24T14:42:00, Close, 10.54\nself.order:  None\n2023-10-24T14:42:00, BUY CREATE, 10.54\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-24T14:43:00, BUY EXECUTED, Price: 10.53, Cost: 10.53, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-24T14:43:00, Close, 10.54\nself.order:  None\n2023-10-24T14:44:00, Close, 10.53\nself.order:  None\n2023-10-24T14:45:00, Close, 10.54\nself.order:  None\n2023-10-24T14:46:00, Close, 10.53\nself.order:  None\n2023-10-24T14:47:00, Close, 10.54\nself.order:  None\n2023-10-24T14:48:00, Close, 10.54\nself.order:  None\n2023-10-24T14:48:00, SELL CREATE, 10.54\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-24T14:49:00, SELL EXECUTED, Price: 10.55, Cost: 10.53, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-24T14:49:00, OPERATION PROFIT: GROSS 0.02, NET -0.00\n2023-10-24T14:49:00, Close, 10.55\nself.order:  None\n2023-10-24T14:50:00, Close, 10.55\nself.order:  None\n2023-10-24T14:51:00, Close, 10.55\nself.order:  None\n2023-10-24T14:52:00, Close, 10.55\nself.order:  None\n2023-10-24T14:53:00, Close, 10.55\nself.order:  None\n2023-10-24T14:54:00, Close, 10.53\nself.order:  None\n2023-10-24T14:55:00, Close, 10.55\nself.order:  None\n2023-10-24T14:56:00, Close, 10.55\nself.order:  None\n2023-10-24T14:57:00, Close, 10.56\nself.order:  None\n2023-10-24T15:00:00, Close, 10.55\nself.order:  None\n2023-10-25T09:31:00, Close, 10.51\nself.order:  None\n2023-10-25T09:31:00, BUY CREATE, 10.51\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-25T09:32:00, BUY EXECUTED, Price: 10.50, Cost: 10.50, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-25T09:32:00, Close, 10.45\nself.order:  None\n2023-10-25T09:33:00, Close, 10.46\nself.order:  None\n2023-10-25T09:34:00, Close, 10.46\nself.order:  None\n2023-10-25T09:35:00, Close, 10.47\nself.order:  None\n2023-10-25T09:36:00, Close, 10.47\nself.order:  None\n2023-10-25T09:37:00, Close, 10.47\nself.order:  None\n2023-10-25T09:37:00, SELL CREATE, 10.47\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-25T09:38:00, SELL EXECUTED, Price: 10.47, Cost: 10.50, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-25T09:38:00, OPERATION PROFIT: GROSS -0.03, NET -0.05\n2023-10-25T09:38:00, Close, 10.48\nself.order:  None\n2023-10-25T09:39:00, Close, 10.49\nself.order:  None\n2023-10-25T09:40:00, Close, 10.49\nself.order:  None\n2023-10-25T09:41:00, Close, 10.47\nself.order:  None\n2023-10-25T09:42:00, Close, 10.46\nself.order:  None\n2023-10-25T09:42:00, BUY CREATE, 10.46\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-25T09:43:00, BUY EXECUTED, Price: 10.47, Cost: 10.47, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-25T09:43:00, Close, 10.46\nself.order:  None\n2023-10-25T09:44:00, Close, 10.47\nself.order:  None\n2023-10-25T09:45:00, Close, 10.46\nself.order:  None\n2023-10-25T09:46:00, Close, 10.45\nself.order:  None\n2023-10-25T09:47:00, Close, 10.42\nself.order:  None\n2023-10-25T09:48:00, Close, 10.44\nself.order:  None\n2023-10-25T09:48:00, SELL CREATE, 10.44\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-25T09:49:00, SELL EXECUTED, Price: 10.43, Cost: 10.47, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-25T09:49:00, OPERATION PROFIT: GROSS -0.04, NET -0.06\n2023-10-25T09:49:00, Close, 10.45\nself.order:  None\n2023-10-25T09:50:00, Close, 10.45\nself.order:  None\n2023-10-25T09:51:00, Close, 10.45\nself.order:  None\n2023-10-25T09:52:00, Close, 10.45\nself.order:  None\n2023-10-25T09:53:00, Close, 10.43\nself.order:  None\n2023-10-25T09:54:00, Close, 10.43\nself.order:  None\n2023-10-25T09:55:00, Close, 10.44\nself.order:  None\n2023-10-25T09:56:00, Close, 10.45\nself.order:  None\n2023-10-25T09:57:00, Close, 10.46\nself.order:  None\n2023-10-25T09:58:00, Close, 10.45\nself.order:  None\n2023-10-25T09:59:00, Close, 10.45\nself.order:  None\n2023-10-25T10:00:00, Close, 10.45\nself.order:  None\n2023-10-25T10:01:00, Close, 10.45\nself.order:  None\n2023-10-25T10:02:00, Close, 10.46\nself.order:  None\n2023-10-25T10:03:00, Close, 10.45\nself.order:  None\n2023-10-25T10:04:00, Close, 10.45\nself.order:  None\n2023-10-25T10:05:00, Close, 10.45\nself.order:  None\n2023-10-25T10:06:00, Close, 10.45\nself.order:  None\n2023-10-25T10:07:00, Close, 10.45\nself.order:  None\n2023-10-25T10:08:00, Close, 10.43\nself.order:  None\n2023-10-25T10:09:00, Close, 10.43\nself.order:  None\n2023-10-25T10:10:00, Close, 10.43\nself.order:  None\n2023-10-25T10:11:00, Close, 10.43\nself.order:  None\n2023-10-25T10:12:00, Close, 10.43\nself.order:  None\n2023-10-25T10:13:00, Close, 10.43\nself.order:  None\n2023-10-25T10:14:00, Close, 10.42\nself.order:  None\n2023-10-25T10:15:00, Close, 10.42\nself.order:  None\n2023-10-25T10:16:00, Close, 10.41\nself.order:  None\n2023-10-25T10:17:00, Close, 10.40\nself.order:  None\n2023-10-25T10:17:00, BUY CREATE, 10.40\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-25T10:18:00, BUY EXECUTED, Price: 10.40, Cost: 10.40, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-25T10:18:00, Close, 10.39\nself.order:  None\n2023-10-25T10:19:00, Close, 10.39\nself.order:  None\n2023-10-25T10:20:00, Close, 10.39\nself.order:  None\n2023-10-25T10:21:00, Close, 10.39\nself.order:  None\n2023-10-25T10:22:00, Close, 10.40\nself.order:  None\n2023-10-25T10:23:00, Close, 10.41\nself.order:  None\n2023-10-25T10:23:00, SELL CREATE, 10.41\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-25T10:24:00, SELL EXECUTED, Price: 10.41, Cost: 10.40, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-25T10:24:00, OPERATION PROFIT: GROSS 0.01, NET -0.01\n2023-10-25T10:24:00, Close, 10.41\nself.order:  None\n2023-10-25T10:25:00, Close, 10.41\nself.order:  None\n2023-10-25T10:26:00, Close, 10.41\nself.order:  None\n2023-10-25T10:27:00, Close, 10.41\nself.order:  None\n2023-10-25T10:28:00, Close, 10.42\nself.order:  None\n2023-10-25T10:29:00, Close, 10.42\nself.order:  None\n2023-10-25T10:30:00, Close, 10.42\nself.order:  None\n2023-10-25T10:31:00, Close, 10.41\nself.order:  None\n2023-10-25T10:32:00, Close, 10.41\nself.order:  None\n2023-10-25T10:33:00, Close, 10.41\nself.order:  None\n2023-10-25T10:34:00, Close, 10.41\nself.order:  None\n2023-10-25T10:35:00, Close, 10.40\nself.order:  None\n2023-10-25T10:36:00, Close, 10.40\nself.order:  None\n2023-10-25T10:37:00, Close, 10.39\nself.order:  None\n2023-10-25T10:38:00, Close, 10.40\nself.order:  None\n2023-10-25T10:39:00, Close, 10.40\nself.order:  None\n2023-10-25T10:40:00, Close, 10.40\nself.order:  None\n2023-10-25T10:41:00, Close, 10.40\nself.order:  None\n2023-10-25T10:42:00, Close, 10.39\nself.order:  None\n2023-10-25T10:43:00, Close, 10.40\nself.order:  None\n2023-10-25T10:44:00, Close, 10.39\nself.order:  None\n2023-10-25T10:45:00, Close, 10.38\nself.order:  None\n2023-10-25T10:45:00, BUY CREATE, 10.38\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-25T10:46:00, BUY EXECUTED, Price: 10.39, Cost: 10.39, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-25T10:46:00, Close, 10.39\nself.order:  None\n2023-10-25T10:47:00, Close, 10.39\nself.order:  None\n2023-10-25T10:48:00, Close, 10.38\nself.order:  None\n2023-10-25T10:49:00, Close, 10.39\nself.order:  None\n2023-10-25T10:50:00, Close, 10.40\nself.order:  None\n2023-10-25T10:51:00, Close, 10.40\nself.order:  None\n2023-10-25T10:51:00, SELL CREATE, 10.40\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-25T10:52:00, SELL EXECUTED, Price: 10.41, Cost: 10.39, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-25T10:52:00, OPERATION PROFIT: GROSS 0.02, NET -0.00\n2023-10-25T10:52:00, Close, 10.39\nself.order:  None\n2023-10-25T10:53:00, Close, 10.40\nself.order:  None\n2023-10-25T10:54:00, Close, 10.40\nself.order:  None\n2023-10-25T10:55:00, Close, 10.41\nself.order:  None\n2023-10-25T10:56:00, Close, 10.40\nself.order:  None\n2023-10-25T10:57:00, Close, 10.40\nself.order:  None\n2023-10-25T10:58:00, Close, 10.40\nself.order:  None\n2023-10-25T10:59:00, Close, 10.40\nself.order:  None\n2023-10-25T11:00:00, Close, 10.40\nself.order:  None\n2023-10-25T11:01:00, Close, 10.40\nself.order:  None\n2023-10-25T11:02:00, Close, 10.42\nself.order:  None\n2023-10-25T11:03:00, Close, 10.40\nself.order:  None\n2023-10-25T11:04:00, Close, 10.41\nself.order:  None\n2023-10-25T11:05:00, Close, 10.42\nself.order:  None\n2023-10-25T11:06:00, Close, 10.42\nself.order:  None\n2023-10-25T11:07:00, Close, 10.42\nself.order:  None\n2023-10-25T11:08:00, Close, 10.41\nself.order:  None\n2023-10-25T11:09:00, Close, 10.41\nself.order:  None\n2023-10-25T11:10:00, Close, 10.42\nself.order:  None\n2023-10-25T11:11:00, Close, 10.41\nself.order:  None\n2023-10-25T11:12:00, Close, 10.39\nself.order:  None\n2023-10-25T11:12:00, BUY CREATE, 10.39\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-25T11:13:00, BUY EXECUTED, Price: 10.40, Cost: 10.40, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-25T11:13:00, Close, 10.39\nself.order:  None\n2023-10-25T11:14:00, Close, 10.39\nself.order:  None\n2023-10-25T11:15:00, Close, 10.39\nself.order:  None\n2023-10-25T11:16:00, Close, 10.38\nself.order:  None\n2023-10-25T11:17:00, Close, 10.38\nself.order:  None\n2023-10-25T11:18:00, Close, 10.39\nself.order:  None\n2023-10-25T11:18:00, SELL CREATE, 10.39\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-25T11:19:00, SELL EXECUTED, Price: 10.39, Cost: 10.40, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-25T11:19:00, OPERATION PROFIT: GROSS -0.01, NET -0.03\n2023-10-25T11:19:00, Close, 10.38\nself.order:  None\n2023-10-25T11:20:00, Close, 10.37\nself.order:  None\n2023-10-25T11:20:00, BUY CREATE, 10.37\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-25T11:21:00, BUY EXECUTED, Price: 10.37, Cost: 10.37, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-25T11:21:00, Close, 10.38\nself.order:  None\n2023-10-25T11:22:00, Close, 10.38\nself.order:  None\n2023-10-25T11:23:00, Close, 10.38\nself.order:  None\n2023-10-25T11:24:00, Close, 10.38\nself.order:  None\n2023-10-25T11:25:00, Close, 10.38\nself.order:  None\n2023-10-25T11:26:00, Close, 10.38\nself.order:  None\n2023-10-25T11:26:00, SELL CREATE, 10.38\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-25T11:27:00, SELL EXECUTED, Price: 10.37, Cost: 10.37, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-25T11:27:00, OPERATION PROFIT: GROSS 0.00, NET -0.02\n2023-10-25T11:27:00, Close, 10.37\nself.order:  None\n2023-10-25T11:28:00, Close, 10.38\nself.order:  None\n2023-10-25T11:29:00, Close, 10.38\nself.order:  None\n2023-10-25T11:30:00, Close, 10.37\nself.order:  None\n2023-10-25T13:01:00, Close, 10.38\nself.order:  None\n2023-10-25T13:02:00, Close, 10.39\nself.order:  None\n2023-10-25T13:03:00, Close, 10.39\nself.order:  None\n2023-10-25T13:04:00, Close, 10.39\nself.order:  None\n2023-10-25T13:05:00, Close, 10.38\nself.order:  None\n2023-10-25T13:06:00, Close, 10.38\nself.order:  None\n2023-10-25T13:07:00, Close, 10.38\nself.order:  None\n2023-10-25T13:08:00, Close, 10.37\nself.order:  None\n2023-10-25T13:09:00, Close, 10.38\nself.order:  None\n2023-10-25T13:10:00, Close, 10.38\nself.order:  None\n2023-10-25T13:11:00, Close, 10.39\nself.order:  None\n2023-10-25T13:12:00, Close, 10.38\nself.order:  None\n2023-10-25T13:13:00, Close, 10.39\nself.order:  None\n2023-10-25T13:14:00, Close, 10.39\nself.order:  None\n2023-10-25T13:15:00, Close, 10.40\nself.order:  None\n2023-10-25T13:16:00, Close, 10.40\nself.order:  None\n2023-10-25T13:17:00, Close, 10.40\nself.order:  None\n2023-10-25T13:18:00, Close, 10.39\nself.order:  None\n2023-10-25T13:19:00, Close, 10.38\nself.order:  None\n2023-10-25T13:19:00, BUY CREATE, 10.38\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-25T13:20:00, BUY EXECUTED, Price: 10.39, Cost: 10.39, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-25T13:20:00, Close, 10.39\nself.order:  None\n2023-10-25T13:21:00, Close, 10.38\nself.order:  None\n2023-10-25T13:22:00, Close, 10.38\nself.order:  None\n2023-10-25T13:23:00, Close, 10.39\nself.order:  None\n2023-10-25T13:24:00, Close, 10.38\nself.order:  None\n2023-10-25T13:25:00, Close, 10.38\nself.order:  None\n2023-10-25T13:25:00, SELL CREATE, 10.38\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-25T13:26:00, SELL EXECUTED, Price: 10.39, Cost: 10.39, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-25T13:26:00, OPERATION PROFIT: GROSS 0.00, NET -0.02\n2023-10-25T13:26:00, Close, 10.40\nself.order:  None\n2023-10-25T13:27:00, Close, 10.39\nself.order:  None\n2023-10-25T13:28:00, Close, 10.39\nself.order:  None\n2023-10-25T13:29:00, Close, 10.39\nself.order:  None\n2023-10-25T13:30:00, Close, 10.39\nself.order:  None\n2023-10-25T13:31:00, Close, 10.40\nself.order:  None\n2023-10-25T13:32:00, Close, 10.39\nself.order:  None\n2023-10-25T13:33:00, Close, 10.39\nself.order:  None\n2023-10-25T13:34:00, Close, 10.39\nself.order:  None\n2023-10-25T13:35:00, Close, 10.39\nself.order:  None\n2023-10-25T13:36:00, Close, 10.39\nself.order:  None\n2023-10-25T13:37:00, Close, 10.39\nself.order:  None\n2023-10-25T13:38:00, Close, 10.39\nself.order:  None\n2023-10-25T13:39:00, Close, 10.39\nself.order:  None\n2023-10-25T13:40:00, Close, 10.39\nself.order:  None\n2023-10-25T13:41:00, Close, 10.39\nself.order:  None\n2023-10-25T13:42:00, Close, 10.39\nself.order:  None\n2023-10-25T13:43:00, Close, 10.38\nself.order:  None\n2023-10-25T13:44:00, Close, 10.40\nself.order:  None\n2023-10-25T13:45:00, Close, 10.39\nself.order:  None\n2023-10-25T13:46:00, Close, 10.40\nself.order:  None\n2023-10-25T13:47:00, Close, 10.40\nself.order:  None\n2023-10-25T13:48:00, Close, 10.41\nself.order:  None\n2023-10-25T13:49:00, Close, 10.41\nself.order:  None\n2023-10-25T13:50:00, Close, 10.40\nself.order:  None\n2023-10-25T13:51:00, Close, 10.41\nself.order:  None\n2023-10-25T13:52:00, Close, 10.41\nself.order:  None\n2023-10-25T13:53:00, Close, 10.40\nself.order:  None\n2023-10-25T13:54:00, Close, 10.40\nself.order:  None\n2023-10-25T13:55:00, Close, 10.40\nself.order:  None\n2023-10-25T13:56:00, Close, 10.40\nself.order:  None\n2023-10-25T13:57:00, Close, 10.40\nself.order:  None\n2023-10-25T13:58:00, Close, 10.40\nself.order:  None\n2023-10-25T13:59:00, Close, 10.40\nself.order:  None\n2023-10-25T14:00:00, Close, 10.40\nself.order:  None\n2023-10-25T14:01:00, Close, 10.41\nself.order:  None\n2023-10-25T14:02:00, Close, 10.41\nself.order:  None\n2023-10-25T14:03:00, Close, 10.41\nself.order:  None\n2023-10-25T14:04:00, Close, 10.41\nself.order:  None\n2023-10-25T14:05:00, Close, 10.41\nself.order:  None\n2023-10-25T14:06:00, Close, 10.41\nself.order:  None\n2023-10-25T14:07:00, Close, 10.41\nself.order:  None\n2023-10-25T14:08:00, Close, 10.41\nself.order:  None\n2023-10-25T14:09:00, Close, 10.40\nself.order:  None\n2023-10-25T14:10:00, Close, 10.41\nself.order:  None\n2023-10-25T14:11:00, Close, 10.41\nself.order:  None\n2023-10-25T14:12:00, Close, 10.41\nself.order:  None\n2023-10-25T14:13:00, Close, 10.40\nself.order:  None\n2023-10-25T14:14:00, Close, 10.40\nself.order:  None\n2023-10-25T14:15:00, Close, 10.40\nself.order:  None\n2023-10-25T14:16:00, Close, 10.39\nself.order:  None\n2023-10-25T14:17:00, Close, 10.40\nself.order:  None\n2023-10-25T14:18:00, Close, 10.39\nself.order:  None\n2023-10-25T14:19:00, Close, 10.39\nself.order:  None\n2023-10-25T14:20:00, Close, 10.40\nself.order:  None\n2023-10-25T14:21:00, Close, 10.40\nself.order:  None\n2023-10-25T14:22:00, Close, 10.39\nself.order:  None\n2023-10-25T14:23:00, Close, 10.39\nself.order:  None\n2023-10-25T14:24:00, Close, 10.39\nself.order:  None\n2023-10-25T14:25:00, Close, 10.39\nself.order:  None\n2023-10-25T14:26:00, Close, 10.40\nself.order:  None\n2023-10-25T14:27:00, Close, 10.40\nself.order:  None\n2023-10-25T14:28:00, Close, 10.39\nself.order:  None\n2023-10-25T14:29:00, Close, 10.39\nself.order:  None\n2023-10-25T14:30:00, Close, 10.39\nself.order:  None\n2023-10-25T14:31:00, Close, 10.39\nself.order:  None\n2023-10-25T14:32:00, Close, 10.38\nself.order:  None\n2023-10-25T14:33:00, Close, 10.38\nself.order:  None\n2023-10-25T14:34:00, Close, 10.38\nself.order:  None\n2023-10-25T14:35:00, Close, 10.38\nself.order:  None\n2023-10-25T14:36:00, Close, 10.39\nself.order:  None\n2023-10-25T14:37:00, Close, 10.39\nself.order:  None\n2023-10-25T14:38:00, Close, 10.39\nself.order:  None\n2023-10-25T14:39:00, Close, 10.38\nself.order:  None\n2023-10-25T14:40:00, Close, 10.38\nself.order:  None\n2023-10-25T14:41:00, Close, 10.39\nself.order:  None\n2023-10-25T14:42:00, Close, 10.38\nself.order:  None\n2023-10-25T14:43:00, Close, 10.38\nself.order:  None\n2023-10-25T14:44:00, Close, 10.38\nself.order:  None\n2023-10-25T14:45:00, Close, 10.37\nself.order:  None\n2023-10-25T14:46:00, Close, 10.37\nself.order:  None\n2023-10-25T14:47:00, Close, 10.37\nself.order:  None\n2023-10-25T14:48:00, Close, 10.37\nself.order:  None\n2023-10-25T14:49:00, Close, 10.37\nself.order:  None\n2023-10-25T14:50:00, Close, 10.36\nself.order:  None\n2023-10-25T14:51:00, Close, 10.37\nself.order:  None\n2023-10-25T14:52:00, Close, 10.37\nself.order:  None\n2023-10-25T14:53:00, Close, 10.38\nself.order:  None\n2023-10-25T14:54:00, Close, 10.38\nself.order:  None\n2023-10-25T14:55:00, Close, 10.37\nself.order:  None\n2023-10-25T14:56:00, Close, 10.37\nself.order:  None\n2023-10-25T14:57:00, Close, 10.38\nself.order:  None\n2023-10-25T15:00:00, Close, 10.38\nself.order:  None\n2023-10-26T09:31:00, Close, 10.36\nself.order:  None\n2023-10-26T09:32:00, Close, 10.35\nself.order:  None\n2023-10-26T09:32:00, BUY CREATE, 10.35\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-26T09:33:00, BUY EXECUTED, Price: 10.35, Cost: 10.35, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-26T09:33:00, Close, 10.35\nself.order:  None\n2023-10-26T09:34:00, Close, 10.36\nself.order:  None\n2023-10-26T09:35:00, Close, 10.37\nself.order:  None\n2023-10-26T09:36:00, Close, 10.37\nself.order:  None\n2023-10-26T09:37:00, Close, 10.37\nself.order:  None\n2023-10-26T09:38:00, Close, 10.36\nself.order:  None\n2023-10-26T09:38:00, SELL CREATE, 10.36\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-26T09:39:00, SELL EXECUTED, Price: 10.37, Cost: 10.35, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-26T09:39:00, OPERATION PROFIT: GROSS 0.02, NET -0.00\n2023-10-26T09:39:00, Close, 10.37\nself.order:  None\n2023-10-26T09:40:00, Close, 10.38\nself.order:  None\n2023-10-26T09:41:00, Close, 10.38\nself.order:  None\n2023-10-26T09:42:00, Close, 10.39\nself.order:  None\n2023-10-26T09:43:00, Close, 10.38\nself.order:  None\n2023-10-26T09:44:00, Close, 10.38\nself.order:  None\n2023-10-26T09:45:00, Close, 10.37\nself.order:  None\n2023-10-26T09:46:00, Close, 10.38\nself.order:  None\n2023-10-26T09:47:00, Close, 10.36\nself.order:  None\n2023-10-26T09:48:00, Close, 10.36\nself.order:  None\n2023-10-26T09:49:00, Close, 10.37\nself.order:  None\n2023-10-26T09:50:00, Close, 10.37\nself.order:  None\n2023-10-26T09:51:00, Close, 10.36\nself.order:  None\n2023-10-26T09:52:00, Close, 10.36\nself.order:  None\n2023-10-26T09:53:00, Close, 10.35\nself.order:  None\n2023-10-26T09:54:00, Close, 10.34\nself.order:  None\n2023-10-26T09:54:00, BUY CREATE, 10.34\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-26T09:55:00, BUY EXECUTED, Price: 10.34, Cost: 10.34, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-26T09:55:00, Close, 10.34\nself.order:  None\n2023-10-26T09:56:00, Close, 10.36\nself.order:  None\n2023-10-26T09:57:00, Close, 10.34\nself.order:  None\n2023-10-26T09:58:00, Close, 10.35\nself.order:  None\n2023-10-26T09:59:00, Close, 10.35\nself.order:  None\n2023-10-26T10:00:00, Close, 10.36\nself.order:  None\n2023-10-26T10:00:00, SELL CREATE, 10.36\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-26T10:01:00, SELL EXECUTED, Price: 10.35, Cost: 10.34, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-26T10:01:00, OPERATION PROFIT: GROSS 0.01, NET -0.01\n2023-10-26T10:01:00, Close, 10.37\nself.order:  None\n2023-10-26T10:02:00, Close, 10.36\nself.order:  None\n2023-10-26T10:03:00, Close, 10.35\nself.order:  None\n2023-10-26T10:03:00, BUY CREATE, 10.35\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-26T10:04:00, BUY EXECUTED, Price: 10.35, Cost: 10.35, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-26T10:04:00, Close, 10.34\nself.order:  None\n2023-10-26T10:05:00, Close, 10.34\nself.order:  None\n2023-10-26T10:06:00, Close, 10.34\nself.order:  None\n2023-10-26T10:07:00, Close, 10.34\nself.order:  None\n2023-10-26T10:08:00, Close, 10.35\nself.order:  None\n2023-10-26T10:09:00, Close, 10.35\nself.order:  None\n2023-10-26T10:09:00, SELL CREATE, 10.35\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-26T10:10:00, SELL EXECUTED, Price: 10.34, Cost: 10.35, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-26T10:10:00, OPERATION PROFIT: GROSS -0.01, NET -0.03\n2023-10-26T10:10:00, Close, 10.34\nself.order:  None\n2023-10-26T10:11:00, Close, 10.35\nself.order:  None\n2023-10-26T10:12:00, Close, 10.34\nself.order:  None\n2023-10-26T10:13:00, Close, 10.35\nself.order:  None\n2023-10-26T10:14:00, Close, 10.35\nself.order:  None\n2023-10-26T10:15:00, Close, 10.35\nself.order:  None\n2023-10-26T10:16:00, Close, 10.34\nself.order:  None\n2023-10-26T10:17:00, Close, 10.34\nself.order:  None\n2023-10-26T10:18:00, Close, 10.35\nself.order:  None\n2023-10-26T10:19:00, Close, 10.35\nself.order:  None\n2023-10-26T10:20:00, Close, 10.34\nself.order:  None\n2023-10-26T10:21:00, Close, 10.33\nself.order:  None\n2023-10-26T10:21:00, BUY CREATE, 10.33\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-26T10:22:00, BUY EXECUTED, Price: 10.33, Cost: 10.33, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-26T10:22:00, Close, 10.33\nself.order:  None\n2023-10-26T10:23:00, Close, 10.33\nself.order:  None\n2023-10-26T10:24:00, Close, 10.34\nself.order:  None\n2023-10-26T10:25:00, Close, 10.34\nself.order:  None\n2023-10-26T10:26:00, Close, 10.33\nself.order:  None\n2023-10-26T10:27:00, Close, 10.34\nself.order:  None\n2023-10-26T10:27:00, SELL CREATE, 10.34\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-26T10:28:00, SELL EXECUTED, Price: 10.34, Cost: 10.33, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-26T10:28:00, OPERATION PROFIT: GROSS 0.01, NET -0.01\n2023-10-26T10:28:00, Close, 10.33\nself.order:  None\n2023-10-26T10:29:00, Close, 10.33\nself.order:  None\n2023-10-26T10:30:00, Close, 10.32\nself.order:  None\n2023-10-26T10:31:00, Close, 10.33\nself.order:  None\n2023-10-26T10:32:00, Close, 10.33\nself.order:  None\n2023-10-26T10:33:00, Close, 10.33\nself.order:  None\n2023-10-26T10:34:00, Close, 10.32\nself.order:  None\n2023-10-26T10:35:00, Close, 10.34\nself.order:  None\n2023-10-26T10:36:00, Close, 10.33\nself.order:  None\n2023-10-26T10:37:00, Close, 10.34\nself.order:  None\n2023-10-26T10:38:00, Close, 10.34\nself.order:  None\n2023-10-26T10:39:00, Close, 10.34\nself.order:  None\n2023-10-26T10:40:00, Close, 10.33\nself.order:  None\n2023-10-26T10:41:00, Close, 10.34\nself.order:  None\n2023-10-26T10:42:00, Close, 10.33\nself.order:  None\n2023-10-26T10:43:00, Close, 10.33\nself.order:  None\n2023-10-26T10:44:00, Close, 10.34\nself.order:  None\n2023-10-26T10:45:00, Close, 10.33\nself.order:  None\n2023-10-26T10:46:00, Close, 10.34\nself.order:  None\n2023-10-26T10:47:00, Close, 10.34\nself.order:  None\n2023-10-26T10:48:00, Close, 10.33\nself.order:  None\n2023-10-26T10:49:00, Close, 10.33\nself.order:  None\n2023-10-26T10:50:00, Close, 10.33\nself.order:  None\n2023-10-26T10:51:00, Close, 10.34\nself.order:  None\n2023-10-26T10:52:00, Close, 10.34\nself.order:  None\n2023-10-26T10:53:00, Close, 10.34\nself.order:  None\n2023-10-26T10:54:00, Close, 10.35\nself.order:  None\n2023-10-26T10:55:00, Close, 10.34\nself.order:  None\n2023-10-26T10:56:00, Close, 10.34\nself.order:  None\n2023-10-26T10:57:00, Close, 10.34\nself.order:  None\n2023-10-26T10:58:00, Close, 10.33\nself.order:  None\n2023-10-26T10:59:00, Close, 10.34\nself.order:  None\n2023-10-26T11:00:00, Close, 10.33\nself.order:  None\n2023-10-26T11:01:00, Close, 10.34\nself.order:  None\n2023-10-26T11:02:00, Close, 10.33\nself.order:  None\n2023-10-26T11:03:00, Close, 10.33\nself.order:  None\n2023-10-26T11:04:00, Close, 10.33\nself.order:  None\n2023-10-26T11:05:00, Close, 10.33\nself.order:  None\n2023-10-26T11:06:00, Close, 10.33\nself.order:  None\n2023-10-26T11:07:00, Close, 10.33\nself.order:  None\n2023-10-26T11:08:00, Close, 10.33\nself.order:  None\n2023-10-26T11:09:00, Close, 10.33\nself.order:  None\n2023-10-26T11:10:00, Close, 10.33\nself.order:  None\n2023-10-26T11:11:00, Close, 10.34\nself.order:  None\n2023-10-26T11:12:00, Close, 10.34\nself.order:  None\n2023-10-26T11:13:00, Close, 10.33\nself.order:  None\n2023-10-26T11:14:00, Close, 10.34\nself.order:  None\n2023-10-26T11:15:00, Close, 10.33\nself.order:  None\n2023-10-26T11:16:00, Close, 10.35\nself.order:  None\n2023-10-26T11:17:00, Close, 10.35\nself.order:  None\n2023-10-26T11:18:00, Close, 10.35\nself.order:  None\n2023-10-26T11:19:00, Close, 10.34\nself.order:  None\n2023-10-26T11:20:00, Close, 10.34\nself.order:  None\n2023-10-26T11:21:00, Close, 10.35\nself.order:  None\n2023-10-26T11:22:00, Close, 10.34\nself.order:  None\n2023-10-26T11:23:00, Close, 10.34\nself.order:  None\n2023-10-26T11:24:00, Close, 10.34\nself.order:  None\n2023-10-26T11:25:00, Close, 10.34\nself.order:  None\n2023-10-26T11:26:00, Close, 10.34\nself.order:  None\n2023-10-26T11:27:00, Close, 10.35\nself.order:  None\n2023-10-26T11:28:00, Close, 10.35\nself.order:  None\n2023-10-26T11:29:00, Close, 10.35\nself.order:  None\n2023-10-26T11:30:00, Close, 10.35\nself.order:  None\n2023-10-26T13:01:00, Close, 10.34\nself.order:  None\n2023-10-26T13:02:00, Close, 10.36\nself.order:  None\n2023-10-26T13:03:00, Close, 10.34\nself.order:  None\n2023-10-26T13:04:00, Close, 10.34\nself.order:  None\n2023-10-26T13:05:00, Close, 10.36\nself.order:  None\n2023-10-26T13:06:00, Close, 10.35\nself.order:  None\n2023-10-26T13:07:00, Close, 10.35\nself.order:  None\n2023-10-26T13:08:00, Close, 10.36\nself.order:  None\n2023-10-26T13:09:00, Close, 10.36\nself.order:  None\n2023-10-26T13:10:00, Close, 10.35\nself.order:  None\n2023-10-26T13:11:00, Close, 10.36\nself.order:  None\n2023-10-26T13:12:00, Close, 10.36\nself.order:  None\n2023-10-26T13:13:00, Close, 10.35\nself.order:  None\n2023-10-26T13:14:00, Close, 10.35\nself.order:  None\n2023-10-26T13:15:00, Close, 10.35\nself.order:  None\n2023-10-26T13:16:00, Close, 10.36\nself.order:  None\n2023-10-26T13:17:00, Close, 10.36\nself.order:  None\n2023-10-26T13:18:00, Close, 10.35\nself.order:  None\n2023-10-26T13:19:00, Close, 10.36\nself.order:  None\n2023-10-26T13:20:00, Close, 10.37\nself.order:  None\n2023-10-26T13:21:00, Close, 10.37\nself.order:  None\n2023-10-26T13:22:00, Close, 10.36\nself.order:  None\n2023-10-26T13:23:00, Close, 10.36\nself.order:  None\n2023-10-26T13:24:00, Close, 10.37\nself.order:  None\n2023-10-26T13:25:00, Close, 10.36\nself.order:  None\n2023-10-26T13:26:00, Close, 10.35\nself.order:  None\n2023-10-26T13:26:00, BUY CREATE, 10.35\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-26T13:27:00, BUY EXECUTED, Price: 10.34, Cost: 10.34, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-26T13:27:00, Close, 10.35\nself.order:  None\n2023-10-26T13:28:00, Close, 10.35\nself.order:  None\n2023-10-26T13:29:00, Close, 10.34\nself.order:  None\n2023-10-26T13:30:00, Close, 10.34\nself.order:  None\n2023-10-26T13:31:00, Close, 10.35\nself.order:  None\n2023-10-26T13:32:00, Close, 10.34\nself.order:  None\n2023-10-26T13:32:00, SELL CREATE, 10.34\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-26T13:33:00, SELL EXECUTED, Price: 10.35, Cost: 10.34, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-26T13:33:00, OPERATION PROFIT: GROSS 0.01, NET -0.01\n2023-10-26T13:33:00, Close, 10.34\nself.order:  None\n2023-10-26T13:34:00, Close, 10.35\nself.order:  None\n2023-10-26T13:35:00, Close, 10.34\nself.order:  None\n2023-10-26T13:36:00, Close, 10.35\nself.order:  None\n2023-10-26T13:37:00, Close, 10.35\nself.order:  None\n2023-10-26T13:38:00, Close, 10.35\nself.order:  None\n2023-10-26T13:39:00, Close, 10.36\nself.order:  None\n2023-10-26T13:40:00, Close, 10.36\nself.order:  None\n2023-10-26T13:41:00, Close, 10.36\nself.order:  None\n2023-10-26T13:42:00, Close, 10.37\nself.order:  None\n2023-10-26T13:43:00, Close, 10.36\nself.order:  None\n2023-10-26T13:44:00, Close, 10.36\nself.order:  None\n2023-10-26T13:45:00, Close, 10.36\nself.order:  None\n2023-10-26T13:46:00, Close, 10.36\nself.order:  None\n2023-10-26T13:47:00, Close, 10.37\nself.order:  None\n2023-10-26T13:48:00, Close, 10.37\nself.order:  None\n2023-10-26T13:49:00, Close, 10.37\nself.order:  None\n2023-10-26T13:50:00, Close, 10.37\nself.order:  None\n2023-10-26T13:51:00, Close, 10.38\nself.order:  None\n2023-10-26T13:52:00, Close, 10.37\nself.order:  None\n2023-10-26T13:53:00, Close, 10.38\nself.order:  None\n2023-10-26T13:54:00, Close, 10.37\nself.order:  None\n2023-10-26T13:55:00, Close, 10.38\nself.order:  None\n2023-10-26T13:56:00, Close, 10.37\nself.order:  None\n2023-10-26T13:57:00, Close, 10.37\nself.order:  None\n2023-10-26T13:58:00, Close, 10.38\nself.order:  None\n2023-10-26T13:59:00, Close, 10.38\nself.order:  None\n2023-10-26T14:00:00, Close, 10.37\nself.order:  None\n2023-10-26T14:01:00, Close, 10.37\nself.order:  None\n2023-10-26T14:02:00, Close, 10.37\nself.order:  None\n2023-10-26T14:03:00, Close, 10.36\nself.order:  None\n2023-10-26T14:04:00, Close, 10.36\nself.order:  None\n2023-10-26T14:05:00, Close, 10.36\nself.order:  None\n2023-10-26T14:06:00, Close, 10.36\nself.order:  None\n2023-10-26T14:07:00, Close, 10.36\nself.order:  None\n2023-10-26T14:08:00, Close, 10.36\nself.order:  None\n2023-10-26T14:09:00, Close, 10.37\nself.order:  None\n2023-10-26T14:10:00, Close, 10.37\nself.order:  None\n2023-10-26T14:11:00, Close, 10.37\nself.order:  None\n2023-10-26T14:12:00, Close, 10.38\nself.order:  None\n2023-10-26T14:13:00, Close, 10.38\nself.order:  None\n2023-10-26T14:14:00, Close, 10.39\nself.order:  None\n2023-10-26T14:15:00, Close, 10.38\nself.order:  None\n2023-10-26T14:16:00, Close, 10.39\nself.order:  None\n2023-10-26T14:17:00, Close, 10.39\nself.order:  None\n2023-10-26T14:18:00, Close, 10.39\nself.order:  None\n2023-10-26T14:19:00, Close, 10.39\nself.order:  None\n2023-10-26T14:20:00, Close, 10.40\nself.order:  None\n2023-10-26T14:21:00, Close, 10.38\nself.order:  None\n2023-10-26T14:22:00, Close, 10.38\nself.order:  None\n2023-10-26T14:23:00, Close, 10.39\nself.order:  None\n2023-10-26T14:24:00, Close, 10.39\nself.order:  None\n2023-10-26T14:25:00, Close, 10.38\nself.order:  None\n2023-10-26T14:26:00, Close, 10.38\nself.order:  None\n2023-10-26T14:27:00, Close, 10.39\nself.order:  None\n2023-10-26T14:28:00, Close, 10.38\nself.order:  None\n2023-10-26T14:29:00, Close, 10.39\nself.order:  None\n2023-10-26T14:30:00, Close, 10.39\nself.order:  None\n2023-10-26T14:31:00, Close, 10.39\nself.order:  None\n2023-10-26T14:32:00, Close, 10.39\nself.order:  None\n2023-10-26T14:33:00, Close, 10.40\nself.order:  None\n2023-10-26T14:34:00, Close, 10.40\nself.order:  None\n2023-10-26T14:35:00, Close, 10.40\nself.order:  None\n2023-10-26T14:36:00, Close, 10.40\nself.order:  None\n2023-10-26T14:37:00, Close, 10.40\nself.order:  None\n2023-10-26T14:38:00, Close, 10.40\nself.order:  None\n2023-10-26T14:39:00, Close, 10.41\nself.order:  None\n2023-10-26T14:40:00, Close, 10.41\nself.order:  None\n2023-10-26T14:41:00, Close, 10.40\nself.order:  None\n2023-10-26T14:42:00, Close, 10.41\nself.order:  None\n2023-10-26T14:43:00, Close, 10.40\nself.order:  None\n2023-10-26T14:44:00, Close, 10.40\nself.order:  None\n2023-10-26T14:45:00, Close, 10.40\nself.order:  None\n2023-10-26T14:46:00, Close, 10.39\nself.order:  None\n2023-10-26T14:47:00, Close, 10.41\nself.order:  None\n2023-10-26T14:48:00, Close, 10.41\nself.order:  None\n2023-10-26T14:49:00, Close, 10.40\nself.order:  None\n2023-10-26T14:50:00, Close, 10.41\nself.order:  None\n2023-10-26T14:51:00, Close, 10.41\nself.order:  None\n2023-10-26T14:52:00, Close, 10.42\nself.order:  None\n2023-10-26T14:53:00, Close, 10.42\nself.order:  None\n2023-10-26T14:54:00, Close, 10.41\nself.order:  None\n2023-10-26T14:55:00, Close, 10.42\nself.order:  None\n2023-10-26T14:56:00, Close, 10.42\nself.order:  None\n2023-10-26T14:57:00, Close, 10.42\nself.order:  None\n2023-10-26T15:00:00, Close, 10.41\nself.order:  None\n2023-10-27T09:31:00, Close, 10.37\nself.order:  None\n2023-10-27T09:31:00, BUY CREATE, 10.37\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T09:32:00, BUY EXECUTED, Price: 10.36, Cost: 10.36, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T09:32:00, Close, 10.35\nself.order:  None\n2023-10-27T09:33:00, Close, 10.36\nself.order:  None\n2023-10-27T09:34:00, Close, 10.38\nself.order:  None\n2023-10-27T09:35:00, Close, 10.38\nself.order:  None\n2023-10-27T09:36:00, Close, 10.38\nself.order:  None\n2023-10-27T09:37:00, Close, 10.38\nself.order:  None\n2023-10-27T09:37:00, SELL CREATE, 10.38\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T09:38:00, SELL EXECUTED, Price: 10.39, Cost: 10.36, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T09:38:00, OPERATION PROFIT: GROSS 0.03, NET 0.01\n2023-10-27T09:38:00, Close, 10.38\nself.order:  None\n2023-10-27T09:39:00, Close, 10.39\nself.order:  None\n2023-10-27T09:40:00, Close, 10.37\nself.order:  None\n2023-10-27T09:41:00, Close, 10.39\nself.order:  None\n2023-10-27T09:42:00, Close, 10.39\nself.order:  None\n2023-10-27T09:43:00, Close, 10.39\nself.order:  None\n2023-10-27T09:44:00, Close, 10.37\nself.order:  None\n2023-10-27T09:45:00, Close, 10.36\nself.order:  None\n2023-10-27T09:45:00, BUY CREATE, 10.36\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T09:46:00, BUY EXECUTED, Price: 10.37, Cost: 10.37, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T09:46:00, Close, 10.34\nself.order:  None\n2023-10-27T09:47:00, Close, 10.35\nself.order:  None\n2023-10-27T09:48:00, Close, 10.35\nself.order:  None\n2023-10-27T09:49:00, Close, 10.35\nself.order:  None\n2023-10-27T09:50:00, Close, 10.36\nself.order:  None\n2023-10-27T09:51:00, Close, 10.37\nself.order:  None\n2023-10-27T09:51:00, SELL CREATE, 10.37\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T09:52:00, SELL EXECUTED, Price: 10.38, Cost: 10.37, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T09:52:00, OPERATION PROFIT: GROSS 0.01, NET -0.01\n2023-10-27T09:52:00, Close, 10.38\nself.order:  None\n2023-10-27T09:53:00, Close, 10.39\nself.order:  None\n2023-10-27T09:54:00, Close, 10.37\nself.order:  None\n2023-10-27T09:55:00, Close, 10.38\nself.order:  None\n2023-10-27T09:56:00, Close, 10.38\nself.order:  None\n2023-10-27T09:57:00, Close, 10.37\nself.order:  None\n2023-10-27T09:58:00, Close, 10.38\nself.order:  None\n2023-10-27T09:59:00, Close, 10.37\nself.order:  None\n2023-10-27T10:00:00, Close, 10.36\nself.order:  None\n2023-10-27T10:00:00, BUY CREATE, 10.36\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T10:01:00, BUY EXECUTED, Price: 10.37, Cost: 10.37, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T10:01:00, Close, 10.38\nself.order:  None\n2023-10-27T10:02:00, Close, 10.38\nself.order:  None\n2023-10-27T10:03:00, Close, 10.37\nself.order:  None\n2023-10-27T10:04:00, Close, 10.38\nself.order:  None\n2023-10-27T10:05:00, Close, 10.38\nself.order:  None\n2023-10-27T10:06:00, Close, 10.38\nself.order:  None\n2023-10-27T10:06:00, SELL CREATE, 10.38\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T10:07:00, SELL EXECUTED, Price: 10.39, Cost: 10.37, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T10:07:00, OPERATION PROFIT: GROSS 0.02, NET -0.00\n2023-10-27T10:07:00, Close, 10.39\nself.order:  None\n2023-10-27T10:08:00, Close, 10.38\nself.order:  None\n2023-10-27T10:09:00, Close, 10.38\nself.order:  None\n2023-10-27T10:10:00, Close, 10.39\nself.order:  None\n2023-10-27T10:11:00, Close, 10.39\nself.order:  None\n2023-10-27T10:12:00, Close, 10.39\nself.order:  None\n2023-10-27T10:13:00, Close, 10.38\nself.order:  None\n2023-10-27T10:14:00, Close, 10.39\nself.order:  None\n2023-10-27T10:15:00, Close, 10.39\nself.order:  None\n2023-10-27T10:16:00, Close, 10.39\nself.order:  None\n2023-10-27T10:17:00, Close, 10.40\nself.order:  None\n2023-10-27T10:18:00, Close, 10.39\nself.order:  None\n2023-10-27T10:19:00, Close, 10.40\nself.order:  None\n2023-10-27T10:20:00, Close, 10.40\nself.order:  None\n2023-10-27T10:21:00, Close, 10.41\nself.order:  None\n2023-10-27T10:22:00, Close, 10.40\nself.order:  None\n2023-10-27T10:23:00, Close, 10.41\nself.order:  None\n2023-10-27T10:24:00, Close, 10.40\nself.order:  None\n2023-10-27T10:25:00, Close, 10.41\nself.order:  None\n2023-10-27T10:26:00, Close, 10.40\nself.order:  None\n2023-10-27T10:27:00, Close, 10.41\nself.order:  None\n2023-10-27T10:28:00, Close, 10.40\nself.order:  None\n2023-10-27T10:29:00, Close, 10.40\nself.order:  None\n2023-10-27T10:30:00, Close, 10.39\nself.order:  None\n2023-10-27T10:31:00, Close, 10.40\nself.order:  None\n2023-10-27T10:32:00, Close, 10.40\nself.order:  None\n2023-10-27T10:33:00, Close, 10.41\nself.order:  None\n2023-10-27T10:34:00, Close, 10.40\nself.order:  None\n2023-10-27T10:35:00, Close, 10.39\nself.order:  None\n2023-10-27T10:35:00, BUY CREATE, 10.39\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T10:36:00, BUY EXECUTED, Price: 10.40, Cost: 10.40, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T10:36:00, Close, 10.39\nself.order:  None\n2023-10-27T10:37:00, Close, 10.38\nself.order:  None\n2023-10-27T10:38:00, Close, 10.39\nself.order:  None\n2023-10-27T10:39:00, Close, 10.39\nself.order:  None\n2023-10-27T10:40:00, Close, 10.39\nself.order:  None\n2023-10-27T10:41:00, Close, 10.38\nself.order:  None\n2023-10-27T10:41:00, SELL CREATE, 10.38\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T10:42:00, SELL EXECUTED, Price: 10.39, Cost: 10.40, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T10:42:00, OPERATION PROFIT: GROSS -0.01, NET -0.03\n2023-10-27T10:42:00, Close, 10.38\nself.order:  None\n2023-10-27T10:43:00, Close, 10.38\nself.order:  None\n2023-10-27T10:44:00, Close, 10.39\nself.order:  None\n2023-10-27T10:45:00, Close, 10.38\nself.order:  None\n2023-10-27T10:46:00, Close, 10.39\nself.order:  None\n2023-10-27T10:47:00, Close, 10.39\nself.order:  None\n2023-10-27T10:48:00, Close, 10.38\nself.order:  None\n2023-10-27T10:49:00, Close, 10.39\nself.order:  None\n2023-10-27T10:50:00, Close, 10.40\nself.order:  None\n2023-10-27T10:51:00, Close, 10.40\nself.order:  None\n2023-10-27T10:52:00, Close, 10.38\nself.order:  None\n2023-10-27T10:53:00, Close, 10.39\nself.order:  None\n2023-10-27T10:54:00, Close, 10.39\nself.order:  None\n2023-10-27T10:55:00, Close, 10.39\nself.order:  None\n2023-10-27T10:56:00, Close, 10.38\nself.order:  None\n2023-10-27T10:57:00, Close, 10.38\nself.order:  None\n2023-10-27T10:58:00, Close, 10.39\nself.order:  None\n2023-10-27T10:59:00, Close, 10.38\nself.order:  None\n2023-10-27T11:00:00, Close, 10.38\nself.order:  None\n2023-10-27T11:01:00, Close, 10.39\nself.order:  None\n2023-10-27T11:02:00, Close, 10.38\nself.order:  None\n2023-10-27T11:03:00, Close, 10.39\nself.order:  None\n2023-10-27T11:04:00, Close, 10.39\nself.order:  None\n2023-10-27T11:05:00, Close, 10.39\nself.order:  None\n2023-10-27T11:06:00, Close, 10.38\nself.order:  None\n2023-10-27T11:07:00, Close, 10.38\nself.order:  None\n2023-10-27T11:08:00, Close, 10.37\nself.order:  None\n2023-10-27T11:09:00, Close, 10.36\nself.order:  None\n2023-10-27T11:09:00, BUY CREATE, 10.36\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T11:10:00, BUY EXECUTED, Price: 10.37, Cost: 10.37, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T11:10:00, Close, 10.36\nself.order:  None\n2023-10-27T11:11:00, Close, 10.37\nself.order:  None\n2023-10-27T11:12:00, Close, 10.37\nself.order:  None\n2023-10-27T11:13:00, Close, 10.37\nself.order:  None\n2023-10-27T11:14:00, Close, 10.37\nself.order:  None\n2023-10-27T11:15:00, Close, 10.37\nself.order:  None\n2023-10-27T11:15:00, SELL CREATE, 10.37\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T11:16:00, SELL EXECUTED, Price: 10.37, Cost: 10.37, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T11:16:00, OPERATION PROFIT: GROSS 0.00, NET -0.02\n2023-10-27T11:16:00, Close, 10.37\nself.order:  None\n2023-10-27T11:17:00, Close, 10.37\nself.order:  None\n2023-10-27T11:18:00, Close, 10.36\nself.order:  None\n2023-10-27T11:19:00, Close, 10.36\nself.order:  None\n2023-10-27T11:20:00, Close, 10.37\nself.order:  None\n2023-10-27T11:21:00, Close, 10.37\nself.order:  None\n2023-10-27T11:22:00, Close, 10.36\nself.order:  None\n2023-10-27T11:23:00, Close, 10.36\nself.order:  None\n2023-10-27T11:24:00, Close, 10.37\nself.order:  None\n2023-10-27T11:25:00, Close, 10.38\nself.order:  None\n2023-10-27T11:26:00, Close, 10.37\nself.order:  None\n2023-10-27T11:27:00, Close, 10.37\nself.order:  None\n2023-10-27T11:28:00, Close, 10.38\nself.order:  None\n2023-10-27T11:29:00, Close, 10.37\nself.order:  None\n2023-10-27T11:30:00, Close, 10.38\nself.order:  None\n2023-10-27T13:01:00, Close, 10.39\nself.order:  None\n2023-10-27T13:02:00, Close, 10.38\nself.order:  None\n2023-10-27T13:03:00, Close, 10.37\nself.order:  None\n2023-10-27T13:03:00, BUY CREATE, 10.37\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T13:04:00, BUY EXECUTED, Price: 10.37, Cost: 10.37, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T13:04:00, Close, 10.39\nself.order:  None\n2023-10-27T13:05:00, Close, 10.39\nself.order:  None\n2023-10-27T13:06:00, Close, 10.39\nself.order:  None\n2023-10-27T13:07:00, Close, 10.38\nself.order:  None\n2023-10-27T13:08:00, Close, 10.39\nself.order:  None\n2023-10-27T13:09:00, Close, 10.39\nself.order:  None\n2023-10-27T13:09:00, SELL CREATE, 10.39\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T13:10:00, SELL EXECUTED, Price: 10.39, Cost: 10.37, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T13:10:00, OPERATION PROFIT: GROSS 0.02, NET -0.00\n2023-10-27T13:10:00, Close, 10.39\nself.order:  None\n2023-10-27T13:11:00, Close, 10.39\nself.order:  None\n2023-10-27T13:12:00, Close, 10.38\nself.order:  None\n2023-10-27T13:13:00, Close, 10.40\nself.order:  None\n2023-10-27T13:14:00, Close, 10.40\nself.order:  None\n2023-10-27T13:15:00, Close, 10.41\nself.order:  None\n2023-10-27T13:16:00, Close, 10.41\nself.order:  None\n2023-10-27T13:17:00, Close, 10.41\nself.order:  None\n2023-10-27T13:18:00, Close, 10.42\nself.order:  None\n2023-10-27T13:19:00, Close, 10.42\nself.order:  None\n2023-10-27T13:20:00, Close, 10.42\nself.order:  None\n2023-10-27T13:21:00, Close, 10.44\nself.order:  None\n2023-10-27T13:22:00, Close, 10.42\nself.order:  None\n2023-10-27T13:23:00, Close, 10.42\nself.order:  None\n2023-10-27T13:24:00, Close, 10.43\nself.order:  None\n2023-10-27T13:25:00, Close, 10.43\nself.order:  None\n2023-10-27T13:26:00, Close, 10.43\nself.order:  None\n2023-10-27T13:27:00, Close, 10.43\nself.order:  None\n2023-10-27T13:28:00, Close, 10.42\nself.order:  None\n2023-10-27T13:29:00, Close, 10.42\nself.order:  None\n2023-10-27T13:30:00, Close, 10.42\nself.order:  None\n2023-10-27T13:31:00, Close, 10.43\nself.order:  None\n2023-10-27T13:32:00, Close, 10.43\nself.order:  None\n2023-10-27T13:33:00, Close, 10.43\nself.order:  None\n2023-10-27T13:34:00, Close, 10.42\nself.order:  None\n2023-10-27T13:35:00, Close, 10.43\nself.order:  None\n2023-10-27T13:36:00, Close, 10.43\nself.order:  None\n2023-10-27T13:37:00, Close, 10.41\nself.order:  None\n2023-10-27T13:38:00, Close, 10.41\nself.order:  None\n2023-10-27T13:39:00, Close, 10.41\nself.order:  None\n2023-10-27T13:40:00, Close, 10.42\nself.order:  None\n2023-10-27T13:41:00, Close, 10.42\nself.order:  None\n2023-10-27T13:42:00, Close, 10.43\nself.order:  None\n2023-10-27T13:43:00, Close, 10.42\nself.order:  None\n2023-10-27T13:44:00, Close, 10.44\nself.order:  None\n2023-10-27T13:45:00, Close, 10.44\nself.order:  None\n2023-10-27T13:46:00, Close, 10.43\nself.order:  None\n2023-10-27T13:47:00, Close, 10.43\nself.order:  None\n2023-10-27T13:48:00, Close, 10.44\nself.order:  None\n2023-10-27T13:49:00, Close, 10.45\nself.order:  None\n2023-10-27T13:50:00, Close, 10.44\nself.order:  None\n2023-10-27T13:51:00, Close, 10.43\nself.order:  None\n2023-10-27T13:51:00, BUY CREATE, 10.43\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T13:52:00, BUY EXECUTED, Price: 10.44, Cost: 10.44, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T13:52:00, Close, 10.43\nself.order:  None\n2023-10-27T13:53:00, Close, 10.44\nself.order:  None\n2023-10-27T13:54:00, Close, 10.43\nself.order:  None\n2023-10-27T13:55:00, Close, 10.44\nself.order:  None\n2023-10-27T13:56:00, Close, 10.44\nself.order:  None\n2023-10-27T13:57:00, Close, 10.44\nself.order:  None\n2023-10-27T13:57:00, SELL CREATE, 10.44\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T13:58:00, SELL EXECUTED, Price: 10.44, Cost: 10.44, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T13:58:00, OPERATION PROFIT: GROSS 0.00, NET -0.02\n2023-10-27T13:58:00, Close, 10.43\nself.order:  None\n2023-10-27T13:59:00, Close, 10.43\nself.order:  None\n2023-10-27T14:00:00, Close, 10.43\nself.order:  None\n2023-10-27T14:01:00, Close, 10.44\nself.order:  None\n2023-10-27T14:02:00, Close, 10.46\nself.order:  None\n2023-10-27T14:03:00, Close, 10.43\nself.order:  None\n2023-10-27T14:04:00, Close, 10.45\nself.order:  None\n2023-10-27T14:05:00, Close, 10.45\nself.order:  None\n2023-10-27T14:06:00, Close, 10.45\nself.order:  None\n2023-10-27T14:07:00, Close, 10.46\nself.order:  None\n2023-10-27T14:08:00, Close, 10.46\nself.order:  None\n2023-10-27T14:09:00, Close, 10.47\nself.order:  None\n2023-10-27T14:10:00, Close, 10.48\nself.order:  None\n2023-10-27T14:11:00, Close, 10.48\nself.order:  None\n2023-10-27T14:12:00, Close, 10.46\nself.order:  None\n2023-10-27T14:13:00, Close, 10.46\nself.order:  None\n2023-10-27T14:14:00, Close, 10.46\nself.order:  None\n2023-10-27T14:15:00, Close, 10.47\nself.order:  None\n2023-10-27T14:16:00, Close, 10.47\nself.order:  None\n2023-10-27T14:17:00, Close, 10.46\nself.order:  None\n2023-10-27T14:18:00, Close, 10.47\nself.order:  None\n2023-10-27T14:19:00, Close, 10.47\nself.order:  None\n2023-10-27T14:20:00, Close, 10.47\nself.order:  None\n2023-10-27T14:21:00, Close, 10.47\nself.order:  None\n2023-10-27T14:22:00, Close, 10.47\nself.order:  None\n2023-10-27T14:23:00, Close, 10.47\nself.order:  None\n2023-10-27T14:24:00, Close, 10.47\nself.order:  None\n2023-10-27T14:25:00, Close, 10.47\nself.order:  None\n2023-10-27T14:26:00, Close, 10.47\nself.order:  None\n2023-10-27T14:27:00, Close, 10.47\nself.order:  None\n2023-10-27T14:28:00, Close, 10.47\nself.order:  None\n2023-10-27T14:29:00, Close, 10.46\nself.order:  None\n2023-10-27T14:30:00, Close, 10.47\nself.order:  None\n2023-10-27T14:31:00, Close, 10.47\nself.order:  None\n2023-10-27T14:32:00, Close, 10.46\nself.order:  None\n2023-10-27T14:33:00, Close, 10.45\nself.order:  None\n2023-10-27T14:33:00, BUY CREATE, 10.45\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T14:34:00, BUY EXECUTED, Price: 10.46, Cost: 10.46, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T14:34:00, Close, 10.46\nself.order:  None\n2023-10-27T14:35:00, Close, 10.46\nself.order:  None\n2023-10-27T14:36:00, Close, 10.45\nself.order:  None\n2023-10-27T14:37:00, Close, 10.45\nself.order:  None\n2023-10-27T14:38:00, Close, 10.45\nself.order:  None\n2023-10-27T14:39:00, Close, 10.45\nself.order:  None\n2023-10-27T14:39:00, SELL CREATE, 10.45\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T14:40:00, SELL EXECUTED, Price: 10.45, Cost: 10.46, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T14:40:00, OPERATION PROFIT: GROSS -0.01, NET -0.03\n2023-10-27T14:40:00, Close, 10.45\nself.order:  None\n2023-10-27T14:41:00, Close, 10.45\nself.order:  None\n2023-10-27T14:42:00, Close, 10.45\nself.order:  None\n2023-10-27T14:43:00, Close, 10.45\nself.order:  None\n2023-10-27T14:44:00, Close, 10.46\nself.order:  None\n2023-10-27T14:45:00, Close, 10.45\nself.order:  None\n2023-10-27T14:46:00, Close, 10.44\nself.order:  None\n2023-10-27T14:46:00, BUY CREATE, 10.44\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T14:47:00, BUY EXECUTED, Price: 10.44, Cost: 10.44, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T14:47:00, Close, 10.45\nself.order:  None\n2023-10-27T14:48:00, Close, 10.45\nself.order:  None\n2023-10-27T14:49:00, Close, 10.45\nself.order:  None\n2023-10-27T14:50:00, Close, 10.45\nself.order:  None\n2023-10-27T14:51:00, Close, 10.45\nself.order:  None\n2023-10-27T14:52:00, Close, 10.45\nself.order:  None\n2023-10-27T14:52:00, SELL CREATE, 10.45\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-27T14:53:00, SELL EXECUTED, Price: 10.44, Cost: 10.44, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-27T14:53:00, OPERATION PROFIT: GROSS 0.00, NET -0.02\n2023-10-27T14:53:00, Close, 10.45\nself.order:  None\n2023-10-27T14:54:00, Close, 10.45\nself.order:  None\n2023-10-27T14:55:00, Close, 10.45\nself.order:  None\n2023-10-27T14:56:00, Close, 10.45\nself.order:  None\n2023-10-27T14:57:00, Close, 10.45\nself.order:  None\n2023-10-27T15:00:00, Close, 10.45\nself.order:  None\n2023-10-30T09:31:00, Close, 10.38\nself.order:  None\n2023-10-30T09:32:00, Close, 10.39\nself.order:  None\n2023-10-30T09:33:00, Close, 10.39\nself.order:  None\n2023-10-30T09:34:00, Close, 10.39\nself.order:  None\n2023-10-30T09:35:00, Close, 10.39\nself.order:  None\n2023-10-30T09:36:00, Close, 10.39\nself.order:  None\n2023-10-30T09:37:00, Close, 10.39\nself.order:  None\n2023-10-30T09:38:00, Close, 10.40\nself.order:  None\n2023-10-30T09:39:00, Close, 10.40\nself.order:  None\n2023-10-30T09:40:00, Close, 10.39\nself.order:  None\n2023-10-30T09:41:00, Close, 10.39\nself.order:  None\n2023-10-30T09:42:00, Close, 10.40\nself.order:  None\n2023-10-30T09:43:00, Close, 10.38\nself.order:  None\n2023-10-30T09:44:00, Close, 10.37\nself.order:  None\n2023-10-30T09:44:00, BUY CREATE, 10.37\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-30T09:45:00, BUY EXECUTED, Price: 10.38, Cost: 10.38, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-30T09:45:00, Close, 10.39\nself.order:  None\n2023-10-30T09:46:00, Close, 10.39\nself.order:  None\n2023-10-30T09:47:00, Close, 10.39\nself.order:  None\n2023-10-30T09:48:00, Close, 10.39\nself.order:  None\n2023-10-30T09:49:00, Close, 10.39\nself.order:  None\n2023-10-30T09:50:00, Close, 10.38\nself.order:  None\n2023-10-30T09:50:00, SELL CREATE, 10.38\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-30T09:51:00, SELL EXECUTED, Price: 10.37, Cost: 10.38, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-30T09:51:00, OPERATION PROFIT: GROSS -0.01, NET -0.03\n2023-10-30T09:51:00, Close, 10.38\nself.order:  None\n2023-10-30T09:52:00, Close, 10.38\nself.order:  None\n2023-10-30T09:53:00, Close, 10.38\nself.order:  None\n2023-10-30T09:54:00, Close, 10.38\nself.order:  None\n2023-10-30T09:55:00, Close, 10.36\nself.order:  None\n2023-10-30T09:56:00, Close, 10.36\nself.order:  None\n2023-10-30T09:57:00, Close, 10.36\nself.order:  None\n2023-10-30T09:58:00, Close, 10.35\nself.order:  None\n2023-10-30T09:59:00, Close, 10.36\nself.order:  None\n2023-10-30T10:00:00, Close, 10.36\nself.order:  None\n2023-10-30T10:01:00, Close, 10.36\nself.order:  None\n2023-10-30T10:02:00, Close, 10.36\nself.order:  None\n2023-10-30T10:03:00, Close, 10.36\nself.order:  None\n2023-10-30T10:04:00, Close, 10.36\nself.order:  None\n2023-10-30T10:05:00, Close, 10.35\nself.order:  None\n2023-10-30T10:06:00, Close, 10.36\nself.order:  None\n2023-10-30T10:07:00, Close, 10.35\nself.order:  None\n2023-10-30T10:08:00, Close, 10.36\nself.order:  None\n2023-10-30T10:09:00, Close, 10.36\nself.order:  None\n2023-10-30T10:10:00, Close, 10.36\nself.order:  None\n2023-10-30T10:11:00, Close, 10.36\nself.order:  None\n2023-10-30T10:12:00, Close, 10.36\nself.order:  None\n2023-10-30T10:13:00, Close, 10.35\nself.order:  None\n2023-10-30T10:14:00, Close, 10.35\nself.order:  None\n2023-10-30T10:15:00, Close, 10.36\nself.order:  None\n2023-10-30T10:16:00, Close, 10.35\nself.order:  None\n2023-10-30T10:17:00, Close, 10.36\nself.order:  None\n2023-10-30T10:18:00, Close, 10.37\nself.order:  None\n2023-10-30T10:19:00, Close, 10.37\nself.order:  None\n2023-10-30T10:20:00, Close, 10.37\nself.order:  None\n2023-10-30T10:21:00, Close, 10.36\nself.order:  None\n2023-10-30T10:22:00, Close, 10.36\nself.order:  None\n2023-10-30T10:23:00, Close, 10.36\nself.order:  None\n2023-10-30T10:24:00, Close, 10.37\nself.order:  None\n2023-10-30T10:25:00, Close, 10.36\nself.order:  None\n2023-10-30T10:26:00, Close, 10.37\nself.order:  None\n2023-10-30T10:27:00, Close, 10.36\nself.order:  None\n2023-10-30T10:28:00, Close, 10.37\nself.order:  None\n2023-10-30T10:29:00, Close, 10.36\nself.order:  None\n2023-10-30T10:30:00, Close, 10.37\nself.order:  None\n2023-10-30T10:31:00, Close, 10.37\nself.order:  None\n2023-10-30T10:32:00, Close, 10.36\nself.order:  None\n2023-10-30T10:33:00, Close, 10.36\nself.order:  None\n2023-10-30T10:34:00, Close, 10.37\nself.order:  None\n2023-10-30T10:35:00, Close, 10.37\nself.order:  None\n2023-10-30T10:36:00, Close, 10.36\nself.order:  None\n2023-10-30T10:37:00, Close, 10.37\nself.order:  None\n2023-10-30T10:38:00, Close, 10.36\nself.order:  None\n2023-10-30T10:39:00, Close, 10.36\nself.order:  None\n2023-10-30T10:40:00, Close, 10.36\nself.order:  None\n2023-10-30T10:41:00, Close, 10.35\nself.order:  None\n2023-10-30T10:42:00, Close, 10.36\nself.order:  None\n2023-10-30T10:43:00, Close, 10.36\nself.order:  None\n2023-10-30T10:44:00, Close, 10.36\nself.order:  None\n2023-10-30T10:45:00, Close, 10.36\nself.order:  None\n2023-10-30T10:46:00, Close, 10.35\nself.order:  None\n2023-10-30T10:47:00, Close, 10.36\nself.order:  None\n2023-10-30T10:48:00, Close, 10.36\nself.order:  None\n2023-10-30T10:49:00, Close, 10.37\nself.order:  None\n2023-10-30T10:50:00, Close, 10.37\nself.order:  None\n2023-10-30T10:51:00, Close, 10.36\nself.order:  None\n2023-10-30T10:52:00, Close, 10.36\nself.order:  None\n2023-10-30T10:53:00, Close, 10.37\nself.order:  None\n2023-10-30T10:54:00, Close, 10.36\nself.order:  None\n2023-10-30T10:55:00, Close, 10.36\nself.order:  None\n2023-10-30T10:56:00, Close, 10.36\nself.order:  None\n2023-10-30T10:57:00, Close, 10.36\nself.order:  None\n2023-10-30T10:58:00, Close, 10.37\nself.order:  None\n2023-10-30T10:59:00, Close, 10.37\nself.order:  None\n2023-10-30T11:00:00, Close, 10.36\nself.order:  None\n2023-10-30T11:01:00, Close, 10.37\nself.order:  None\n2023-10-30T11:02:00, Close, 10.36\nself.order:  None\n2023-10-30T11:03:00, Close, 10.36\nself.order:  None\n2023-10-30T11:04:00, Close, 10.36\nself.order:  None\n2023-10-30T11:05:00, Close, 10.37\nself.order:  None\n2023-10-30T11:06:00, Close, 10.36\nself.order:  None\n2023-10-30T11:07:00, Close, 10.35\nself.order:  None\n2023-10-30T11:07:00, BUY CREATE, 10.35\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-30T11:08:00, BUY EXECUTED, Price: 10.36, Cost: 10.36, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-30T11:08:00, Close, 10.36\nself.order:  None\n2023-10-30T11:09:00, Close, 10.36\nself.order:  None\n2023-10-30T11:10:00, Close, 10.35\nself.order:  None\n2023-10-30T11:11:00, Close, 10.36\nself.order:  None\n2023-10-30T11:12:00, Close, 10.36\nself.order:  None\n2023-10-30T11:13:00, Close, 10.36\nself.order:  None\n2023-10-30T11:13:00, SELL CREATE, 10.36\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-30T11:14:00, SELL EXECUTED, Price: 10.37, Cost: 10.36, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-30T11:14:00, OPERATION PROFIT: GROSS 0.01, NET -0.01\n2023-10-30T11:14:00, Close, 10.38\nself.order:  None\n2023-10-30T11:15:00, Close, 10.37\nself.order:  None\n2023-10-30T11:16:00, Close, 10.37\nself.order:  None\n2023-10-30T11:17:00, Close, 10.38\nself.order:  None\n2023-10-30T11:18:00, Close, 10.37\nself.order:  None\n2023-10-30T11:19:00, Close, 10.37\nself.order:  None\n2023-10-30T11:20:00, Close, 10.37\nself.order:  None\n2023-10-30T11:21:00, Close, 10.37\nself.order:  None\n2023-10-30T11:22:00, Close, 10.37\nself.order:  None\n2023-10-30T11:23:00, Close, 10.37\nself.order:  None\n2023-10-30T11:24:00, Close, 10.38\nself.order:  None\n2023-10-30T11:25:00, Close, 10.38\nself.order:  None\n2023-10-30T11:26:00, Close, 10.39\nself.order:  None\n2023-10-30T11:27:00, Close, 10.40\nself.order:  None\n2023-10-30T11:28:00, Close, 10.41\nself.order:  None\n2023-10-30T11:29:00, Close, 10.41\nself.order:  None\n2023-10-30T11:30:00, Close, 10.41\nself.order:  None\n2023-10-30T13:01:00, Close, 10.39\nself.order:  None\n2023-10-30T13:02:00, Close, 10.38\nself.order:  None\n2023-10-30T13:02:00, BUY CREATE, 10.38\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-30T13:03:00, BUY EXECUTED, Price: 10.38, Cost: 10.38, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-30T13:03:00, Close, 10.38\nself.order:  None\n2023-10-30T13:04:00, Close, 10.38\nself.order:  None\n2023-10-30T13:05:00, Close, 10.38\nself.order:  None\n2023-10-30T13:06:00, Close, 10.39\nself.order:  None\n2023-10-30T13:07:00, Close, 10.39\nself.order:  None\n2023-10-30T13:08:00, Close, 10.39\nself.order:  None\n2023-10-30T13:08:00, SELL CREATE, 10.39\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-30T13:09:00, SELL EXECUTED, Price: 10.38, Cost: 10.38, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-30T13:09:00, OPERATION PROFIT: GROSS 0.00, NET -0.02\n2023-10-30T13:09:00, Close, 10.38\nself.order:  None\n2023-10-30T13:10:00, Close, 10.39\nself.order:  None\n2023-10-30T13:11:00, Close, 10.38\nself.order:  None\n2023-10-30T13:12:00, Close, 10.38\nself.order:  None\n2023-10-30T13:13:00, Close, 10.38\nself.order:  None\n2023-10-30T13:14:00, Close, 10.39\nself.order:  None\n2023-10-30T13:15:00, Close, 10.38\nself.order:  None\n2023-10-30T13:16:00, Close, 10.38\nself.order:  None\n2023-10-30T13:17:00, Close, 10.38\nself.order:  None\n2023-10-30T13:18:00, Close, 10.39\nself.order:  None\n2023-10-30T13:19:00, Close, 10.38\nself.order:  None\n2023-10-30T13:20:00, Close, 10.38\nself.order:  None\n2023-10-30T13:21:00, Close, 10.38\nself.order:  None\n2023-10-30T13:22:00, Close, 10.39\nself.order:  None\n2023-10-30T13:23:00, Close, 10.39\nself.order:  None\n2023-10-30T13:24:00, Close, 10.38\nself.order:  None\n2023-10-30T13:25:00, Close, 10.40\nself.order:  None\n2023-10-30T13:26:00, Close, 10.39\nself.order:  None\n2023-10-30T13:27:00, Close, 10.40\nself.order:  None\n2023-10-30T13:28:00, Close, 10.40\nself.order:  None\n2023-10-30T13:29:00, Close, 10.39\nself.order:  None\n2023-10-30T13:30:00, Close, 10.39\nself.order:  None\n2023-10-30T13:31:00, Close, 10.40\nself.order:  None\n2023-10-30T13:32:00, Close, 10.40\nself.order:  None\n2023-10-30T13:33:00, Close, 10.42\nself.order:  None\n2023-10-30T13:34:00, Close, 10.42\nself.order:  None\n2023-10-30T13:35:00, Close, 10.42\nself.order:  None\n2023-10-30T13:36:00, Close, 10.41\nself.order:  None\n2023-10-30T13:37:00, Close, 10.41\nself.order:  None\n2023-10-30T13:38:00, Close, 10.40\nself.order:  None\n2023-10-30T13:39:00, Close, 10.40\nself.order:  None\n2023-10-30T13:40:00, Close, 10.41\nself.order:  None\n2023-10-30T13:41:00, Close, 10.41\nself.order:  None\n2023-10-30T13:42:00, Close, 10.42\nself.order:  None\n2023-10-30T13:43:00, Close, 10.43\nself.order:  None\n2023-10-30T13:44:00, Close, 10.43\nself.order:  None\n2023-10-30T13:45:00, Close, 10.43\nself.order:  None\n2023-10-30T13:46:00, Close, 10.42\nself.order:  None\n2023-10-30T13:47:00, Close, 10.42\nself.order:  None\n2023-10-30T13:48:00, Close, 10.42\nself.order:  None\n2023-10-30T13:49:00, Close, 10.42\nself.order:  None\n2023-10-30T13:50:00, Close, 10.41\nself.order:  None\n2023-10-30T13:51:00, Close, 10.41\nself.order:  None\n2023-10-30T13:52:00, Close, 10.43\nself.order:  None\n2023-10-30T13:53:00, Close, 10.42\nself.order:  None\n2023-10-30T13:54:00, Close, 10.43\nself.order:  None\n2023-10-30T13:55:00, Close, 10.43\nself.order:  None\n2023-10-30T13:56:00, Close, 10.42\nself.order:  None\n2023-10-30T13:57:00, Close, 10.43\nself.order:  None\n2023-10-30T13:58:00, Close, 10.43\nself.order:  None\n2023-10-30T13:59:00, Close, 10.43\nself.order:  None\n2023-10-30T14:00:00, Close, 10.45\nself.order:  None\n2023-10-30T14:01:00, Close, 10.45\nself.order:  None\n2023-10-30T14:02:00, Close, 10.45\nself.order:  None\n2023-10-30T14:03:00, Close, 10.45\nself.order:  None\n2023-10-30T14:04:00, Close, 10.45\nself.order:  None\n2023-10-30T14:05:00, Close, 10.44\nself.order:  None\n2023-10-30T14:06:00, Close, 10.44\nself.order:  None\n2023-10-30T14:07:00, Close, 10.43\nself.order:  None\n2023-10-30T14:08:00, Close, 10.43\nself.order:  None\n2023-10-30T14:09:00, Close, 10.43\nself.order:  None\n2023-10-30T14:10:00, Close, 10.44\nself.order:  None\n2023-10-30T14:11:00, Close, 10.43\nself.order:  None\n2023-10-30T14:12:00, Close, 10.44\nself.order:  None\n2023-10-30T14:13:00, Close, 10.44\nself.order:  None\n2023-10-30T14:14:00, Close, 10.45\nself.order:  None\n2023-10-30T14:15:00, Close, 10.44\nself.order:  None\n2023-10-30T14:16:00, Close, 10.45\nself.order:  None\n2023-10-30T14:17:00, Close, 10.45\nself.order:  None\n2023-10-30T14:18:00, Close, 10.44\nself.order:  None\n2023-10-30T14:19:00, Close, 10.44\nself.order:  None\n2023-10-30T14:20:00, Close, 10.45\nself.order:  None\n2023-10-30T14:21:00, Close, 10.44\nself.order:  None\n2023-10-30T14:22:00, Close, 10.44\nself.order:  None\n2023-10-30T14:23:00, Close, 10.44\nself.order:  None\n2023-10-30T14:24:00, Close, 10.44\nself.order:  None\n2023-10-30T14:25:00, Close, 10.44\nself.order:  None\n2023-10-30T14:26:00, Close, 10.45\nself.order:  None\n2023-10-30T14:27:00, Close, 10.44\nself.order:  None\n2023-10-30T14:28:00, Close, 10.44\nself.order:  None\n2023-10-30T14:29:00, Close, 10.44\nself.order:  None\n2023-10-30T14:30:00, Close, 10.45\nself.order:  None\n2023-10-30T14:31:00, Close, 10.44\nself.order:  None\n2023-10-30T14:32:00, Close, 10.44\nself.order:  None\n2023-10-30T14:33:00, Close, 10.44\nself.order:  None\n2023-10-30T14:34:00, Close, 10.45\nself.order:  None\n2023-10-30T14:35:00, Close, 10.44\nself.order:  None\n2023-10-30T14:36:00, Close, 10.45\nself.order:  None\n2023-10-30T14:37:00, Close, 10.44\nself.order:  None\n2023-10-30T14:38:00, Close, 10.45\nself.order:  None\n2023-10-30T14:39:00, Close, 10.45\nself.order:  None\n2023-10-30T14:40:00, Close, 10.44\nself.order:  None\n2023-10-30T14:41:00, Close, 10.45\nself.order:  None\n2023-10-30T14:42:00, Close, 10.44\nself.order:  None\n2023-10-30T14:43:00, Close, 10.45\nself.order:  None\n2023-10-30T14:44:00, Close, 10.45\nself.order:  None\n2023-10-30T14:45:00, Close, 10.45\nself.order:  None\n2023-10-30T14:46:00, Close, 10.45\nself.order:  None\n2023-10-30T14:47:00, Close, 10.44\nself.order:  None\n2023-10-30T14:48:00, Close, 10.44\nself.order:  None\n2023-10-30T14:49:00, Close, 10.45\nself.order:  None\n2023-10-30T14:50:00, Close, 10.44\nself.order:  None\n2023-10-30T14:51:00, Close, 10.44\nself.order:  None\n2023-10-30T14:52:00, Close, 10.44\nself.order:  None\n2023-10-30T14:53:00, Close, 10.45\nself.order:  None\n2023-10-30T14:54:00, Close, 10.45\nself.order:  None\n2023-10-30T14:55:00, Close, 10.46\nself.order:  None\n2023-10-30T14:56:00, Close, 10.46\nself.order:  None\n2023-10-30T14:57:00, Close, 10.46\nself.order:  None\n2023-10-30T15:00:00, Close, 10.45\nself.order:  None\n2023-10-31T09:31:00, Close, 10.42\nself.order:  None\n2023-10-31T09:31:00, BUY CREATE, 10.42\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-31T09:32:00, BUY EXECUTED, Price: 10.42, Cost: 10.42, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-31T09:32:00, Close, 10.43\nself.order:  None\n2023-10-31T09:33:00, Close, 10.44\nself.order:  None\n2023-10-31T09:34:00, Close, 10.44\nself.order:  None\n2023-10-31T09:35:00, Close, 10.45\nself.order:  None\n2023-10-31T09:36:00, Close, 10.47\nself.order:  None\n2023-10-31T09:37:00, Close, 10.48\nself.order:  None\n2023-10-31T09:37:00, SELL CREATE, 10.48\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-31T09:38:00, SELL EXECUTED, Price: 10.48, Cost: 10.42, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-31T09:38:00, OPERATION PROFIT: GROSS 0.06, NET 0.04\n2023-10-31T09:38:00, Close, 10.46\nself.order:  None\n2023-10-31T09:39:00, Close, 10.47\nself.order:  None\n2023-10-31T09:40:00, Close, 10.47\nself.order:  None\n2023-10-31T09:41:00, Close, 10.46\nself.order:  None\n2023-10-31T09:42:00, Close, 10.46\nself.order:  None\n2023-10-31T09:43:00, Close, 10.46\nself.order:  None\n2023-10-31T09:44:00, Close, 10.46\nself.order:  None\n2023-10-31T09:45:00, Close, 10.45\nself.order:  None\n2023-10-31T09:46:00, Close, 10.45\nself.order:  None\n2023-10-31T09:47:00, Close, 10.45\nself.order:  None\n2023-10-31T09:48:00, Close, 10.45\nself.order:  None\n2023-10-31T09:49:00, Close, 10.45\nself.order:  None\n2023-10-31T09:50:00, Close, 10.45\nself.order:  None\n2023-10-31T09:51:00, Close, 10.45\nself.order:  None\n2023-10-31T09:52:00, Close, 10.45\nself.order:  None\n2023-10-31T09:53:00, Close, 10.45\nself.order:  None\n2023-10-31T09:54:00, Close, 10.47\nself.order:  None\n2023-10-31T09:55:00, Close, 10.47\nself.order:  None\n2023-10-31T09:56:00, Close, 10.47\nself.order:  None\n2023-10-31T09:57:00, Close, 10.47\nself.order:  None\n2023-10-31T09:58:00, Close, 10.46\nself.order:  None\n2023-10-31T09:59:00, Close, 10.46\nself.order:  None\n2023-10-31T10:00:00, Close, 10.46\nself.order:  None\n2023-10-31T10:01:00, Close, 10.47\nself.order:  None\n2023-10-31T10:02:00, Close, 10.48\nself.order:  None\n2023-10-31T10:03:00, Close, 10.48\nself.order:  None\n2023-10-31T10:04:00, Close, 10.48\nself.order:  None\n2023-10-31T10:05:00, Close, 10.48\nself.order:  None\n2023-10-31T10:06:00, Close, 10.49\nself.order:  None\n2023-10-31T10:07:00, Close, 10.49\nself.order:  None\n2023-10-31T10:08:00, Close, 10.49\nself.order:  None\n2023-10-31T10:09:00, Close, 10.47\nself.order:  None\n2023-10-31T10:10:00, Close, 10.48\nself.order:  None\n2023-10-31T10:11:00, Close, 10.48\nself.order:  None\n2023-10-31T10:12:00, Close, 10.47\nself.order:  None\n2023-10-31T10:13:00, Close, 10.47\nself.order:  None\n2023-10-31T10:14:00, Close, 10.46\nself.order:  None\n2023-10-31T10:15:00, Close, 10.47\nself.order:  None\n2023-10-31T10:16:00, Close, 10.46\nself.order:  None\n2023-10-31T10:17:00, Close, 10.45\nself.order:  None\n2023-10-31T10:17:00, BUY CREATE, 10.45\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-31T10:18:00, BUY EXECUTED, Price: 10.45, Cost: 10.45, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-31T10:18:00, Close, 10.45\nself.order:  None\n2023-10-31T10:19:00, Close, 10.43\nself.order:  None\n2023-10-31T10:20:00, Close, 10.44\nself.order:  None\n2023-10-31T10:21:00, Close, 10.43\nself.order:  None\n2023-10-31T10:22:00, Close, 10.43\nself.order:  None\n2023-10-31T10:23:00, Close, 10.43\nself.order:  None\n2023-10-31T10:23:00, SELL CREATE, 10.43\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-31T10:24:00, SELL EXECUTED, Price: 10.43, Cost: 10.45, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-31T10:24:00, OPERATION PROFIT: GROSS -0.02, NET -0.04\n2023-10-31T10:24:00, Close, 10.44\nself.order:  None\n2023-10-31T10:25:00, Close, 10.44\nself.order:  None\n2023-10-31T10:26:00, Close, 10.43\nself.order:  None\n2023-10-31T10:27:00, Close, 10.43\nself.order:  None\n2023-10-31T10:28:00, Close, 10.43\nself.order:  None\n2023-10-31T10:29:00, Close, 10.43\nself.order:  None\n2023-10-31T10:30:00, Close, 10.43\nself.order:  None\n2023-10-31T10:31:00, Close, 10.43\nself.order:  None\n2023-10-31T10:32:00, Close, 10.43\nself.order:  None\n2023-10-31T10:33:00, Close, 10.43\nself.order:  None\n2023-10-31T10:34:00, Close, 10.43\nself.order:  None\n2023-10-31T10:35:00, Close, 10.43\nself.order:  None\n2023-10-31T10:36:00, Close, 10.44\nself.order:  None\n2023-10-31T10:37:00, Close, 10.44\nself.order:  None\n2023-10-31T10:38:00, Close, 10.45\nself.order:  None\n2023-10-31T10:39:00, Close, 10.44\nself.order:  None\n2023-10-31T10:40:00, Close, 10.45\nself.order:  None\n2023-10-31T10:41:00, Close, 10.44\nself.order:  None\n2023-10-31T10:42:00, Close, 10.44\nself.order:  None\n2023-10-31T10:43:00, Close, 10.43\nself.order:  None\n2023-10-31T10:44:00, Close, 10.43\nself.order:  None\n2023-10-31T10:45:00, Close, 10.44\nself.order:  None\n2023-10-31T10:46:00, Close, 10.44\nself.order:  None\n2023-10-31T10:47:00, Close, 10.44\nself.order:  None\n2023-10-31T10:48:00, Close, 10.44\nself.order:  None\n2023-10-31T10:49:00, Close, 10.44\nself.order:  None\n2023-10-31T10:50:00, Close, 10.44\nself.order:  None\n2023-10-31T10:51:00, Close, 10.44\nself.order:  None\n2023-10-31T10:52:00, Close, 10.44\nself.order:  None\n2023-10-31T10:53:00, Close, 10.43\nself.order:  None\n2023-10-31T10:54:00, Close, 10.43\nself.order:  None\n2023-10-31T10:55:00, Close, 10.42\nself.order:  None\n2023-10-31T10:56:00, Close, 10.42\nself.order:  None\n2023-10-31T10:57:00, Close, 10.42\nself.order:  None\n2023-10-31T10:58:00, Close, 10.42\nself.order:  None\n2023-10-31T10:59:00, Close, 10.42\nself.order:  None\n2023-10-31T11:00:00, Close, 10.41\nself.order:  None\n2023-10-31T11:01:00, Close, 10.42\nself.order:  None\n2023-10-31T11:02:00, Close, 10.43\nself.order:  None\n2023-10-31T11:03:00, Close, 10.42\nself.order:  None\n2023-10-31T11:04:00, Close, 10.43\nself.order:  None\n2023-10-31T11:05:00, Close, 10.43\nself.order:  None\n2023-10-31T11:06:00, Close, 10.43\nself.order:  None\n2023-10-31T11:07:00, Close, 10.43\nself.order:  None\n2023-10-31T11:08:00, Close, 10.43\nself.order:  None\n2023-10-31T11:09:00, Close, 10.42\nself.order:  None\n2023-10-31T11:10:00, Close, 10.42\nself.order:  None\n2023-10-31T11:11:00, Close, 10.43\nself.order:  None\n2023-10-31T11:12:00, Close, 10.42\nself.order:  None\n2023-10-31T11:13:00, Close, 10.43\nself.order:  None\n2023-10-31T11:14:00, Close, 10.42\nself.order:  None\n2023-10-31T11:15:00, Close, 10.43\nself.order:  None\n2023-10-31T11:16:00, Close, 10.42\nself.order:  None\n2023-10-31T11:17:00, Close, 10.43\nself.order:  None\n2023-10-31T11:18:00, Close, 10.42\nself.order:  None\n2023-10-31T11:19:00, Close, 10.42\nself.order:  None\n2023-10-31T11:20:00, Close, 10.42\nself.order:  None\n2023-10-31T11:21:00, Close, 10.42\nself.order:  None\n2023-10-31T11:22:00, Close, 10.42\nself.order:  None\n2023-10-31T11:23:00, Close, 10.42\nself.order:  None\n2023-10-31T11:24:00, Close, 10.42\nself.order:  None\n2023-10-31T11:25:00, Close, 10.42\nself.order:  None\n2023-10-31T11:26:00, Close, 10.43\nself.order:  None\n2023-10-31T11:27:00, Close, 10.43\nself.order:  None\n2023-10-31T11:28:00, Close, 10.43\nself.order:  None\n2023-10-31T11:29:00, Close, 10.43\nself.order:  None\n2023-10-31T11:30:00, Close, 10.43\nself.order:  None\n2023-10-31T13:01:00, Close, 10.44\nself.order:  None\n2023-10-31T13:02:00, Close, 10.43\nself.order:  None\n2023-10-31T13:03:00, Close, 10.42\nself.order:  None\n2023-10-31T13:03:00, BUY CREATE, 10.42\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-31T13:04:00, BUY EXECUTED, Price: 10.42, Cost: 10.42, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-31T13:04:00, Close, 10.42\nself.order:  None\n2023-10-31T13:05:00, Close, 10.43\nself.order:  None\n2023-10-31T13:06:00, Close, 10.42\nself.order:  None\n2023-10-31T13:07:00, Close, 10.42\nself.order:  None\n2023-10-31T13:08:00, Close, 10.42\nself.order:  None\n2023-10-31T13:09:00, Close, 10.42\nself.order:  None\n2023-10-31T13:09:00, SELL CREATE, 10.42\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-31T13:10:00, SELL EXECUTED, Price: 10.41, Cost: 10.42, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-31T13:10:00, OPERATION PROFIT: GROSS -0.01, NET -0.03\n2023-10-31T13:10:00, Close, 10.41\nself.order:  None\n2023-10-31T13:11:00, Close, 10.42\nself.order:  None\n2023-10-31T13:12:00, Close, 10.43\nself.order:  None\n2023-10-31T13:13:00, Close, 10.43\nself.order:  None\n2023-10-31T13:14:00, Close, 10.42\nself.order:  None\n2023-10-31T13:15:00, Close, 10.42\nself.order:  None\n2023-10-31T13:16:00, Close, 10.42\nself.order:  None\n2023-10-31T13:17:00, Close, 10.42\nself.order:  None\n2023-10-31T13:18:00, Close, 10.43\nself.order:  None\n2023-10-31T13:19:00, Close, 10.42\nself.order:  None\n2023-10-31T13:20:00, Close, 10.42\nself.order:  None\n2023-10-31T13:21:00, Close, 10.43\nself.order:  None\n2023-10-31T13:22:00, Close, 10.42\nself.order:  None\n2023-10-31T13:23:00, Close, 10.42\nself.order:  None\n2023-10-31T13:24:00, Close, 10.43\nself.order:  None\n2023-10-31T13:25:00, Close, 10.43\nself.order:  None\n2023-10-31T13:26:00, Close, 10.43\nself.order:  None\n2023-10-31T13:27:00, Close, 10.43\nself.order:  None\n2023-10-31T13:28:00, Close, 10.43\nself.order:  None\n2023-10-31T13:29:00, Close, 10.43\nself.order:  None\n2023-10-31T13:30:00, Close, 10.43\nself.order:  None\n2023-10-31T13:31:00, Close, 10.44\nself.order:  None\n2023-10-31T13:32:00, Close, 10.44\nself.order:  None\n2023-10-31T13:33:00, Close, 10.43\nself.order:  None\n2023-10-31T13:34:00, Close, 10.45\nself.order:  None\n2023-10-31T13:35:00, Close, 10.46\nself.order:  None\n2023-10-31T13:36:00, Close, 10.47\nself.order:  None\n2023-10-31T13:37:00, Close, 10.47\nself.order:  None\n2023-10-31T13:38:00, Close, 10.47\nself.order:  None\n2023-10-31T13:39:00, Close, 10.46\nself.order:  None\n2023-10-31T13:40:00, Close, 10.47\nself.order:  None\n2023-10-31T13:41:00, Close, 10.47\nself.order:  None\n2023-10-31T13:42:00, Close, 10.46\nself.order:  None\n2023-10-31T13:43:00, Close, 10.47\nself.order:  None\n2023-10-31T13:44:00, Close, 10.47\nself.order:  None\n2023-10-31T13:45:00, Close, 10.47\nself.order:  None\n2023-10-31T13:46:00, Close, 10.47\nself.order:  None\n2023-10-31T13:47:00, Close, 10.47\nself.order:  None\n2023-10-31T13:48:00, Close, 10.47\nself.order:  None\n2023-10-31T13:49:00, Close, 10.46\nself.order:  None\n2023-10-31T13:50:00, Close, 10.46\nself.order:  None\n2023-10-31T13:51:00, Close, 10.46\nself.order:  None\n2023-10-31T13:52:00, Close, 10.46\nself.order:  None\n2023-10-31T13:53:00, Close, 10.46\nself.order:  None\n2023-10-31T13:54:00, Close, 10.47\nself.order:  None\n2023-10-31T13:55:00, Close, 10.47\nself.order:  None\n2023-10-31T13:56:00, Close, 10.47\nself.order:  None\n2023-10-31T13:57:00, Close, 10.46\nself.order:  None\n2023-10-31T13:58:00, Close, 10.45\nself.order:  None\n2023-10-31T13:58:00, BUY CREATE, 10.45\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-31T13:59:00, BUY EXECUTED, Price: 10.46, Cost: 10.46, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-31T13:59:00, Close, 10.46\nself.order:  None\n2023-10-31T14:00:00, Close, 10.46\nself.order:  None\n2023-10-31T14:01:00, Close, 10.47\nself.order:  None\n2023-10-31T14:02:00, Close, 10.46\nself.order:  None\n2023-10-31T14:03:00, Close, 10.46\nself.order:  None\n2023-10-31T14:04:00, Close, 10.46\nself.order:  None\n2023-10-31T14:04:00, SELL CREATE, 10.46\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-31T14:05:00, SELL EXECUTED, Price: 10.45, Cost: 10.46, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-31T14:05:00, OPERATION PROFIT: GROSS -0.01, NET -0.03\n2023-10-31T14:05:00, Close, 10.45\nself.order:  None\n2023-10-31T14:06:00, Close, 10.44\nself.order:  None\n2023-10-31T14:06:00, BUY CREATE, 10.44\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-31T14:07:00, BUY EXECUTED, Price: 10.44, Cost: 10.44, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-31T14:07:00, Close, 10.44\nself.order:  None\n2023-10-31T14:08:00, Close, 10.44\nself.order:  None\n2023-10-31T14:09:00, Close, 10.45\nself.order:  None\n2023-10-31T14:10:00, Close, 10.44\nself.order:  None\n2023-10-31T14:11:00, Close, 10.44\nself.order:  None\n2023-10-31T14:12:00, Close, 10.45\nself.order:  None\n2023-10-31T14:12:00, SELL CREATE, 10.45\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-10-31T14:13:00, SELL EXECUTED, Price: 10.45, Cost: 10.44, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-10-31T14:13:00, OPERATION PROFIT: GROSS 0.01, NET -0.01\n2023-10-31T14:13:00, Close, 10.44\nself.order:  None\n2023-10-31T14:14:00, Close, 10.45\nself.order:  None\n2023-10-31T14:15:00, Close, 10.44\nself.order:  None\n2023-10-31T14:16:00, Close, 10.44\nself.order:  None\n2023-10-31T14:17:00, Close, 10.45\nself.order:  None\n2023-10-31T14:18:00, Close, 10.45\nself.order:  None\n2023-10-31T14:19:00, Close, 10.46\nself.order:  None\n2023-10-31T14:20:00, Close, 10.45\nself.order:  None\n2023-10-31T14:21:00, Close, 10.45\nself.order:  None\n2023-10-31T14:22:00, Close, 10.45\nself.order:  None\n2023-10-31T14:23:00, Close, 10.46\nself.order:  None\n2023-10-31T14:24:00, Close, 10.46\nself.order:  None\n2023-10-31T14:25:00, Close, 10.46\nself.order:  None\n2023-10-31T14:26:00, Close, 10.45\nself.order:  None\n2023-10-31T14:27:00, Close, 10.46\nself.order:  None\n2023-10-31T14:28:00, Close, 10.46\nself.order:  None\n2023-10-31T14:29:00, Close, 10.45\nself.order:  None\n2023-10-31T14:30:00, Close, 10.45\nself.order:  None\n2023-10-31T14:31:00, Close, 10.45\nself.order:  None\n2023-10-31T14:32:00, Close, 10.46\nself.order:  None\n2023-10-31T14:33:00, Close, 10.45\nself.order:  None\n2023-10-31T14:34:00, Close, 10.46\nself.order:  None\n2023-10-31T14:35:00, Close, 10.47\nself.order:  None\n2023-10-31T14:36:00, Close, 10.46\nself.order:  None\n2023-10-31T14:37:00, Close, 10.46\nself.order:  None\n2023-10-31T14:38:00, Close, 10.46\nself.order:  None\n2023-10-31T14:39:00, Close, 10.46\nself.order:  None\n2023-10-31T14:40:00, Close, 10.47\nself.order:  None\n2023-10-31T14:41:00, Close, 10.47\nself.order:  None\n2023-10-31T14:42:00, Close, 10.46\nself.order:  None\n2023-10-31T14:43:00, Close, 10.46\nself.order:  None\n2023-10-31T14:44:00, Close, 10.47\nself.order:  None\n2023-10-31T14:45:00, Close, 10.47\nself.order:  None\n2023-10-31T14:46:00, Close, 10.47\nself.order:  None\n2023-10-31T14:47:00, Close, 10.47\nself.order:  None\n2023-10-31T14:48:00, Close, 10.47\nself.order:  None\n2023-10-31T14:49:00, Close, 10.47\nself.order:  None\n2023-10-31T14:50:00, Close, 10.47\nself.order:  None\n2023-10-31T14:51:00, Close, 10.47\nself.order:  None\n2023-10-31T14:52:00, Close, 10.46\nself.order:  None\n2023-10-31T14:53:00, Close, 10.46\nself.order:  None\n2023-10-31T14:54:00, Close, 10.46\nself.order:  None\n2023-10-31T14:55:00, Close, 10.46\nself.order:  None\n2023-10-31T14:56:00, Close, 10.46\nself.order:  None\n2023-10-31T14:57:00, Close, 10.47\nself.order:  None\n2023-10-31T15:00:00, Close, 10.46\nself.order:  None\n2023-11-01T09:31:00, Close, 10.52\nself.order:  None\n2023-11-01T09:32:00, Close, 10.52\nself.order:  None\n2023-11-01T09:33:00, Close, 10.52\nself.order:  None\n2023-11-01T09:34:00, Close, 10.50\nself.order:  None\n2023-11-01T09:35:00, Close, 10.48\nself.order:  None\n2023-11-01T09:35:00, BUY CREATE, 10.48\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-01T09:36:00, BUY EXECUTED, Price: 10.48, Cost: 10.48, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-01T09:36:00, Close, 10.48\nself.order:  None\n2023-11-01T09:37:00, Close, 10.49\nself.order:  None\n2023-11-01T09:38:00, Close, 10.47\nself.order:  None\n2023-11-01T09:39:00, Close, 10.49\nself.order:  None\n2023-11-01T09:40:00, Close, 10.50\nself.order:  None\n2023-11-01T09:41:00, Close, 10.50\nself.order:  None\n2023-11-01T09:41:00, SELL CREATE, 10.50\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-01T09:42:00, SELL EXECUTED, Price: 10.50, Cost: 10.48, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-01T09:42:00, OPERATION PROFIT: GROSS 0.02, NET -0.00\n2023-11-01T09:42:00, Close, 10.51\nself.order:  None\n2023-11-01T09:43:00, Close, 10.53\nself.order:  None\n2023-11-01T09:44:00, Close, 10.51\nself.order:  None\n2023-11-01T09:45:00, Close, 10.51\nself.order:  None\n2023-11-01T09:46:00, Close, 10.49\nself.order:  None\n2023-11-01T09:47:00, Close, 10.50\nself.order:  None\n2023-11-01T09:48:00, Close, 10.52\nself.order:  None\n2023-11-01T09:49:00, Close, 10.51\nself.order:  None\n2023-11-01T09:50:00, Close, 10.51\nself.order:  None\n2023-11-01T09:51:00, Close, 10.50\nself.order:  None\n2023-11-01T09:52:00, Close, 10.50\nself.order:  None\n2023-11-01T09:53:00, Close, 10.50\nself.order:  None\n2023-11-01T09:54:00, Close, 10.49\nself.order:  None\n2023-11-01T09:55:00, Close, 10.49\nself.order:  None\n2023-11-01T09:56:00, Close, 10.48\nself.order:  None\n2023-11-01T09:57:00, Close, 10.48\nself.order:  None\n2023-11-01T09:58:00, Close, 10.49\nself.order:  None\n2023-11-01T09:59:00, Close, 10.48\nself.order:  None\n2023-11-01T10:00:00, Close, 10.47\nself.order:  None\n2023-11-01T10:00:00, BUY CREATE, 10.47\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-01T10:01:00, BUY EXECUTED, Price: 10.48, Cost: 10.48, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-01T10:01:00, Close, 10.48\nself.order:  None\n2023-11-01T10:02:00, Close, 10.48\nself.order:  None\n2023-11-01T10:03:00, Close, 10.48\nself.order:  None\n2023-11-01T10:04:00, Close, 10.48\nself.order:  None\n2023-11-01T10:05:00, Close, 10.47\nself.order:  None\n2023-11-01T10:06:00, Close, 10.46\nself.order:  None\n2023-11-01T10:06:00, SELL CREATE, 10.46\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-01T10:07:00, SELL EXECUTED, Price: 10.47, Cost: 10.48, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-01T10:07:00, OPERATION PROFIT: GROSS -0.01, NET -0.03\n2023-11-01T10:07:00, Close, 10.46\nself.order:  None\n2023-11-01T10:08:00, Close, 10.47\nself.order:  None\n2023-11-01T10:09:00, Close, 10.46\nself.order:  None\n2023-11-01T10:10:00, Close, 10.47\nself.order:  None\n2023-11-01T10:11:00, Close, 10.47\nself.order:  None\n2023-11-01T10:12:00, Close, 10.47\nself.order:  None\n2023-11-01T10:13:00, Close, 10.46\nself.order:  None\n2023-11-01T10:14:00, Close, 10.46\nself.order:  None\n2023-11-01T10:15:00, Close, 10.46\nself.order:  None\n2023-11-01T10:16:00, Close, 10.46\nself.order:  None\n2023-11-01T10:17:00, Close, 10.46\nself.order:  None\n2023-11-01T10:18:00, Close, 10.46\nself.order:  None\n2023-11-01T10:19:00, Close, 10.47\nself.order:  None\n2023-11-01T10:20:00, Close, 10.46\nself.order:  None\n2023-11-01T10:21:00, Close, 10.47\nself.order:  None\n2023-11-01T10:22:00, Close, 10.47\nself.order:  None\n2023-11-01T10:23:00, Close, 10.47\nself.order:  None\n2023-11-01T10:24:00, Close, 10.46\nself.order:  None\n2023-11-01T10:25:00, Close, 10.46\nself.order:  None\n2023-11-01T10:26:00, Close, 10.47\nself.order:  None\n2023-11-01T10:27:00, Close, 10.47\nself.order:  None\n2023-11-01T10:28:00, Close, 10.47\nself.order:  None\n2023-11-01T10:29:00, Close, 10.47\nself.order:  None\n2023-11-01T10:30:00, Close, 10.47\nself.order:  None\n2023-11-01T10:31:00, Close, 10.47\nself.order:  None\n2023-11-01T10:32:00, Close, 10.47\nself.order:  None\n2023-11-01T10:33:00, Close, 10.47\nself.order:  None\n2023-11-01T10:34:00, Close, 10.46\nself.order:  None\n2023-11-01T10:35:00, Close, 10.46\nself.order:  None\n2023-11-01T10:36:00, Close, 10.47\nself.order:  None\n2023-11-01T10:37:00, Close, 10.48\nself.order:  None\n2023-11-01T10:38:00, Close, 10.49\nself.order:  None\n2023-11-01T10:39:00, Close, 10.48\nself.order:  None\n2023-11-01T10:40:00, Close, 10.48\nself.order:  None\n2023-11-01T10:41:00, Close, 10.48\nself.order:  None\n2023-11-01T10:42:00, Close, 10.49\nself.order:  None\n2023-11-01T10:43:00, Close, 10.48\nself.order:  None\n2023-11-01T10:44:00, Close, 10.49\nself.order:  None\n2023-11-01T10:45:00, Close, 10.48\nself.order:  None\n2023-11-01T10:46:00, Close, 10.48\nself.order:  None\n2023-11-01T10:47:00, Close, 10.48\nself.order:  None\n2023-11-01T10:48:00, Close, 10.48\nself.order:  None\n2023-11-01T10:49:00, Close, 10.48\nself.order:  None\n2023-11-01T10:50:00, Close, 10.47\nself.order:  None\n2023-11-01T10:51:00, Close, 10.47\nself.order:  None\n2023-11-01T10:52:00, Close, 10.47\nself.order:  None\n2023-11-01T10:53:00, Close, 10.46\nself.order:  None\n2023-11-01T10:54:00, Close, 10.48\nself.order:  None\n2023-11-01T10:55:00, Close, 10.48\nself.order:  None\n2023-11-01T10:56:00, Close, 10.47\nself.order:  None\n2023-11-01T10:57:00, Close, 10.47\nself.order:  None\n2023-11-01T10:58:00, Close, 10.48\nself.order:  None\n2023-11-01T10:59:00, Close, 10.48\nself.order:  None\n2023-11-01T11:00:00, Close, 10.48\nself.order:  None\n2023-11-01T11:01:00, Close, 10.47\nself.order:  None\n2023-11-01T11:02:00, Close, 10.47\nself.order:  None\n2023-11-01T11:03:00, Close, 10.47\nself.order:  None\n2023-11-01T11:04:00, Close, 10.47\nself.order:  None\n2023-11-01T11:05:00, Close, 10.46\nself.order:  None\n2023-11-01T11:06:00, Close, 10.47\nself.order:  None\n2023-11-01T11:07:00, Close, 10.46\nself.order:  None\n2023-11-01T11:08:00, Close, 10.47\nself.order:  None\n2023-11-01T11:09:00, Close, 10.47\nself.order:  None\n2023-11-01T11:10:00, Close, 10.47\nself.order:  None\n2023-11-01T11:11:00, Close, 10.48\nself.order:  None\n2023-11-01T11:12:00, Close, 10.47\nself.order:  None\n2023-11-01T11:13:00, Close, 10.47\nself.order:  None\n2023-11-01T11:14:00, Close, 10.46\nself.order:  None\n2023-11-01T11:15:00, Close, 10.46\nself.order:  None\n2023-11-01T11:16:00, Close, 10.46\nself.order:  None\n2023-11-01T11:17:00, Close, 10.46\nself.order:  None\n2023-11-01T11:18:00, Close, 10.47\nself.order:  None\n2023-11-01T11:19:00, Close, 10.46\nself.order:  None\n2023-11-01T11:20:00, Close, 10.47\nself.order:  None\n2023-11-01T11:21:00, Close, 10.47\nself.order:  None\n2023-11-01T11:22:00, Close, 10.47\nself.order:  None\n2023-11-01T11:23:00, Close, 10.48\nself.order:  None\n2023-11-01T11:24:00, Close, 10.48\nself.order:  None\n2023-11-01T11:25:00, Close, 10.48\nself.order:  None\n2023-11-01T11:26:00, Close, 10.49\nself.order:  None\n2023-11-01T11:27:00, Close, 10.47\nself.order:  None\n2023-11-01T11:28:00, Close, 10.48\nself.order:  None\n2023-11-01T11:29:00, Close, 10.47\nself.order:  None\n2023-11-01T11:30:00, Close, 10.47\nself.order:  None\n2023-11-01T13:01:00, Close, 10.48\nself.order:  None\n2023-11-01T13:02:00, Close, 10.48\nself.order:  None\n2023-11-01T13:03:00, Close, 10.48\nself.order:  None\n2023-11-01T13:04:00, Close, 10.48\nself.order:  None\n2023-11-01T13:05:00, Close, 10.47\nself.order:  None\n2023-11-01T13:06:00, Close, 10.47\nself.order:  None\n2023-11-01T13:07:00, Close, 10.47\nself.order:  None\n2023-11-01T13:08:00, Close, 10.48\nself.order:  None\n2023-11-01T13:09:00, Close, 10.48\nself.order:  None\n2023-11-01T13:10:00, Close, 10.48\nself.order:  None\n2023-11-01T13:11:00, Close, 10.48\nself.order:  None\n2023-11-01T13:12:00, Close, 10.47\nself.order:  None\n2023-11-01T13:13:00, Close, 10.48\nself.order:  None\n2023-11-01T13:14:00, Close, 10.48\nself.order:  None\n2023-11-01T13:15:00, Close, 10.48\nself.order:  None\n2023-11-01T13:16:00, Close, 10.48\nself.order:  None\n2023-11-01T13:17:00, Close, 10.47\nself.order:  None\n2023-11-01T13:18:00, Close, 10.48\nself.order:  None\n2023-11-01T13:19:00, Close, 10.47\nself.order:  None\n2023-11-01T13:20:00, Close, 10.47\nself.order:  None\n2023-11-01T13:21:00, Close, 10.49\nself.order:  None\n2023-11-01T13:22:00, Close, 10.49\nself.order:  None\n2023-11-01T13:23:00, Close, 10.48\nself.order:  None\n2023-11-01T13:24:00, Close, 10.48\nself.order:  None\n2023-11-01T13:25:00, Close, 10.47\nself.order:  None\n2023-11-01T13:26:00, Close, 10.47\nself.order:  None\n2023-11-01T13:27:00, Close, 10.47\nself.order:  None\n2023-11-01T13:28:00, Close, 10.47\nself.order:  None\n2023-11-01T13:29:00, Close, 10.47\nself.order:  None\n2023-11-01T13:30:00, Close, 10.47\nself.order:  None\n2023-11-01T13:31:00, Close, 10.47\nself.order:  None\n2023-11-01T13:32:00, Close, 10.48\nself.order:  None\n2023-11-01T13:33:00, Close, 10.49\nself.order:  None\n2023-11-01T13:34:00, Close, 10.48\nself.order:  None\n2023-11-01T13:35:00, Close, 10.48\nself.order:  None\n2023-11-01T13:36:00, Close, 10.48\nself.order:  None\n2023-11-01T13:37:00, Close, 10.48\nself.order:  None\n2023-11-01T13:38:00, Close, 10.48\nself.order:  None\n2023-11-01T13:39:00, Close, 10.48\nself.order:  None\n2023-11-01T13:40:00, Close, 10.48\nself.order:  None\n2023-11-01T13:41:00, Close, 10.48\nself.order:  None\n2023-11-01T13:42:00, Close, 10.48\nself.order:  None\n2023-11-01T13:43:00, Close, 10.48\nself.order:  None\n2023-11-01T13:44:00, Close, 10.48\nself.order:  None\n2023-11-01T13:45:00, Close, 10.48\nself.order:  None\n2023-11-01T13:46:00, Close, 10.48\nself.order:  None\n2023-11-01T13:47:00, Close, 10.47\nself.order:  None\n2023-11-01T13:48:00, Close, 10.47\nself.order:  None\n2023-11-01T13:49:00, Close, 10.47\nself.order:  None\n2023-11-01T13:50:00, Close, 10.48\nself.order:  None\n2023-11-01T13:51:00, Close, 10.48\nself.order:  None\n2023-11-01T13:52:00, Close, 10.48\nself.order:  None\n2023-11-01T13:53:00, Close, 10.47\nself.order:  None\n2023-11-01T13:54:00, Close, 10.47\nself.order:  None\n2023-11-01T13:55:00, Close, 10.48\nself.order:  None\n2023-11-01T13:56:00, Close, 10.48\nself.order:  None\n2023-11-01T13:57:00, Close, 10.48\nself.order:  None\n2023-11-01T13:58:00, Close, 10.48\nself.order:  None\n2023-11-01T13:59:00, Close, 10.48\nself.order:  None\n2023-11-01T14:00:00, Close, 10.48\nself.order:  None\n2023-11-01T14:01:00, Close, 10.48\nself.order:  None\n2023-11-01T14:02:00, Close, 10.48\nself.order:  None\n2023-11-01T14:03:00, Close, 10.48\nself.order:  None\n2023-11-01T14:04:00, Close, 10.49\nself.order:  None\n2023-11-01T14:05:00, Close, 10.49\nself.order:  None\n2023-11-01T14:06:00, Close, 10.48\nself.order:  None\n2023-11-01T14:07:00, Close, 10.49\nself.order:  None\n2023-11-01T14:08:00, Close, 10.49\nself.order:  None\n2023-11-01T14:09:00, Close, 10.49\nself.order:  None\n2023-11-01T14:10:00, Close, 10.49\nself.order:  None\n2023-11-01T14:11:00, Close, 10.49\nself.order:  None\n2023-11-01T14:12:00, Close, 10.48\nself.order:  None\n2023-11-01T14:13:00, Close, 10.49\nself.order:  None\n2023-11-01T14:14:00, Close, 10.50\nself.order:  None\n2023-11-01T14:15:00, Close, 10.50\nself.order:  None\n2023-11-01T14:16:00, Close, 10.49\nself.order:  None\n2023-11-01T14:17:00, Close, 10.50\nself.order:  None\n2023-11-01T14:18:00, Close, 10.49\nself.order:  None\n2023-11-01T14:19:00, Close, 10.49\nself.order:  None\n2023-11-01T14:20:00, Close, 10.50\nself.order:  None\n2023-11-01T14:21:00, Close, 10.50\nself.order:  None\n2023-11-01T14:22:00, Close, 10.50\nself.order:  None\n2023-11-01T14:23:00, Close, 10.50\nself.order:  None\n2023-11-01T14:24:00, Close, 10.50\nself.order:  None\n2023-11-01T14:25:00, Close, 10.50\nself.order:  None\n2023-11-01T14:26:00, Close, 10.50\nself.order:  None\n2023-11-01T14:27:00, Close, 10.49\nself.order:  None\n2023-11-01T14:28:00, Close, 10.49\nself.order:  None\n2023-11-01T14:29:00, Close, 10.49\nself.order:  None\n2023-11-01T14:30:00, Close, 10.49\nself.order:  None\n2023-11-01T14:31:00, Close, 10.49\nself.order:  None\n2023-11-01T14:32:00, Close, 10.49\nself.order:  None\n2023-11-01T14:33:00, Close, 10.49\nself.order:  None\n2023-11-01T14:34:00, Close, 10.50\nself.order:  None\n2023-11-01T14:35:00, Close, 10.49\nself.order:  None\n2023-11-01T14:36:00, Close, 10.49\nself.order:  None\n2023-11-01T14:37:00, Close, 10.49\nself.order:  None\n2023-11-01T14:38:00, Close, 10.51\nself.order:  None\n2023-11-01T14:39:00, Close, 10.50\nself.order:  None\n2023-11-01T14:40:00, Close, 10.50\nself.order:  None\n2023-11-01T14:41:00, Close, 10.49\nself.order:  None\n2023-11-01T14:42:00, Close, 10.49\nself.order:  None\n2023-11-01T14:43:00, Close, 10.50\nself.order:  None\n2023-11-01T14:44:00, Close, 10.50\nself.order:  None\n2023-11-01T14:45:00, Close, 10.50\nself.order:  None\n2023-11-01T14:46:00, Close, 10.49\nself.order:  None\n2023-11-01T14:47:00, Close, 10.49\nself.order:  None\n2023-11-01T14:48:00, Close, 10.49\nself.order:  None\n2023-11-01T14:49:00, Close, 10.50\nself.order:  None\n2023-11-01T14:50:00, Close, 10.49\nself.order:  None\n2023-11-01T14:51:00, Close, 10.50\nself.order:  None\n2023-11-01T14:52:00, Close, 10.49\nself.order:  None\n2023-11-01T14:53:00, Close, 10.49\nself.order:  None\n2023-11-01T14:54:00, Close, 10.48\nself.order:  None\n2023-11-01T14:55:00, Close, 10.48\nself.order:  None\n2023-11-01T14:56:00, Close, 10.48\nself.order:  None\n2023-11-01T14:57:00, Close, 10.49\nself.order:  None\n2023-11-01T15:00:00, Close, 10.48\nself.order:  None\n2023-11-02T09:31:00, Close, 10.52\nself.order:  None\n2023-11-02T09:32:00, Close, 10.52\nself.order:  None\n2023-11-02T09:33:00, Close, 10.52\nself.order:  None\n2023-11-02T09:34:00, Close, 10.54\nself.order:  None\n2023-11-02T09:35:00, Close, 10.54\nself.order:  None\n2023-11-02T09:36:00, Close, 10.54\nself.order:  None\n2023-11-02T09:37:00, Close, 10.57\nself.order:  None\n2023-11-02T09:38:00, Close, 10.57\nself.order:  None\n2023-11-02T09:39:00, Close, 10.58\nself.order:  None\n2023-11-02T09:40:00, Close, 10.59\nself.order:  None\n2023-11-02T09:41:00, Close, 10.60\nself.order:  None\n2023-11-02T09:42:00, Close, 10.59\nself.order:  None\n2023-11-02T09:43:00, Close, 10.59\nself.order:  None\n2023-11-02T09:44:00, Close, 10.59\nself.order:  None\n2023-11-02T09:45:00, Close, 10.58\nself.order:  None\n2023-11-02T09:46:00, Close, 10.57\nself.order:  None\n2023-11-02T09:46:00, BUY CREATE, 10.57\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-02T09:47:00, BUY EXECUTED, Price: 10.56, Cost: 10.56, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-02T09:47:00, Close, 10.57\nself.order:  None\n2023-11-02T09:48:00, Close, 10.58\nself.order:  None\n2023-11-02T09:49:00, Close, 10.57\nself.order:  None\n2023-11-02T09:50:00, Close, 10.57\nself.order:  None\n2023-11-02T09:51:00, Close, 10.56\nself.order:  None\n2023-11-02T09:52:00, Close, 10.56\nself.order:  None\n2023-11-02T09:52:00, SELL CREATE, 10.56\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-02T09:53:00, SELL EXECUTED, Price: 10.56, Cost: 10.56, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-02T09:53:00, OPERATION PROFIT: GROSS 0.00, NET -0.02\n2023-11-02T09:53:00, Close, 10.56\nself.order:  None\n2023-11-02T09:54:00, Close, 10.55\nself.order:  None\n2023-11-02T09:55:00, Close, 10.55\nself.order:  None\n2023-11-02T09:56:00, Close, 10.55\nself.order:  None\n2023-11-02T09:57:00, Close, 10.55\nself.order:  None\n2023-11-02T09:58:00, Close, 10.55\nself.order:  None\n2023-11-02T09:59:00, Close, 10.55\nself.order:  None\n2023-11-02T10:00:00, Close, 10.54\nself.order:  None\n2023-11-02T10:01:00, Close, 10.55\nself.order:  None\n2023-11-02T10:02:00, Close, 10.54\nself.order:  None\n2023-11-02T10:03:00, Close, 10.53\nself.order:  None\n2023-11-02T10:03:00, BUY CREATE, 10.53\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-02T10:04:00, BUY EXECUTED, Price: 10.53, Cost: 10.53, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-02T10:04:00, Close, 10.53\nself.order:  None\n2023-11-02T10:05:00, Close, 10.52\nself.order:  None\n2023-11-02T10:06:00, Close, 10.53\nself.order:  None\n2023-11-02T10:07:00, Close, 10.53\nself.order:  None\n2023-11-02T10:08:00, Close, 10.51\nself.order:  None\n2023-11-02T10:09:00, Close, 10.52\nself.order:  None\n2023-11-02T10:09:00, SELL CREATE, 10.52\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-02T10:10:00, SELL EXECUTED, Price: 10.52, Cost: 10.53, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-02T10:10:00, OPERATION PROFIT: GROSS -0.01, NET -0.03\n2023-11-02T10:10:00, Close, 10.52\nself.order:  None\n2023-11-02T10:11:00, Close, 10.52\nself.order:  None\n2023-11-02T10:12:00, Close, 10.51\nself.order:  None\n2023-11-02T10:13:00, Close, 10.52\nself.order:  None\n2023-11-02T10:14:00, Close, 10.52\nself.order:  None\n2023-11-02T10:15:00, Close, 10.52\nself.order:  None\n2023-11-02T10:16:00, Close, 10.52\nself.order:  None\n2023-11-02T10:17:00, Close, 10.54\nself.order:  None\n2023-11-02T10:18:00, Close, 10.54\nself.order:  None\n2023-11-02T10:19:00, Close, 10.52\nself.order:  None\n2023-11-02T10:20:00, Close, 10.52\nself.order:  None\n2023-11-02T10:21:00, Close, 10.53\nself.order:  None\n2023-11-02T10:22:00, Close, 10.52\nself.order:  None\n2023-11-02T10:23:00, Close, 10.52\nself.order:  None\n2023-11-02T10:24:00, Close, 10.51\nself.order:  None\n2023-11-02T10:25:00, Close, 10.51\nself.order:  None\n2023-11-02T10:26:00, Close, 10.51\nself.order:  None\n2023-11-02T10:27:00, Close, 10.51\nself.order:  None\n2023-11-02T10:28:00, Close, 10.51\nself.order:  None\n2023-11-02T10:29:00, Close, 10.51\nself.order:  None\n2023-11-02T10:30:00, Close, 10.51\nself.order:  None\n2023-11-02T10:31:00, Close, 10.51\nself.order:  None\n2023-11-02T10:32:00, Close, 10.52\nself.order:  None\n2023-11-02T10:33:00, Close, 10.51\nself.order:  None\n2023-11-02T10:34:00, Close, 10.51\nself.order:  None\n2023-11-02T10:35:00, Close, 10.52\nself.order:  None\n2023-11-02T10:36:00, Close, 10.51\nself.order:  None\n2023-11-02T10:37:00, Close, 10.52\nself.order:  None\n2023-11-02T10:38:00, Close, 10.52\nself.order:  None\n2023-11-02T10:39:00, Close, 10.51\nself.order:  None\n2023-11-02T10:40:00, Close, 10.52\nself.order:  None\n2023-11-02T10:41:00, Close, 10.52\nself.order:  None\n2023-11-02T10:42:00, Close, 10.52\nself.order:  None\n2023-11-02T10:43:00, Close, 10.52\nself.order:  None\n2023-11-02T10:44:00, Close, 10.53\nself.order:  None\n2023-11-02T10:45:00, Close, 10.52\nself.order:  None\n2023-11-02T10:46:00, Close, 10.52\nself.order:  None\n2023-11-02T10:47:00, Close, 10.52\nself.order:  None\n2023-11-02T10:48:00, Close, 10.53\nself.order:  None\n2023-11-02T10:49:00, Close, 10.52\nself.order:  None\n2023-11-02T10:50:00, Close, 10.52\nself.order:  None\n2023-11-02T10:51:00, Close, 10.52\nself.order:  None\n2023-11-02T10:52:00, Close, 10.54\nself.order:  None\n2023-11-02T10:53:00, Close, 10.53\nself.order:  None\n2023-11-02T10:54:00, Close, 10.53\nself.order:  None\n2023-11-02T10:55:00, Close, 10.53\nself.order:  None\n2023-11-02T10:56:00, Close, 10.52\nself.order:  None\n2023-11-02T10:57:00, Close, 10.52\nself.order:  None\n2023-11-02T10:58:00, Close, 10.52\nself.order:  None\n2023-11-02T10:59:00, Close, 10.52\nself.order:  None\n2023-11-02T11:00:00, Close, 10.53\nself.order:  None\n2023-11-02T11:01:00, Close, 10.52\nself.order:  None\n2023-11-02T11:02:00, Close, 10.52\nself.order:  None\n2023-11-02T11:03:00, Close, 10.53\nself.order:  None\n2023-11-02T11:04:00, Close, 10.52\nself.order:  None\n2023-11-02T11:05:00, Close, 10.53\nself.order:  None\n2023-11-02T11:06:00, Close, 10.53\nself.order:  None\n2023-11-02T11:07:00, Close, 10.52\nself.order:  None\n2023-11-02T11:08:00, Close, 10.53\nself.order:  None\n2023-11-02T11:09:00, Close, 10.53\nself.order:  None\n2023-11-02T11:10:00, Close, 10.52\nself.order:  None\n2023-11-02T11:11:00, Close, 10.53\nself.order:  None\n2023-11-02T11:12:00, Close, 10.52\nself.order:  None\n2023-11-02T11:13:00, Close, 10.53\nself.order:  None\n2023-11-02T11:14:00, Close, 10.53\nself.order:  None\n2023-11-02T11:15:00, Close, 10.55\nself.order:  None\n2023-11-02T11:16:00, Close, 10.55\nself.order:  None\n2023-11-02T11:17:00, Close, 10.54\nself.order:  None\n2023-11-02T11:18:00, Close, 10.54\nself.order:  None\n2023-11-02T11:19:00, Close, 10.55\nself.order:  None\n2023-11-02T11:20:00, Close, 10.55\nself.order:  None\n2023-11-02T11:21:00, Close, 10.54\nself.order:  None\n2023-11-02T11:22:00, Close, 10.54\nself.order:  None\n2023-11-02T11:23:00, Close, 10.54\nself.order:  None\n2023-11-02T11:24:00, Close, 10.54\nself.order:  None\n2023-11-02T11:25:00, Close, 10.55\nself.order:  None\n2023-11-02T11:26:00, Close, 10.54\nself.order:  None\n2023-11-02T11:27:00, Close, 10.54\nself.order:  None\n2023-11-02T11:28:00, Close, 10.54\nself.order:  None\n2023-11-02T11:29:00, Close, 10.54\nself.order:  None\n2023-11-02T11:30:00, Close, 10.54\nself.order:  None\n2023-11-02T13:01:00, Close, 10.53\nself.order:  None\n2023-11-02T13:02:00, Close, 10.53\nself.order:  None\n2023-11-02T13:03:00, Close, 10.54\nself.order:  None\n2023-11-02T13:04:00, Close, 10.53\nself.order:  None\n2023-11-02T13:05:00, Close, 10.52\nself.order:  None\n2023-11-02T13:05:00, BUY CREATE, 10.52\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-02T13:06:00, BUY EXECUTED, Price: 10.52, Cost: 10.52, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-02T13:06:00, Close, 10.52\nself.order:  None\n2023-11-02T13:07:00, Close, 10.53\nself.order:  None\n2023-11-02T13:08:00, Close, 10.51\nself.order:  None\n2023-11-02T13:09:00, Close, 10.51\nself.order:  None\n2023-11-02T13:10:00, Close, 10.52\nself.order:  None\n2023-11-02T13:11:00, Close, 10.52\nself.order:  None\n2023-11-02T13:11:00, SELL CREATE, 10.52\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-02T13:12:00, SELL EXECUTED, Price: 10.51, Cost: 10.52, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-02T13:12:00, OPERATION PROFIT: GROSS -0.01, NET -0.03\n2023-11-02T13:12:00, Close, 10.51\nself.order:  None\n2023-11-02T13:13:00, Close, 10.51\nself.order:  None\n2023-11-02T13:14:00, Close, 10.52\nself.order:  None\n2023-11-02T13:15:00, Close, 10.52\nself.order:  None\n2023-11-02T13:16:00, Close, 10.51\nself.order:  None\n2023-11-02T13:17:00, Close, 10.51\nself.order:  None\n2023-11-02T13:18:00, Close, 10.51\nself.order:  None\n2023-11-02T13:19:00, Close, 10.51\nself.order:  None\n2023-11-02T13:20:00, Close, 10.52\nself.order:  None\n2023-11-02T13:21:00, Close, 10.51\nself.order:  None\n2023-11-02T13:22:00, Close, 10.52\nself.order:  None\n2023-11-02T13:23:00, Close, 10.52\nself.order:  None\n2023-11-02T13:24:00, Close, 10.52\nself.order:  None\n2023-11-02T13:25:00, Close, 10.51\nself.order:  None\n2023-11-02T13:26:00, Close, 10.51\nself.order:  None\n2023-11-02T13:27:00, Close, 10.51\nself.order:  None\n2023-11-02T13:28:00, Close, 10.52\nself.order:  None\n2023-11-02T13:29:00, Close, 10.52\nself.order:  None\n2023-11-02T13:30:00, Close, 10.51\nself.order:  None\n2023-11-02T13:31:00, Close, 10.51\nself.order:  None\n2023-11-02T13:32:00, Close, 10.51\nself.order:  None\n2023-11-02T13:33:00, Close, 10.51\nself.order:  None\n2023-11-02T13:34:00, Close, 10.51\nself.order:  None\n2023-11-02T13:35:00, Close, 10.52\nself.order:  None\n2023-11-02T13:36:00, Close, 10.51\nself.order:  None\n2023-11-02T13:37:00, Close, 10.52\nself.order:  None\n2023-11-02T13:38:00, Close, 10.51\nself.order:  None\n2023-11-02T13:39:00, Close, 10.52\nself.order:  None\n2023-11-02T13:40:00, Close, 10.51\nself.order:  None\n2023-11-02T13:41:00, Close, 10.51\nself.order:  None\n2023-11-02T13:42:00, Close, 10.51\nself.order:  None\n2023-11-02T13:43:00, Close, 10.51\nself.order:  None\n2023-11-02T13:44:00, Close, 10.52\nself.order:  None\n2023-11-02T13:45:00, Close, 10.52\nself.order:  None\n2023-11-02T13:46:00, Close, 10.52\nself.order:  None\n2023-11-02T13:47:00, Close, 10.52\nself.order:  None\n2023-11-02T13:48:00, Close, 10.52\nself.order:  None\n2023-11-02T13:49:00, Close, 10.52\nself.order:  None\n2023-11-02T13:50:00, Close, 10.52\nself.order:  None\n2023-11-02T13:51:00, Close, 10.51\nself.order:  None\n2023-11-02T13:52:00, Close, 10.52\nself.order:  None\n2023-11-02T13:53:00, Close, 10.51\nself.order:  None\n2023-11-02T13:54:00, Close, 10.51\nself.order:  None\n2023-11-02T13:55:00, Close, 10.51\nself.order:  None\n2023-11-02T13:56:00, Close, 10.52\nself.order:  None\n2023-11-02T13:57:00, Close, 10.50\nself.order:  None\n2023-11-02T13:58:00, Close, 10.50\nself.order:  None\n2023-11-02T13:59:00, Close, 10.50\nself.order:  None\n2023-11-02T14:00:00, Close, 10.49\nself.order:  None\n2023-11-02T14:01:00, Close, 10.49\nself.order:  None\n2023-11-02T14:02:00, Close, 10.49\nself.order:  None\n2023-11-02T14:03:00, Close, 10.49\nself.order:  None\n2023-11-02T14:04:00, Close, 10.50\nself.order:  None\n2023-11-02T14:05:00, Close, 10.49\nself.order:  None\n2023-11-02T14:06:00, Close, 10.49\nself.order:  None\n2023-11-02T14:07:00, Close, 10.49\nself.order:  None\n2023-11-02T14:08:00, Close, 10.48\nself.order:  None\n2023-11-02T14:09:00, Close, 10.49\nself.order:  None\n2023-11-02T14:10:00, Close, 10.50\nself.order:  None\n2023-11-02T14:11:00, Close, 10.50\nself.order:  None\n2023-11-02T14:12:00, Close, 10.49\nself.order:  None\n2023-11-02T14:13:00, Close, 10.49\nself.order:  None\n2023-11-02T14:14:00, Close, 10.50\nself.order:  None\n2023-11-02T14:15:00, Close, 10.49\nself.order:  None\n2023-11-02T14:16:00, Close, 10.49\nself.order:  None\n2023-11-02T14:17:00, Close, 10.50\nself.order:  None\n2023-11-02T14:18:00, Close, 10.49\nself.order:  None\n2023-11-02T14:19:00, Close, 10.50\nself.order:  None\n2023-11-02T14:20:00, Close, 10.51\nself.order:  None\n2023-11-02T14:21:00, Close, 10.50\nself.order:  None\n2023-11-02T14:22:00, Close, 10.50\nself.order:  None\n2023-11-02T14:23:00, Close, 10.50\nself.order:  None\n2023-11-02T14:24:00, Close, 10.50\nself.order:  None\n2023-11-02T14:25:00, Close, 10.50\nself.order:  None\n2023-11-02T14:26:00, Close, 10.50\nself.order:  None\n2023-11-02T14:27:00, Close, 10.50\nself.order:  None\n2023-11-02T14:28:00, Close, 10.50\nself.order:  None\n2023-11-02T14:29:00, Close, 10.51\nself.order:  None\n2023-11-02T14:30:00, Close, 10.51\nself.order:  None\n2023-11-02T14:31:00, Close, 10.50\nself.order:  None\n2023-11-02T14:32:00, Close, 10.50\nself.order:  None\n2023-11-02T14:33:00, Close, 10.50\nself.order:  None\n2023-11-02T14:34:00, Close, 10.50\nself.order:  None\n2023-11-02T14:35:00, Close, 10.50\nself.order:  None\n2023-11-02T14:36:00, Close, 10.51\nself.order:  None\n2023-11-02T14:37:00, Close, 10.50\nself.order:  None\n2023-11-02T14:38:00, Close, 10.50\nself.order:  None\n2023-11-02T14:39:00, Close, 10.50\nself.order:  None\n2023-11-02T14:40:00, Close, 10.50\nself.order:  None\n2023-11-02T14:41:00, Close, 10.50\nself.order:  None\n2023-11-02T14:42:00, Close, 10.49\nself.order:  None\n2023-11-02T14:43:00, Close, 10.50\nself.order:  None\n2023-11-02T14:44:00, Close, 10.50\nself.order:  None\n2023-11-02T14:45:00, Close, 10.50\nself.order:  None\n2023-11-02T14:46:00, Close, 10.49\nself.order:  None\n2023-11-02T14:47:00, Close, 10.49\nself.order:  None\n2023-11-02T14:48:00, Close, 10.49\nself.order:  None\n2023-11-02T14:49:00, Close, 10.48\nself.order:  None\n2023-11-02T14:50:00, Close, 10.49\nself.order:  None\n2023-11-02T14:51:00, Close, 10.48\nself.order:  None\n2023-11-02T14:52:00, Close, 10.49\nself.order:  None\n2023-11-02T14:53:00, Close, 10.48\nself.order:  None\n2023-11-02T14:54:00, Close, 10.48\nself.order:  None\n2023-11-02T14:55:00, Close, 10.49\nself.order:  None\n2023-11-02T14:56:00, Close, 10.49\nself.order:  None\n2023-11-02T14:57:00, Close, 10.49\nself.order:  None\n2023-11-02T15:00:00, Close, 10.48\nself.order:  None\n2023-11-03T09:31:00, Close, 10.50\nself.order:  None\n2023-11-03T09:32:00, Close, 10.48\nself.order:  None\n2023-11-03T09:33:00, Close, 10.46\nself.order:  None\n2023-11-03T09:33:00, BUY CREATE, 10.46\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-03T09:34:00, BUY EXECUTED, Price: 10.47, Cost: 10.47, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-03T09:34:00, Close, 10.47\nself.order:  None\n2023-11-03T09:35:00, Close, 10.47\nself.order:  None\n2023-11-03T09:36:00, Close, 10.48\nself.order:  None\n2023-11-03T09:37:00, Close, 10.50\nself.order:  None\n2023-11-03T09:38:00, Close, 10.50\nself.order:  None\n2023-11-03T09:39:00, Close, 10.50\nself.order:  None\n2023-11-03T09:39:00, SELL CREATE, 10.50\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-03T09:40:00, SELL EXECUTED, Price: 10.50, Cost: 10.47, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-03T09:40:00, OPERATION PROFIT: GROSS 0.03, NET 0.01\n2023-11-03T09:40:00, Close, 10.50\nself.order:  None\n2023-11-03T09:41:00, Close, 10.50\nself.order:  None\n2023-11-03T09:42:00, Close, 10.49\nself.order:  None\n2023-11-03T09:43:00, Close, 10.50\nself.order:  None\n2023-11-03T09:44:00, Close, 10.49\nself.order:  None\n2023-11-03T09:45:00, Close, 10.49\nself.order:  None\n2023-11-03T09:46:00, Close, 10.47\nself.order:  None\n2023-11-03T09:47:00, Close, 10.48\nself.order:  None\n2023-11-03T09:48:00, Close, 10.47\nself.order:  None\n2023-11-03T09:49:00, Close, 10.48\nself.order:  None\n2023-11-03T09:50:00, Close, 10.47\nself.order:  None\n2023-11-03T09:51:00, Close, 10.46\nself.order:  None\n2023-11-03T09:51:00, BUY CREATE, 10.46\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-03T09:52:00, BUY EXECUTED, Price: 10.46, Cost: 10.46, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-03T09:52:00, Close, 10.47\nself.order:  None\n2023-11-03T09:53:00, Close, 10.45\nself.order:  None\n2023-11-03T09:54:00, Close, 10.46\nself.order:  None\n2023-11-03T09:55:00, Close, 10.44\nself.order:  None\n2023-11-03T09:56:00, Close, 10.44\nself.order:  None\n2023-11-03T09:57:00, Close, 10.44\nself.order:  None\n2023-11-03T09:57:00, SELL CREATE, 10.44\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-03T09:58:00, SELL EXECUTED, Price: 10.44, Cost: 10.46, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-03T09:58:00, OPERATION PROFIT: GROSS -0.02, NET -0.04\n2023-11-03T09:58:00, Close, 10.45\nself.order:  None\n2023-11-03T09:59:00, Close, 10.45\nself.order:  None\n2023-11-03T10:00:00, Close, 10.45\nself.order:  None\n2023-11-03T10:01:00, Close, 10.45\nself.order:  None\n2023-11-03T10:02:00, Close, 10.46\nself.order:  None\n2023-11-03T10:03:00, Close, 10.45\nself.order:  None\n2023-11-03T10:04:00, Close, 10.45\nself.order:  None\n2023-11-03T10:05:00, Close, 10.45\nself.order:  None\n2023-11-03T10:06:00, Close, 10.45\nself.order:  None\n2023-11-03T10:07:00, Close, 10.45\nself.order:  None\n2023-11-03T10:08:00, Close, 10.46\nself.order:  None\n2023-11-03T10:09:00, Close, 10.46\nself.order:  None\n2023-11-03T10:10:00, Close, 10.45\nself.order:  None\n2023-11-03T10:11:00, Close, 10.45\nself.order:  None\n2023-11-03T10:12:00, Close, 10.45\nself.order:  None\n2023-11-03T10:13:00, Close, 10.46\nself.order:  None\n2023-11-03T10:14:00, Close, 10.47\nself.order:  None\n2023-11-03T10:15:00, Close, 10.48\nself.order:  None\n2023-11-03T10:16:00, Close, 10.47\nself.order:  None\n2023-11-03T10:17:00, Close, 10.48\nself.order:  None\n2023-11-03T10:18:00, Close, 10.46\nself.order:  None\n2023-11-03T10:19:00, Close, 10.46\nself.order:  None\n2023-11-03T10:20:00, Close, 10.47\nself.order:  None\n2023-11-03T10:21:00, Close, 10.47\nself.order:  None\n2023-11-03T10:22:00, Close, 10.47\nself.order:  None\n2023-11-03T10:23:00, Close, 10.47\nself.order:  None\n2023-11-03T10:24:00, Close, 10.46\nself.order:  None\n2023-11-03T10:25:00, Close, 10.47\nself.order:  None\n2023-11-03T10:26:00, Close, 10.46\nself.order:  None\n2023-11-03T10:27:00, Close, 10.46\nself.order:  None\n2023-11-03T10:28:00, Close, 10.47\nself.order:  None\n2023-11-03T10:29:00, Close, 10.46\nself.order:  None\n2023-11-03T10:30:00, Close, 10.46\nself.order:  None\n2023-11-03T10:31:00, Close, 10.47\nself.order:  None\n2023-11-03T10:32:00, Close, 10.48\nself.order:  None\n2023-11-03T10:33:00, Close, 10.48\nself.order:  None\n2023-11-03T10:34:00, Close, 10.49\nself.order:  None\n2023-11-03T10:35:00, Close, 10.49\nself.order:  None\n2023-11-03T10:36:00, Close, 10.49\nself.order:  None\n2023-11-03T10:37:00, Close, 10.50\nself.order:  None\n2023-11-03T10:38:00, Close, 10.51\nself.order:  None\n2023-11-03T10:39:00, Close, 10.52\nself.order:  None\n2023-11-03T10:40:00, Close, 10.52\nself.order:  None\n2023-11-03T10:41:00, Close, 10.52\nself.order:  None\n2023-11-03T10:42:00, Close, 10.51\nself.order:  None\n2023-11-03T10:43:00, Close, 10.50\nself.order:  None\n2023-11-03T10:43:00, BUY CREATE, 10.50\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-03T10:44:00, BUY EXECUTED, Price: 10.50, Cost: 10.50, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-03T10:44:00, Close, 10.50\nself.order:  None\n2023-11-03T10:45:00, Close, 10.51\nself.order:  None\n2023-11-03T10:46:00, Close, 10.50\nself.order:  None\n2023-11-03T10:47:00, Close, 10.51\nself.order:  None\n2023-11-03T10:48:00, Close, 10.50\nself.order:  None\n2023-11-03T10:49:00, Close, 10.50\nself.order:  None\n2023-11-03T10:49:00, SELL CREATE, 10.50\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-03T10:50:00, SELL EXECUTED, Price: 10.50, Cost: 10.50, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-03T10:50:00, OPERATION PROFIT: GROSS 0.00, NET -0.02\n2023-11-03T10:50:00, Close, 10.51\nself.order:  None\n2023-11-03T10:51:00, Close, 10.51\nself.order:  None\n2023-11-03T10:52:00, Close, 10.50\nself.order:  None\n2023-11-03T10:53:00, Close, 10.51\nself.order:  None\n2023-11-03T10:54:00, Close, 10.51\nself.order:  None\n2023-11-03T10:55:00, Close, 10.50\nself.order:  None\n2023-11-03T10:56:00, Close, 10.50\nself.order:  None\n2023-11-03T10:57:00, Close, 10.49\nself.order:  None\n2023-11-03T10:58:00, Close, 10.50\nself.order:  None\n2023-11-03T10:59:00, Close, 10.50\nself.order:  None\n2023-11-03T11:00:00, Close, 10.49\nself.order:  None\n2023-11-03T11:01:00, Close, 10.50\nself.order:  None\n2023-11-03T11:02:00, Close, 10.50\nself.order:  None\n2023-11-03T11:03:00, Close, 10.50\nself.order:  None\n2023-11-03T11:04:00, Close, 10.50\nself.order:  None\n2023-11-03T11:05:00, Close, 10.49\nself.order:  None\n2023-11-03T11:06:00, Close, 10.49\nself.order:  None\n2023-11-03T11:07:00, Close, 10.49\nself.order:  None\n2023-11-03T11:08:00, Close, 10.49\nself.order:  None\n2023-11-03T11:09:00, Close, 10.49\nself.order:  None\n2023-11-03T11:10:00, Close, 10.49\nself.order:  None\n2023-11-03T11:11:00, Close, 10.49\nself.order:  None\n2023-11-03T11:12:00, Close, 10.50\nself.order:  None\n2023-11-03T11:13:00, Close, 10.49\nself.order:  None\n2023-11-03T11:14:00, Close, 10.49\nself.order:  None\n2023-11-03T11:15:00, Close, 10.49\nself.order:  None\n2023-11-03T11:16:00, Close, 10.49\nself.order:  None\n2023-11-03T11:17:00, Close, 10.50\nself.order:  None\n2023-11-03T11:18:00, Close, 10.49\nself.order:  None\n2023-11-03T11:19:00, Close, 10.50\nself.order:  None\n2023-11-03T11:20:00, Close, 10.50\nself.order:  None\n2023-11-03T11:21:00, Close, 10.50\nself.order:  None\n2023-11-03T11:22:00, Close, 10.50\nself.order:  None\n2023-11-03T11:23:00, Close, 10.50\nself.order:  None\n2023-11-03T11:24:00, Close, 10.50\nself.order:  None\n2023-11-03T11:25:00, Close, 10.50\nself.order:  None\n2023-11-03T11:26:00, Close, 10.50\nself.order:  None\n2023-11-03T11:27:00, Close, 10.50\nself.order:  None\n2023-11-03T11:28:00, Close, 10.50\nself.order:  None\n2023-11-03T11:29:00, Close, 10.49\nself.order:  None\n2023-11-03T11:30:00, Close, 10.49\nself.order:  None\n2023-11-03T13:01:00, Close, 10.49\nself.order:  None\n2023-11-03T13:02:00, Close, 10.49\nself.order:  None\n2023-11-03T13:03:00, Close, 10.50\nself.order:  None\n2023-11-03T13:04:00, Close, 10.49\nself.order:  None\n2023-11-03T13:05:00, Close, 10.48\nself.order:  None\n2023-11-03T13:05:00, BUY CREATE, 10.48\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-03T13:06:00, BUY EXECUTED, Price: 10.48, Cost: 10.48, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-03T13:06:00, Close, 10.50\nself.order:  None\n2023-11-03T13:07:00, Close, 10.48\nself.order:  None\n2023-11-03T13:08:00, Close, 10.50\nself.order:  None\n2023-11-03T13:09:00, Close, 10.48\nself.order:  None\n2023-11-03T13:10:00, Close, 10.49\nself.order:  None\n2023-11-03T13:11:00, Close, 10.49\nself.order:  None\n2023-11-03T13:11:00, SELL CREATE, 10.49\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 1 Submitted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 2 Accepted\n\u5728\u4e00\u6b21\u8ba2\u5355\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_order\u51fd\u6570\norder.status: 4 Completed\n2023-11-03T13:12:00, SELL EXECUTED, Price: 10.49, Cost: 10.48, Comm 0.01\n\u5728\u4e00\u6b21\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u65f6\u90fd\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\n2023-11-03T13:12:00, OPERATION PROFIT: GROSS 0.01, NET -0.01\n2023-11-03T13:12:00, Close, 10.49\nself.order:  None\n2023-11-03T13:13:00, Close, 10.49\nself.order:  None\n2023-11-03T13:14:00, Close, 10.49\nself.order:  None\n2023-11-03T13:15:00, Close, 10.48\nself.order:  None\n2023-11-03T13:16:00, Close, 10.49\nself.order:  None\n2023-11-03T13:17:00, Close, 10.49\nself.order:  None\n2023-11-03T13:18:00, Close, 10.48\nself.order:  None\n2023-11-03T13:19:00, Close, 10.48\nself.order:  None\n2023-11-03T13:20:00, Close, 10.48\nself.order:  None\n2023-11-03T13:21:00, Close, 10.49\nself.order:  None\n2023-11-03T13:22:00, Close, 10.48\nself.order:  None\n2023-11-03T13:23:00, Close, 10.48\nself.order:  None\n2023-11-03T13:24:00, Close, 10.49\nself.order:  None\n2023-11-03T13:25:00, Close, 10.49\nself.order:  None\n2023-11-03T13:26:00, Close, 10.49\nself.order:  None\n2023-11-03T13:27:00, Close, 10.48\nself.order:  None\n2023-11-03T13:28:00, Close, 10.48\nself.order:  None\n2023-11-03T13:29:00, Close, 10.49\nself.order:  None\n2023-11-03T13:30:00, Close, 10.48\nself.order:  None\n2023-11-03T13:31:00, Close, 10.48\nself.order:  None\n2023-11-03T13:32:00, Close, 10.48\nself.order:  None\n2023-11-03T13:33:00, Close, 10.48\nself.order:  None\n2023-11-03T13:34:00, Close, 10.48\nself.order:  None\n2023-11-03T13:35:00, Close, 10.49\nself.order:  None\n2023-11-03T13:36:00, Close, 10.48\nself.order:  None\n2023-11-03T13:37:00, Close, 10.48\nself.order:  None\n2023-11-03T13:38:00, Close, 10.48\nself.order:  None\n2023-11-03T13:39:00, Close, 10.48\nself.order:  None\n2023-11-03T13:40:00, Close, 10.47\nself.order:  None\n2023-11-03T13:41:00, Close, 10.47\nself.order:  None\n2023-11-03T13:42:00, Close, 10.47\nself.order:  None\n2023-11-03T13:43:00, Close, 10.47\nself.order:  None\n2023-11-03T13:44:00, Close, 10.48\nself.order:  None\n2023-11-03T13:45:00, Close, 10.46\nself.order:  None\n2023-11-03T13:46:00, Close, 10.47\nself.order:  None\n2023-11-03T13:47:00, Close, 10.45\nself.order:  None\n2023-11-03T13:48:00, Close, 10.46\nself.order:  None\n2023-11-03T13:49:00, Close, 10.46\nself.order:  None\n2023-11-03T13:50:00, Close, 10.46\nself.order:  None\n2023-11-03T13:51:00, Close, 10.46\nself.order:  None\n2023-11-03T13:52:00, Close, 10.45\nself.order:  None\n2023-11-03T13:53:00, Close, 10.45\nself.order:  None\n2023-11-03T13:54:00, Close, 10.46\nself.order:  None\n2023-11-03T13:55:00, Close, 10.45\nself.order:  None\n2023-11-03T13:56:00, Close, 10.45\nself.order:  None\n2023-11-03T13:57:00, Close, 10.45\nself.order:  None\n2023-11-03T13:58:00, Close, 10.46\nself.order:  None\n2023-11-03T13:59:00, Close, 10.46\nself.order:  None\n2023-11-03T14:00:00, Close, 10.45\nself.order:  None\n2023-11-03T14:01:00, Close, 10.45\nself.order:  None\n2023-11-03T14:02:00, Close, 10.45\nself.order:  None\n2023-11-03T14:03:00, Close, 10.46\nself.order:  None\n2023-11-03T14:04:00, Close, 10.46\nself.order:  None\n2023-11-03T14:05:00, Close, 10.46\nself.order:  None\n2023-11-03T14:06:00, Close, 10.47\nself.order:  None\n2023-11-03T14:07:00, Close, 10.47\nself.order:  None\n2023-11-03T14:08:00, Close, 10.48\nself.order:  None\n2023-11-03T14:09:00, Close, 10.48\nself.order:  None\n2023-11-03T14:10:00, Close, 10.47\nself.order:  None\n2023-11-03T14:11:00, Close, 10.47\nself.order:  None\n2023-11-03T14:12:00, Close, 10.46\nself.order:  None\n2023-11-03T14:13:00, Close, 10.46\nself.order:  None\n2023-11-03T14:14:00, Close, 10.46\nself.order:  None\n2023-11-03T14:15:00, Close, 10.47\nself.order:  None\n2023-11-03T14:16:00, Close, 10.47\nself.order:  None\n2023-11-03T14:17:00, Close, 10.47\nself.order:  None\n2023-11-03T14:18:00, Close, 10.47\nself.order:  None\n2023-11-03T14:19:00, Close, 10.46\nself.order:  None\n2023-11-03T14:20:00, Close, 10.46\nself.order:  None\n2023-11-03T14:21:00, Close, 10.47\nself.order:  None\n2023-11-03T14:22:00, Close, 10.47\nself.order:  None\n2023-11-03T14:23:00, Close, 10.47\nself.order:  None\n2023-11-03T14:24:00, Close, 10.46\nself.order:  None\n2023-11-03T14:25:00, Close, 10.46\nself.order:  None\n2023-11-03T14:26:00, Close, 10.46\nself.order:  None\n2023-11-03T14:27:00, Close, 10.46\nself.order:  None\n2023-11-03T14:28:00, Close, 10.46\nself.order:  None\n2023-11-03T14:29:00, Close, 10.47\nself.order:  None\n2023-11-03T14:30:00, Close, 10.47\nself.order:  None\n2023-11-03T14:31:00, Close, 10.46\nself.order:  None\n2023-11-03T14:32:00, Close, 10.46\nself.order:  None\n2023-11-03T14:33:00, Close, 10.47\nself.order:  None\n2023-11-03T14:34:00, Close, 10.46\nself.order:  None\n2023-11-03T14:35:00, Close, 10.46\nself.order:  None\n2023-11-03T14:36:00, Close, 10.46\nself.order:  None\n2023-11-03T14:37:00, Close, 10.47\nself.order:  None\n2023-11-03T14:38:00, Close, 10.46\nself.order:  None\n2023-11-03T14:39:00, Close, 10.47\nself.order:  None\n2023-11-03T14:40:00, Close, 10.46\nself.order:  None\n2023-11-03T14:41:00, Close, 10.46\nself.order:  None\n2023-11-03T14:42:00, Close, 10.45\nself.order:  None\n2023-11-03T14:43:00, Close, 10.46\nself.order:  None\n2023-11-03T14:44:00, Close, 10.46\nself.order:  None\n2023-11-03T14:45:00, Close, 10.46\nself.order:  None\n2023-11-03T14:46:00, Close, 10.46\nself.order:  None\n2023-11-03T14:47:00, Close, 10.46\nself.order:  None\n2023-11-03T14:48:00, Close, 10.46\nself.order:  None\n2023-11-03T14:49:00, Close, 10.47\nself.order:  None\n2023-11-03T14:50:00, Close, 10.46\nself.order:  None\n2023-11-03T14:51:00, Close, 10.46\nself.order:  None\n2023-11-03T14:52:00, Close, 10.46\nself.order:  None\n2023-11-03T14:53:00, Close, 10.46\nself.order:  None\n2023-11-03T14:54:00, Close, 10.46\nself.order:  None\n2023-11-03T14:55:00, Close, 10.46\nself.order:  None\n2023-11-03T14:56:00, Close, 10.46\nself.order:  None\n2023-11-03T14:57:00, Close, 10.46\nself.order:  None\n2023-11-03T15:00:00, Close, 10.48\nself.order:  None\nFinal Portfolio Value: 99999.26\n</pre> In\u00a0[110]: Copied! <pre>from __future__ import (absolute_import, division, print_function,\n                        unicode_literals)\n\nimport datetime  # For datetime objects\nimport os.path  # To manage paths\nimport sys  # To find out the script name (in argv[0])\n\n# Import the backtrader platform\nimport backtrader as bt\n\n\n# Create a Stratey\nclass TestStrategy(bt.Strategy):\n    # \u5176\u5b9e\u5c31\u662f\u5b9a\u4e49\u4e86\u4e00\u4e2aTestStrategy\u7684\u7c7b\u53c2\u6570\uff0c\u8fd9\u91cc\u7684wla\u4e5f\u662f\u7c7b\u53c2\u6570\u3002\n    # \u5b9a\u4e49\u6210params\u540d\u79f0\uff0c\u7528tuple\u7c7b\u578b\u5b58\u653e\u5c31\u53ef\u4ee5\u7528self.params.exitbars\u8fd9\u79cd\u65b9\u6cd5\u65b9\u4fbf\u5730\u8c03\u7528\n    params = (\n        ('exitbars', 5),\n    )\n    wla = 'wla'\n\n    def log(self, txt, dt=None):\n        ''' Logging function fot this strategy'''\n        dt = dt or self.datas[0].datetime.date(0)\n        print('%s, %s' % (dt.isoformat(), txt))\n\n    def __init__(self):\n        # Keep a reference to the \"close\" line in the data[0] dataseries\n        self.dataclose = self.datas[0].close\n\n        # To keep track of pending orders and buy price/commission\n        self.order = None\n        self.buyprice = None\n        self.buycomm = None\n\n    def notify_order(self, order):\n        if order.status in [order.Submitted, order.Accepted]:\n            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n            return\n\n        # Check if an order has been completed\n        # Attention: broker could reject order if not enough cash\n        if order.status in [order.Completed]:\n            if order.isbuy():\n                self.log(\n                    'BUY EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %\n                    (order.executed.price,\n                     order.executed.value,\n                     order.executed.comm))\n\n                self.buyprice = order.executed.price\n                self.buycomm = order.executed.comm\n            else:  # Sell\n                self.log('SELL EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %\n                         (order.executed.price,\n                          order.executed.value,\n                          order.executed.comm))\n\n            self.bar_executed = len(self)\n\n        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n            self.log('Order Canceled/Margin/Rejected')\n\n        self.order = None\n\n    def notify_trade(self, trade):\n        if not trade.isclosed:\n            return\n\n        self.log('OPERATION PROFIT, GROSS %.2f, NET %.2f' %\n                 (trade.pnl, trade.pnlcomm))\n\n    def next(self):\n        # Simply log the closing price of the series from the reference\n        self.log('Close, %.2f' % self.dataclose[0])\n\n        # Check if an order is pending ... if yes, we cannot send a 2nd one\n        if self.order:\n            return\n\n        # Check if we are in the market\n        if not self.position:\n\n            # Not yet ... we MIGHT BUY if ...\n            if self.dataclose[0] &lt; self.dataclose[-1]:\n                    # current close less than previous close\n\n                    if self.dataclose[-1] &lt; self.dataclose[-2]:\n                        # previous close less than the previous close\n\n                        # BUY, BUY, BUY!!! (with default parameters)\n                        self.log('BUY CREATE, %.2f' % self.dataclose[0])\n\n                        # Keep track of the created order to avoid a 2nd order\n                        self.order = self.buy()\n\n        else:\n\n            # Already in the market ... we might sell\n            if len(self) &gt;= (self.bar_executed + self.params.exitbars):\n#                 print('self.params: ', self.params)\n                print('self.params.exitbars: ', self.params.exitbars)\n                print('self.wla: ', self.wla)\n                # SELL, SELL, SELL!!! (with all possible default parameters)\n                self.log('SELL CREATE, %.2f' % self.dataclose[0])\n\n                # Keep track of the created order to avoid a 2nd order\n                self.order = self.sell()\n                \n\nclass TestStrategy2(bt.Strategy):\n    params = (\n        ('maperiod', 15),\n    )\n\n    def log(self, txt, dt=None):\n        ''' Logging function fot this strategy'''\n        dt = dt or self.datas[0].datetime.date(0)\n        print('%s, %s' % (dt.isoformat(), txt))\n\n    def __init__(self):\n        # Keep a reference to the \"close\" line in the data[0] dataseries\n        self.dataclose = self.datas[0].close\n\n        # To keep track of pending orders and buy price/commission\n        self.order = None\n        self.buyprice = None\n        self.buycomm = None\n\n        # Add a MovingAverageSimple indicator\n        self.sma = bt.indicators.SimpleMovingAverage(\n            self.datas[0], period=self.params.maperiod)\n\n    def notify_order(self, order):\n        if order.status in [order.Submitted, order.Accepted]:\n            # Buy/Sell order submitted/accepted to/by broker - Nothing to do\n            return\n\n        # Check if an order has been completed\n        # Attention: broker could reject order if not enough cash\n        if order.status in [order.Completed]:\n            if order.isbuy():\n                self.log(\n                    'BUY EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %\n                    (order.executed.price,\n                     order.executed.value,\n                     order.executed.comm))\n\n                self.buyprice = order.executed.price\n                self.buycomm = order.executed.comm\n            else:  # Sell\n                self.log('SELL EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %\n                         (order.executed.price,\n                          order.executed.value,\n                          order.executed.comm))\n\n            self.bar_executed = len(self)\n\n        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n            self.log('Order Canceled/Margin/Rejected')\n\n        self.order = None\n\n    def notify_trade(self, trade):\n        if not trade.isclosed:\n            return\n\n        self.log('OPERATION PROFIT, GROSS %.2f, NET %.2f' %\n                 (trade.pnl, trade.pnlcomm))\n\n    def next(self):\n        # Simply log the closing price of the series from the reference\n        self.log('Close, %.2f' % self.dataclose[0])\n\n        # Check if an order is pending ... if yes, we cannot send a 2nd one\n        if self.order:\n            return\n\n        # Check if we are in the market\n        if not self.position:\n\n            # Not yet ... we MIGHT BUY if ...\n            if self.dataclose[0] &gt; self.sma[0]:\n\n                # BUY, BUY, BUY!!! (with all possible default parameters)\n                self.log('BUY CREATE, %.2f' % self.dataclose[0])\n\n                # Keep track of the created order to avoid a 2nd order\n                self.order = self.buy()\n\n        else:\n\n            if self.dataclose[0] &lt; self.sma[0]:\n                # SELL, SELL, SELL!!! (with all possible default parameters)\n                self.log('SELL CREATE, %.2f' % self.dataclose[0])\n\n                # Keep track of the created order to avoid a 2nd order\n                self.order = self.sell()\n\n\nif __name__ == '__main__':\n    # Create a cerebro entity\n    cerebro = bt.Cerebro()\n\n    # Add a strategy\n#     cerebro.addstrategy(TestStrategy)\n    cerebro.addstrategy(TestStrategy2)\n\n    data = bt.feeds.PandasData(dataname=df, datetime=-1)\n\n    # Add the Data Feed to Cerebro\n    cerebro.adddata(data)\n\n    # Set our desired cash start\n    cerebro.broker.setcash(100000.0)\n\n    # Add a FixedSize sizer according to the stake\n    cerebro.addsizer(bt.sizers.FixedSize, stake=10)\n\n    # Set the commission - 0.1% ... divide by 100 to remove the %\n    cerebro.broker.setcommission(commission=0.001)\n\n    # Print out the starting conditions\n    print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())\n\n    # Run over everything\n    cerebro.run()\n\n    # Print out the final result\n    print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue())\n</pre> from __future__ import (absolute_import, division, print_function,                         unicode_literals)  import datetime  # For datetime objects import os.path  # To manage paths import sys  # To find out the script name (in argv[0])  # Import the backtrader platform import backtrader as bt   # Create a Stratey class TestStrategy(bt.Strategy):     # \u5176\u5b9e\u5c31\u662f\u5b9a\u4e49\u4e86\u4e00\u4e2aTestStrategy\u7684\u7c7b\u53c2\u6570\uff0c\u8fd9\u91cc\u7684wla\u4e5f\u662f\u7c7b\u53c2\u6570\u3002     # \u5b9a\u4e49\u6210params\u540d\u79f0\uff0c\u7528tuple\u7c7b\u578b\u5b58\u653e\u5c31\u53ef\u4ee5\u7528self.params.exitbars\u8fd9\u79cd\u65b9\u6cd5\u65b9\u4fbf\u5730\u8c03\u7528     params = (         ('exitbars', 5),     )     wla = 'wla'      def log(self, txt, dt=None):         ''' Logging function fot this strategy'''         dt = dt or self.datas[0].datetime.date(0)         print('%s, %s' % (dt.isoformat(), txt))      def __init__(self):         # Keep a reference to the \"close\" line in the data[0] dataseries         self.dataclose = self.datas[0].close          # To keep track of pending orders and buy price/commission         self.order = None         self.buyprice = None         self.buycomm = None      def notify_order(self, order):         if order.status in [order.Submitted, order.Accepted]:             # Buy/Sell order submitted/accepted to/by broker - Nothing to do             return          # Check if an order has been completed         # Attention: broker could reject order if not enough cash         if order.status in [order.Completed]:             if order.isbuy():                 self.log(                     'BUY EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %                     (order.executed.price,                      order.executed.value,                      order.executed.comm))                  self.buyprice = order.executed.price                 self.buycomm = order.executed.comm             else:  # Sell                 self.log('SELL EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %                          (order.executed.price,                           order.executed.value,                           order.executed.comm))              self.bar_executed = len(self)          elif order.status in [order.Canceled, order.Margin, order.Rejected]:             self.log('Order Canceled/Margin/Rejected')          self.order = None      def notify_trade(self, trade):         if not trade.isclosed:             return          self.log('OPERATION PROFIT, GROSS %.2f, NET %.2f' %                  (trade.pnl, trade.pnlcomm))      def next(self):         # Simply log the closing price of the series from the reference         self.log('Close, %.2f' % self.dataclose[0])          # Check if an order is pending ... if yes, we cannot send a 2nd one         if self.order:             return          # Check if we are in the market         if not self.position:              # Not yet ... we MIGHT BUY if ...             if self.dataclose[0] &lt; self.dataclose[-1]:                     # current close less than previous close                      if self.dataclose[-1] &lt; self.dataclose[-2]:                         # previous close less than the previous close                          # BUY, BUY, BUY!!! (with default parameters)                         self.log('BUY CREATE, %.2f' % self.dataclose[0])                          # Keep track of the created order to avoid a 2nd order                         self.order = self.buy()          else:              # Already in the market ... we might sell             if len(self) &gt;= (self.bar_executed + self.params.exitbars): #                 print('self.params: ', self.params)                 print('self.params.exitbars: ', self.params.exitbars)                 print('self.wla: ', self.wla)                 # SELL, SELL, SELL!!! (with all possible default parameters)                 self.log('SELL CREATE, %.2f' % self.dataclose[0])                  # Keep track of the created order to avoid a 2nd order                 self.order = self.sell()                   class TestStrategy2(bt.Strategy):     params = (         ('maperiod', 15),     )      def log(self, txt, dt=None):         ''' Logging function fot this strategy'''         dt = dt or self.datas[0].datetime.date(0)         print('%s, %s' % (dt.isoformat(), txt))      def __init__(self):         # Keep a reference to the \"close\" line in the data[0] dataseries         self.dataclose = self.datas[0].close          # To keep track of pending orders and buy price/commission         self.order = None         self.buyprice = None         self.buycomm = None          # Add a MovingAverageSimple indicator         self.sma = bt.indicators.SimpleMovingAverage(             self.datas[0], period=self.params.maperiod)      def notify_order(self, order):         if order.status in [order.Submitted, order.Accepted]:             # Buy/Sell order submitted/accepted to/by broker - Nothing to do             return          # Check if an order has been completed         # Attention: broker could reject order if not enough cash         if order.status in [order.Completed]:             if order.isbuy():                 self.log(                     'BUY EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %                     (order.executed.price,                      order.executed.value,                      order.executed.comm))                  self.buyprice = order.executed.price                 self.buycomm = order.executed.comm             else:  # Sell                 self.log('SELL EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %                          (order.executed.price,                           order.executed.value,                           order.executed.comm))              self.bar_executed = len(self)          elif order.status in [order.Canceled, order.Margin, order.Rejected]:             self.log('Order Canceled/Margin/Rejected')          self.order = None      def notify_trade(self, trade):         if not trade.isclosed:             return          self.log('OPERATION PROFIT, GROSS %.2f, NET %.2f' %                  (trade.pnl, trade.pnlcomm))      def next(self):         # Simply log the closing price of the series from the reference         self.log('Close, %.2f' % self.dataclose[0])          # Check if an order is pending ... if yes, we cannot send a 2nd one         if self.order:             return          # Check if we are in the market         if not self.position:              # Not yet ... we MIGHT BUY if ...             if self.dataclose[0] &gt; self.sma[0]:                  # BUY, BUY, BUY!!! (with all possible default parameters)                 self.log('BUY CREATE, %.2f' % self.dataclose[0])                  # Keep track of the created order to avoid a 2nd order                 self.order = self.buy()          else:              if self.dataclose[0] &lt; self.sma[0]:                 # SELL, SELL, SELL!!! (with all possible default parameters)                 self.log('SELL CREATE, %.2f' % self.dataclose[0])                  # Keep track of the created order to avoid a 2nd order                 self.order = self.sell()   if __name__ == '__main__':     # Create a cerebro entity     cerebro = bt.Cerebro()      # Add a strategy #     cerebro.addstrategy(TestStrategy)     cerebro.addstrategy(TestStrategy2)      data = bt.feeds.PandasData(dataname=df, datetime=-1)      # Add the Data Feed to Cerebro     cerebro.adddata(data)      # Set our desired cash start     cerebro.broker.setcash(100000.0)      # Add a FixedSize sizer according to the stake     cerebro.addsizer(bt.sizers.FixedSize, stake=10)      # Set the commission - 0.1% ... divide by 100 to remove the %     cerebro.broker.setcommission(commission=0.001)      # Print out the starting conditions     print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())      # Run over everything     cerebro.run()      # Print out the final result     print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue())  <pre>Starting Portfolio Value: 100000.00\n2023-10-24, Close, 10.60\n2023-10-24, BUY CREATE, 10.60\n2023-10-24, BUY EXECUTED, Price: 10.60, Cost: 106.00, Comm 0.11\n2023-10-24, Close, 10.61\n2023-10-24, Close, 10.60\n2023-10-24, Close, 10.59\n2023-10-24, SELL CREATE, 10.59\n2023-10-24, SELL EXECUTED, Price: 10.59, Cost: 106.00, Comm 0.11\n2023-10-24, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-24, Close, 10.59\n2023-10-24, Close, 10.60\n2023-10-24, BUY CREATE, 10.60\n2023-10-24, BUY EXECUTED, Price: 10.60, Cost: 106.00, Comm 0.11\n2023-10-24, Close, 10.60\n2023-10-24, Close, 10.60\n2023-10-24, Close, 10.61\n2023-10-24, Close, 10.59\n2023-10-24, SELL CREATE, 10.59\n2023-10-24, SELL EXECUTED, Price: 10.59, Cost: 106.00, Comm 0.11\n2023-10-24, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-24, Close, 10.59\n2023-10-24, Close, 10.59\n2023-10-24, Close, 10.58\n2023-10-24, Close, 10.58\n2023-10-24, Close, 10.58\n2023-10-24, Close, 10.59\n2023-10-24, Close, 10.59\n2023-10-24, Close, 10.58\n2023-10-24, Close, 10.59\n2023-10-24, Close, 10.59\n2023-10-24, Close, 10.58\n2023-10-24, Close, 10.57\n2023-10-24, Close, 10.57\n2023-10-24, Close, 10.58\n2023-10-24, Close, 10.57\n2023-10-24, Close, 10.57\n2023-10-24, Close, 10.57\n2023-10-24, Close, 10.56\n2023-10-24, Close, 10.56\n2023-10-24, Close, 10.56\n2023-10-24, Close, 10.56\n2023-10-24, Close, 10.56\n2023-10-24, Close, 10.56\n2023-10-24, Close, 10.57\n2023-10-24, BUY CREATE, 10.57\n2023-10-24, BUY EXECUTED, Price: 10.57, Cost: 105.70, Comm 0.11\n2023-10-24, Close, 10.56\n2023-10-24, SELL CREATE, 10.56\n2023-10-24, SELL EXECUTED, Price: 10.56, Cost: 105.70, Comm 0.11\n2023-10-24, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-24, Close, 10.54\n2023-10-24, Close, 10.54\n2023-10-24, Close, 10.53\n2023-10-24, Close, 10.54\n2023-10-24, Close, 10.53\n2023-10-24, Close, 10.54\n2023-10-24, Close, 10.54\n2023-10-24, Close, 10.55\n2023-10-24, BUY CREATE, 10.55\n2023-10-24, BUY EXECUTED, Price: 10.55, Cost: 105.50, Comm 0.11\n2023-10-24, Close, 10.55\n2023-10-24, Close, 10.55\n2023-10-24, Close, 10.55\n2023-10-24, Close, 10.55\n2023-10-24, Close, 10.53\n2023-10-24, SELL CREATE, 10.53\n2023-10-24, SELL EXECUTED, Price: 10.54, Cost: 105.50, Comm 0.11\n2023-10-24, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-24, Close, 10.55\n2023-10-24, BUY CREATE, 10.55\n2023-10-24, BUY EXECUTED, Price: 10.55, Cost: 105.50, Comm 0.11\n2023-10-24, Close, 10.55\n2023-10-24, Close, 10.56\n2023-10-24, Close, 10.55\n2023-10-25, Close, 10.51\n2023-10-25, SELL CREATE, 10.51\n2023-10-25, SELL EXECUTED, Price: 10.50, Cost: 105.50, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS -0.50, NET -0.71\n2023-10-25, Close, 10.45\n2023-10-25, Close, 10.46\n2023-10-25, Close, 10.46\n2023-10-25, Close, 10.47\n2023-10-25, Close, 10.47\n2023-10-25, Close, 10.47\n2023-10-25, Close, 10.48\n2023-10-25, Close, 10.49\n2023-10-25, Close, 10.49\n2023-10-25, Close, 10.47\n2023-10-25, Close, 10.46\n2023-10-25, Close, 10.46\n2023-10-25, Close, 10.47\n2023-10-25, Close, 10.46\n2023-10-25, Close, 10.45\n2023-10-25, Close, 10.42\n2023-10-25, Close, 10.44\n2023-10-25, Close, 10.45\n2023-10-25, Close, 10.45\n2023-10-25, Close, 10.45\n2023-10-25, Close, 10.45\n2023-10-25, Close, 10.43\n2023-10-25, Close, 10.43\n2023-10-25, Close, 10.44\n2023-10-25, Close, 10.45\n2023-10-25, BUY CREATE, 10.45\n2023-10-25, BUY EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-10-25, Close, 10.46\n2023-10-25, Close, 10.45\n2023-10-25, Close, 10.45\n2023-10-25, Close, 10.45\n2023-10-25, Close, 10.45\n2023-10-25, Close, 10.46\n2023-10-25, Close, 10.45\n2023-10-25, Close, 10.45\n2023-10-25, Close, 10.45\n2023-10-25, Close, 10.45\n2023-10-25, Close, 10.45\n2023-10-25, Close, 10.43\n2023-10-25, SELL CREATE, 10.43\n2023-10-25, SELL EXECUTED, Price: 10.44, Cost: 104.50, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-25, Close, 10.43\n2023-10-25, Close, 10.43\n2023-10-25, Close, 10.43\n2023-10-25, Close, 10.43\n2023-10-25, Close, 10.43\n2023-10-25, Close, 10.42\n2023-10-25, Close, 10.42\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.41\n2023-10-25, BUY CREATE, 10.41\n2023-10-25, BUY EXECUTED, Price: 10.40, Cost: 104.00, Comm 0.10\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.42\n2023-10-25, Close, 10.42\n2023-10-25, Close, 10.42\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.40\n2023-10-25, SELL CREATE, 10.40\n2023-10-25, SELL EXECUTED, Price: 10.41, Cost: 104.00, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.40\n2023-10-25, BUY CREATE, 10.40\n2023-10-25, BUY EXECUTED, Price: 10.40, Cost: 104.00, Comm 0.10\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.39\n2023-10-25, SELL CREATE, 10.39\n2023-10-25, SELL EXECUTED, Price: 10.40, Cost: 104.00, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-25, Close, 10.40\n2023-10-25, BUY CREATE, 10.40\n2023-10-25, BUY EXECUTED, Price: 10.40, Cost: 104.00, Comm 0.10\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.42\n2023-10-25, Close, 10.40\n2023-10-25, SELL CREATE, 10.40\n2023-10-25, SELL EXECUTED, Price: 10.41, Cost: 104.00, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-25, Close, 10.41\n2023-10-25, BUY CREATE, 10.41\n2023-10-25, BUY EXECUTED, Price: 10.41, Cost: 104.10, Comm 0.10\n2023-10-25, Close, 10.42\n2023-10-25, Close, 10.42\n2023-10-25, Close, 10.42\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.42\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.39\n2023-10-25, SELL CREATE, 10.39\n2023-10-25, SELL EXECUTED, Price: 10.40, Cost: 104.10, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.37\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.37\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.37\n2023-10-25, Close, 10.38\n2023-10-25, BUY CREATE, 10.38\n2023-10-25, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.38\n2023-10-25, SELL CREATE, 10.38\n2023-10-25, SELL EXECUTED, Price: 10.38, Cost: 103.90, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.37\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.39\n2023-10-25, BUY CREATE, 10.39\n2023-10-25, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-25, Close, 10.38\n2023-10-25, SELL CREATE, 10.38\n2023-10-25, SELL EXECUTED, Price: 10.37, Cost: 103.90, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS -0.20, NET -0.41\n2023-10-25, Close, 10.39\n2023-10-25, BUY CREATE, 10.39\n2023-10-25, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.38\n2023-10-25, SELL CREATE, 10.38\n2023-10-25, SELL EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-25, Close, 10.39\n2023-10-25, BUY CREATE, 10.39\n2023-10-25, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-25, Close, 10.38\n2023-10-25, SELL CREATE, 10.38\n2023-10-25, SELL EXECUTED, Price: 10.38, Cost: 103.90, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.39\n2023-10-25, BUY CREATE, 10.39\n2023-10-25, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-25, Close, 10.38\n2023-10-25, SELL CREATE, 10.38\n2023-10-25, SELL EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.40\n2023-10-25, BUY CREATE, 10.40\n2023-10-25, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, SELL CREATE, 10.39\n2023-10-25, SELL EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.40\n2023-10-25, BUY CREATE, 10.40\n2023-10-25, BUY EXECUTED, Price: 10.40, Cost: 104.00, Comm 0.10\n2023-10-25, Close, 10.39\n2023-10-25, SELL CREATE, 10.39\n2023-10-25, SELL EXECUTED, Price: 10.40, Cost: 104.00, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-25, Close, 10.40\n2023-10-25, BUY CREATE, 10.40\n2023-10-25, BUY EXECUTED, Price: 10.40, Cost: 104.00, Comm 0.10\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, SELL CREATE, 10.40\n2023-10-25, SELL EXECUTED, Price: 10.40, Cost: 104.00, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.41\n2023-10-25, BUY CREATE, 10.41\n2023-10-25, BUY EXECUTED, Price: 10.40, Cost: 104.00, Comm 0.10\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.40\n2023-10-25, SELL CREATE, 10.40\n2023-10-25, SELL EXECUTED, Price: 10.40, Cost: 104.00, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-25, Close, 10.41\n2023-10-25, BUY CREATE, 10.41\n2023-10-25, BUY EXECUTED, Price: 10.41, Cost: 104.10, Comm 0.10\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.41\n2023-10-25, Close, 10.40\n2023-10-25, SELL CREATE, 10.40\n2023-10-25, SELL EXECUTED, Price: 10.40, Cost: 104.10, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.40\n2023-10-25, BUY CREATE, 10.40\n2023-10-25, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-25, Close, 10.40\n2023-10-25, Close, 10.39\n2023-10-25, SELL CREATE, 10.39\n2023-10-25, SELL EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.39\n2023-10-25, BUY CREATE, 10.39\n2023-10-25, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.39\n2023-10-25, Close, 10.38\n2023-10-25, SELL CREATE, 10.38\n2023-10-25, SELL EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.39\n2023-10-25, BUY CREATE, 10.39\n2023-10-25, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-25, Close, 10.38\n2023-10-25, SELL CREATE, 10.38\n2023-10-25, SELL EXECUTED, Price: 10.38, Cost: 103.90, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.37\n2023-10-25, Close, 10.37\n2023-10-25, Close, 10.37\n2023-10-25, Close, 10.37\n2023-10-25, Close, 10.37\n2023-10-25, Close, 10.36\n2023-10-25, Close, 10.37\n2023-10-25, Close, 10.37\n2023-10-25, Close, 10.38\n2023-10-25, BUY CREATE, 10.38\n2023-10-25, BUY EXECUTED, Price: 10.38, Cost: 103.80, Comm 0.10\n2023-10-25, Close, 10.38\n2023-10-25, Close, 10.37\n2023-10-25, SELL CREATE, 10.37\n2023-10-25, SELL EXECUTED, Price: 10.37, Cost: 103.80, Comm 0.10\n2023-10-25, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-25, Close, 10.37\n2023-10-25, Close, 10.38\n2023-10-25, BUY CREATE, 10.38\n2023-10-25, BUY EXECUTED, Price: 10.38, Cost: 103.80, Comm 0.10\n2023-10-25, Close, 10.38\n2023-10-26, Close, 10.36\n2023-10-26, SELL CREATE, 10.36\n2023-10-26, SELL EXECUTED, Price: 10.36, Cost: 103.80, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS -0.20, NET -0.41\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.37\n2023-10-26, BUY CREATE, 10.37\n2023-10-26, BUY EXECUTED, Price: 10.36, Cost: 103.60, Comm 0.10\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.36\n2023-10-26, SELL CREATE, 10.36\n2023-10-26, SELL EXECUTED, Price: 10.37, Cost: 103.60, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-26, Close, 10.37\n2023-10-26, BUY CREATE, 10.37\n2023-10-26, BUY EXECUTED, Price: 10.37, Cost: 103.70, Comm 0.10\n2023-10-26, Close, 10.38\n2023-10-26, Close, 10.38\n2023-10-26, Close, 10.39\n2023-10-26, Close, 10.38\n2023-10-26, Close, 10.38\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.38\n2023-10-26, Close, 10.36\n2023-10-26, SELL CREATE, 10.36\n2023-10-26, SELL EXECUTED, Price: 10.36, Cost: 103.70, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.36\n2023-10-26, BUY CREATE, 10.36\n2023-10-26, BUY EXECUTED, Price: 10.35, Cost: 103.50, Comm 0.10\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.35\n2023-10-26, SELL CREATE, 10.35\n2023-10-26, SELL EXECUTED, Price: 10.35, Cost: 103.50, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.35\n2023-10-26, BUY CREATE, 10.35\n2023-10-26, BUY EXECUTED, Price: 10.34, Cost: 103.40, Comm 0.10\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.34\n2023-10-26, SELL CREATE, 10.34\n2023-10-26, SELL EXECUTED, Price: 10.35, Cost: 103.40, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-26, Close, 10.35\n2023-10-26, BUY CREATE, 10.35\n2023-10-26, BUY EXECUTED, Price: 10.34, Cost: 103.40, Comm 0.10\n2023-10-26, Close, 10.34\n2023-10-26, SELL CREATE, 10.34\n2023-10-26, SELL EXECUTED, Price: 10.34, Cost: 103.40, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-26, Close, 10.35\n2023-10-26, BUY CREATE, 10.35\n2023-10-26, BUY EXECUTED, Price: 10.34, Cost: 103.40, Comm 0.10\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.34\n2023-10-26, SELL CREATE, 10.34\n2023-10-26, SELL EXECUTED, Price: 10.34, Cost: 103.40, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.35\n2023-10-26, BUY CREATE, 10.35\n2023-10-26, BUY EXECUTED, Price: 10.34, Cost: 103.40, Comm 0.10\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.34\n2023-10-26, SELL CREATE, 10.34\n2023-10-26, SELL EXECUTED, Price: 10.33, Cost: 103.40, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.32\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.32\n2023-10-26, Close, 10.34\n2023-10-26, BUY CREATE, 10.34\n2023-10-26, BUY EXECUTED, Price: 10.33, Cost: 103.30, Comm 0.10\n2023-10-26, Close, 10.33\n2023-10-26, SELL CREATE, 10.33\n2023-10-26, SELL EXECUTED, Price: 10.33, Cost: 103.30, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-26, Close, 10.34\n2023-10-26, BUY CREATE, 10.34\n2023-10-26, BUY EXECUTED, Price: 10.33, Cost: 103.30, Comm 0.10\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.33\n2023-10-26, SELL CREATE, 10.33\n2023-10-26, SELL EXECUTED, Price: 10.33, Cost: 103.30, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-26, Close, 10.34\n2023-10-26, BUY CREATE, 10.34\n2023-10-26, BUY EXECUTED, Price: 10.33, Cost: 103.30, Comm 0.10\n2023-10-26, Close, 10.33\n2023-10-26, SELL CREATE, 10.33\n2023-10-26, SELL EXECUTED, Price: 10.32, Cost: 103.30, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.34\n2023-10-26, BUY CREATE, 10.34\n2023-10-26, BUY EXECUTED, Price: 10.33, Cost: 103.30, Comm 0.10\n2023-10-26, Close, 10.33\n2023-10-26, SELL CREATE, 10.33\n2023-10-26, SELL EXECUTED, Price: 10.33, Cost: 103.30, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-26, Close, 10.34\n2023-10-26, BUY CREATE, 10.34\n2023-10-26, BUY EXECUTED, Price: 10.34, Cost: 103.40, Comm 0.10\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.33\n2023-10-26, SELL CREATE, 10.33\n2023-10-26, SELL EXECUTED, Price: 10.33, Cost: 103.40, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.34\n2023-10-26, BUY CREATE, 10.34\n2023-10-26, BUY EXECUTED, Price: 10.33, Cost: 103.30, Comm 0.10\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.33\n2023-10-26, SELL CREATE, 10.33\n2023-10-26, SELL EXECUTED, Price: 10.33, Cost: 103.30, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-26, Close, 10.34\n2023-10-26, BUY CREATE, 10.34\n2023-10-26, BUY EXECUTED, Price: 10.34, Cost: 103.40, Comm 0.10\n2023-10-26, Close, 10.33\n2023-10-26, SELL CREATE, 10.33\n2023-10-26, SELL EXECUTED, Price: 10.33, Cost: 103.40, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-26, Close, 10.34\n2023-10-26, BUY CREATE, 10.34\n2023-10-26, BUY EXECUTED, Price: 10.34, Cost: 103.40, Comm 0.10\n2023-10-26, Close, 10.33\n2023-10-26, SELL CREATE, 10.33\n2023-10-26, SELL EXECUTED, Price: 10.33, Cost: 103.40, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.33\n2023-10-26, Close, 10.34\n2023-10-26, BUY CREATE, 10.34\n2023-10-26, BUY EXECUTED, Price: 10.34, Cost: 103.40, Comm 0.10\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.33\n2023-10-26, SELL CREATE, 10.33\n2023-10-26, SELL EXECUTED, Price: 10.34, Cost: 103.40, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-26, Close, 10.34\n2023-10-26, BUY CREATE, 10.34\n2023-10-26, BUY EXECUTED, Price: 10.33, Cost: 103.30, Comm 0.10\n2023-10-26, Close, 10.33\n2023-10-26, SELL CREATE, 10.33\n2023-10-26, SELL EXECUTED, Price: 10.33, Cost: 103.30, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-26, Close, 10.35\n2023-10-26, BUY CREATE, 10.35\n2023-10-26, BUY EXECUTED, Price: 10.35, Cost: 103.50, Comm 0.10\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.34\n2023-10-26, SELL CREATE, 10.34\n2023-10-26, SELL EXECUTED, Price: 10.33, Cost: 103.50, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS -0.20, NET -0.41\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.35\n2023-10-26, BUY CREATE, 10.35\n2023-10-26, BUY EXECUTED, Price: 10.35, Cost: 103.50, Comm 0.10\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.34\n2023-10-26, SELL CREATE, 10.34\n2023-10-26, SELL EXECUTED, Price: 10.34, Cost: 103.50, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-26, Close, 10.36\n2023-10-26, BUY CREATE, 10.36\n2023-10-26, BUY EXECUTED, Price: 10.36, Cost: 103.60, Comm 0.10\n2023-10-26, Close, 10.34\n2023-10-26, SELL CREATE, 10.34\n2023-10-26, SELL EXECUTED, Price: 10.35, Cost: 103.60, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.36\n2023-10-26, BUY CREATE, 10.36\n2023-10-26, BUY EXECUTED, Price: 10.35, Cost: 103.50, Comm 0.10\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.35\n2023-10-26, SELL CREATE, 10.35\n2023-10-26, SELL EXECUTED, Price: 10.35, Cost: 103.50, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.36\n2023-10-26, BUY CREATE, 10.36\n2023-10-26, BUY EXECUTED, Price: 10.35, Cost: 103.50, Comm 0.10\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.35\n2023-10-26, SELL CREATE, 10.35\n2023-10-26, SELL EXECUTED, Price: 10.36, Cost: 103.50, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-26, Close, 10.36\n2023-10-26, BUY CREATE, 10.36\n2023-10-26, BUY EXECUTED, Price: 10.36, Cost: 103.60, Comm 0.10\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.35\n2023-10-26, SELL CREATE, 10.35\n2023-10-26, SELL EXECUTED, Price: 10.34, Cost: 103.60, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS -0.20, NET -0.41\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.34\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.35\n2023-10-26, BUY CREATE, 10.35\n2023-10-26, BUY EXECUTED, Price: 10.36, Cost: 103.60, Comm 0.10\n2023-10-26, Close, 10.35\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.38\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.38\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.38\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.38\n2023-10-26, Close, 10.38\n2023-10-26, Close, 10.37\n2023-10-26, SELL CREATE, 10.37\n2023-10-26, SELL EXECUTED, Price: 10.38, Cost: 103.60, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.20, NET -0.01\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.36\n2023-10-26, Close, 10.37\n2023-10-26, BUY CREATE, 10.37\n</pre> <pre>2023-10-26, BUY EXECUTED, Price: 10.37, Cost: 103.70, Comm 0.10\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.37\n2023-10-26, Close, 10.38\n2023-10-26, Close, 10.38\n2023-10-26, Close, 10.39\n2023-10-26, Close, 10.38\n2023-10-26, Close, 10.39\n2023-10-26, Close, 10.39\n2023-10-26, Close, 10.39\n2023-10-26, Close, 10.39\n2023-10-26, Close, 10.40\n2023-10-26, Close, 10.38\n2023-10-26, Close, 10.38\n2023-10-26, SELL CREATE, 10.38\n2023-10-26, SELL EXECUTED, Price: 10.39, Cost: 103.70, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.20, NET -0.01\n2023-10-26, Close, 10.39\n2023-10-26, BUY CREATE, 10.39\n2023-10-26, BUY EXECUTED, Price: 10.38, Cost: 103.80, Comm 0.10\n2023-10-26, Close, 10.39\n2023-10-26, Close, 10.38\n2023-10-26, SELL CREATE, 10.38\n2023-10-26, SELL EXECUTED, Price: 10.39, Cost: 103.80, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-26, Close, 10.38\n2023-10-26, Close, 10.39\n2023-10-26, BUY CREATE, 10.39\n2023-10-26, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-26, Close, 10.38\n2023-10-26, SELL CREATE, 10.38\n2023-10-26, SELL EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-26, Close, 10.39\n2023-10-26, BUY CREATE, 10.39\n2023-10-26, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-26, Close, 10.39\n2023-10-26, Close, 10.39\n2023-10-26, Close, 10.39\n2023-10-26, Close, 10.40\n2023-10-26, Close, 10.40\n2023-10-26, Close, 10.40\n2023-10-26, Close, 10.40\n2023-10-26, Close, 10.40\n2023-10-26, Close, 10.40\n2023-10-26, Close, 10.41\n2023-10-26, Close, 10.41\n2023-10-26, Close, 10.40\n2023-10-26, Close, 10.41\n2023-10-26, Close, 10.40\n2023-10-26, Close, 10.40\n2023-10-26, Close, 10.40\n2023-10-26, SELL CREATE, 10.40\n2023-10-26, SELL EXECUTED, Price: 10.40, Cost: 103.90, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-26, Close, 10.39\n2023-10-26, Close, 10.41\n2023-10-26, BUY CREATE, 10.41\n2023-10-26, BUY EXECUTED, Price: 10.40, Cost: 104.00, Comm 0.10\n2023-10-26, Close, 10.41\n2023-10-26, Close, 10.40\n2023-10-26, SELL CREATE, 10.40\n2023-10-26, SELL EXECUTED, Price: 10.41, Cost: 104.00, Comm 0.10\n2023-10-26, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-26, Close, 10.41\n2023-10-26, BUY CREATE, 10.41\n2023-10-26, BUY EXECUTED, Price: 10.41, Cost: 104.10, Comm 0.10\n2023-10-26, Close, 10.41\n2023-10-26, Close, 10.42\n2023-10-26, Close, 10.42\n2023-10-26, Close, 10.41\n2023-10-26, Close, 10.42\n2023-10-26, Close, 10.42\n2023-10-26, Close, 10.42\n2023-10-26, Close, 10.41\n2023-10-27, Close, 10.37\n2023-10-27, SELL CREATE, 10.37\n2023-10-27, SELL EXECUTED, Price: 10.36, Cost: 104.10, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS -0.50, NET -0.71\n2023-10-27, Close, 10.35\n2023-10-27, Close, 10.36\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.37\n2023-10-27, Close, 10.39\n2023-10-27, BUY CREATE, 10.39\n2023-10-27, BUY EXECUTED, Price: 10.38, Cost: 103.80, Comm 0.10\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.37\n2023-10-27, SELL CREATE, 10.37\n2023-10-27, SELL EXECUTED, Price: 10.38, Cost: 103.80, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-27, Close, 10.36\n2023-10-27, Close, 10.34\n2023-10-27, Close, 10.35\n2023-10-27, Close, 10.35\n2023-10-27, Close, 10.35\n2023-10-27, Close, 10.36\n2023-10-27, Close, 10.37\n2023-10-27, BUY CREATE, 10.37\n2023-10-27, BUY EXECUTED, Price: 10.38, Cost: 103.80, Comm 0.10\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.37\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.37\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.37\n2023-10-27, Close, 10.36\n2023-10-27, SELL CREATE, 10.36\n2023-10-27, SELL EXECUTED, Price: 10.37, Cost: 103.80, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-27, Close, 10.38\n2023-10-27, BUY CREATE, 10.38\n2023-10-27, BUY EXECUTED, Price: 10.38, Cost: 103.80, Comm 0.10\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.37\n2023-10-27, SELL CREATE, 10.37\n2023-10-27, SELL EXECUTED, Price: 10.37, Cost: 103.80, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-27, Close, 10.38\n2023-10-27, BUY CREATE, 10.38\n2023-10-27, BUY EXECUTED, Price: 10.38, Cost: 103.80, Comm 0.10\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.40\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.40\n2023-10-27, Close, 10.40\n2023-10-27, Close, 10.41\n2023-10-27, Close, 10.40\n2023-10-27, Close, 10.41\n2023-10-27, Close, 10.40\n2023-10-27, Close, 10.41\n2023-10-27, Close, 10.40\n2023-10-27, Close, 10.41\n2023-10-27, Close, 10.40\n2023-10-27, Close, 10.40\n2023-10-27, SELL CREATE, 10.40\n2023-10-27, SELL EXECUTED, Price: 10.40, Cost: 103.80, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS 0.20, NET -0.01\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.40\n2023-10-27, Close, 10.40\n2023-10-27, Close, 10.41\n2023-10-27, BUY CREATE, 10.41\n2023-10-27, BUY EXECUTED, Price: 10.41, Cost: 104.10, Comm 0.10\n2023-10-27, Close, 10.40\n2023-10-27, SELL CREATE, 10.40\n2023-10-27, SELL EXECUTED, Price: 10.40, Cost: 104.10, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.39\n2023-10-27, BUY CREATE, 10.39\n2023-10-27, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.38\n2023-10-27, SELL CREATE, 10.38\n2023-10-27, SELL EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-27, Close, 10.39\n2023-10-27, BUY CREATE, 10.39\n2023-10-27, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-27, Close, 10.40\n2023-10-27, Close, 10.40\n2023-10-27, Close, 10.38\n2023-10-27, SELL CREATE, 10.38\n2023-10-27, SELL EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-27, Close, 10.39\n2023-10-27, BUY CREATE, 10.39\n2023-10-27, BUY EXECUTED, Price: 10.40, Cost: 104.00, Comm 0.10\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.38\n2023-10-27, SELL CREATE, 10.38\n2023-10-27, SELL EXECUTED, Price: 10.39, Cost: 104.00, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.39\n2023-10-27, BUY CREATE, 10.39\n2023-10-27, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-27, Close, 10.38\n2023-10-27, SELL CREATE, 10.38\n2023-10-27, SELL EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.39\n2023-10-27, BUY CREATE, 10.39\n2023-10-27, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-27, Close, 10.38\n2023-10-27, SELL CREATE, 10.38\n2023-10-27, SELL EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-27, Close, 10.39\n2023-10-27, BUY CREATE, 10.39\n2023-10-27, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.38\n2023-10-27, SELL CREATE, 10.38\n2023-10-27, SELL EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.37\n2023-10-27, Close, 10.36\n2023-10-27, Close, 10.36\n2023-10-27, Close, 10.37\n2023-10-27, Close, 10.37\n2023-10-27, Close, 10.37\n2023-10-27, Close, 10.37\n2023-10-27, Close, 10.37\n2023-10-27, Close, 10.37\n2023-10-27, Close, 10.37\n2023-10-27, Close, 10.36\n2023-10-27, Close, 10.36\n2023-10-27, Close, 10.37\n2023-10-27, BUY CREATE, 10.37\n2023-10-27, BUY EXECUTED, Price: 10.37, Cost: 103.70, Comm 0.10\n2023-10-27, Close, 10.37\n2023-10-27, Close, 10.36\n2023-10-27, SELL CREATE, 10.36\n2023-10-27, SELL EXECUTED, Price: 10.37, Cost: 103.70, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-27, Close, 10.36\n2023-10-27, Close, 10.37\n2023-10-27, BUY CREATE, 10.37\n2023-10-27, BUY EXECUTED, Price: 10.37, Cost: 103.70, Comm 0.10\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.37\n2023-10-27, Close, 10.37\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.37\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.37\n2023-10-27, SELL CREATE, 10.37\n2023-10-27, SELL EXECUTED, Price: 10.37, Cost: 103.70, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-27, Close, 10.39\n2023-10-27, BUY CREATE, 10.39\n2023-10-27, BUY EXECUTED, Price: 10.38, Cost: 103.80, Comm 0.10\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.38\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.39\n2023-10-27, Close, 10.38\n2023-10-27, SELL CREATE, 10.38\n2023-10-27, SELL EXECUTED, Price: 10.39, Cost: 103.80, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-27, Close, 10.40\n2023-10-27, BUY CREATE, 10.40\n2023-10-27, BUY EXECUTED, Price: 10.40, Cost: 104.00, Comm 0.10\n2023-10-27, Close, 10.40\n2023-10-27, Close, 10.41\n2023-10-27, Close, 10.41\n2023-10-27, Close, 10.41\n2023-10-27, Close, 10.42\n2023-10-27, Close, 10.42\n2023-10-27, Close, 10.42\n2023-10-27, Close, 10.44\n2023-10-27, Close, 10.42\n2023-10-27, Close, 10.42\n2023-10-27, Close, 10.43\n2023-10-27, Close, 10.43\n2023-10-27, Close, 10.43\n2023-10-27, Close, 10.43\n2023-10-27, Close, 10.42\n2023-10-27, SELL CREATE, 10.42\n2023-10-27, SELL EXECUTED, Price: 10.43, Cost: 104.00, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS 0.30, NET 0.09\n2023-10-27, Close, 10.42\n2023-10-27, Close, 10.42\n2023-10-27, Close, 10.43\n2023-10-27, BUY CREATE, 10.43\n2023-10-27, BUY EXECUTED, Price: 10.43, Cost: 104.30, Comm 0.10\n2023-10-27, Close, 10.43\n2023-10-27, Close, 10.43\n2023-10-27, Close, 10.42\n2023-10-27, SELL CREATE, 10.42\n2023-10-27, SELL EXECUTED, Price: 10.43, Cost: 104.30, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-27, Close, 10.43\n2023-10-27, BUY CREATE, 10.43\n2023-10-27, BUY EXECUTED, Price: 10.43, Cost: 104.30, Comm 0.10\n2023-10-27, Close, 10.43\n2023-10-27, Close, 10.41\n2023-10-27, SELL CREATE, 10.41\n2023-10-27, SELL EXECUTED, Price: 10.42, Cost: 104.30, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-27, Close, 10.41\n2023-10-27, Close, 10.41\n2023-10-27, Close, 10.42\n2023-10-27, Close, 10.42\n2023-10-27, Close, 10.43\n2023-10-27, BUY CREATE, 10.43\n2023-10-27, BUY EXECUTED, Price: 10.42, Cost: 104.20, Comm 0.10\n2023-10-27, Close, 10.42\n2023-10-27, SELL CREATE, 10.42\n2023-10-27, SELL EXECUTED, Price: 10.43, Cost: 104.20, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-27, Close, 10.44\n2023-10-27, BUY CREATE, 10.44\n2023-10-27, BUY EXECUTED, Price: 10.44, Cost: 104.40, Comm 0.10\n2023-10-27, Close, 10.44\n2023-10-27, Close, 10.43\n2023-10-27, Close, 10.43\n2023-10-27, Close, 10.44\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.44\n2023-10-27, Close, 10.43\n2023-10-27, Close, 10.43\n2023-10-27, Close, 10.44\n2023-10-27, Close, 10.43\n2023-10-27, SELL CREATE, 10.43\n2023-10-27, SELL EXECUTED, Price: 10.44, Cost: 104.40, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-27, Close, 10.44\n2023-10-27, BUY CREATE, 10.44\n2023-10-27, BUY EXECUTED, Price: 10.44, Cost: 104.40, Comm 0.10\n2023-10-27, Close, 10.44\n2023-10-27, Close, 10.44\n2023-10-27, Close, 10.43\n2023-10-27, SELL CREATE, 10.43\n2023-10-27, SELL EXECUTED, Price: 10.43, Cost: 104.40, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-27, Close, 10.43\n2023-10-27, Close, 10.43\n2023-10-27, Close, 10.44\n2023-10-27, BUY CREATE, 10.44\n2023-10-27, BUY EXECUTED, Price: 10.44, Cost: 104.40, Comm 0.10\n2023-10-27, Close, 10.46\n2023-10-27, Close, 10.43\n2023-10-27, SELL CREATE, 10.43\n2023-10-27, SELL EXECUTED, Price: 10.43, Cost: 104.40, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-27, Close, 10.45\n2023-10-27, BUY CREATE, 10.45\n2023-10-27, BUY EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.46\n2023-10-27, Close, 10.46\n2023-10-27, Close, 10.47\n2023-10-27, Close, 10.48\n2023-10-27, Close, 10.48\n2023-10-27, Close, 10.46\n2023-10-27, Close, 10.46\n2023-10-27, Close, 10.46\n2023-10-27, Close, 10.47\n2023-10-27, Close, 10.47\n2023-10-27, Close, 10.46\n2023-10-27, SELL CREATE, 10.46\n2023-10-27, SELL EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-27, Close, 10.47\n2023-10-27, BUY CREATE, 10.47\n2023-10-27, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-10-27, Close, 10.47\n2023-10-27, Close, 10.47\n2023-10-27, Close, 10.47\n2023-10-27, Close, 10.47\n2023-10-27, Close, 10.47\n2023-10-27, Close, 10.47\n2023-10-27, Close, 10.47\n2023-10-27, Close, 10.47\n2023-10-27, Close, 10.47\n2023-10-27, Close, 10.47\n2023-10-27, Close, 10.46\n2023-10-27, SELL CREATE, 10.46\n2023-10-27, SELL EXECUTED, Price: 10.46, Cost: 104.70, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-27, Close, 10.47\n2023-10-27, BUY CREATE, 10.47\n2023-10-27, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-10-27, Close, 10.47\n2023-10-27, Close, 10.46\n2023-10-27, SELL CREATE, 10.46\n2023-10-27, SELL EXECUTED, Price: 10.46, Cost: 104.70, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.46\n2023-10-27, Close, 10.46\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.46\n2023-10-27, BUY CREATE, 10.46\n2023-10-27, BUY EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-10-27, Close, 10.45\n2023-10-27, SELL CREATE, 10.45\n2023-10-27, SELL EXECUTED, Price: 10.44, Cost: 104.50, Comm 0.10\n2023-10-27, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-27, Close, 10.44\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-27, Close, 10.45\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.40\n2023-10-30, Close, 10.40\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.40\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.39\n2023-10-30, BUY CREATE, 10.39\n2023-10-30, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.38\n2023-10-30, SELL CREATE, 10.38\n2023-10-30, SELL EXECUTED, Price: 10.37, Cost: 103.90, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS -0.20, NET -0.41\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.35\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.35\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.35\n2023-10-30, Close, 10.36\n2023-10-30, BUY CREATE, 10.36\n2023-10-30, BUY EXECUTED, Price: 10.36, Cost: 103.60, Comm 0.10\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.35\n2023-10-30, SELL CREATE, 10.35\n2023-10-30, SELL EXECUTED, Price: 10.35, Cost: 103.60, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-30, Close, 10.35\n2023-10-30, Close, 10.36\n2023-10-30, BUY CREATE, 10.36\n2023-10-30, BUY EXECUTED, Price: 10.35, Cost: 103.50, Comm 0.10\n2023-10-30, Close, 10.35\n2023-10-30, SELL CREATE, 10.35\n2023-10-30, SELL EXECUTED, Price: 10.36, Cost: 103.50, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-30, Close, 10.36\n2023-10-30, BUY CREATE, 10.36\n2023-10-30, BUY EXECUTED, Price: 10.36, Cost: 103.60, Comm 0.10\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.36\n2023-10-30, SELL CREATE, 10.36\n2023-10-30, SELL EXECUTED, Price: 10.37, Cost: 103.60, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-30, Close, 10.37\n2023-10-30, BUY CREATE, 10.37\n2023-10-30, BUY EXECUTED, Price: 10.36, Cost: 103.60, Comm 0.10\n2023-10-30, Close, 10.36\n2023-10-30, SELL CREATE, 10.36\n2023-10-30, SELL EXECUTED, Price: 10.37, Cost: 103.60, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-30, Close, 10.37\n2023-10-30, BUY CREATE, 10.37\n2023-10-30, BUY EXECUTED, Price: 10.36, Cost: 103.60, Comm 0.10\n2023-10-30, Close, 10.36\n2023-10-30, SELL CREATE, 10.36\n2023-10-30, SELL EXECUTED, Price: 10.36, Cost: 103.60, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.37\n2023-10-30, BUY CREATE, 10.37\n2023-10-30, BUY EXECUTED, Price: 10.37, Cost: 103.70, Comm 0.10\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.36\n2023-10-30, SELL CREATE, 10.36\n2023-10-30, SELL EXECUTED, Price: 10.36, Cost: 103.70, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.37\n2023-10-30, BUY CREATE, 10.37\n2023-10-30, BUY EXECUTED, Price: 10.37, Cost: 103.70, Comm 0.10\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.36\n2023-10-30, SELL CREATE, 10.36\n2023-10-30, SELL EXECUTED, Price: 10.37, Cost: 103.70, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.37\n2023-10-30, BUY CREATE, 10.37\n2023-10-30, BUY EXECUTED, Price: 10.37, Cost: 103.70, Comm 0.10\n2023-10-30, Close, 10.36\n2023-10-30, SELL CREATE, 10.36\n2023-10-30, SELL EXECUTED, Price: 10.36, Cost: 103.70, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.35\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.35\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.37\n2023-10-30, BUY CREATE, 10.37\n2023-10-30, BUY EXECUTED, Price: 10.36, Cost: 103.60, Comm 0.10\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.36\n2023-10-30, SELL CREATE, 10.36\n2023-10-30, SELL EXECUTED, Price: 10.37, Cost: 103.60, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-30, Close, 10.36\n2023-10-30, BUY CREATE, 10.36\n2023-10-30, BUY EXECUTED, Price: 10.36, Cost: 103.60, Comm 0.10\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.36\n2023-10-30, SELL CREATE, 10.36\n2023-10-30, SELL EXECUTED, Price: 10.36, Cost: 103.60, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.37\n2023-10-30, BUY CREATE, 10.37\n2023-10-30, BUY EXECUTED, Price: 10.37, Cost: 103.70, Comm 0.10\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.36\n2023-10-30, SELL CREATE, 10.36\n2023-10-30, SELL EXECUTED, Price: 10.37, Cost: 103.70, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.37\n2023-10-30, BUY CREATE, 10.37\n2023-10-30, BUY EXECUTED, Price: 10.37, Cost: 103.70, Comm 0.10\n2023-10-30, Close, 10.36\n2023-10-30, SELL CREATE, 10.36\n2023-10-30, SELL EXECUTED, Price: 10.37, Cost: 103.70, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.37\n2023-10-30, BUY CREATE, 10.37\n2023-10-30, BUY EXECUTED, Price: 10.37, Cost: 103.70, Comm 0.10\n2023-10-30, Close, 10.36\n2023-10-30, SELL CREATE, 10.36\n2023-10-30, SELL EXECUTED, Price: 10.36, Cost: 103.70, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-30, Close, 10.35\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.35\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.36\n2023-10-30, Close, 10.38\n2023-10-30, BUY CREATE, 10.38\n2023-10-30, BUY EXECUTED, Price: 10.37, Cost: 103.70, Comm 0.10\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.37\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.40\n2023-10-30, Close, 10.41\n2023-10-30, Close, 10.41\n2023-10-30, Close, 10.41\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.38\n2023-10-30, SELL CREATE, 10.38\n2023-10-30, SELL EXECUTED, Price: 10.38, Cost: 103.70, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.39\n2023-10-30, BUY CREATE, 10.39\n2023-10-30, BUY EXECUTED, Price: 10.38, Cost: 103.80, Comm 0.10\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.39\n2023-10-30, SELL CREATE, 10.39\n2023-10-30, SELL EXECUTED, Price: 10.38, Cost: 103.80, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.39\n2023-10-30, BUY CREATE, 10.39\n2023-10-30, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-30, Close, 10.38\n2023-10-30, SELL CREATE, 10.38\n2023-10-30, SELL EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.39\n2023-10-30, BUY CREATE, 10.39\n2023-10-30, BUY EXECUTED, Price: 10.38, Cost: 103.80, Comm 0.10\n2023-10-30, Close, 10.38\n2023-10-30, SELL CREATE, 10.38\n2023-10-30, SELL EXECUTED, Price: 10.38, Cost: 103.80, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.38\n2023-10-30, Close, 10.39\n2023-10-30, BUY CREATE, 10.39\n2023-10-30, BUY EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.38\n2023-10-30, SELL CREATE, 10.38\n2023-10-30, SELL EXECUTED, Price: 10.39, Cost: 103.90, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.40\n2023-10-30, BUY CREATE, 10.40\n2023-10-30, BUY EXECUTED, Price: 10.40, Cost: 104.00, Comm 0.10\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.40\n2023-10-30, Close, 10.40\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.39\n2023-10-30, Close, 10.40\n2023-10-30, Close, 10.40\n2023-10-30, Close, 10.42\n2023-10-30, Close, 10.42\n2023-10-30, Close, 10.42\n2023-10-30, Close, 10.41\n2023-10-30, Close, 10.41\n2023-10-30, Close, 10.40\n2023-10-30, SELL CREATE, 10.40\n2023-10-30, SELL EXECUTED, Price: 10.40, Cost: 104.00, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.40\n2023-10-30, Close, 10.41\n2023-10-30, BUY CREATE, 10.41\n2023-10-30, BUY EXECUTED, Price: 10.41, Cost: 104.10, Comm 0.10\n2023-10-30, Close, 10.41\n2023-10-30, Close, 10.42\n2023-10-30, Close, 10.43\n2023-10-30, Close, 10.43\n2023-10-30, Close, 10.43\n2023-10-30, Close, 10.42\n2023-10-30, Close, 10.42\n2023-10-30, Close, 10.42\n2023-10-30, Close, 10.42\n2023-10-30, Close, 10.41\n2023-10-30, SELL CREATE, 10.41\n2023-10-30, SELL EXECUTED, Price: 10.42, Cost: 104.10, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-30, Close, 10.41\n2023-10-30, Close, 10.43\n2023-10-30, BUY CREATE, 10.43\n2023-10-30, BUY EXECUTED, Price: 10.42, Cost: 104.20, Comm 0.10\n2023-10-30, Close, 10.42\n2023-10-30, Close, 10.43\n2023-10-30, Close, 10.43\n2023-10-30, Close, 10.42\n2023-10-30, SELL CREATE, 10.42\n2023-10-30, SELL EXECUTED, Price: 10.42, Cost: 104.20, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.43\n2023-10-30, BUY CREATE, 10.43\n2023-10-30, BUY EXECUTED, Price: 10.42, Cost: 104.20, Comm 0.10\n2023-10-30, Close, 10.43\n2023-10-30, Close, 10.43\n2023-10-30, Close, 10.45\n2023-10-30, Close, 10.45\n2023-10-30, Close, 10.45\n2023-10-30, Close, 10.45\n2023-10-30, Close, 10.45\n2023-10-30, Close, 10.44\n2023-10-30, Close, 10.44\n2023-10-30, Close, 10.43\n2023-10-30, SELL CREATE, 10.43\n2023-10-30, SELL EXECUTED, Price: 10.43, Cost: 104.20, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-30, Close, 10.43\n2023-10-30, Close, 10.43\n2023-10-30, Close, 10.44\n2023-10-30, BUY CREATE, 10.44\n2023-10-30, BUY EXECUTED, Price: 10.43, Cost: 104.30, Comm 0.10\n2023-10-30, Close, 10.43\n2023-10-30, SELL CREATE, 10.43\n2023-10-30, SELL EXECUTED, Price: 10.43, Cost: 104.30, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.44\n2023-10-30, BUY CREATE, 10.44\n2023-10-30, BUY EXECUTED, Price: 10.43, Cost: 104.30, Comm 0.10\n2023-10-30, Close, 10.44\n2023-10-30, Close, 10.45\n2023-10-30, Close, 10.44\n2023-10-30, SELL CREATE, 10.44\n2023-10-30, SELL EXECUTED, Price: 10.44, Cost: 104.30, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-30, Close, 10.45\n2023-10-30, BUY CREATE, 10.45\n2023-10-30, BUY EXECUTED, Price: 10.44, Cost: 104.40, Comm 0.10\n2023-10-30, Close, 10.45\n2023-10-30, Close, 10.44\n2023-10-30, Close, 10.44\n2023-10-30, Close, 10.45\n2023-10-30, Close, 10.44\n2023-10-30, Close, 10.44\n2023-10-30, SELL CREATE, 10.44\n2023-10-30, SELL EXECUTED, Price: 10.45, Cost: 104.40, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-30, Close, 10.44\n2023-10-30, Close, 10.44\n2023-10-30, Close, 10.44\n2023-10-30, Close, 10.45\n2023-10-30, BUY CREATE, 10.45\n2023-10-30, BUY EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-10-30, Close, 10.44\n2023-10-30, SELL CREATE, 10.44\n2023-10-30, SELL EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.44\n2023-10-30, Close, 10.44\n2023-10-30, Close, 10.45\n2023-10-30, BUY CREATE, 10.45\n2023-10-30, BUY EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-10-30, Close, 10.44\n2023-10-30, SELL CREATE, 10.44\n2023-10-30, SELL EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.44\n2023-10-30, Close, 10.44\n2023-10-30, Close, 10.45\n2023-10-30, BUY CREATE, 10.45\n2023-10-30, BUY EXECUTED, Price: 10.44, Cost: 104.40, Comm 0.10\n2023-10-30, Close, 10.44\n2023-10-30, SELL CREATE, 10.44\n2023-10-30, SELL EXECUTED, Price: 10.45, Cost: 104.40, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-30, Close, 10.45\n2023-10-30, BUY CREATE, 10.45\n2023-10-30, BUY EXECUTED, Price: 10.44, Cost: 104.40, Comm 0.10\n2023-10-30, Close, 10.44\n2023-10-30, SELL CREATE, 10.44\n2023-10-30, SELL EXECUTED, Price: 10.44, Cost: 104.40, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.45\n2023-10-30, BUY CREATE, 10.45\n2023-10-30, BUY EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-10-30, Close, 10.45\n2023-10-30, Close, 10.44\n2023-10-30, SELL CREATE, 10.44\n2023-10-30, SELL EXECUTED, Price: 10.44, Cost: 104.50, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-30, Close, 10.45\n2023-10-30, BUY CREATE, 10.45\n2023-10-30, BUY EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-10-30, Close, 10.44\n2023-10-30, SELL CREATE, 10.44\n2023-10-30, SELL EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.45\n2023-10-30, BUY CREATE, 10.45\n2023-10-30, BUY EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-10-30, Close, 10.45\n2023-10-30, Close, 10.45\n2023-10-30, Close, 10.45\n2023-10-30, Close, 10.44\n2023-10-30, SELL CREATE, 10.44\n2023-10-30, SELL EXECUTED, Price: 10.44, Cost: 104.50, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-30, Close, 10.44\n2023-10-30, Close, 10.45\n2023-10-30, BUY CREATE, 10.45\n2023-10-30, BUY EXECUTED, Price: 10.44, Cost: 104.40, Comm 0.10\n2023-10-30, Close, 10.44\n2023-10-30, SELL CREATE, 10.44\n2023-10-30, SELL EXECUTED, Price: 10.44, Cost: 104.40, Comm 0.10\n2023-10-30, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-30, Close, 10.44\n2023-10-30, Close, 10.44\n2023-10-30, Close, 10.45\n2023-10-30, BUY CREATE, 10.45\n2023-10-30, BUY EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-10-30, Close, 10.45\n2023-10-30, Close, 10.46\n2023-10-30, Close, 10.46\n2023-10-30, Close, 10.46\n2023-10-30, Close, 10.45\n2023-10-31, Close, 10.42\n2023-10-31, SELL CREATE, 10.42\n2023-10-31, SELL EXECUTED, Price: 10.42, Cost: 104.50, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS -0.30, NET -0.51\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.45\n2023-10-31, BUY CREATE, 10.45\n2023-10-31, BUY EXECUTED, Price: 10.44, Cost: 104.40, Comm 0.10\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.48\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.45\n2023-10-31, SELL CREATE, 10.45\n2023-10-31, SELL EXECUTED, Price: 10.45, Cost: 104.40, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.47\n2023-10-31, BUY CREATE, 10.47\n2023-10-31, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.48\n2023-10-31, Close, 10.48\n2023-10-31, Close, 10.48\n2023-10-31, Close, 10.48\n2023-10-31, Close, 10.49\n2023-10-31, Close, 10.49\n2023-10-31, Close, 10.49\n2023-10-31, Close, 10.47\n2023-10-31, SELL CREATE, 10.47\n2023-10-31, SELL EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-31, Close, 10.48\n2023-10-31, BUY CREATE, 10.48\n2023-10-31, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-10-31, Close, 10.48\n2023-10-31, Close, 10.47\n2023-10-31, SELL CREATE, 10.47\n2023-10-31, SELL EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.44\n2023-10-31, BUY CREATE, 10.44\n2023-10-31, BUY EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.43\n2023-10-31, SELL CREATE, 10.43\n2023-10-31, SELL EXECUTED, Price: 10.43, Cost: 104.50, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS -0.20, NET -0.41\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.44\n2023-10-31, BUY CREATE, 10.44\n2023-10-31, BUY EXECUTED, Price: 10.44, Cost: 104.40, Comm 0.10\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.43\n2023-10-31, SELL CREATE, 10.43\n2023-10-31, SELL EXECUTED, Price: 10.43, Cost: 104.40, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.41\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.43\n2023-10-31, BUY CREATE, 10.43\n2023-10-31, BUY EXECUTED, Price: 10.42, Cost: 104.20, Comm 0.10\n2023-10-31, Close, 10.42\n2023-10-31, SELL CREATE, 10.42\n2023-10-31, SELL EXECUTED, Price: 10.42, Cost: 104.20, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-31, Close, 10.43\n2023-10-31, BUY CREATE, 10.43\n2023-10-31, BUY EXECUTED, Price: 10.43, Cost: 104.30, Comm 0.10\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.42\n2023-10-31, SELL CREATE, 10.42\n2023-10-31, SELL EXECUTED, Price: 10.42, Cost: 104.30, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.43\n2023-10-31, BUY CREATE, 10.43\n2023-10-31, BUY EXECUTED, Price: 10.42, Cost: 104.20, Comm 0.10\n2023-10-31, Close, 10.42\n2023-10-31, SELL CREATE, 10.42\n2023-10-31, SELL EXECUTED, Price: 10.42, Cost: 104.20, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-31, Close, 10.43\n2023-10-31, BUY CREATE, 10.43\n2023-10-31, BUY EXECUTED, Price: 10.43, Cost: 104.30, Comm 0.10\n2023-10-31, Close, 10.42\n2023-10-31, SELL CREATE, 10.42\n2023-10-31, SELL EXECUTED, Price: 10.43, Cost: 104.30, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-31, Close, 10.43\n2023-10-31, BUY CREATE, 10.43\n2023-10-31, BUY EXECUTED, Price: 10.42, Cost: 104.20, Comm 0.10\n2023-10-31, Close, 10.42\n2023-10-31, SELL CREATE, 10.42\n2023-10-31, SELL EXECUTED, Price: 10.42, Cost: 104.20, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-31, Close, 10.43\n2023-10-31, BUY CREATE, 10.43\n2023-10-31, BUY EXECUTED, Price: 10.43, Cost: 104.30, Comm 0.10\n2023-10-31, Close, 10.42\n2023-10-31, SELL CREATE, 10.42\n2023-10-31, SELL EXECUTED, Price: 10.42, Cost: 104.30, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.43\n2023-10-31, BUY CREATE, 10.43\n2023-10-31, BUY EXECUTED, Price: 10.43, Cost: 104.30, Comm 0.10\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.42\n2023-10-31, SELL CREATE, 10.42\n2023-10-31, SELL EXECUTED, Price: 10.42, Cost: 104.30, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.43\n2023-10-31, BUY CREATE, 10.43\n2023-10-31, BUY EXECUTED, Price: 10.42, Cost: 104.20, Comm 0.10\n2023-10-31, Close, 10.42\n2023-10-31, SELL CREATE, 10.42\n2023-10-31, SELL EXECUTED, Price: 10.42, Cost: 104.20, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.41\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.43\n2023-10-31, BUY CREATE, 10.43\n2023-10-31, BUY EXECUTED, Price: 10.42, Cost: 104.20, Comm 0.10\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.42\n2023-10-31, SELL CREATE, 10.42\n2023-10-31, SELL EXECUTED, Price: 10.42, Cost: 104.20, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.43\n2023-10-31, BUY CREATE, 10.43\n2023-10-31, BUY EXECUTED, Price: 10.42, Cost: 104.20, Comm 0.10\n2023-10-31, Close, 10.42\n2023-10-31, SELL CREATE, 10.42\n2023-10-31, SELL EXECUTED, Price: 10.43, Cost: 104.20, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.43\n2023-10-31, BUY CREATE, 10.43\n2023-10-31, BUY EXECUTED, Price: 10.43, Cost: 104.30, Comm 0.10\n2023-10-31, Close, 10.42\n2023-10-31, SELL CREATE, 10.42\n2023-10-31, SELL EXECUTED, Price: 10.43, Cost: 104.30, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-31, Close, 10.42\n2023-10-31, Close, 10.43\n2023-10-31, BUY CREATE, 10.43\n2023-10-31, BUY EXECUTED, Price: 10.43, Cost: 104.30, Comm 0.10\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.43\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.46\n2023-10-31, SELL CREATE, 10.46\n2023-10-31, SELL EXECUTED, Price: 10.45, Cost: 104.30, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS 0.20, NET -0.01\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.47\n2023-10-31, BUY CREATE, 10.47\n2023-10-31, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.46\n2023-10-31, SELL CREATE, 10.46\n2023-10-31, SELL EXECUTED, Price: 10.46, Cost: 104.70, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.47\n2023-10-31, BUY CREATE, 10.47\n2023-10-31, BUY EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-10-31, Close, 10.46\n2023-10-31, SELL CREATE, 10.46\n2023-10-31, SELL EXECUTED, Price: 10.47, Cost: 104.60, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.44\n2023-10-31, Close, 10.45\n2023-10-31, BUY CREATE, 10.45\n2023-10-31, BUY EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.45\n2023-10-31, SELL CREATE, 10.45\n2023-10-31, SELL EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-10-31, Close, 10.46\n2023-10-31, BUY CREATE, 10.46\n2023-10-31, BUY EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.45\n2023-10-31, SELL CREATE, 10.45\n2023-10-31, SELL EXECUTED, Price: 10.45, Cost: 104.60, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.45\n2023-10-31, Close, 10.46\n2023-10-31, BUY CREATE, 10.46\n2023-10-31, BUY EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-10-31, Close, 10.45\n2023-10-31, SELL CREATE, 10.45\n2023-10-31, SELL EXECUTED, Price: 10.46, Cost: 104.50, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-31, Close, 10.46\n2023-10-31, BUY CREATE, 10.46\n2023-10-31, BUY EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.47\n2023-10-31, Close, 10.46\n2023-10-31, SELL CREATE, 10.46\n2023-10-31, SELL EXECUTED, Price: 10.47, Cost: 104.60, Comm 0.10\n2023-10-31, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.46\n2023-10-31, Close, 10.47\n2023-10-31, BUY CREATE, 10.47\n2023-10-31, BUY EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-10-31, Close, 10.46\n2023-10-31, SELL CREATE, 10.46\n2023-11-01, SELL EXECUTED, Price: 10.55, Cost: 104.60, Comm 0.11\n2023-11-01, OPERATION PROFIT, GROSS 0.90, NET 0.69\n2023-11-01, Close, 10.52\n2023-11-01, BUY CREATE, 10.52\n2023-11-01, BUY EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-01, Close, 10.52\n2023-11-01, Close, 10.52\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.47\n2023-11-01, SELL CREATE, 10.47\n2023-11-01, SELL EXECUTED, Price: 10.48, Cost: 105.20, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS -0.40, NET -0.61\n2023-11-01, Close, 10.49\n2023-11-01, BUY CREATE, 10.49\n2023-11-01, BUY EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.51\n2023-11-01, Close, 10.53\n2023-11-01, Close, 10.51\n2023-11-01, Close, 10.51\n2023-11-01, Close, 10.49\n2023-11-01, SELL CREATE, 10.49\n2023-11-01, SELL EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-01, Close, 10.50\n2023-11-01, BUY CREATE, 10.50\n2023-11-01, BUY EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-01, Close, 10.52\n2023-11-01, Close, 10.51\n2023-11-01, Close, 10.51\n2023-11-01, Close, 10.50\n2023-11-01, SELL CREATE, 10.50\n2023-11-01, SELL EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.47\n2023-11-01, BUY CREATE, 10.47\n2023-11-01, BUY EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-11-01, Close, 10.46\n2023-11-01, SELL CREATE, 10.46\n2023-11-01, SELL EXECUTED, Price: 10.47, Cost: 104.60, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-11-01, Close, 10.47\n2023-11-01, BUY CREATE, 10.47\n2023-11-01, BUY EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.46\n2023-11-01, SELL CREATE, 10.46\n2023-11-01, SELL EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.47\n2023-11-01, BUY CREATE, 10.47\n2023-11-01, BUY EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.46\n2023-11-01, SELL CREATE, 10.46\n2023-11-01, SELL EXECUTED, Price: 10.47, Cost: 104.60, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.47\n2023-11-01, BUY CREATE, 10.47\n2023-11-01, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.47\n2023-11-01, SELL CREATE, 10.47\n2023-11-01, SELL EXECUTED, Price: 10.48, Cost: 104.70, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.48\n2023-11-01, BUY CREATE, 10.48\n2023-11-01, BUY EXECUTED, Price: 10.48, Cost: 104.80, Comm 0.10\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.47\n2023-11-01, SELL CREATE, 10.47\n2023-11-01, SELL EXECUTED, Price: 10.48, Cost: 104.80, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.48\n2023-11-01, BUY CREATE, 10.48\n2023-11-01, BUY EXECUTED, Price: 10.48, Cost: 104.80, Comm 0.10\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.47\n2023-11-01, SELL CREATE, 10.47\n2023-11-01, SELL EXECUTED, Price: 10.47, Cost: 104.80, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.48\n2023-11-01, BUY CREATE, 10.48\n2023-11-01, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-11-01, Close, 10.47\n2023-11-01, SELL CREATE, 10.47\n2023-11-01, SELL EXECUTED, Price: 10.46, Cost: 104.70, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.46\n2023-11-01, Close, 10.47\n2023-11-01, BUY CREATE, 10.47\n2023-11-01, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-11-01, Close, 10.46\n2023-11-01, SELL CREATE, 10.46\n2023-11-01, SELL EXECUTED, Price: 10.46, Cost: 104.70, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-01, Close, 10.47\n2023-11-01, BUY CREATE, 10.47\n2023-11-01, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.47\n2023-11-01, SELL CREATE, 10.47\n2023-11-01, SELL EXECUTED, Price: 10.48, Cost: 104.70, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.48\n2023-11-01, BUY CREATE, 10.48\n2023-11-01, BUY EXECUTED, Price: 10.48, Cost: 104.80, Comm 0.10\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.47\n2023-11-01, SELL CREATE, 10.47\n2023-11-01, SELL EXECUTED, Price: 10.48, Cost: 104.80, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.48\n2023-11-01, BUY CREATE, 10.48\n2023-11-01, BUY EXECUTED, Price: 10.48, Cost: 104.80, Comm 0.10\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.47\n2023-11-01, SELL CREATE, 10.47\n2023-11-01, SELL EXECUTED, Price: 10.47, Cost: 104.80, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-01, Close, 10.48\n2023-11-01, BUY CREATE, 10.48\n2023-11-01, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.47\n2023-11-01, SELL CREATE, 10.47\n2023-11-01, SELL EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-01, Close, 10.48\n2023-11-01, BUY CREATE, 10.48\n2023-11-01, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-11-01, Close, 10.47\n2023-11-01, SELL CREATE, 10.47\n2023-11-01, SELL EXECUTED, Price: 10.48, Cost: 104.70, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.49\n2023-11-01, BUY CREATE, 10.49\n2023-11-01, BUY EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.47\n2023-11-01, SELL CREATE, 10.47\n2023-11-01, SELL EXECUTED, Price: 10.48, Cost: 104.90, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.48\n2023-11-01, BUY CREATE, 10.48\n2023-11-01, BUY EXECUTED, Price: 10.48, Cost: 104.80, Comm 0.10\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, SELL CREATE, 10.48\n2023-11-01, SELL EXECUTED, Price: 10.47, Cost: 104.80, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.48\n2023-11-01, BUY CREATE, 10.48\n2023-11-01, BUY EXECUTED, Price: 10.48, Cost: 104.80, Comm 0.10\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.47\n2023-11-01, SELL CREATE, 10.47\n2023-11-01, SELL EXECUTED, Price: 10.48, Cost: 104.80, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-01, Close, 10.47\n2023-11-01, Close, 10.48\n2023-11-01, BUY CREATE, 10.48\n2023-11-01, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.48\n2023-11-01, SELL CREATE, 10.48\n2023-11-01, SELL EXECUTED, Price: 10.49, Cost: 104.70, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS 0.20, NET -0.01\n2023-11-01, Close, 10.49\n2023-11-01, BUY CREATE, 10.49\n2023-11-01, BUY EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.49\n2023-11-01, SELL CREATE, 10.49\n2023-11-01, SELL EXECUTED, Price: 10.49, Cost: 105.00, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.50\n2023-11-01, BUY CREATE, 10.50\n2023-11-01, BUY EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.49\n2023-11-01, SELL CREATE, 10.49\n2023-11-01, SELL EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.50\n2023-11-01, BUY CREATE, 10.50\n2023-11-01, BUY EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-01, Close, 10.49\n2023-11-01, SELL CREATE, 10.49\n2023-11-01, SELL EXECUTED, Price: 10.49, Cost: 105.00, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.51\n2023-11-01, BUY CREATE, 10.51\n2023-11-01, BUY EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.49\n2023-11-01, SELL CREATE, 10.49\n2023-11-01, SELL EXECUTED, Price: 10.49, Cost: 105.00, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.50\n2023-11-01, BUY CREATE, 10.50\n2023-11-01, BUY EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.50\n2023-11-01, Close, 10.49\n2023-11-01, SELL CREATE, 10.49\n2023-11-01, SELL EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.50\n2023-11-01, BUY CREATE, 10.50\n2023-11-01, BUY EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-01, Close, 10.49\n2023-11-01, SELL CREATE, 10.49\n2023-11-01, SELL EXECUTED, Price: 10.49, Cost: 105.00, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-01, Close, 10.50\n2023-11-01, BUY CREATE, 10.50\n2023-11-01, BUY EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-01, Close, 10.49\n2023-11-01, SELL CREATE, 10.49\n2023-11-01, SELL EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-01, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.48\n2023-11-01, Close, 10.49\n2023-11-01, Close, 10.48\n2023-11-02, Close, 10.52\n2023-11-02, BUY CREATE, 10.52\n2023-11-02, BUY EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.57\n2023-11-02, Close, 10.57\n2023-11-02, Close, 10.58\n2023-11-02, Close, 10.59\n2023-11-02, Close, 10.60\n2023-11-02, Close, 10.59\n2023-11-02, Close, 10.59\n2023-11-02, Close, 10.59\n2023-11-02, Close, 10.58\n2023-11-02, Close, 10.57\n2023-11-02, Close, 10.57\n2023-11-02, Close, 10.58\n2023-11-02, Close, 10.57\n2023-11-02, SELL CREATE, 10.57\n2023-11-02, SELL EXECUTED, Price: 10.58, Cost: 105.20, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.60, NET 0.39\n2023-11-02, Close, 10.57\n2023-11-02, Close, 10.56\n2023-11-02, Close, 10.56\n2023-11-02, Close, 10.56\n2023-11-02, Close, 10.55\n2023-11-02, Close, 10.55\n2023-11-02, Close, 10.55\n2023-11-02, Close, 10.55\n2023-11-02, Close, 10.55\n2023-11-02, Close, 10.55\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.55\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.53\n2023-11-02, Close, 10.53\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.53\n2023-11-02, Close, 10.53\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.54\n2023-11-02, BUY CREATE, 10.54\n2023-11-02, BUY EXECUTED, Price: 10.53, Cost: 105.30, Comm 0.11\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.52\n2023-11-02, SELL CREATE, 10.52\n2023-11-02, SELL EXECUTED, Price: 10.52, Cost: 105.30, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.53\n2023-11-02, BUY CREATE, 10.53\n2023-11-02, BUY EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, Close, 10.52\n2023-11-02, SELL CREATE, 10.52\n2023-11-02, SELL EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.52\n2023-11-02, BUY CREATE, 10.52\n2023-11-02, BUY EXECUTED, Price: 10.51, Cost: 105.10, Comm 0.11\n2023-11-02, Close, 10.51\n2023-11-02, SELL CREATE, 10.51\n2023-11-02, SELL EXECUTED, Price: 10.52, Cost: 105.10, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.52\n2023-11-02, BUY CREATE, 10.52\n2023-11-02, BUY EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, Close, 10.51\n2023-11-02, SELL CREATE, 10.51\n2023-11-02, SELL EXECUTED, Price: 10.51, Cost: 105.20, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-02, Close, 10.52\n2023-11-02, BUY CREATE, 10.52\n2023-11-02, BUY EXECUTED, Price: 10.51, Cost: 105.10, Comm 0.11\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.51\n2023-11-02, SELL CREATE, 10.51\n2023-11-02, SELL EXECUTED, Price: 10.51, Cost: 105.10, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-02, Close, 10.52\n2023-11-02, BUY CREATE, 10.52\n2023-11-02, BUY EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.53\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.53\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, SELL CREATE, 10.52\n2023-11-02, SELL EXECUTED, Price: 10.53, Cost: 105.20, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-11-02, Close, 10.54\n2023-11-02, BUY CREATE, 10.54\n2023-11-02, BUY EXECUTED, Price: 10.53, Cost: 105.30, Comm 0.11\n2023-11-02, Close, 10.53\n2023-11-02, Close, 10.53\n2023-11-02, Close, 10.53\n2023-11-02, Close, 10.52\n2023-11-02, SELL CREATE, 10.52\n2023-11-02, SELL EXECUTED, Price: 10.53, Cost: 105.30, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.53\n2023-11-02, BUY CREATE, 10.53\n2023-11-02, BUY EXECUTED, Price: 10.53, Cost: 105.30, Comm 0.11\n2023-11-02, Close, 10.52\n2023-11-02, SELL CREATE, 10.52\n2023-11-02, SELL EXECUTED, Price: 10.52, Cost: 105.30, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.53\n2023-11-02, BUY CREATE, 10.53\n2023-11-02, BUY EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, Close, 10.52\n2023-11-02, SELL CREATE, 10.52\n2023-11-02, SELL EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-02, Close, 10.53\n2023-11-02, BUY CREATE, 10.53\n2023-11-02, BUY EXECUTED, Price: 10.53, Cost: 105.30, Comm 0.11\n2023-11-02, Close, 10.53\n2023-11-02, Close, 10.52\n2023-11-02, SELL CREATE, 10.52\n2023-11-02, SELL EXECUTED, Price: 10.53, Cost: 105.30, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-02, Close, 10.53\n2023-11-02, BUY CREATE, 10.53\n2023-11-02, BUY EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, Close, 10.53\n2023-11-02, Close, 10.52\n2023-11-02, SELL CREATE, 10.52\n2023-11-02, SELL EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-02, Close, 10.53\n2023-11-02, BUY CREATE, 10.53\n2023-11-02, BUY EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, Close, 10.52\n2023-11-02, SELL CREATE, 10.52\n2023-11-02, SELL EXECUTED, Price: 10.53, Cost: 105.20, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-11-02, Close, 10.53\n2023-11-02, BUY CREATE, 10.53\n2023-11-02, BUY EXECUTED, Price: 10.53, Cost: 105.30, Comm 0.11\n2023-11-02, Close, 10.53\n2023-11-02, Close, 10.55\n2023-11-02, Close, 10.55\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.55\n2023-11-02, Close, 10.55\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.55\n2023-11-02, Close, 10.54\n2023-11-02, SELL CREATE, 10.54\n2023-11-02, SELL EXECUTED, Price: 10.54, Cost: 105.30, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.53\n2023-11-02, Close, 10.53\n2023-11-02, Close, 10.54\n2023-11-02, Close, 10.53\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.53\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.52\n2023-11-02, BUY CREATE, 10.52\n2023-11-02, BUY EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, Close, 10.51\n2023-11-02, SELL CREATE, 10.51\n2023-11-02, SELL EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-02, Close, 10.52\n2023-11-02, BUY CREATE, 10.52\n2023-11-02, BUY EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.51\n2023-11-02, SELL CREATE, 10.51\n2023-11-02, SELL EXECUTED, Price: 10.51, Cost: 105.20, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.52\n2023-11-02, BUY CREATE, 10.52\n2023-11-02, BUY EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.51\n2023-11-02, SELL CREATE, 10.51\n2023-11-02, SELL EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.52\n2023-11-02, BUY CREATE, 10.52\n2023-11-02, BUY EXECUTED, Price: 10.51, Cost: 105.10, Comm 0.11\n2023-11-02, Close, 10.51\n2023-11-02, SELL CREATE, 10.51\n2023-11-02, SELL EXECUTED, Price: 10.51, Cost: 105.10, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-02, Close, 10.52\n2023-11-02, BUY CREATE, 10.52\n2023-11-02, BUY EXECUTED, Price: 10.51, Cost: 105.10, Comm 0.11\n2023-11-02, Close, 10.51\n2023-11-02, SELL CREATE, 10.51\n2023-11-02, SELL EXECUTED, Price: 10.52, Cost: 105.10, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-11-02, Close, 10.52\n2023-11-02, BUY CREATE, 10.52\n2023-11-02, BUY EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, Close, 10.51\n2023-11-02, SELL CREATE, 10.51\n2023-11-02, SELL EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.52\n2023-11-02, BUY CREATE, 10.52\n2023-11-02, BUY EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.52\n2023-11-02, Close, 10.51\n2023-11-02, SELL CREATE, 10.51\n2023-11-02, SELL EXECUTED, Price: 10.51, Cost: 105.20, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-02, Close, 10.52\n2023-11-02, BUY CREATE, 10.52\n2023-11-02, BUY EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, Close, 10.51\n2023-11-02, SELL CREATE, 10.51\n2023-11-02, SELL EXECUTED, Price: 10.52, Cost: 105.20, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.52\n2023-11-02, BUY CREATE, 10.52\n2023-11-02, BUY EXECUTED, Price: 10.51, Cost: 105.10, Comm 0.11\n2023-11-02, Close, 10.50\n2023-11-02, SELL CREATE, 10.50\n2023-11-02, SELL EXECUTED, Price: 10.51, Cost: 105.10, Comm 0.11\n2023-11-02, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.48\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.50\n2023-11-02, BUY CREATE, 10.50\n2023-11-02, BUY EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.49\n2023-11-02, SELL CREATE, 10.49\n2023-11-02, SELL EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-02, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.50\n2023-11-02, BUY CREATE, 10.50\n2023-11-02, BUY EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-02, Close, 10.49\n2023-11-02, SELL CREATE, 10.49\n2023-11-02, SELL EXECUTED, Price: 10.49, Cost: 105.00, Comm 0.10\n2023-11-02, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.50\n2023-11-02, BUY CREATE, 10.50\n2023-11-02, BUY EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-02, Close, 10.49\n2023-11-02, SELL CREATE, 10.49\n2023-11-02, SELL EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-02, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-02, Close, 10.50\n2023-11-02, BUY CREATE, 10.50\n2023-11-02, BUY EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.51\n2023-11-02, Close, 10.50\n2023-11-02, SELL CREATE, 10.50\n2023-11-02, SELL EXECUTED, Price: 10.50, Cost: 104.90, Comm 0.10\n2023-11-02, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.51\n2023-11-02, BUY CREATE, 10.51\n2023-11-02, BUY EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-02, Close, 10.50\n2023-11-02, SELL CREATE, 10.50\n2023-11-02, SELL EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-02, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.50\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.48\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.48\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.48\n2023-11-02, Close, 10.48\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.49\n2023-11-02, BUY CREATE, 10.49\n2023-11-02, BUY EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-02, Close, 10.49\n2023-11-02, Close, 10.48\n2023-11-02, SELL CREATE, 10.48\n2023-11-03, SELL EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-03, Close, 10.50\n2023-11-03, BUY CREATE, 10.50\n2023-11-03, BUY EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-03, Close, 10.48\n2023-11-03, SELL CREATE, 10.48\n2023-11-03, SELL EXECUTED, Price: 10.48, Cost: 104.90, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.50\n2023-11-03, BUY CREATE, 10.50\n2023-11-03, BUY EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.47\n2023-11-03, SELL CREATE, 10.47\n2023-11-03, SELL EXECUTED, Price: 10.47, Cost: 104.90, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS -0.20, NET -0.41\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.44\n2023-11-03, Close, 10.44\n2023-11-03, Close, 10.44\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.46\n2023-11-03, BUY CREATE, 10.46\n2023-11-03, BUY EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-11-03, Close, 10.45\n2023-11-03, SELL CREATE, 10.45\n2023-11-03, SELL EXECUTED, Price: 10.45, Cost: 104.60, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.45\n2023-11-03, BUY CREATE, 10.45\n2023-11-03, BUY EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.45\n2023-11-03, SELL CREATE, 10.45\n2023-11-03, SELL EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.46\n2023-11-03, BUY CREATE, 10.46\n2023-11-03, BUY EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.46\n2023-11-03, SELL CREATE, 10.46\n2023-11-03, SELL EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-03, Close, 10.47\n2023-11-03, BUY CREATE, 10.47\n2023-11-03, BUY EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-11-03, Close, 10.46\n2023-11-03, SELL CREATE, 10.46\n2023-11-03, SELL EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.47\n2023-11-03, BUY CREATE, 10.47\n2023-11-03, BUY EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-11-03, Close, 10.46\n2023-11-03, SELL CREATE, 10.46\n2023-11-03, SELL EXECUTED, Price: 10.47, Cost: 104.60, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.47\n2023-11-03, BUY CREATE, 10.47\n2023-11-03, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.51\n2023-11-03, Close, 10.52\n2023-11-03, Close, 10.52\n2023-11-03, Close, 10.52\n2023-11-03, Close, 10.51\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.51\n2023-11-03, Close, 10.50\n2023-11-03, SELL CREATE, 10.50\n2023-11-03, SELL EXECUTED, Price: 10.50, Cost: 104.70, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.30, NET 0.09\n2023-11-03, Close, 10.51\n2023-11-03, BUY CREATE, 10.51\n2023-11-03, BUY EXECUTED, Price: 10.51, Cost: 105.10, Comm 0.11\n2023-11-03, Close, 10.50\n2023-11-03, SELL CREATE, 10.50\n2023-11-03, SELL EXECUTED, Price: 10.50, Cost: 105.10, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.51\n2023-11-03, BUY CREATE, 10.51\n2023-11-03, BUY EXECUTED, Price: 10.51, Cost: 105.10, Comm 0.11\n2023-11-03, Close, 10.51\n2023-11-03, Close, 10.50\n2023-11-03, SELL CREATE, 10.50\n2023-11-03, SELL EXECUTED, Price: 10.51, Cost: 105.10, Comm 0.11\n2023-11-03, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-03, Close, 10.51\n2023-11-03, BUY CREATE, 10.51\n2023-11-03, BUY EXECUTED, Price: 10.51, Cost: 105.10, Comm 0.11\n2023-11-03, Close, 10.51\n2023-11-03, Close, 10.50\n2023-11-03, SELL CREATE, 10.50\n2023-11-03, SELL EXECUTED, Price: 10.49, Cost: 105.10, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS -0.20, NET -0.41\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.50\n2023-11-03, BUY CREATE, 10.50\n2023-11-03, BUY EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-03, Close, 10.49\n2023-11-03, SELL CREATE, 10.49\n2023-11-03, SELL EXECUTED, Price: 10.49, Cost: 105.00, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.50\n2023-11-03, BUY CREATE, 10.50\n2023-11-03, BUY EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-03, Close, 10.49\n2023-11-03, SELL CREATE, 10.49\n2023-11-03, SELL EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-03, Close, 10.50\n2023-11-03, BUY CREATE, 10.50\n2023-11-03, BUY EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.50\n2023-11-03, Close, 10.49\n2023-11-03, SELL CREATE, 10.49\n2023-11-03, SELL EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.50\n2023-11-03, BUY CREATE, 10.50\n2023-11-03, BUY EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-03, Close, 10.49\n2023-11-03, SELL CREATE, 10.49\n2023-11-03, SELL EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.50\n2023-11-03, BUY CREATE, 10.50\n2023-11-03, BUY EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-03, Close, 10.48\n2023-11-03, SELL CREATE, 10.48\n2023-11-03, SELL EXECUTED, Price: 10.48, Cost: 105.00, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS -0.20, NET -0.41\n2023-11-03, Close, 10.50\n2023-11-03, BUY CREATE, 10.50\n2023-11-03, BUY EXECUTED, Price: 10.50, Cost: 105.00, Comm 0.10\n2023-11-03, Close, 10.48\n2023-11-03, SELL CREATE, 10.48\n2023-11-03, SELL EXECUTED, Price: 10.48, Cost: 105.00, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS -0.20, NET -0.41\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.49\n2023-11-03, BUY CREATE, 10.49\n2023-11-03, BUY EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.48\n2023-11-03, SELL CREATE, 10.48\n2023-11-03, SELL EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.49\n2023-11-03, BUY CREATE, 10.49\n2023-11-03, BUY EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-03, Close, 10.48\n2023-11-03, SELL CREATE, 10.48\n2023-11-03, SELL EXECUTED, Price: 10.48, Cost: 104.90, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.49\n2023-11-03, BUY CREATE, 10.49\n2023-11-03, BUY EXECUTED, Price: 10.48, Cost: 104.80, Comm 0.10\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.49\n2023-11-03, Close, 10.48\n2023-11-03, SELL CREATE, 10.48\n2023-11-03, SELL EXECUTED, Price: 10.48, Cost: 104.80, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.49\n2023-11-03, BUY CREATE, 10.49\n2023-11-03, BUY EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-03, Close, 10.48\n2023-11-03, SELL CREATE, 10.48\n2023-11-03, SELL EXECUTED, Price: 10.49, Cost: 104.90, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.49\n2023-11-03, BUY CREATE, 10.49\n2023-11-03, BUY EXECUTED, Price: 10.48, Cost: 104.80, Comm 0.10\n2023-11-03, Close, 10.48\n2023-11-03, SELL CREATE, 10.48\n2023-11-03, SELL EXECUTED, Price: 10.48, Cost: 104.80, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.48\n2023-11-03, BUY CREATE, 10.48\n2023-11-03, BUY EXECUTED, Price: 10.48, Cost: 104.80, Comm 0.10\n2023-11-03, Close, 10.46\n2023-11-03, SELL CREATE, 10.46\n2023-11-03, SELL EXECUTED, Price: 10.46, Cost: 104.80, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS -0.20, NET -0.41\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.46\n2023-11-03, BUY CREATE, 10.46\n2023-11-03, BUY EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.45\n2023-11-03, SELL CREATE, 10.45\n2023-11-03, SELL EXECUTED, Price: 10.45, Cost: 104.60, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.46\n2023-11-03, BUY CREATE, 10.46\n2023-11-03, BUY EXECUTED, Price: 10.45, Cost: 104.50, Comm 0.10\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.48\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.46\n2023-11-03, SELL CREATE, 10.46\n2023-11-03, SELL EXECUTED, Price: 10.47, Cost: 104.50, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.20, NET -0.01\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.47\n2023-11-03, BUY CREATE, 10.47\n2023-11-03, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.46\n2023-11-03, SELL CREATE, 10.46\n2023-11-03, SELL EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.47\n2023-11-03, BUY CREATE, 10.47\n2023-11-03, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.46\n2023-11-03, SELL CREATE, 10.46\n2023-11-03, SELL EXECUTED, Price: 10.46, Cost: 104.70, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.47\n2023-11-03, BUY CREATE, 10.47\n2023-11-03, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-11-03, Close, 10.47\n2023-11-03, Close, 10.46\n2023-11-03, SELL CREATE, 10.46\n2023-11-03, SELL EXECUTED, Price: 10.46, Cost: 104.70, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS -0.10, NET -0.31\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.47\n2023-11-03, BUY CREATE, 10.47\n2023-11-03, BUY EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-11-03, Close, 10.46\n2023-11-03, SELL CREATE, 10.46\n2023-11-03, SELL EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.47\n2023-11-03, BUY CREATE, 10.47\n2023-11-03, BUY EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-11-03, Close, 10.46\n2023-11-03, SELL CREATE, 10.46\n2023-11-03, SELL EXECUTED, Price: 10.47, Cost: 104.70, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-03, Close, 10.47\n2023-11-03, BUY CREATE, 10.47\n2023-11-03, BUY EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-11-03, Close, 10.46\n2023-11-03, SELL CREATE, 10.46\n2023-11-03, SELL EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.00, NET -0.21\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.45\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.47\n2023-11-03, BUY CREATE, 10.47\n2023-11-03, BUY EXECUTED, Price: 10.46, Cost: 104.60, Comm 0.10\n2023-11-03, Close, 10.46\n2023-11-03, SELL CREATE, 10.46\n2023-11-03, SELL EXECUTED, Price: 10.47, Cost: 104.60, Comm 0.10\n2023-11-03, OPERATION PROFIT, GROSS 0.10, NET -0.11\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.46\n2023-11-03, Close, 10.48\n2023-11-03, BUY CREATE, 10.48\nFinal Portfolio Value: 99949.31\n</pre> In\u00a0[115]: Copied! <pre>df\n</pre> df Out[115]: datetime open high low close volume 0 2023-10-24 13:53:00 10.55 10.59 10.55 10.58 1562200 1 2023-10-24 13:54:00 10.57 10.60 10.57 10.60 1539663 2 2023-10-24 13:55:00 10.59 10.60 10.59 10.59 338000 3 2023-10-24 13:56:00 10.59 10.61 10.58 10.61 1019300 4 2023-10-24 13:57:00 10.60 10.60 10.58 10.59 216600 ... ... ... ... ... ... ... 1965 2023-11-03 14:54:00 10.46 10.46 10.45 10.46 282200 1966 2023-11-03 14:55:00 10.45 10.47 10.45 10.46 722900 1967 2023-11-03 14:56:00 10.46 10.47 10.45 10.46 137400 1968 2023-11-03 14:57:00 10.46 10.47 10.46 10.46 411500 1969 2023-11-03 15:00:00 10.48 10.48 10.48 10.48 1529300 <p>1970 rows \u00d7 6 columns</p> In\u00a0[116]: Copied! <pre>df = df.sort_values(by='datetime')\ndf\n</pre> df = df.sort_values(by='datetime') df Out[116]: datetime open high low close volume 0 2023-10-24 13:53:00 10.55 10.59 10.55 10.58 1562200 1 2023-10-24 13:54:00 10.57 10.60 10.57 10.60 1539663 2 2023-10-24 13:55:00 10.59 10.60 10.59 10.59 338000 3 2023-10-24 13:56:00 10.59 10.61 10.58 10.61 1019300 4 2023-10-24 13:57:00 10.60 10.60 10.58 10.59 216600 ... ... ... ... ... ... ... 1965 2023-11-03 14:54:00 10.46 10.46 10.45 10.46 282200 1966 2023-11-03 14:55:00 10.45 10.47 10.45 10.46 722900 1967 2023-11-03 14:56:00 10.46 10.47 10.45 10.46 137400 1968 2023-11-03 14:57:00 10.46 10.47 10.46 10.46 411500 1969 2023-11-03 15:00:00 10.48 10.48 10.48 10.48 1529300 <p>1970 rows \u00d7 6 columns</p> In\u00a0[16]: Copied! <pre>class MyStrategy(bt.Strategy):\n    def __init__(self):\n        self.sma = bt.indicators.SimpleMovingAverage(self.data, period=15)\n\n    def next(self):\n        if self.data.close &gt; self.sma:\n            self.buy()\n            print(f'{self.sma}')\n        elif self.data.close &lt; self.sma:\n            self.sell()\n</pre> class MyStrategy(bt.Strategy):     def __init__(self):         self.sma = bt.indicators.SimpleMovingAverage(self.data, period=15)      def next(self):         if self.data.close &gt; self.sma:             self.buy()             print(f'{self.sma}')         elif self.data.close &lt; self.sma:             self.sell() <p><code>self.datas</code>\u662fBacktrader\u4e2d\u7684\u4e00\u4e2a\u5c5e\u6027\uff0c\u5b83\u662f\u4e00\u4e2a\u5305\u542b\u6240\u6709\u6570\u636e\u6e90\u7684\u5217\u8868\u3002\u6bcf\u4e2a\u6570\u636e\u6e90\u90fd\u662f\u4e00\u4e2a<code>bt.feeds</code>\u5bf9\u8c61\uff0c\u5305\u542b\u6709\u5173\u6570\u636e\u7684\u4fe1\u606f\uff0c\u4f8b\u5982\u5f00\u76d8\u4ef7\u3001\u6536\u76d8\u4ef7\u7b49\u3002\u60a8\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u4ee3\u7801\u4ece<code>self.datas</code>\u4e2d\u83b7\u53d6\u6570\u636e\uff1a</p> <pre>data = self.datas[0]\n</pre> <p>\u8fd9\u5c06\u8fd4\u56de\u7b2c\u4e00\u4e2a\u6570\u636e\u6e90\u3002\u5982\u679c\u60a8\u6709\u591a\u4e2a\u6570\u636e\u6e90\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u4e0d\u540c\u7684\u7d22\u5f15\u6765\u8bbf\u95ee\u5b83\u4eec\u3002\u4f8b\u5982\uff0c\u8981\u8bbf\u95ee\u7b2c\u4e8c\u4e2a\u6570\u636e\u6e90\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u4ee3\u7801\uff1a</p> <pre>data = self.datas[1]\n</pre> <p>\u4e00\u65e6\u60a8\u83b7\u5f97\u4e86\u6570\u636e\u6e90\uff0c\u60a8\u5c31\u53ef\u4ee5\u4f7f\u7528\u5b83\u6765\u6267\u884c\u5404\u79cd\u64cd\u4f5c\uff0c\u4f8b\u5982\u8ba1\u7b97\u6307\u6807\u3001\u751f\u6210\u4fe1\u53f7\u7b49\u3002</p> <p>\u5e0c\u671b\u8fd9\u53ef\u4ee5\u5e2e\u52a9\u60a8\u89e3\u51b3\u95ee\u9898\u3002\u5982\u679c\u60a8\u9700\u8981\u66f4\u591a\u5e2e\u52a9\uff0c\u8bf7\u544a\u8bc9\u6211\u3002</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/2 (1) Backtrader\u6765\u5566\uff1a\u6570\u636e\u7bc7-\u817e\u8baf\u4e91\u5f00\u53d1\u8005\u793e\u533a-\u817e\u8baf\u4e91. https://cloud.tencent.com/developer/article/1820100. (2) backtrader\u6559\u7a0b\uff08\u4e09\uff09- \u5355\uff08\u591a\uff09\u80a1\u7968\u7b56\u7565\u7bc7 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/402559960. (3) Data Feeds - Backtrader. https://www.backtrader.com/docu/datafeed/.</p> <p>\u8981\u5728Backtrader\u4e2d\u4f20\u5165\u591a\u4e2a\u6570\u636e\u6e90\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u4ee3\u7801\uff1a</p> <pre>data1 = bt.feeds.PandasData(dataname=dataframe1)\ndata2 = bt.feeds.PandasData(dataname=dataframe2)\ncerebro.adddata(data1)\ncerebro.adddata(data2)\n</pre> <p>\u8fd9\u5c06\u521b\u5efa\u4e24\u4e2a\u6570\u636e\u6e90<code>data1</code>\u548c<code>data2</code>\uff0c\u5e76\u5c06\u5b83\u4eec\u6dfb\u52a0\u5230Backtrader\u5f15\u64ce\u4e2d\u3002\u8bf7\u6ce8\u610f\uff0c\u60a8\u9700\u8981\u4e3a\u6bcf\u4e2a\u6570\u636e\u6e90\u521b\u5efa\u4e00\u4e2a<code>bt.feeds</code>\u5bf9\u8c61\uff0c\u5e76\u5c06\u5176\u4f20\u9012\u7ed9<code>cerebro.adddata()</code>\u65b9\u6cd5\u3002</p> <p>\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u5047\u8bbe\u60a8\u6709\u4e24\u4e2aPandas DataFrame\u5bf9\u8c61<code>dataframe1</code>\u548c<code>dataframe2</code>\uff0c\u5b83\u4eec\u5305\u542b\u60a8\u8981\u56de\u6d4b\u7684\u6570\u636e\u3002\u60a8\u53ef\u4ee5\u4f7f\u7528\u8fd9\u4e9b\u6570\u636e\u6e90\u6765\u6267\u884c\u5404\u79cd\u64cd\u4f5c\uff0c\u4f8b\u5982\u8ba1\u7b97\u6307\u6807\u3001\u751f\u6210\u4fe1\u53f7\u7b49\u3002</p> <p>\u5e0c\u671b\u8fd9\u53ef\u4ee5\u5e2e\u52a9\u60a8\u89e3\u51b3\u95ee\u9898\u3002\u5982\u679c\u60a8\u9700\u8981\u66f4\u591a\u5e2e\u52a9\uff0c\u8bf7\u544a\u8bc9\u6211\u3002</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/2 (1) Using Multiple Datasets in Backtrader\u2019s Strategies. https://quantnomad.com/using-multiple-datasets-in-backtraders-strategies/. (2) Running Backtesting for Universe of Stocks in Python with Backtrader .... https://quantnomad.com/running-backtesting-for-universe-of-stocks-in-python-with-backtrader/. (3) Multiple Data Strategy - Backtrader. https://www.backtrader.com/blog/posts/2015-09-03-multidata-strategy/multidata-strategy/. (4) Multi-Data Example - Backtrader. https://www.backtrader.com/blog/posts/2017-04-09-multi-example/multi-example/.</p> <p>\u8981\u8bbf\u95ee<code>self.datas[0]</code>\u4e2d\u7684<code>close</code>\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u4ee3\u7801\uff1a</p> <pre>data = self.datas[0]\nclose_price = data.close[0]\n</pre> <p>\u8fd9\u5c06\u8fd4\u56de\u7b2c\u4e00\u4e2a\u6570\u636e\u6e90\u7684\u6700\u65b0\u6536\u76d8\u4ef7\u3002\u5982\u679c\u60a8\u60f3\u8bbf\u95ee\u4e4b\u524d\u7684\u6536\u76d8\u4ef7\uff0c\u53ea\u9700\u5c06\u7d22\u5f15\u66f4\u6539\u4e3a\u6240\u9700\u7684\u4f4d\u7f6e\u5373\u53ef\u3002</p> <p>\u5e0c\u671b\u8fd9\u53ef\u4ee5\u5e2e\u52a9\u60a8\u89e3\u51b3\u95ee\u9898\u3002\u5982\u679c\u60a8\u9700\u8981\u66f4\u591a\u5e2e\u52a9\uff0c\u8bf7\u544a\u8bc9\u6211\u3002</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/2 (1) Backtrader\u6765\u5566\uff1a\u6570\u636e\u7bc7-\u817e\u8baf\u4e91\u5f00\u53d1\u8005\u793e\u533a-\u817e\u8baf\u4e91. https://cloud.tencent.com/developer/article/1820100. (2) Difference between self.data and self.datas in Strategy | Backtrader .... https://community.backtrader.com/topic/5226/difference-between-self-data-and-self-datas-in-strategy. (3) Backtrader\uff08\u4e94\uff09- \u7b56\u7565\u5e38\u7528\u5bf9\u8c61_self.position = get_pos-CSDN\u535a\u5ba2. https://blog.csdn.net/weixin_44785098/article/details/122522121. (4) Backtrader\u7cfb\u5217\u6559\u7a0b\u2461:\u6570\u636e\u7bc7_bt.feeds.pandasdata-CSDN\u535a\u5ba2. https://blog.csdn.net/qq_41578115/article/details/122529156. (5) Platform Concepts - Backtrader. https://www.backtrader.com/docu/concepts/.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p><code>self.bar_executed</code>\u662fBacktrader\u4e2d\u7684\u4e00\u4e2a\u5c5e\u6027\uff0c\u5b83\u8bb0\u5f55\u4e86\u5728\u8ba2\u5355\u76f8\u5173\u901a\u77e5\u53d1\u51fa\u65f6\u6570\u636e\u6e90\u7684\u957f\u5ea6\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5b83\u8bb0\u5f55\u4e86\u5728\u8ba2\u5355\u76f8\u5173\u901a\u77e5\u53d1\u51fa\u65f6\u6570\u636e\u6e90\u4e2d\u7684\u6761\u76ee\u6570\u3002\u4f8b\u5982\uff0c\u5982\u679c\u60a8\u7684\u6570\u636e\u6e90\u5305\u542b100\u4e2a\u6761\u76ee\uff0c\u5e76\u4e14\u5728\u7b2c50\u4e2a\u6761\u76ee\u5904\u53d1\u51fa\u4e86\u8ba2\u5355\u76f8\u5173\u901a\u77e5\uff0c\u5219<code>self.bar_executed</code>\u5c06\u4e3a50\u3002</p> <p>\u60a8\u53ef\u4ee5\u4f7f\u7528<code>self.bar_executed</code>\u6765\u786e\u5b9a\u8ba2\u5355\u4f55\u65f6\u88ab\u6267\u884c\u3002\u4f8b\u5982\uff0c\u5982\u679c\u60a8\u60f3\u5728\u8ba2\u5355\u6267\u884c\u540e\u6253\u5370\u4e00\u6761\u6d88\u606f\uff0c\u5219\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u4ee3\u7801\uff1a</p> <pre>class MyStrategy(bt.Strategy):\n    def notify_order(self, order):\n        if order.status in [order.Completed]:\n            self.log('Order executed at {}'.format(self.datas[0].datetime.date()))\n            self.log('Bars executed: {}'.format(self.bar_executed))\n</pre> <p>\u5728\u8fd9\u91cc\uff0c\u6211\u4eec\u5b9a\u4e49\u4e86\u4e00\u4e2a\u540d\u4e3a<code>MyStrategy</code>\u7684\u7b56\u7565\uff0c\u5e76\u5728<code>notify_order()</code>\u65b9\u6cd5\u4e2d\u4f7f\u7528\u4e86<code>self.bar_executed</code>\u6765\u83b7\u53d6\u5df2\u6267\u884c\u7684\u6570\u636e\u6e90\u6761\u76ee\u6570\u3002\u8bf7\u6ce8\u610f\uff0c\u53ea\u6709\u5f53\u8ba2\u5355\u72b6\u6001\u4e3a\u5df2\u5b8c\u6210\u65f6\uff0c\u624d\u4f1a\u6253\u5370\u6d88\u606f\u3002</p> <p>\u5e0c\u671b\u8fd9\u53ef\u4ee5\u5e2e\u52a9\u60a8\u89e3\u51b3\u95ee\u9898\u3002\u5982\u679c\u60a8\u9700\u8981\u66f4\u591a\u5e2e\u52a9\uff0c\u8bf7\u544a\u8bc9\u6211\u3002</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/2 (1) I wonder What self.bar_executed means?? - Backtrader Community. https://community.backtrader.com/topic/2422/i-wonder-what-self-bar_executed-means. (2) Orders - Creation/Execution - Backtrader. https://www.backtrader.com/docu/order-creation-execution/order-creation-execution/. (3) Backtrader: How can I have stops execute on the same bar they were .... https://stackoverflow.com/questions/75242615/backtrader-how-can-i-have-stops-execute-on-the-same-bar-they-were-entered-on. (4) Python\u56de\u6d4b\u795e\u5668-Backtrader\uff08\u4e2d\uff09 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/262068794.</p> <p>\u5728backtrader\u4e2d\uff0cstrategy\u662f\u4e00\u4e2a\u7c7b\uff0c\u5b83\u5b9a\u4e49\u4e86\u4ea4\u6613\u7b56\u7565\u7684\u903b\u8f91\u548c\u53c2\u6570\u3002len(self)\u662f\u4e00\u4e2a\u65b9\u6cd5\uff0c\u5b83\u8fd4\u56de\u5f53\u524d\u7b56\u7565\u5904\u7406\u8fc7\u7684\u6570\u636e\uff08bar\uff09\u7684\u6570\u91cf\u00b2\u3002\u4e5f\u5c31\u662f\u8bf4\uff0clen(self)\u8868\u793a\u7b56\u7565\u4ece\u5f00\u59cb\u8fd0\u884c\u5230\u73b0\u5728\uff0c\u63a5\u6536\u5230\u4e86\u591a\u5c11\u4e2a\u6570\u636e\u70b9\u3002</p> <p>len(self)\u7684\u503c\u548c\u6570\u636e\u8868\u683c\u4e2d\u7684\u7d22\u5f15\u503c\u53ef\u80fd\u4e0d\u4e00\u81f4\uff0c\u6709\u4e24\u79cd\u53ef\u80fd\u7684\u539f\u56e0\u00b3\uff1a</p> <ol> <li>\u56de\u6d4b\u5f00\u59cb\u65f6\u95f4\u548c\u6570\u636e\u8868\u683c\u5f00\u59cb\u65f6\u95f4\u4e0d\u4e00\u81f4\u3002\u6bd4\u5982\uff0c\u6570\u636e\u8868\u683c\u4ece2020\u5e741\u67081\u65e5\u5f00\u59cb\uff0c\u4f46\u662f\u56de\u6d4b\u4ece2020\u5e746\u67081\u65e5\u5f00\u59cb\uff0c\u90a3\u4e48len(self)\u7684\u503c\u4f1a\u6bd4\u6570\u636e\u8868\u683c\u7684\u7d22\u5f15\u503c\u5c0f6\u4e2a\u6708\u7684\u6570\u636e\u91cf\u3002</li> <li>\u4f7f\u7528\u4e86\u79fb\u52a8\u5e73\u5747\u7ebf\u7b49\u6709\u6700\u5c0f\u5468\u671f\u7684\u6307\u6807\u3002\u6bd4\u5982\uff0c\u4f7f\u7528\u4e8620\u65e5\u79fb\u52a8\u5e73\u5747\u7ebf\uff0c\u90a3\u4e48\u7b56\u7565\u9700\u8981\u81f3\u5c1120\u4e2a\u6570\u636e\u70b9\u624d\u80fd\u8ba1\u7b97\u51fa\u7b2c\u4e00\u4e2a\u79fb\u52a8\u5e73\u5747\u503c\uff0c\u6240\u4ee5len(self)\u7684\u503c\u4f1a\u6bd4\u6570\u636e\u8868\u683c\u7684\u7d22\u5f15\u503c\u5c0f20\u3002</li> </ol> <p>\u5e0c\u671b\u8fd9\u80fd\u56de\u7b54\u4f60\u7684\u95ee\u9898\u3002\u5982\u679c\u4f60\u8fd8\u6709\u5176\u4ed6\u5173\u4e8ebacktrader\u7684\u95ee\u9898\uff0c\u6b22\u8fce\u7ee7\u7eed\u63d0\u95ee\u3002\ud83d\ude0a</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/4 (1) backtrader \u4e2d\uff0cnext\uff08\uff09\u91cc\u9762\uff0clen\uff08self\uff09\u7684\u503c\u4e3a\u4ec0\u4e48\u548c\u6211 .... https://www.zhihu.com/question/525069122. (2) backtrader\u5b66\u4e60\uff08\u4e00\uff09 \u7b56\u7565\u6267\u884c\u987a\u5e8f - CSDN\u535a\u5ba2. https://blog.csdn.net/czttcztt/article/details/121978185. (3) \u91cf\u5316\u6846\u67b6backtrader\u4e2d\u6587\u7ffb\u8bd1\u4e4b\u7b2c\u4e00\u4e2a\u7b56\u7565(3) - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/148937038.</p> <p>len(self)\u548cself.bar_executed\u7684\u503c\u90fd\u662f\u7528\u6765\u8868\u793abacktrader\u4e2d\u5904\u7406\u8fc7\u7684\u6570\u636e\uff08bar\uff09\u7684\u6570\u91cf\u7684\u3002\u4f46\u662f\uff0c\u5b83\u4eec\u4e4b\u95f4\u6709\u4e00\u4e9b\u533a\u522b\uff1a</p> <ul> <li>len(self)\u662f\u4e00\u4e2a\u5185\u7f6e\u51fd\u6570\uff0c\u5b83\u8fd4\u56de\u4e00\u4e2a\u5bf9\u8c61\u7684\u957f\u5ea6\u3002\u5728backtrader\u4e2d\uff0clen(self)\u8fd4\u56de\u7b56\u7565\u5bf9\u8c61\u7684\u957f\u5ea6\uff0c\u4e5f\u5c31\u662f\u5b83\u5df2\u7ecf\u63a5\u6536\u5230\u7684\u6570\u636e\u7684\u6570\u91cf\u3002len(self)\u7684\u503c\u4f1a\u968f\u7740\u6bcf\u4e2a\u65b0\u7684\u6570\u636e\u70b9\u800c\u589e\u52a0\u3002</li> <li>self.bar_executed\u662f\u4e00\u4e2a\u7b56\u7565\u5bf9\u8c61\u7684\u5c5e\u6027\uff0c\u5b83\u8bb0\u5f55\u4e86\u6700\u540e\u4e00\u6b21\u6267\u884c\u8ba2\u5355\u7684\u6570\u636e\u7d22\u5f15\u3002self.bar_executed\u7684\u503c\u53ea\u6709\u5728\u8ba2\u5355\u88ab\u6267\u884c\u65f6\u624d\u4f1a\u66f4\u65b0\uff0c\u5426\u5219\u4fdd\u6301\u4e0d\u53d8\u3002</li> </ul> <p>\u56e0\u6b64\uff0clen(self)\u548cself.bar_executed\u7684\u503c\u53ef\u80fd\u76f8\u540c\uff0c\u4e5f\u53ef\u80fd\u4e0d\u540c\uff0c\u8fd9\u53d6\u51b3\u4e8e\u6570\u636e\u662f\u5426\u88ab\u9884\u52a0\u8f7d\uff0c\u4ee5\u53ca\u8ba2\u5355\u662f\u5426\u88ab\u6267\u884c\u3002\u00b2\u00b3</p> <p>\u5982\u679c\u60a8\u60f3\u4e86\u89e3\u66f4\u591a\u5173\u4e8ebacktrader\u7684\u77e5\u8bc6\uff0c\u60a8\u53ef\u4ee5\u53c2\u8003\u8fd9\u7bc7\u6587\u7ae0\u2074\uff0c\u5b83\u8be6\u7ec6\u89e3\u6790\u4e86Python\u4e2d\u7684self\u7684\u542b\u4e49\u548c\u7528\u6cd5\u3002\u5e0c\u671b\u8fd9\u5bf9\u60a8\u6709\u6240\u5e2e\u52a9\u3002\ud83d\udc4d</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/4 (1) backtrader line\u957f\u5ea6\uff0c\u5df2\u7ecf\u5904\u7406\u8fc7\u591a\u5c11\u6761 - CSDN\u535a\u5ba2. https://blog.csdn.net/silence_pinot/article/details/125636337. (2) backtrader \u4e2d\uff0cnext\uff08\uff09\u91cc\u9762\uff0clen\uff08self\uff09\u7684\u503c\u4e3a\u4ec0\u4e48\u548c\u6211 .... https://www.zhihu.com/question/525069122. (3) Python\u4e2d\u7684self\u8be6\u7ec6\u89e3\u6790 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/356325860. (4) Python\u91cf\u5316\u4ea4\u6613\u5b66\u4e60\u7b14\u8bb0\uff0810\uff09\u2014\u2014\u7b2c\u4e00\u4e2a\u7b56\u7565\u56de\u6d4b\u7a0b\u5e8f .... https://blog.csdn.net/m0_46603114/article/details/104972859.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p><code>notify_trade</code> \u65b9\u6cd5\u662f <code>Backtrader</code> \u4e2d\u7684\u4e00\u4e2a\u56de\u8c03\u51fd\u6570\uff0c\u5b83\u4f1a\u5728\u4ea4\u6613\u72b6\u6001\u53d1\u751f\u53d8\u5316\u65f6\u88ab\u8c03\u7528 \u00b2. \u8be5\u65b9\u6cd5\u7684\u9ed8\u8ba4\u5b9e\u73b0\u4f1a\u5728\u4ea4\u6613\u5173\u95ed\u65f6\u6253\u5370\u51fa\u4ea4\u6613\u7684\u6bdb\u6536\u76ca\u3001\u6263\u4f63\u540e\u6536\u76ca\u548c\u4f63\u91d1 \u00b2\u00b3.</p> <p>\u5982\u679c\u60a8\u60f3\u81ea\u5b9a\u4e49 <code>notify_trade</code> \u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u60a8\u7684\u7b56\u7565\u7c7b\u4e2d\u91cd\u5199\u8be5\u65b9\u6cd5\u3002\u4f8b\u5982\uff0c\u60a8\u53ef\u4ee5\u5728\u4ea4\u6613\u5173\u95ed\u65f6\u8bb0\u5f55\u4ea4\u6613\u7684\u76c8\u5229\u60c5\u51b5\uff0c\u5982\u4e0b\u6240\u793a\uff1a</p> <pre>class MyStrategy(bt.Strategy):\n    def notify_trade(self, trade):\n        if trade.isclosed:\n            print('\u6bdb\u6536\u76ca %0.2f, \u6263\u4f63\u540e\u6536\u76ca % 0.2f, \u4f63\u91d1 %.2f' % (trade.pnl, trade.pnlcomm, trade.commission))\n</pre> <p>\u5728\u4e0a\u8ff0\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u91cd\u5199\u4e86 <code>notify_trade</code> \u65b9\u6cd5\uff0c\u5f53\u4ea4\u6613\u5173\u95ed\u65f6\uff0c\u4f1a\u6253\u5370\u51fa\u4ea4\u6613\u7684\u6bdb\u6536\u76ca\u3001\u6263\u4f63\u540e\u6536\u76ca\u548c\u4f63\u91d1 \u00b2.</p> <p>\u5982\u679c\u60a8\u60f3\u4e86\u89e3\u66f4\u591a\u5173\u4e8e <code>Backtrader</code> \u7684\u4fe1\u606f\uff0c\u53ef\u4ee5\u53c2\u8003\u8fd9\u7bc7\u6587\u7ae0 \u00b9.</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/4 (1) backtrader\u4e2d\u4f55\u4e3a\u4e00\u4e2a\u4ea4\u6613trade?\u4f60\u53ef\u80fd\u5e76\u6ca1\u7406\u89e3\u5b83 - CSDN\u535a\u5ba2. https://blog.csdn.net/qtbgo/article/details/109799469. (2) backtrader\u4e2d\u4f55\u4e3a\u4e00\u4e2a\u4ea4\u6613trade?\u4f60\u53ef\u80fd\u5e76\u6ca1\u7406\u89e3\u5b83\u3002 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/299630905. (3) \u91cf\u5316\u6295\u8d44\u4e4b\u5de5\u5177\u7bc7\uff1aBacktrader\u4ece\u5165\u95e8\u5230\u7cbe\u901a\uff085\uff09Strategy .... https://zhuanlan.zhihu.com/p/464114946. (4) backtrader\u6e90\u7801\u89e3\u8bfb (6)\uff1a\u7b56\u7565 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/621758956.</p> <p><code>trade.isclosed</code> \u662f <code>Backtrader</code> \u4e2d\u7684\u4e00\u4e2a\u5c5e\u6027\uff0c\u5b83\u8bb0\u5f55\u4e86\u4ea4\u6613\u662f\u5426\u5df2\u7ecf\u5173\u95ed \u00b9. \u5f53\u4ea4\u6613\u7684\u4ed3\u4f4d\u4ece\u6b63\u503c\u53d8\u4e3a0\u65f6\uff0c\u8be5\u4ea4\u6613\u4f1a\u88ab\u5173\u95ed\uff0c\u6b64\u65f6 <code>trade.isclosed</code> \u4f1a\u88ab\u8bbe\u7f6e\u4e3a <code>True</code> \u00b9\u00b2.</p> <p>\u4f8b\u5982\uff0c\u5047\u8bbe\u60a8\u5728 <code>Backtrader</code> \u4e2d\u8fdb\u884c\u4e86\u4e00\u6b21\u4ea4\u6613\uff0c\u5f00\u4ed3\u4ef7\u683c\u4e3a <code>100</code>\uff0c\u5e73\u5747\u4ef7\u683c\u4e3a <code>110</code>\uff0c\u6570\u91cf\u4e3a <code>10</code>\uff0c\u4f63\u91d1\u4e3a <code>5</code>\uff0c\u5219\u8be5\u4ea4\u6613\u7684\u6bdb\u6536\u76ca\u548c\u6263\u4f63\u540e\u6536\u76ca\u5206\u522b\u4e3a\uff1a</p> <pre><code>trade.pnl = (110 - 100) * 10 = 100\ntrade.pnlcomm = 100 - 5 = 95\n</code></pre> <p>\u5f53\u8be5\u4ea4\u6613\u88ab\u5173\u95ed\u65f6\uff0c<code>trade.isclosed</code> \u4f1a\u88ab\u8bbe\u7f6e\u4e3a <code>True</code> \u00b9.</p> <p>\u5982\u679c\u60a8\u60f3\u4e86\u89e3\u66f4\u591a\u5173\u4e8e <code>Backtrader</code> \u7684\u4fe1\u606f\uff0c\u53ef\u4ee5\u53c2\u8003\u8fd9\u7bc7\u6587\u7ae0 \u00b9.</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/4 (1) Trade - Backtrader. https://www.backtrader.com/docu/trade/. (2) backtrader\u4e2d\u4f55\u4e3a\u4e00\u4e2a\u4ea4\u6613trade?\u4f60\u53ef\u80fd\u5e76\u6ca1\u7406\u89e3\u5b83 - CSDN\u535a\u5ba2. https://blog.csdn.net/qtbgo/article/details/109799469. (3) backtrader\u4e2d\u4f55\u4e3a\u4e00\u4e2a\u4ea4\u6613trade?\u4f60\u53ef\u80fd\u5e76\u6ca1\u7406\u89e3\u5b83\u3002 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/299630905. (4) Backtrader\u4e2d\u6587\u7b14\u8bb0\u4e4bTrade(\u4ea4\u6613) - \u5c31\u662f\u60f3\u5b66\u4e60 - \u535a\u5ba2\u56ed. https://www.cnblogs.com/sidianok/p/13703966.html.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>\u90a3\u4e48backtrader\u4e2d\u662f\u5982\u4f55\u5b9a\u4e49\u4ea4\u6613\u7684\u5462\uff1f \u5bf9\u6b63\u5e38\u91c7\u7528\u81ea\u6709\u8d44\u91d1\u8d2d\u4e70\u80a1\u7968\uff0c\u4e0d\u80fd\u505a\u7a7a\u7684\u60c5\u51b5\u4e0b\uff0c\u5f53\u4e00\u4e2a\u8ba2\u5355\u4f7f\u5f97\u4ed3\u4f4d\u4ece0\u53d8\u4e3a\u6b63\u503c\uff0c\u5219\u6253\u5f00\u4e86\u4e00\u4e2a\u4ea4\u6613\uff0c\u6b64\u540e\uff0c\u5f53\u67d0\u8ba2\u5355\u4f7f\u5f97\u4ed3\u4f4d\u4ece\u6b63\u503c\u53d8\u4e3a0\uff0c\u5219\u8be5\u4ea4\u6613\u5173\u95ed\uff0c\u8fd9\u4e24\u79cd\u60c5\u51b5\u90fd\u4f1a\u89e6\u53d1notify_trade\u65b9\u6cd5\u3002</p> <p>\u4e00\u4e2a\u4ea4\u6613\u53ef\u80fd\u7531\u591a\u4e2a\u8ba2\u5355\u7ec4\u6210\u3002\u4e0d\u80fd\u505a\u7a7a\u7684\u60c5\u51b5\u4e0b\uff0c\u4e3e\u4e2a\u4f8b\u5b50\u89c2\u5bdf\u4ea4\u6613\u72b6\u6001\u7684\u53d8\u5316\uff0c\u5728next\u65b9\u6cd5\u4e2d\uff1a</p> <p>\u7b2c\u4e00\u6b21\u4e0b\u4e70\u5355\u4e70100\u80a1\uff0c\u6b64\u8ba2\u5355\u6267\u884c\u65f6\uff0c\u4ed3\u4f4d\u4ece0\u53d8\u4e3a\u6b63\u503c\uff08100\uff09\uff0c\u7cfb\u7edf\u6253\u5f00\u4e00\u4e2a\u4ea4\u6613\uff0c\u4f1a\u89e6\u53d1notify_trade\u65b9\u6cd5\uff0c\u5728notify_trade\u4e2d\u68c0\u67e5\u4ea4\u6613\u72b6\u6001status\uff0c\u4e3a1 open\u3002</p> <p>\u7136\u540e\u4e0b\u7b2c\u4e8c\u5f20\u4e70\u5355100\u80a1\uff0c\u8ba2\u5355\u6267\u884c\u65f6\u4e0d\u4f1a\u89e6\u53d1notify_trade\uff0c\u4ed3\u4f4d\u53d8\u4e3a200\u3002</p> <p>\u7136\u540e\u4e0b\u5356\u5355\u5356100\u80a1\uff0c\u4ecd\u7136\u4e0d\u4f1a\u89e6\u53d1notify_trade\uff0c\u4ed3\u4f4d\u53d8\u4e3a100\u3002</p> <p>\u518d\u4e0b\u4e00\u4e2a\u5356\u5355\u5356100\u80a1\uff0c\u6267\u884c\u65f6\uff0c\u4ed3\u4f4d\u4ece100\u53d8\u4e3a0\uff0c\u5173\u95ed\u4ea4\u6613\uff0c\u89e6\u53d1notify_trade\uff0c\u4ea4\u6613\u72b6\u6001\u4e3a2 close\u3002</p> <p>\u4e0d\u80fd\u505a\u7a7a\u7684\u60c5\u51b5\u4e0b\uff0cself.close()\u547d\u4ee4\u4f1a\u4e00\u6b21\u6027\u5e02\u4ef7\u5356\u51fa\u5168\u90e8\u4ed3\u4f4d\uff0c\u5173\u95ed\u4ea4\u6613\u3002</p> <p>\u5728\u53ef\u4ee5\u505a\u7a7a\u7684\u60c5\u51b5\u4e0b\uff0c\u5f53\u4ed3\u4f4d\u4ece0\u53d8\u4e3a\u975e0\uff08\u957f\u4ed3\u4e3a\u6b63\u503c\uff0c\u77ed\u4ed3\u4e3a\u8d1f\u503c\uff09\uff0c\u5219\u6253\u5f00\u4e86\u4e00\u4e2a\u4ea4\u6613\uff0c\u6b64\u540e\u4ed3\u4f4d\u4ece\u975e0\u503c\u53d8\u4e3a0\u503c\uff0c\u5219\u4ea4\u6613\u5173\u95ed\u3002\u5728\u5356\u7a7a\u64cd\u4f5c\u4e2d\uff0cself.close()\u9ed8\u8ba4\u4f1a\u5e02\u4ef7\u4e70\u56de\u6240\u6709\u5356\u7a7a\u4ed3\u4f4d\uff0c\u5173\u95ed\u4ea4\u6613\u3002</p> <p>\u5982\u679c\u67d0\u4e2a\u8ba2\u5355\u4f7f\u5f97\u4ed3\u4f4d\u4ece\u6b63\u503c\u53d8\u5230\u8d1f\u503c\uff0c\u6216\u8d1f\u503c\u53d8\u5230\u6b63\u503c\uff0c\u5219\u610f\u5473\u7740\u4e24\u4e2a\u52a8\u4f5c\uff1a\u4e00\u4e2a\u4ea4\u6613\u88ab\u5173\u95ed\u4e86\uff08\u4ed3\u4f4d\u4ece\u975e0\u503c\u53d8\u4e3a0\uff09\uff0c\u4e00\u4e2a\u65b0\u4ea4\u6613\u88ab\u6253\u5f00\u4e86\uff08\u4ed3\u4f4d\u4ece0\u53d8\u4e3a\u975e0\uff09\u3002 \u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014\u2014 \u7248\u6743\u58f0\u660e\uff1a\u672c\u6587\u4e3aCSDN\u535a\u4e3b\u300c\u626b\u5730\u50e7\u91cf\u5316\u300d\u7684\u539f\u521b\u6587\u7ae0\uff0c\u9075\u5faaCC 4.0 BY-SA\u7248\u6743\u534f\u8bae\uff0c\u8f6c\u8f7d\u8bf7\u9644\u4e0a\u539f\u6587\u51fa\u5904\u94fe\u63a5\u53ca\u672c\u58f0\u660e\u3002 \u539f\u6587\u94fe\u63a5\uff1ahttps://blog.csdn.net/qtbgo/article/details/109799469</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p><code>notify_order</code> \u65b9\u6cd5\u662f <code>Backtrader</code> \u4e2d\u7684\u4e00\u4e2a\u56de\u8c03\u51fd\u6570\uff0c\u5b83\u4f1a\u5728\u8ba2\u5355\u72b6\u6001\u53d1\u751f\u53d8\u5316\u65f6\u88ab\u8c03\u7528 \u00b9. \u8be5\u65b9\u6cd5\u7684\u9ed8\u8ba4\u5b9e\u73b0\u4f1a\u5728\u8ba2\u5355\u88ab\u63d0\u4ea4\u3001\u63a5\u53d7\u3001\u5b8c\u6210\u3001\u53d6\u6d88\u3001\u62d2\u7edd\u6216\u51fa\u73b0\u4fdd\u8bc1\u91d1\u95ee\u9898\u65f6\u6253\u5370\u51fa\u76f8\u5e94\u7684\u4fe1\u606f \u00b9\u00b2.</p> <p>\u5982\u679c\u60a8\u60f3\u81ea\u5b9a\u4e49 <code>notify_order</code> \u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u60a8\u7684\u7b56\u7565\u7c7b\u4e2d\u91cd\u5199\u8be5\u65b9\u6cd5\u3002\u4f8b\u5982\uff0c\u60a8\u53ef\u4ee5\u5728\u8ba2\u5355\u88ab\u5b8c\u6210\u65f6\u8bb0\u5f55\u8ba2\u5355\u7684\u6bdb\u6536\u76ca\u3001\u6263\u4f63\u540e\u6536\u76ca\u548c\u4f63\u91d1\uff0c\u5982\u4e0b\u6240\u793a\uff1a</p> <pre>class MyStrategy(bt.Strategy):\n    def notify_order(self, order):\n        if order.status == order.Completed:\n            if order.isbuy():\n                self.log('BUY EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' % (order.executed.price, order.executed.value, order.executed.comm))\n            else:\n                self.log('SELL EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' % (order.executed.price, order.executed.value, order.executed.comm))\n            self.bar_executed = len(self)\n        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n            self.log('Order Canceled/Margin/Rejected')\n        self.order = None\n</pre> <p>\u5728\u4e0a\u8ff0\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u91cd\u5199\u4e86 <code>notify_order</code> \u65b9\u6cd5\uff0c\u5f53\u8ba2\u5355\u88ab\u5b8c\u6210\u65f6\uff0c\u4f1a\u6253\u5370\u51fa\u8ba2\u5355\u7684\u6bdb\u6536\u76ca\u3001\u6263\u4f63\u540e\u6536\u76ca\u548c\u4f63\u91d1 \u00b9.</p> <p>\u5982\u679c\u60a8\u60f3\u4e86\u89e3\u66f4\u591a\u5173\u4e8e <code>Backtrader</code> \u7684\u4fe1\u606f\uff0c\u53ef\u4ee5\u53c2\u8003\u8fd9\u7bc7\u6587\u7ae0 \u00b9.</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/4 (1) Backtrader for Backtesting (Python) \u2013 A Complete Guide - AlgoTrading101. https://algotrading101.com/learn/backtrader-for-backtesting/. (2) Ask on the logic of notify order and next to execute strategy. https://community.backtrader.com/topic/2211/ask-on-the-logic-of-notify-order-and-next-to-execute-strategy. (3) Stop-Loss Trading - Backtrader. https://www.backtrader.com/blog/posts/2018-02-01-stop-trading/stop-trading/. (4) Backtrader\u91cf\u5316\u5e73\u53f0\u6559\u7a0b\uff08\u4e09\uff09Indicator-\u817e\u8baf\u4e91\u5f00\u53d1\u8005\u793e\u533a .... https://cloud.tencent.com/developer/article/1388330. (5) Quickstart Guide - Backtrader. https://www.backtrader.com/docu/quickstart/quickstart/. (6) Orders - General - Backtrader. https://www.backtrader.com/docu/order/. (7) Strategy - Backtrader. https://www.backtrader.com/docu/strategy/. (8) Python\u91cf\u5316backtrader18\uff1aOrders\u3010\u8ba2\u5355\u3011 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/365877037. (9) github.com. https://github.com/zsalem2023/Backtrader/tree/59b719ebb2d49c70b5fe35e674b3e196524cdc29/Strategies%2FSimpleMovingAverage.py. (10) github.com. https://github.com/bolobox/ichibot/tree/9ee7ebe9a7f3b97a11bc5a55e6971f74ce1e366d/app%2Fstrategies%2Fbasestrategy.py. (11) github.com. https://github.com/Airwiwin/flouz/tree/4158813d1fde028d6f009121dbd82850d772e96d/hello_backtrader.py.</p> <p><code>notify_order</code> \u548c <code>notify_position</code> \u90fd\u662f <code>Backtrader</code> \u4e2d\u7684\u56de\u8c03\u51fd\u6570\uff0c\u4f46\u5b83\u4eec\u7684\u4f5c\u7528\u4e0d\u540c \u00b9\u00b2.</p> <p><code>notify_order</code> \u65b9\u6cd5\u4f1a\u5728\u8ba2\u5355\u72b6\u6001\u53d1\u751f\u53d8\u5316\u65f6\u88ab\u8c03\u7528\uff0c\u4f8b\u5982\u8ba2\u5355\u88ab\u63d0\u4ea4\u3001\u63a5\u53d7\u3001\u5b8c\u6210\u3001\u53d6\u6d88\u3001\u62d2\u7edd\u6216\u51fa\u73b0\u4fdd\u8bc1\u91d1\u95ee\u9898\u65f6 \u00b9. \u8be5\u65b9\u6cd5\u7684\u9ed8\u8ba4\u5b9e\u73b0\u4f1a\u5728\u8ba2\u5355\u72b6\u6001\u53d1\u751f\u53d8\u5316\u65f6\u6253\u5370\u51fa\u76f8\u5e94\u7684\u4fe1\u606f \u00b9\u00b2.</p> <p><code>notify_position</code> \u65b9\u6cd5\u4f1a\u5728\u4ea4\u6613\u72b6\u6001\u53d1\u751f\u53d8\u5316\u65f6\u88ab\u8c03\u7528\uff0c\u4f8b\u5982\u4ea4\u6613\u88ab\u6253\u5f00\u3001\u66f4\u65b0\u6216\u5173\u95ed\u65f6 \u00b9. \u8be5\u65b9\u6cd5\u7684\u9ed8\u8ba4\u5b9e\u73b0\u4f1a\u5728\u4ea4\u6613\u72b6\u6001\u53d1\u751f\u53d8\u5316\u65f6\u6253\u5370\u51fa\u76f8\u5e94\u7684\u4fe1\u606f \u00b9\u00b2.</p> <p>\u5982\u679c\u60a8\u60f3\u81ea\u5b9a\u4e49 <code>notify_order</code> \u6216 <code>notify_position</code> \u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u60a8\u7684\u7b56\u7565\u7c7b\u4e2d\u91cd\u5199\u8fd9\u4e9b\u65b9\u6cd5\u3002\u4f8b\u5982\uff0c\u60a8\u53ef\u4ee5\u5728\u8ba2\u5355\u72b6\u6001\u53d1\u751f\u53d8\u5316\u65f6\u8bb0\u5f55\u8ba2\u5355\u7684\u6bdb\u6536\u76ca\u3001\u6263\u4f63\u540e\u6536\u76ca\u548c\u4f63\u91d1\uff0c\u5982\u4e0b\u6240\u793a\uff1a</p> <pre>class MyStrategy(bt.Strategy):\n    def notify_order(self, order):\n        if order.status == order.Completed:\n            if order.isbuy():\n                self.log('BUY EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' % (order.executed.price, order.executed.value, order.executed.comm))\n            else:\n                self.log('SELL EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' % (order.executed.price, order.executed.value, order.executed.comm))\n            self.bar_executed = len(self)\n        elif order.status in [order.Canceled, order.Margin, order.Rejected]:\n            self.log('Order Canceled/Margin/Rejected')\n        self.order = None\n\n    def notify_trade(self, trade):\n        if trade.isclosed:\n            self.log('\u6bdb\u6536\u76ca %0.2f, \u6263\u4f63\u540e\u6536\u76ca % 0.2f, \u4f63\u91d1 %.2f' % (trade.pnl, trade.pnlcomm, trade.commission))\n</pre> <p>\u5728\u4e0a\u8ff0\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u91cd\u5199\u4e86 <code>notify_order</code> \u548c <code>notify_trade</code> \u65b9\u6cd5\uff0c\u5f53\u8ba2\u5355\u88ab\u5b8c\u6210\u65f6\uff0c\u4f1a\u6253\u5370\u51fa\u8ba2\u5355\u7684\u6bdb\u6536\u76ca\u3001\u6263\u4f63\u540e\u6536\u76ca\u548c\u4f63\u91d1 \u00b9.</p> <p>\u5982\u679c\u60a8\u60f3\u4e86\u89e3\u66f4\u591a\u5173\u4e8e <code>Backtrader</code> \u7684\u4fe1\u606f\uff0c\u53ef\u4ee5\u53c2\u8003\u8fd9\u7bc7\u6587\u7ae0 \u00b9.</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/4 (1) Backtrader\uff08\u5341\u4e03\uff09-Order\u8ba2\u5355 - \u8ba2\u5355\u901a\u77e5_backtrader notify .... https://blog.csdn.net/weixin_44785098/article/details/122681266. (2) Backtrader\u91cf\u5316\u5e73\u53f0\u6559\u7a0b\uff08\u4e09\uff09Indicator-\u817e\u8baf\u4e91\u5f00\u53d1\u8005\u793e\u533a .... https://cloud.tencent.com/developer/article/1388330. (3) backtrader\u4e2d\u4f55\u4e3a\u4e00\u4e2a\u4ea4\u6613trade?\u4f60\u53ef\u80fd\u5e76\u6ca1\u7406\u89e3\u5b83\u3002 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/299630905. (4) MT5\u4e2dposition\u3001order\u3001deal \u533a\u522b_orders deals positions-CSDN\u535a\u5ba2. https://blog.csdn.net/xjjatdna/article/details/115796960. (5) Python\u91cf\u5316\u4ea4\u6613\u5b66\u4e60\u7b14\u8bb0\uff0826\uff09\u2014\u2014backtrader\u7684order\u6982\u8ff0 .... https://blog.csdn.net/m0_46603114/article/details/106031259. (6) Orders - General - Backtrader. https://www.backtrader.com/docu/order/. (7) Strategy - Backtrader. https://www.backtrader.com/docu/strategy/. (8) Stop-Loss Trading - Backtrader. https://www.backtrader.com/blog/posts/2018-02-01-stop-trading/stop-trading/. (9) Python\u91cf\u5316backtrader18\uff1aOrders\u3010\u8ba2\u5355\u3011 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/365877037. (10) github.com. https://github.com/zsalem2023/Backtrader/tree/59b719ebb2d49c70b5fe35e674b3e196524cdc29/Strategies%2FSimpleMovingAverage.py. (11) github.com. https://github.com/Airwiwin/flouz/tree/4158813d1fde028d6f009121dbd82850d772e96d/hello_backtrader.py. (12) github.com. https://github.com/bolobox/ichibot/tree/9ee7ebe9a7f3b97a11bc5a55e6971f74ce1e366d/app%2Fstrategies%2Fbasestrategy.py. (13) github.com. https://github.com/gejianxin/stock/tree/3a2c15e6a031a1dac3bd4a18b57d94f4980cd076/strategies%2FPolyStrategy.py. (14) github.com. https://github.com/zhengxingXue/trading_platform_learning/tree/678e8a1fc9210f5075825a093271ea0fef852c43/backtrader%2Fquickstart_3_simple_moving_average.py.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p><code>cerebro.addsizer</code> \u662f <code>Backtrader</code> \u4e2d\u7684\u4e00\u4e2a\u65b9\u6cd5\uff0c\u7528\u4e8e\u5411 <code>Cerebro</code> \u5bf9\u8c61\u4e2d\u6dfb\u52a0\u4e00\u4e2a\u4ea4\u6613\u91cf\u8c03\u6574\u5668\uff08sizer\uff09 \u00b9. \u4ea4\u6613\u91cf\u8c03\u6574\u5668\u662f\u7528\u4e8e\u8ba1\u7b97\u6bcf\u4e2a\u8ba2\u5355\u7684\u4ea4\u6613\u91cf\u7684\u5bf9\u8c61\uff0c\u5b83\u53ef\u4ee5\u6839\u636e\u60a8\u7684\u7b56\u7565\u548c\u5e02\u573a\u60c5\u51b5\u81ea\u52a8\u8c03\u6574\u4ea4\u6613\u91cf \u00b2.</p> <p><code>cerebro.addsizer</code> \u65b9\u6cd5\u6709\u4e24\u4e2a\u53c2\u6570\uff1a</p> <ul> <li><code>sizercls</code>\uff1a\u4ea4\u6613\u91cf\u8c03\u6574\u5668\u7684\u7c7b\u3002</li> <li><code>*args</code> \u548c <code>**kwargs</code>\uff1a\u4f20\u9012\u7ed9\u4ea4\u6613\u91cf\u8c03\u6574\u5668\u7684\u53c2\u6570\u3002</li> </ul> <p>\u4f8b\u5982\uff0c\u5982\u679c\u60a8\u60f3\u4f7f\u7528 <code>bt.sizers.FixedSize</code> \u4f5c\u4e3a\u4ea4\u6613\u91cf\u8c03\u6574\u5668\uff0c\u5e76\u5c06\u4ea4\u6613\u91cf\u8bbe\u7f6e\u4e3a <code>10</code>\uff0c\u5219\u53ef\u4ee5\u4f7f\u7528\u4ee5\u4e0b\u4ee3\u7801\uff1a</p> <pre>cerebro.addsizer(bt.sizers.FixedSize, stake=10)\n</pre> <p>\u5982\u679c\u60a8\u60f3\u4e86\u89e3\u66f4\u591a\u5173\u4e8e <code>Backtrader</code> \u7684\u4fe1\u606f\uff0c\u53ef\u4ee5\u53c2\u8003\u8fd9\u7bc7\u6587\u7ae0 \u00b9.</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/4 (1) Sizers - Backtrader. https://www.backtrader.com/docu/sizers/sizers/. (2) Backtrader - sizer - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT .... https://ithelp.ithome.com.tw/articles/10279754. (3) backtrader\u65e0\u6cd5\u6ee1\u4ed3\u4ea4\u6613\u7684\u95ee\u9898 - CSDN\u535a\u5ba2. https://blog.csdn.net/haydengao/article/details/118330186. (4) \u5b66\u4e60backtrader\u6846\u67b6---\u7ed9\u7b56\u7565\u6dfb\u52a0\u53c2\u6570\u3001\u6307\u6807\u7684\u4e00\u4e9b\u6ce8\u610f .... https://blog.csdn.net/weixin_42612813/article/details/90678446. (5) Cerebro - Backtrader. https://www.backtrader.com/docu/cerebro/.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p><code>cerebro.addsizer</code> \u65b9\u6cd5\u6709\u4e24\u4e2a\u53c2\u6570\uff1a</p> <ul> <li><code>sizercls</code>\uff1a\u4ea4\u6613\u91cf\u8c03\u6574\u5668\u7684\u7c7b\u3002</li> <li><code>*args</code> \u548c <code>**kwargs</code>\uff1a\u4f20\u9012\u7ed9\u4ea4\u6613\u91cf\u8c03\u6574\u5668\u7684\u53c2\u6570\u3002</li> </ul> <p>\u5176\u4e2d\uff0c<code>stake</code> \u548c <code>percent</code> \u662f <code>bt.sizers.FixedSize</code> \u548c <code>bt.sizers.PercentSizer</code> \u4e24\u4e2a\u4ea4\u6613\u91cf\u8c03\u6574\u5668\u7684\u53c2\u6570\u4e4b\u4e00 \u2075.</p> <ul> <li><code>stake</code>\uff1a\u8868\u793a\u6bcf\u4e2a\u8ba2\u5355\u7684\u4ea4\u6613\u91cf\uff0c\u901a\u5e38\u662f\u4e00\u4e2a\u6574\u6570\u6216\u6d6e\u70b9\u6570 \u2075.</li> <li><code>percent</code>\uff1a\u8868\u793a\u6bcf\u4e2a\u8ba2\u5355\u7684\u4ea4\u6613\u91cf\u5360\u53ef\u7528\u8d44\u91d1\u7684\u767e\u5206\u6bd4\uff0c\u901a\u5e38\u662f\u4e00\u4e2a\u6d6e\u70b9\u6570 \u2075.</li> </ul> <p>\u5982\u679c\u60a8\u60f3\u4e86\u89e3\u66f4\u591a\u5173\u4e8e <code>Backtrader</code> \u7684\u4fe1\u606f\uff0c\u53ef\u4ee5\u53c2\u8003\u8fd9\u7bc7\u6587\u7ae0 \u00b9.</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/4 (1) \u91cf\u5316\u6295\u8d44\u4e4b\u5de5\u5177\u7bc7\uff1aBacktrader\u4ece\u5165\u95e8\u5230\u7cbe\u901a\uff0810\uff09\u4ea4\u6613 .... https://zhuanlan.zhihu.com/p/494061468. (2) Cerebro - Backtrader. https://www.backtrader.com/docu/cerebro/. (3) \u5b66\u4e60backtrader\u6846\u67b6---\u7ed9\u7b56\u7565\u6dfb\u52a0\u53c2\u6570\u3001\u6307\u6807\u7684\u4e00\u4e9b\u6ce8\u610f .... https://blog.csdn.net/weixin_42612813/article/details/90678446. (4) How to write your first, simple backtrader strategy - Quant Nomad. https://quantnomad.com/faq-how-to-write-your-first-simple-backtrader-strategy/. (5) Sizers - Backtrader. https://www.backtrader.com/docu/sizers/sizers/. (6) Sizers - Reference - Backtrader. https://www.backtrader.com/docu/sizers-reference/. (7) Backtrader - sizer - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT .... https://bing.com/search?q=cerebro.addsizer+percent. (8) Backtrader - sizer - iT \u90a6\u5e6b\u5fd9::\u4e00\u8d77\u5e6b\u5fd9\u89e3\u6c7a\u96e3\u984c\uff0c\u62ef\u6551 IT .... https://ithelp.ithome.com.tw/articles/10279754?sc=hot. (9) Backtrader - sizer. http://25230.com/17200404/3831.html. (10) Beginner\u2019s Guide to Sizers in Backtrader | by JohnJoy | Medium. https://medium.com/@jesso1908joy/beginners-guide-to-sizers-in-backtrader-6c0ba892fe80. (11) Backtrader\u4e2d\u6587\u7b14\u8bb0\u4e4bSizers - \u5c31\u662f\u60f3\u5b66\u4e60 - \u535a\u5ba2\u56ed. https://www.cnblogs.com/sidianok/p/13709384.html.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>\u60a8\u597d\uff0c\u8fd9\u662fBing\u3002\u611f\u8c22\u60a8\u7684\u63d0\u95ee\u3002\ud83d\ude0a</p> <p>backtrader\u662f\u4e00\u4e2aPython\u5e93\uff0c\u7528\u4e8e\u8fdb\u884c\u56de\u6d4b\u548c\u4ea4\u6613\u7b56\u7565\u7684\u5f00\u53d1\u548c\u6d4b\u8bd5\u00b9\u3002backtrader\u4e2d\uff0c\u4e00\u4e2a\u8ba2\u5355\uff08order\uff09\u662f\u4e00\u4e2a\u6307\u793a\u4e70\u5165\u6216\u5356\u51fa\u67d0\u4e2a\u8d44\u4ea7\u7684\u5bf9\u8c61\u00b2\u3002\u4e00\u4e2a\u8ba2\u5355\u662f\u5426\u4ecd\u7136\u5b58\u5728\uff0c\u53d6\u51b3\u4e8e\u5b83\u7684\u72b6\u6001\uff08status\uff09\u00b3\u3002</p> <p>backtrader\u63d0\u4f9b\u4e86\u4e00\u4e2a\u679a\u4e3e\u7c7bOrder.Status\uff0c\u7528\u4e8e\u8868\u793a\u8ba2\u5355\u7684\u4e0d\u540c\u72b6\u6001\u00b3\u3002\u8fd9\u4e9b\u72b6\u6001\u5305\u62ec\uff1a</p> <ul> <li>Order.Created\uff1a\u8ba2\u5355\u88ab\u521b\u5efa\uff0c\u4f46\u8fd8\u6ca1\u6709\u63d0\u4ea4\u5230\u5e02\u573a\u3002</li> <li>Order.Submitted\uff1a\u8ba2\u5355\u5df2\u7ecf\u63d0\u4ea4\u5230\u5e02\u573a\uff0c\u7b49\u5f85\u88ab\u63a5\u53d7\u6216\u62d2\u7edd\u3002</li> <li>Order.Accepted\uff1a\u8ba2\u5355\u5df2\u7ecf\u88ab\u5e02\u573a\u63a5\u53d7\uff0c\u7b49\u5f85\u88ab\u6267\u884c\u6216\u53d6\u6d88\u3002</li> <li>Order.Partial\uff1a\u8ba2\u5355\u5df2\u7ecf\u90e8\u5206\u6267\u884c\uff0c\u5269\u4f59\u7684\u90e8\u5206\u4ecd\u7136\u5728\u5e02\u573a\u4e2d\u3002</li> <li>Order.Completed\uff1a\u8ba2\u5355\u5df2\u7ecf\u5b8c\u5168\u6267\u884c\uff0c\u6ca1\u6709\u5269\u4f59\u7684\u90e8\u5206\u3002</li> <li>Order.Canceled\uff1a\u8ba2\u5355\u5df2\u7ecf\u88ab\u53d6\u6d88\uff0c\u6ca1\u6709\u88ab\u6267\u884c\u7684\u90e8\u5206\u3002</li> <li>Order.Margin\uff1a\u8ba2\u5355\u7531\u4e8e\u8d44\u91d1\u4e0d\u8db3\u800c\u88ab\u53d6\u6d88\u3002</li> <li>Order.Rejected\uff1a\u8ba2\u5355\u88ab\u5e02\u573a\u62d2\u7edd\uff0c\u6ca1\u6709\u88ab\u6267\u884c\u3002</li> </ul> <p>\u6839\u636e\u8fd9\u4e9b\u72b6\u6001\uff0c\u6211\u4eec\u53ef\u4ee5\u5224\u65ad\u4e00\u4e2a\u8ba2\u5355\u662f\u5426\u4ecd\u7136\u5b58\u5728\u7684\u65b9\u6cd5\u662f\uff1a</p> <ul> <li>\u5982\u679c\u8ba2\u5355\u7684\u72b6\u6001\u662fOrder.Created\uff0cOrder.Submitted\uff0cOrder.Accepted\u6216Order.Partial\uff0c\u90a3\u4e48\u8ba2\u5355\u4ecd\u7136\u5b58\u5728\uff0c\u53ef\u80fd\u4f1a\u5728\u672a\u6765\u88ab\u6267\u884c\u6216\u53d6\u6d88\u3002</li> <li>\u5982\u679c\u8ba2\u5355\u7684\u72b6\u6001\u662fOrder.Completed\uff0cOrder.Canceled\uff0cOrder.Margin\u6216Order.Rejected\uff0c\u90a3\u4e48\u8ba2\u5355\u5df2\u7ecf\u4e0d\u5b58\u5728\uff0c\u4e0d\u4f1a\u518d\u6709\u4efb\u4f55\u53d8\u5316\u3002</li> </ul> <p>backtrader\u63d0\u4f9b\u4e86\u4e00\u4e9b\u65b9\u6cd5\u548c\u5c5e\u6027\uff0c\u7528\u4e8e\u83b7\u53d6\u548c\u4fee\u6539\u8ba2\u5355\u7684\u72b6\u6001\u00b3\u3002\u4f8b\u5982\uff1a</p> <ul> <li>order.status\uff1a\u8fd4\u56de\u8ba2\u5355\u7684\u5f53\u524d\u72b6\u6001\u3002</li> <li>order.cancel()\uff1a\u53d6\u6d88\u8ba2\u5355\uff0c\u5982\u679c\u8ba2\u5355\u8fd8\u6ca1\u6709\u88ab\u6267\u884c\u6216\u53d6\u6d88\u3002</li> <li>order.executed\uff1a\u8fd4\u56de\u4e00\u4e2a\u5bf9\u8c61\uff0c\u5305\u542b\u8ba2\u5355\u7684\u6267\u884c\u4fe1\u606f\uff0c\u5982\u4ef7\u683c\uff0c\u6570\u91cf\uff0c\u4f63\u91d1\u7b49\u3002</li> <li>order.isbuy()\uff1a\u8fd4\u56de\u4e00\u4e2a\u5e03\u5c14\u503c\uff0c\u8868\u793a\u8ba2\u5355\u662f\u5426\u662f\u4e70\u5165\u3002</li> <li>order.issell()\uff1a\u8fd4\u56de\u4e00\u4e2a\u5e03\u5c14\u503c\uff0c\u8868\u793a\u8ba2\u5355\u662f\u5426\u662f\u5356\u51fa\u3002</li> </ul> <p>\u5e0c\u671b\u8fd9\u4e9b\u4fe1\u606f\u80fd\u591f\u5bf9\u60a8\u6709\u6240\u5e2e\u52a9\u3002\u5982\u679c\u60a8\u8fd8\u6709\u5176\u4ed6\u95ee\u9898\uff0c\u6b22\u8fce\u7ee7\u7eed\u63d0\u95ee\u3002\ud83d\ude0a</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/5 (1) Python\u91cf\u5316backtrader18\uff1aOrders\u3010\u8ba2\u5355\u3011 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/365877037. (2) Backtrader\u6765\u5566\uff1a\u4ea4\u6613\u7bc7\uff08\u4e0b\uff09 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/381273223. (3) backtrader\u4e2d\u4f55\u4e3a\u4e00\u4e2a\u4ea4\u6613trade?\u4f60\u53ef\u80fd\u5e76\u6ca1\u7406\u89e3\u5b83\u3002 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/299630905. (4) Backtrader\uff08\u5341\u4e8c\uff09- \u8ba2\u5355 Order -buy\u3001sell\u3001close - CSDN\u535a\u5ba2. https://blog.csdn.net/weixin_44785098/article/details/122647991.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>\u60a8\u597d\uff0c\u8fd9\u662fBing\u3002\u611f\u8c22\u60a8\u7684\u63d0\u95ee\u3002\ud83d\ude0a</p> <p>backtrader\u662f\u4e00\u4e2a\u7528\u4e8e\u56de\u6d4b\u548c\u4ea4\u6613\u7684Python\u6846\u67b6\uff0c\u5b83\u53ef\u4ee5\u5e2e\u52a9\u60a8\u5f00\u53d1\u548c\u6d4b\u8bd5\u60a8\u7684\u4ea4\u6613\u7b56\u7565\u00b9\u3002backtrader\u6ca1\u6709\u63d0\u4f9b\u4e00\u4e2a\u76f4\u63a5\u7684\u65b9\u6cd5\u6765\u89c4\u5b9a\u6700\u5927\u56de\u64a4\uff0c\u4f46\u662f\u60a8\u53ef\u4ee5\u4f7f\u7528\u4e00\u4e9b\u6280\u5de7\u6765\u5b9e\u73b0\u8fd9\u4e2a\u529f\u80fd\u3002</p> <p>\u4e00\u79cd\u53ef\u80fd\u7684\u65b9\u6cd5\u662f\u4f7f\u7528<code>self.broker.getvalue()</code>\u6765\u83b7\u53d6\u5f53\u524d\u7684\u8d26\u6237\u4ef7\u503c\uff0c\u7136\u540e\u4e0e\u4e4b\u524d\u7684\u6700\u9ad8\u4ef7\u503c\u8fdb\u884c\u6bd4\u8f83\uff0c\u5982\u679c\u8d85\u8fc7\u4e86\u60a8\u8bbe\u5b9a\u7684\u6700\u5927\u56de\u64a4\u6bd4\u4f8b\uff0c\u5c31\u89e6\u53d1\u4e00\u4e2a\u4fe1\u53f7\u6765\u5e73\u4ed3\u6216\u8005\u505c\u6b62\u4ea4\u6613\u00b2\u3002\u4f8b\u5982\uff0c\u60a8\u53ef\u4ee5\u5728\u60a8\u7684\u7b56\u7565\u7c7b\u4e2d\u5b9a\u4e49\u4e00\u4e2a\u5c5e\u6027<code>self.max_drawdown</code>\u6765\u5b58\u50a8\u60a8\u7684\u6700\u5927\u56de\u64a4\u6bd4\u4f8b\uff0c\u7136\u540e\u5728<code>next</code>\u65b9\u6cd5\u4e2d\u6dfb\u52a0\u5982\u4e0b\u7684\u4ee3\u7801\uff1a</p> <pre># \u83b7\u53d6\u5f53\u524d\u7684\u8d26\u6237\u4ef7\u503c\ncurrent_value = self.broker.getvalue()\n# \u66f4\u65b0\u6700\u9ad8\u4ef7\u503c\nself.high_value = max(self.high_value, current_value)\n# \u8ba1\u7b97\u5f53\u524d\u7684\u56de\u64a4\u6bd4\u4f8b\ndrawdown_ratio = (self.high_value - current_value) / self.high_value\n# \u5982\u679c\u8d85\u8fc7\u4e86\u6700\u5927\u56de\u64a4\u6bd4\u4f8b\uff0c\u5c31\u89e6\u53d1\u4e00\u4e2a\u4fe1\u53f7\nif drawdown_ratio &gt; self.max_drawdown:\n    # \u5e73\u4ed3\u6216\u8005\u505c\u6b62\u4ea4\u6613\u7684\u903b\u8f91\n    ...\n</pre> <p>\u53e6\u4e00\u79cd\u53ef\u80fd\u7684\u65b9\u6cd5\u662f\u4f7f\u7528<code>self.analyzers.drawdown.get_analysis()</code>\u6765\u83b7\u53d6\u5f53\u524d\u7684\u56de\u6d4b\u5206\u6790\u7ed3\u679c\uff0c\u7136\u540e\u4ece\u4e2d\u63d0\u53d6\u5f53\u524d\u7684\u56de\u64a4\u6bd4\u4f8b\uff0c\u5982\u679c\u8d85\u8fc7\u4e86\u60a8\u8bbe\u5b9a\u7684\u6700\u5927\u56de\u64a4\u6bd4\u4f8b\uff0c\u5c31\u89e6\u53d1\u4e00\u4e2a\u4fe1\u53f7\u6765\u5e73\u4ed3\u6216\u8005\u505c\u6b62\u4ea4\u6613\u00b3\u3002\u4f8b\u5982\uff0c\u60a8\u53ef\u4ee5\u5728\u60a8\u7684\u7b56\u7565\u7c7b\u4e2d\u5b9a\u4e49\u4e00\u4e2a\u5c5e\u6027<code>self.max_drawdown</code>\u6765\u5b58\u50a8\u60a8\u7684\u6700\u5927\u56de\u64a4\u6bd4\u4f8b\uff0c\u7136\u540e\u5728<code>next</code>\u65b9\u6cd5\u4e2d\u6dfb\u52a0\u5982\u4e0b\u7684\u4ee3\u7801\uff1a</p> <pre># \u83b7\u53d6\u5f53\u524d\u7684\u56de\u6d4b\u5206\u6790\u7ed3\u679c\ndrawdown_analysis = self.analyzers.drawdown.get_analysis()\n# \u63d0\u53d6\u5f53\u524d\u7684\u56de\u64a4\u6bd4\u4f8b\ndrawdown_ratio = drawdown_analysis.drawdown / 100\n# \u5982\u679c\u8d85\u8fc7\u4e86\u6700\u5927\u56de\u64a4\u6bd4\u4f8b\uff0c\u5c31\u89e6\u53d1\u4e00\u4e2a\u4fe1\u53f7\nif drawdown_ratio &gt; self.max_drawdown:\n    # \u5e73\u4ed3\u6216\u8005\u505c\u6b62\u4ea4\u6613\u7684\u903b\u8f91\n    ...\n</pre> <p>\u4ee5\u4e0a\u662f\u4e24\u79cd\u53ef\u80fd\u7684\u65b9\u6cd5\u6765\u89c4\u5b9a\u6700\u5927\u56de\u64a4\uff0c\u60a8\u53ef\u4ee5\u6839\u636e\u60a8\u7684\u5177\u4f53\u9700\u6c42\u548c\u504f\u597d\u6765\u9009\u62e9\u548c\u8c03\u6574\u3002\u5e0c\u671b\u8fd9\u4e9b\u4fe1\u606f\u5bf9\u60a8\u6709\u6240\u5e2e\u52a9\u3002\u5982\u679c\u60a8\u8fd8\u6709\u5176\u4ed6\u95ee\u9898\uff0c\u6b22\u8fce\u7ee7\u7eed\u63d0\u95ee\u3002\ud83d\ude0a</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/5 (1) \u91cf\u5316\u6295\u8d44\u5b66\u4e60\u7b14\u8bb073\u2014\u2014backtrader\u5b9e\u64cd - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/158405659. (2) BackTrader\u8e29\u5751\u8bb0\u5f55 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/616104522. (3) backtrader\u91cf\u5316\u56de\u6d4b\u5b9e\u8df5\u7bc7 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/397459857. (4) Backtrader\u5feb\u901f\u5165\u95e8\u2014\u20142. \u7b56\u7565\u8868\u73b0\u8bc4\u4f30_backtrader \u6700\u5927\u56de .... https://blog.csdn.net/Castlehe/article/details/113772133.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>\u5728backtrader\u4e2d\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528<code>stop</code>\u65b9\u6cd5\u6765\u505c\u6b62\u4ea4\u6613\u3002<code>stop</code>\u65b9\u6cd5\u662f\u4e00\u4e2a\u56de\u8c03\u51fd\u6570\uff0c\u5f53\u7b56\u7565\u505c\u6b62\u65f6\u4f1a\u88ab\u8c03\u7528\u3002\u60a8\u53ef\u4ee5\u5728<code>stop</code>\u65b9\u6cd5\u4e2d\u6dfb\u52a0\u903b\u8f91\u6765\u5224\u65ad\u662f\u5426\u9700\u8981\u505c\u6b62\u4ea4\u6613\u3002\u4f8b\u5982\uff0c\u60a8\u53ef\u4ee5\u5728\u7b56\u7565\u7c7b\u4e2d\u5b9a\u4e49\u4e00\u4e2a\u5c5e\u6027<code>self.stop_trading</code>\uff0c\u5e76\u5728<code>stop</code>\u65b9\u6cd5\u4e2d\u68c0\u67e5\u5b83\u7684\u503c\uff0c\u5982\u679c\u4e3a<code>True</code>\uff0c\u5c31\u505c\u6b62\u4ea4\u6613\u3002\u5728\u7b56\u7565\u7c7b\u4e2d\uff0c\u60a8\u53ef\u4ee5\u4f7f\u7528<code>next</code>\u65b9\u6cd5\u6765\u5904\u7406\u6bcf\u4e2a\u6570\u636e\u70b9\uff0c\u7136\u540e\u5728<code>next</code>\u65b9\u6cd5\u4e2d\u6dfb\u52a0\u903b\u8f91\u6765\u5224\u65ad\u662f\u5426\u9700\u8981\u505c\u6b62\u4ea4\u6613\u3002\u4f8b\u5982\uff0c\u60a8\u53ef\u4ee5\u5728<code>next</code>\u65b9\u6cd5\u4e2d\u8ba1\u7b97\u5f53\u524d\u7684\u56de\u64a4\u6bd4\u4f8b\uff0c\u5982\u679c\u8d85\u8fc7\u4e86\u60a8\u8bbe\u5b9a\u7684\u6700\u5927\u56de\u64a4\u6bd4\u4f8b\uff0c\u5c31\u5c06<code>self.stop_trading</code>\u8bbe\u7f6e\u4e3a<code>True</code>\uff0c\u89e6\u53d1\u505c\u6b62\u4ea4\u6613\u4fe1\u53f7\u3002\u4ee5\u4e0b\u662f\u4e00\u4e2a\u793a\u4f8b\u4ee3\u7801\uff0c\u7528\u4e8e\u5728\u56de\u6d4b\u8fc7\u7a0b\u4e2d\u5b9e\u65f6\u76d1\u6d4b\u6700\u5927\u56de\u64a4\uff0c\u5e76\u5728\u56de\u64a4\u8d85\u8fc7\u6700\u5927\u56de\u64a4\u6bd4\u4f8b\u65f6\u505c\u6b62\u4ea4\u6613\uff1a</p> <pre>import backtrader as bt\n\nclass MyStrategy(bt.Strategy):\n    params = (\n        ('max_drawdown', 0.1),  # \u6700\u5927\u56de\u64a4\u6bd4\u4f8b\n    )\n\n    def __init__(self):\n        self.high_value = self.broker.getvalue()  # \u6700\u9ad8\u4ef7\u503c\n        self.stop_trading = False  # \u662f\u5426\u505c\u6b62\u4ea4\u6613\n\n    def next(self):\n        current_value = self.broker.getvalue()  # \u5f53\u524d\u4ef7\u503c\n        drawdown_ratio = (self.high_value - current_value) / self.high_value  # \u5f53\u524d\u56de\u64a4\u6bd4\u4f8b\n        if drawdown_ratio &gt; self.params.max_drawdown:\n            self.stop_trading = True  # \u89e6\u53d1\u505c\u6b62\u4ea4\u6613\u4fe1\u53f7\n        if not self.position and not self.stop_trading:\n            self.buy()\n        elif self.position and not self.stop_trading:\n            self.sell()\n\n    def stop(self):\n        if self.stop_trading:\n            print('\u4ea4\u6613\u5df2\u505c\u6b62\uff0c\u6700\u5927\u56de\u64a4\u8d85\u8fc7\u6700\u5927\u56de\u64a4\u6bd4\u4f8b')\n</pre> <p>\u5728\u4e0a\u9762\u7684\u4ee3\u7801\u4e2d\uff0c\u6211\u4eec\u5b9a\u4e49\u4e86\u4e00\u4e2a<code>MyStrategy</code>\u7b56\u7565\u7c7b\uff0c\u5b83\u5305\u62ec\u4e00\u4e2a<code>max_drawdown</code>\u53c2\u6570\uff0c\u7528\u4e8e\u8bbe\u7f6e\u6700\u5927\u56de\u64a4\u6bd4\u4f8b\u3002\u5728<code>__init__</code>\u65b9\u6cd5\u4e2d\uff0c\u6211\u4eec\u521d\u59cb\u5316\u4e86<code>high_value</code>\u548c<code>stop_trading</code>\u4e24\u4e2a\u53d8\u91cf\u3002<code>high_value</code>\u7528\u4e8e\u8bb0\u5f55\u5f53\u524d\u7684\u6700\u9ad8\u4ef7\u503c\uff0c<code>stop_trading</code>\u7528\u4e8e\u8bb0\u5f55\u662f\u5426\u505c\u6b62\u4ea4\u6613\u3002\u5728<code>next</code>\u65b9\u6cd5\u4e2d\uff0c\u6211\u4eec\u9996\u5148\u8ba1\u7b97\u5f53\u524d\u7684\u56de\u64a4\u6bd4\u4f8b\uff0c\u5982\u679c\u8d85\u8fc7\u4e86\u6700\u5927\u56de\u64a4\u6bd4\u4f8b\uff0c\u5c31\u5c06<code>stop_trading</code>\u8bbe\u7f6e\u4e3a<code>True</code>\uff0c\u89e6\u53d1\u505c\u6b62\u4ea4\u6613\u4fe1\u53f7\u3002\u5982\u679c\u5f53\u524d\u6ca1\u6709\u6301\u4ed3\u4e14\u672a\u89e6\u53d1\u505c\u6b62\u4ea4\u6613\u4fe1\u53f7\uff0c\u5c31\u53d1\u51fa\u4e70\u5165\u4fe1\u53f7\uff1b\u5982\u679c\u5f53\u524d\u6709\u6301\u4ed3\u4e14\u672a\u89e6\u53d1\u505c\u6b62\u4ea4\u6613\u4fe1\u53f7\uff0c\u5c31\u53d1\u51fa\u5356\u51fa\u4fe1\u53f7\u3002\u5728<code>stop</code>\u65b9\u6cd5\u4e2d\uff0c\u6211\u4eec\u68c0\u67e5\u662f\u5426\u89e6\u53d1\u4e86\u505c\u6b62\u4ea4\u6613\u4fe1\u53f7\uff0c\u5982\u679c\u662f\uff0c\u5c31\u8f93\u51fa\u4e00\u6761\u6d88\u606f\uff0c\u8868\u793a\u4ea4\u6613\u5df2\u7ecf\u505c\u6b62\u3002</p> <p>\u5e0c\u671b\u8fd9\u4e9b\u4fe1\u606f\u5bf9\u60a8\u6709\u6240\u5e2e\u52a9\u3002\u5982\u679c\u60a8\u8fd8\u6709\u5176\u4ed6\u95ee\u9898\uff0c\u6b22\u8fce\u7ee7\u7eed\u63d0\u95ee\u3002\ud83d\ude0a</p> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/5 (1) Backtrader\u6765\u5566\uff1a\u4ea4\u6613\u7bc7\uff08\u4e0b\uff09 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/381273223. (2) \u3010\u624b\u628a\u624b\u6559\u4f60\u3011\u7528backtrader\u91cf\u5316\u56de\u6d4b\u6d77\u9f9f\u4ea4\u6613\u7b56\u7565 - \u96ea\u7403. https://xueqiu.com/1444657641/154494557. (3) backtrader\u4e2d\u4f55\u4e3a\u4e00\u4e2a\u4ea4\u6613trade?\u4f60\u53ef\u80fd\u5e76\u6ca1\u7406\u89e3\u5b83\u3002 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/299630905. (4) Backtrader\u6765\u5566\uff1a\u4ea4\u6613\u7bc7\uff08\u4e0a\uff09 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/381275772. (5) \u91cf\u5316\u6295\u8d44\u4e4b\u5de5\u5177\u7bc7\uff1aBacktrader\u4ece\u5165\u95e8\u5230\u7cbe\u901a\uff088\uff09\u4ea4\u6613 .... https://zhuanlan.zhihu.com/p/486905723. (6) Stop-Loss Trading - Backtrader. https://www.backtrader.com/blog/posts/2018-02-01-stop-trading/stop-trading/. (7) Observers - Statistics - Backtrader. https://www.backtrader.com/docu/observers-and-statistics/observers-and-statistics/. (8) Backtrader\u4e2d\u6587\u7b14\u8bb0\u4e4bAnalyzers Reference - \u5c31\u662f\u60f3\u5b66\u4e60 - \u535a\u5ba2\u56ed. https://www.cnblogs.com/sidianok/p/13661588.html.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>\u5728<code>backtrader</code>\u4e2d\uff0c<code>self.broker.getcash()</code>\u65b9\u6cd5\u8fd4\u56de\u7684\u662f\u5f53\u524d\u6301\u4ed3\u7684\u73b0\u91d1\u4ef7\u503c\u3002\u5982\u679c\u4f60\u5728\u5f53\u5929\u8fdb\u884c\u4e86\u4e00\u7b14\u4e70\u5165\u4ea4\u6613\uff0c\u90a3\u4e48\u4f60\u7684\u6301\u4ed3\u7684\u73b0\u91d1\u4ef7\u503c\u4f1a\u53d1\u751f\u53d8\u5316\u3002\u5177\u4f53\u7684\u8ba1\u7b97\u516c\u5f0f\u5982\u4e0b\uff1a</p> <ul> <li>\u5047\u8bbe\u4f60\u7684\u521d\u59cb\u73b0\u91d1\u4e3a<code>cash0</code>\uff0c\u4f60\u7684\u4ea4\u6613\u6570\u91cf\u4e3a<code>size</code>\uff0c\u4f60\u7684\u4e70\u5165\u4ef7\u683c\u4e3a<code>price</code>\uff0c\u4f60\u7684\u4ea4\u6613\u4f63\u91d1\u4e3a<code>commission</code>\uff0c\u90a3\u4e48\u4f60\u7684\u4ea4\u6613\u6210\u672c\u4e3a<code>cost = size * price * (1 + commission)</code>\u3002</li> <li>\u5047\u8bbe\u4f60\u7684\u4ea4\u6613\u53d1\u751f\u5728\u5f53\u5929\u7684\u5f00\u76d8\u65f6\u523b\uff0c\u90a3\u4e48\u4f60\u7684\u6301\u4ed3\u7684\u73b0\u91d1\u4ef7\u503c\u4e3a<code>cash1 = cash0 - cost</code>\u3002</li> <li>\u5047\u8bbe\u4f60\u7684\u4ea4\u6613\u53d1\u751f\u5728\u5f53\u5929\u7684\u6536\u76d8\u65f6\u523b\uff0c\u90a3\u4e48\u4f60\u7684\u6301\u4ed3\u7684\u73b0\u91d1\u4ef7\u503c\u4e3a<code>cash2 = cash0 - cost + size * close</code>\uff0c\u5176\u4e2d<code>close</code>\u662f\u5f53\u5929\u7684\u6536\u76d8\u4ef7\u683c\u3002</li> </ul> <p>\u4e3e\u4e00\u4e2a\u4f8b\u5b50\uff1a</p> <ul> <li>\u5047\u8bbe\u4f60\u7684\u521d\u59cb\u73b0\u91d1\u4e3a$10000$\uff0c\u4f60\u7684\u4ea4\u6613\u6570\u91cf\u4e3a$100$\uff0c\u4f60\u7684\u4e70\u5165\u4ef7\u683c\u4e3a$200$\uff0c\u4f60\u7684\u4ea4\u6613\u4f63\u91d1\u4e3a$0.001$\uff0c\u90a3\u4e48\u4f60\u7684\u4ea4\u6613\u6210\u672c\u4e3a$cost = 100 * 200 * (1 + 0.001) = 20020$\u3002</li> <li>\u5047\u8bbe\u4f60\u7684\u4ea4\u6613\u53d1\u751f\u5728\u5f53\u5929\u7684\u5f00\u76d8\u65f6\u523b\uff0c\u90a3\u4e48\u4f60\u7684\u6301\u4ed3\u7684\u73b0\u91d1\u4ef7\u503c\u4e3a<code>cash1 = 10000 - 20020 = -8020</code>\u3002</li> <li>\u5047\u8bbe\u4f60\u7684\u4ea4\u6613\u53d1\u751f\u5728\u5f53\u5929\u7684\u6536\u76d8\u65f6\u523b\uff0c\u4e14\u5f53\u5929\u7684\u6536\u76d8\u4ef7\u683c\u4e3a$210$\uff0c\u90a3\u4e48\u4f60\u7684\u6301\u4ed3\u7684\u73b0\u91d1\u4ef7\u503c\u4e3a<code>cash2 = 10000 - 20020 + 100 * 210 = 18980</code>\u3002</li> </ul> <p>\u6e90: \u4e0e\u5fc5\u5e94\u7684\u5bf9\u8bdd\uff0c 2023/11/5 (1) Broker - Backtrader. https://www.backtrader.com/docu/broker/. (2) Kelly Criterion : Backtrader Hacks | by JohnJoy | Medium. https://medium.com/@jesso1908joy/kelly-criterion-backtrader-hacks-c982a67907e2. (3) \u56de\u6d4b\u6846\u67b6 backtrader \u600e\u4e48\u83b7\u5f97\u6bcf\u4e00\u6b65\u7684cash\u6216value\uff1f - \u77e5\u4e4e. https://www.zhihu.com/question/413504483. (4) \u5b66\u4e60backtrader\u7684\u6377\u5f84-\u5199\u7ed9backtrader\u521d\u5b66\u8005 - \u77e5\u4e4e. https://zhuanlan.zhihu.com/p/406717815.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>https://blog.csdn.net/weixin_42612813/article/details/90678446</p> <p>\u5173\u4e8echeat on close https://zhuanlan.zhihu.com/p/270871069</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/interview_utils/python_algorithm_puzzles/backtrader/","title":"\u81ea\u5b9a\u4e49\u53c2\u6570\u8c03\u53c2\u00b6","text":""},{"location":"markdown/interview_utils/python_algorithm_puzzles/%E6%9C%80%E5%A4%9A%E6%94%BE%E4%B8%8B%E7%9A%84%E9%95%BF%E6%96%B9%E5%BD%A2/","title":"\u6700\u591a\u653e\u4e0b\u7684\u957f\u65b9\u5f62","text":"In\u00a0[1]: Copied! <pre>def max_rectangles(N, M):\n    dp = [[0] * (M+1) for _ in range(N+1)]\n    for i in range(1, N+1):\n        for j in range(1, M+1):\n            dp[i][j] = dp[i][j-1]\n            if j &gt;= 2:\n                dp[i][j] = max(dp[i][j], dp[i-1][j-2]+1)\n    return dp[N][M]\n</pre> def max_rectangles(N, M):     dp = [[0] * (M+1) for _ in range(N+1)]     for i in range(1, N+1):         for j in range(1, M+1):             dp[i][j] = dp[i][j-1]             if j &gt;= 2:                 dp[i][j] = max(dp[i][j], dp[i-1][j-2]+1)     return dp[N][M] In\u00a0[2]: Copied! <pre>def max_rectangles(N, M):\n    a = max(N, M)\n    b = min(N, M)\n    if a % 2 == 0:\n        return (a // 2) * b\n    else:\n        return (a // 2) * b + (b // 2) \n        \n</pre> def max_rectangles(N, M):     a = max(N, M)     b = min(N, M)     if a % 2 == 0:         return (a // 2) * b     else:         return (a // 2) * b + (b // 2)           In\u00a0[3]: Copied! <pre>max_rectangles(2, 4)\n</pre> max_rectangles(2, 4) Out[3]: <pre>4</pre> In\u00a0[4]: Copied! <pre>max_rectangles(4, 5)\n</pre> max_rectangles(4, 5) Out[4]: <pre>10</pre> In\u00a0[5]: Copied! <pre>max_rectangles(3, 5)\n</pre> max_rectangles(3, 5) Out[5]: <pre>7</pre> In\u00a0[6]: Copied! <pre>6 // 2\n</pre> 6 // 2 Out[6]: <pre>3</pre> In\u00a0[7]: Copied! <pre>5 // 2\n</pre> 5 // 2 Out[7]: <pre>2</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[8]: Copied! <pre>print('hello')\n</pre> print('hello') <pre>hello\n</pre>"},{"location":"markdown/interview_utils/python_algorithm_puzzles/%E9%9A%9C%E7%A2%8D%E7%89%A9%E5%B2%9B%E5%B1%BF%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84/","title":"\u969c\u788d\u7269\u5c9b\u5c7f\u6700\u77ed\u8def\u5f84","text":"In\u00a0[2]: Copied! <pre>from typing import List\nfrom collections import deque\n</pre> from typing import List from collections import deque In\u00a0[46]: Copied! <pre>def min_path(grid: List[List[int]]) -&gt; int:\n    # \u6280\u5de7\uff1a\u4f7f\u7528bfs\uff0c\u5e76\u4e14\u5728\u904d\u5386\u7684\u5750\u6807\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u5b58\u653e\u8d70\u8fc7\u7684\u8def\u7a0b\n    visited = [[False] * len(grid[0]) for _ in range(len(grid))]\n    visited[0][0] = True\n\n    directions = [[0, 1], [0, -1], [-1, 0], [1, 0]]\n    queue = deque()\n    queue.append((0, 0, 0))\n    min_step = float('inf')\n\n    while queue:\n        i, j, step = queue.popleft()\n        for k in range(4):\n            next_i = i + directions[k][0]\n            next_j = j + directions[k][1]\n\n            if next_i &lt; 0 or next_i &gt;= len(grid) or next_j &lt; 0 or next_j &gt;= len(grid[0]):\n                continue\n            if grid[next_i][next_j] == 1 or visited[next_i][next_j]:\n                continue\n            \n            step += 1\n            \n            if (next_i == len(grid) - 1) and (next_j == len(grid[0]) - 1):\n                min_step = min(min_step, step)\n    \n            visited[next_i][next_j] = True\n            queue.append((next_i, next_j, step))\n\n    return min_step\n        \n</pre> def min_path(grid: List[List[int]]) -&gt; int:     # \u6280\u5de7\uff1a\u4f7f\u7528bfs\uff0c\u5e76\u4e14\u5728\u904d\u5386\u7684\u5750\u6807\u589e\u52a0\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u5b58\u653e\u8d70\u8fc7\u7684\u8def\u7a0b     visited = [[False] * len(grid[0]) for _ in range(len(grid))]     visited[0][0] = True      directions = [[0, 1], [0, -1], [-1, 0], [1, 0]]     queue = deque()     queue.append((0, 0, 0))     min_step = float('inf')      while queue:         i, j, step = queue.popleft()         for k in range(4):             next_i = i + directions[k][0]             next_j = j + directions[k][1]              if next_i &lt; 0 or next_i &gt;= len(grid) or next_j &lt; 0 or next_j &gt;= len(grid[0]):                 continue             if grid[next_i][next_j] == 1 or visited[next_i][next_j]:                 continue                          step += 1                          if (next_i == len(grid) - 1) and (next_j == len(grid[0]) - 1):                 min_step = min(min_step, step)                  visited[next_i][next_j] = True             queue.append((next_i, next_j, step))      return min_step          In\u00a0[42]: Copied! <pre>grid = [[0, 1, 1, 0, 1], [0, 1, 0, 0, 1], [0, 0, 0, 0, 0], [1, 1, 0, 0, 0]]\n</pre> grid = [[0, 1, 1, 0, 1], [0, 1, 0, 0, 1], [0, 0, 0, 0, 0], [1, 1, 0, 0, 0]] In\u00a0[47]: Copied! <pre>min_path(grid)\n</pre> min_path(grid) Out[47]: <pre>7</pre> In\u00a0[51]: Copied! <pre>grid = [[0, 1, 1, 0, 1], [0, 1, 0, 0, 0], [0, 0, 0, 1, 0], [1, 1, 0, 1, 0]]\n</pre> grid = [[0, 1, 1, 0, 1], [0, 1, 0, 0, 0], [0, 0, 0, 1, 0], [1, 1, 0, 1, 0]] In\u00a0[52]: Copied! <pre>min_path(grid)\n</pre> min_path(grid) Out[52]: <pre>9</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <p>\u5173\u4e8edeque\u7684\u6ce8\u610f\u70b9</p> In\u00a0[50]: Copied! <pre>queue = deque((0, 0))\n</pre> queue = deque((0, 0)) In\u00a0[14]: Copied! <pre>i, j = queue.popleft()\n</pre> i, j = queue.popleft() <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[14], line 1\n----&gt; 1 i, j = queue.popleft()\n\nTypeError: cannot unpack non-iterable int object</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[18]: Copied! <pre>queue = deque()\nqueue.append((0, 0))\n</pre> queue = deque() queue.append((0, 0)) In\u00a0[19]: Copied! <pre>i, j = queue.popleft()\ni, j\n</pre> i, j = queue.popleft() i, j Out[19]: <pre>(0, 0)</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/interview_utils/python_algorithm_puzzles/%E9%9D%A2%E8%AF%95%E9%81%87%E5%88%B0%E7%9A%84%E4%BB%A3%E7%A0%81%E9%A2%98/","title":"\u9762\u8bd5\u9047\u5230\u7684\u4ee3\u7801\u9898","text":"<ol> <li>\u7ed9\u5b9a\u4e00\u4e2a\u957f\u5ea6\u4e3an\u7684\u5e8f\u5217a\u548c\u4e00\u4e2a\u6570\u5b57k\uff0c\u95eea\u4e2d\u6709\u591a\u5c11\u5b50\u5e8f\u5217\u6070\u597d\u5305\u542bk\u4e2a\u4e0d\u540c\u7684\u6570\u5b57\u3002</li> </ol> In\u00a0[\u00a0]: Copied! <ol> <li>\u7ed9\u5b9a\u957f\u5ea6\u4e3an\u7684\u4e00\u4e2a\u6570\u5b57\u5e8f\u5217a\u3001\u4e00\u4e2a\u957f\u5ea6\u4e3an\u7684\u5b57\u7b26\u4e32s\u548c\u4e00\u4e2a\u6b63\u6574\u6570k\u3002\u5176\u4e2ds\u5305\u542b'R'\u6216\u8005'B'\uff0c\u4ee3\u8868a\u4e2d\u5bf9\u5e94\u4f4d\u7f6e\u7684\u5143\u7d20\u88ab\u67d3\u6210\u7ea2\u8272\u6216\u8005\u84dd\u8272\u3002 \u73b0\u5728\u60f3\u8981\u627e\u5230\u4e00\u4e2aa\u7684\u8fde\u7eed\u5b50\u5e8f\u5217\uff0c\u4f7f\u5f97\u5b50\u5e8f\u5217\u4e2d\u4e2d<code>\u88ab\u67d3\u6210\u7ea2\u8272\u7684\u5143\u7d20\u7684\u4e58\u79ef\u7684\u672b\u5c3e0\u7684\u4e2a\u6570</code>\u548c<code>a\u4e2d\u88ab\u67d3\u6210\u84dd\u8272\u7684\u5143\u7d20\u7684\u4e58\u79ef\u7684\u672b\u5c3e0\u7684\u4e2a\u6570</code>\u76f8\u52a0\u7684\u548c\u5c0f\u4e8e\u7b49\u4e8ek\uff0c \u6c42\u8fd9\u4e2a\u5b50\u5e8f\u5217\u7684\u6700\u5c0f\u957f\u5ea6\u3002 e.g. a = [1, 4, 15, 8, 5], s = ['B', 'R', 'R', 'B', 'B'], n = 5, k = 2, \u5219\u7b54\u6848\u4e3a4\uff0c\u6700\u77ed\u5b50\u5e8f\u5217\u4e3a[4, 15, 8, 5]</li> </ol> In\u00a0[5]: Copied! <pre># \u4f7f\u7528\u52a8\u6001\u89c4\u5212\ndef decompose_number(num):\n    count_2 = 0\n    count_5 = 0\n    \n    # \u5206\u89e3\u56e0\u5b502\n    while num % 2 == 0:\n        num = num // 2\n        count_2 += 1\n    \n    # \u5206\u89e3\u56e0\u5b505\n    while num % 5 == 0:\n        num = num // 5\n        count_5 += 1\n    \n    # \u8f93\u51fa\u7ed3\u679c\n    return count_2, count_5\n\n# dp[i][j]: i\u5f00\u5934j\u7ed3\u5c3e\u7684\u5b50\u5e8f\u5217\u4e2d\uff0c2\u7684\u4e2a\u6570\u548c5\u7684\u4e2a\u6570\ndecompose_number(100)\n</pre> # \u4f7f\u7528\u52a8\u6001\u89c4\u5212 def decompose_number(num):     count_2 = 0     count_5 = 0          # \u5206\u89e3\u56e0\u5b502     while num % 2 == 0:         num = num // 2         count_2 += 1          # \u5206\u89e3\u56e0\u5b505     while num % 5 == 0:         num = num // 5         count_5 += 1          # \u8f93\u51fa\u7ed3\u679c     return count_2, count_5  # dp[i][j]: i\u5f00\u5934j\u7ed3\u5c3e\u7684\u5b50\u5e8f\u5217\u4e2d\uff0c2\u7684\u4e2a\u6570\u548c5\u7684\u4e2a\u6570 decompose_number(100) Out[5]: <pre>(2, 2)</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <ol> <li>\u7ed9\u5b9a\u6b63\u6574\u6570n\uff0c\u95ee\u6709\u591a\u5c11\u79cd\u65b9\u5f0f\u53ef\u4ee5\u5c06n\u62c6\u6210\u591a\u4e2a\u6570\u5b57\u7684\u52a0\u548c\u5f62\u5f0f\uff0c\u4e14\u76f8\u90bb\u7684\u6570\u5b57\u4e3a\u5947\u5076\u4ea4\u66ff\u7684\u3002</li> </ol> In\u00a0[\u00a0]: Copied! <pre>\n</pre> <ol> <li>\u7ed9\u5b9a\u4e00\u4e2a\u6570\u7ec4\u548c\u4e00\u4e2a\u6b63\u6574\u6570k\uff0ck\u4ee3\u8868\u4e86\u5141\u8bb8\u64cd\u4f5c\u6570\u91cf\u7684\u4e0a\u9650\uff0c\u6bcf\u6b21\u64cd\u4f5c\u53ef\u4ee5\u5c06\u6570\u7ec4\u4e2d\u67d0\u4e2a\u6570\u5b57\u52a0\u4e00\uff0c \u95ee\u6700\u591a\u53ef\u4ee5\u4f7f\u5f97\u6570\u7ec4\u4e2d\u591a\u5c11\u4e2a\u6570\u5b57\u76f8\u7b49\uff1f\u8bf7\u4f7f\u7528Python\u5199\u4e00\u4e2a\u4ee3\u7801\u5b9e\u73b0\u8fd9\u4e2a\u95ee\u9898\u3002</li> </ol> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre># \u8fd9\u9898\u5f88\u7b80\u5355\uff0c\u4e0d\u505a\u4e86\nT = int(input())\ndata = []\nfor _ in T:\n    data.append(list(map(int, input().split())))\n\nfor line in data:\n    h, w = line\n    if h &lt;= 360 and w &lt;= 360:\n        print('break')\n    elif\n        ...\n</pre> # \u8fd9\u9898\u5f88\u7b80\u5355\uff0c\u4e0d\u505a\u4e86 T = int(input()) data = [] for _ in T:     data.append(list(map(int, input().split())))  for line in data:     h, w = line     if h &lt;= 360 and w &lt;= 360:         print('break')     elif         ... In\u00a0[\u00a0]: Copied! <pre># \u76f4\u63a5\u7a77\u4e3e\u904d\u5386\u5c31\u597d\uff0c\u590d\u6742\u5ea6\u4e3aO(n)\n</pre> # \u76f4\u63a5\u7a77\u4e3e\u904d\u5386\u5c31\u597d\uff0c\u590d\u6742\u5ea6\u4e3aO(n) In\u00a0[4]: Copied! <pre>s = 'a'\ns.lower() == s\n</pre> s = 'a' s.lower() == s Out[4]: <pre>True</pre> In\u00a0[7]: Copied! <pre>path = ['r', 'e', 'd']\n''.join(path) == 'red'\n</pre> path = ['r', 'e', 'd'] ''.join(path) == 'red' Out[7]: <pre>True</pre> In\u00a0[8]: Copied! <pre>for j in range(4, 2):\n    print(j)\n</pre> for j in range(4, 2):     print(j) In\u00a0[9]: Copied! <pre>arr = [1, 2, 3, 4, 5]\narr[4: 5]\n</pre> arr = [1, 2, 3, 4, 5] arr[4: 5] Out[9]: <pre>[5]</pre> In\u00a0[14]: Copied! <pre>arr[:0]\n</pre> arr[:0] Out[14]: <pre>[]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[16]: Copied! <pre>path = set()\npath.add(1)\npath\nlist(path)\n</pre> path = set() path.add(1) path list(path) Out[16]: <pre>[1]</pre> In\u00a0[12]: Copied! <pre>arr.index(max(arr))\n</pre> arr.index(max(arr)) Out[12]: <pre>4</pre>"},{"location":"markdown/interview_utils/python_algorithm_puzzles/%E9%9D%A2%E8%AF%95%E9%81%87%E5%88%B0%E7%9A%84%E4%BB%A3%E7%A0%81%E9%A2%98/","title":"\u9762\u8bd5\u9047\u5230\u7684\u4ee3\u7801\u9898\u00b6","text":""},{"location":"markdown/interview_utils/python_algorithm_puzzles/%E9%9D%A2%E8%AF%95%E9%81%87%E5%88%B0%E7%9A%84%E4%BB%A3%E7%A0%81%E9%A2%98/","title":"\u7f8e\u56e2\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/backtrader/","title":"\u4f7f\u7528backtrader\u5b9e\u73b0\u4e00\u4e2a\u57fa\u672c\u7b56\u7565\u7684\u56de\u6d4b","text":"In\u00a0[3]: Copied! <pre>from __future__ import (absolute_import, division, print_function, unicode_literals)\nimport os\nimport sys\nfrom datetime import datetime\nimport pandas as pd\nimport akshare as ak\nimport backtrader as bt\n</pre> from __future__ import (absolute_import, division, print_function, unicode_literals) import os import sys from datetime import datetime import pandas as pd import akshare as ak import backtrader as bt  In\u00a0[4]: Copied! <pre>df_stock = ak.stock_zh_a_spot_em()\n</pre> df_stock = ak.stock_zh_a_spot_em() In\u00a0[5]: Copied! <pre># \u4ee5\u4e2d\u56fd\u5e73\u5b89\u7684\u8fd1\u4e24\u5e74\u540e\u590d\u6743\u65e5\u9891\u6570\u636e\u4e3a\u4f8b\ninstrument_id = df_stock[df_stock['\u540d\u79f0'] == '\u4e2d\u56fd\u5e73\u5b89'].iloc[0]['\u4ee3\u7801']\ndf_price = ak.stock_zh_a_hist(symbol=instrument_id, period=\"daily\", start_date=\"20201101\", \n                              end_date='20221101', adjust=\"hfq\")\ndf_price.head(5)\n</pre> # \u4ee5\u4e2d\u56fd\u5e73\u5b89\u7684\u8fd1\u4e24\u5e74\u540e\u590d\u6743\u65e5\u9891\u6570\u636e\u4e3a\u4f8b instrument_id = df_stock[df_stock['\u540d\u79f0'] == '\u4e2d\u56fd\u5e73\u5b89'].iloc[0]['\u4ee3\u7801'] df_price = ak.stock_zh_a_hist(symbol=instrument_id, period=\"daily\", start_date=\"20201101\",                                end_date='20221101', adjust=\"hfq\") df_price.head(5) Out[5]: \u65e5\u671f \u5f00\u76d8 \u6536\u76d8 \u6700\u9ad8 \u6700\u4f4e \u6210\u4ea4\u91cf \u6210\u4ea4\u989d \u632f\u5e45 \u6da8\u8dcc\u5e45 \u6da8\u8dcc\u989d \u6362\u624b\u7387 0 2020-11-02 176.47 173.93 177.09 173.49 638720 4.955636e+09 2.06 -0.69 -1.20 0.59 1 2020-11-03 175.01 177.79 178.15 174.27 615433 4.838929e+09 2.23 2.22 3.86 0.57 2 2020-11-04 177.03 178.47 179.17 176.67 434671 3.448542e+09 1.41 0.38 0.68 0.40 3 2020-11-05 180.17 181.35 182.83 179.87 537095 4.346337e+09 1.66 1.61 2.88 0.50 4 2020-11-06 181.67 182.07 182.97 180.51 510389 4.140944e+09 1.36 0.40 0.72 0.47 In\u00a0[6]: Copied! <pre>rename_map = {'\u65e5\u671f': 'datetime', '\u5f00\u76d8': 'open', '\u6700\u9ad8': 'high', '\u6700\u4f4e': 'low', '\u6536\u76d8': 'close', '\u6210\u4ea4\u91cf': 'volume'}\ndf_price.rename(columns=rename_map, inplace=True)\ndf_price = df_price[list(rename_map.values())].copy()\ndf_price['datetime'] = pd.to_datetime(df_price['datetime'])\ndf_price['volume'] = df_price['volume'].astype(int)\n</pre> rename_map = {'\u65e5\u671f': 'datetime', '\u5f00\u76d8': 'open', '\u6700\u9ad8': 'high', '\u6700\u4f4e': 'low', '\u6536\u76d8': 'close', '\u6210\u4ea4\u91cf': 'volume'} df_price.rename(columns=rename_map, inplace=True) df_price = df_price[list(rename_map.values())].copy() df_price['datetime'] = pd.to_datetime(df_price['datetime']) df_price['volume'] = df_price['volume'].astype(int) In\u00a0[7]: Copied! <pre>df_price.head(5)\n</pre> df_price.head(5) Out[7]: datetime open high low close volume 0 2020-11-02 176.47 177.09 173.49 173.93 638720 1 2020-11-03 175.01 178.15 174.27 177.79 615433 2 2020-11-04 177.03 179.17 176.67 178.47 434671 3 2020-11-05 180.17 182.83 179.87 181.35 537095 4 2020-11-06 181.67 182.97 180.51 182.07 510389 <p>\u5b9e\u73b0\u4e00\u4e2a\u5f88\u7b80\u5355\u7684\u5747\u503c\u56de\u5f52\u7b56\u7565\uff1a</p> <ol> <li>\u5982\u679c\u5f53\u524d\u7684\u4ef7\u683c\u4f4e\u4e8e\u8fc7\u53bb20\u4e2a\u4ea4\u6613\u65e5\u7684\u4ef7\u683c\u7684\u79fb\u52a8\u5e73\u5747\u503c\uff0c\u5c31\u4e70\u5165\uff0c\u6bcf\u6b21\u4e70\u5165100\u80a1\uff0c\u5982\u679c\u672c\u91d1\u4e0d\u591f\uff0c\u90a3\u4e48\u5c31\u80fd\u4e70\u591a\u5c11\u4e70\u591a\u5c11\u3002</li> <li>\u5982\u679c\u5f53\u524d\u4ef7\u683c\u9ad8\u4e8e\u8fc7\u53bb20\u4e2a\u4ea4\u6613\u65e5\u7684\u4ef7\u683c\u7684\u79fb\u52a8\u5e73\u5747\u503c\uff0c\u5c31\u5356\u51fa\uff0c\u6bcf\u6b21\u5356\u51fa100\u80a1\u3002</li> </ol> <p>\u6ce8\u610f\u70b9\uff1a</p> <ol> <li>\u8003\u8651\u4f63\u91d1</li> <li>\u6700\u5927\u56de\u64a4\u4e0d\u80fd\u8d85\u8fc750%\u3002\u5982\u679c\u8d85\u8fc7\uff0c\u90a3\u4e48\u76f4\u63a5\u5e73\u4ed3\uff0c\u7ed3\u675f\u7b56\u7565\u3002</li> <li>\u56de\u6d4b\u5468\u671f\u4e3a2020.11.1 - 2022.11.1\u3002</li> </ol> In\u00a0[12]: Copied! <pre>df_test = df_price.head(10).copy()\n</pre> df_test = df_price.head(10).copy() In\u00a0[13]: Copied! <pre>df_test\n</pre> df_test Out[13]: datetime open high low close volume 0 2020-11-02 176.47 177.09 173.49 173.93 638720 1 2020-11-03 175.01 178.15 174.27 177.79 615433 2 2020-11-04 177.03 179.17 176.67 178.47 434671 3 2020-11-05 180.17 182.83 179.87 181.35 537095 4 2020-11-06 181.67 182.97 180.51 182.07 510389 5 2020-11-09 184.47 186.47 184.07 185.43 809965 6 2020-11-10 187.95 188.97 185.57 185.87 789003 7 2020-11-11 185.87 187.53 184.77 186.51 542825 8 2020-11-12 186.97 188.41 183.07 184.01 490544 9 2020-11-13 181.63 182.87 178.73 180.15 707942 <p>\u4ee5\u4e0b\u6d4b\u8bd5\u7b56\u7565\uff0c\u6211\u4eec\u5047\u8bbe\u5728\u5947\u6570tick\u65f6\u4e70\u4e2d\u56fd\u5e73\u5b89100\u80a1\uff0c\u5728\u5076\u6570tick\u65f6\u5356100\u80a1\uff0c\u4e0d\u7ba1\u5176\u5b83\u4efb\u4f55\u7684\u4ef7\u683c\u7b49\u4fe1\u606f\uff0ctick\u4ece\u7d22\u5f151\u5f00\u59cb\uff0c\u7d22\u5f151\u4ee3\u886811\u67082\u65e5\uff0c\u89c4\u5b9a\u6bcf\u65e5\u6302\u7684\u4e70\u5355\u7684tradeid\u4e3atick\uff0c\u6b21\u65e5\u7684\u5356\u5355\u7684tradeid\u548c\u4eca\u5929\u7684\u4e70\u5355\u5c5e\u4e8e\u540c\u4e00\u4e2a\u4ea4\u6613\uff0ctradeid\u76f8\u540c </p> <ul> <li>\u6b63\u5e38\u6a21\u5f0f\u7684\u6267\u884c\u987a\u5e8f\u5982\u4e0b\uff1a</li> </ul> <ol> <li><p>11\u67082\u65e5\u6536\u76d8\u540e\u89e6\u53d1next\uff0c\u540c\u65f6\u8fd0\u884cself.buy(size=100)</p> </li> <li><p>11\u67083\u65e5\u4f7f\u752811\u67083\u65e5\u7684open\u630211\u67082\u65e5\u7684\u8ba2\u5355\uff08tradeid=1\uff09\uff0c\u6b64\u65f6\u8ba2\u5355\u88abSubmitted &amp; Accepted\uff0c\u540c\u65f6\u8ba2\u5355\u6210\u4ea4Completed\uff0c\u89e6\u53d1notify_order</p> </li> <li><p>11\u67083\u65e5\u6302\u7684\u4e70\u5355\u6210\u4ea4\uff0c\u5bfc\u81f4tradeid=1\u7684\u4ea4\u6613\u7684\u4ed3\u4f4d\u75310\u53d8\u4e3a100\uff0c\u6b64\u65f6\u4ea4\u6613\u72b6\u6001\u53d1\u751f\u6539\u53d8\uff0c\u89e6\u53d1notify_trade\uff0c\u6b64\u65f6trade.status == trade.Open</p> </li> <li><p>11\u67083\u65e5\u6536\u76d8\u540e\u89e6\u53d1next\uff0c\u540c\u65f6\u8fd0\u884cself.sell(size=100)</p> </li> <li><p>11\u67084\u65e5\u4f7f\u752811\u67084\u65e5\u7684open\u630211\u67083\u65e5\u7684\u8ba2\u5355\uff08tradeid=1\uff09\uff0c\u6b64\u65f6\u8ba2\u5355\u88abSubmitted &amp; Accepted\uff0c\u540c\u65f6\u8ba2\u5355\u6210\u4ea4Completed\uff0c\u89e6\u53d1notify_order</p> </li> <li><p>11\u67084\u65e5\u6302\u7684\u5356\u5355\u6210\u4ea4\uff0c\u5bfc\u81f4tradeid=1\u7684\u4ea4\u6613\u4ed3\u4f4d\u7531100\u53d8\u4e3a0\uff0c\u6b64\u65f6\u4ea4\u6613\u72b6\u6001\u53d1\u751f\u6539\u53d8\uff0c\u89e6\u53d1notify_trade\uff0c\u6b64\u65f6trade.status == trade.Closed</p> </li> <li><p>11\u67084\u65e5\u6536\u76d8\u540e\u89e6\u53d1next\uff0c\u540c\u65f6\u8fd0\u884cself.buy(size=100)</p> </li> <li><p>11\u67085\u65e5\u4f7f\u752811\u67085\u65e5\u7684open\u630211\u67084\u65e5\u7684\u8ba2\u5355\uff08tradeid=3\uff09\uff0c\u6b64\u65f6\u8ba2\u5355\u88abSubmitted &amp; Accepted\uff0c\u540c\u65f6\u8ba2\u5355\u6210\u4ea4Completed\uff0c\u89e6\u53d1notify_order</p> </li> <li><p>11\u67085\u65e5\u6302\u7684\u4e70\u5355\u6210\u4ea4\uff0c\u5bfc\u81f4tradeid=3\u7684\u4ea4\u6613\u4ed3\u4f4d\u75310\u53d8\u4e3a100\uff0c\u6b64\u65f6\u4ea4\u6613\u72b6\u6001\u53d1\u751f\u6539\u53d8\uff0c\u89e6\u53d1notify_trade\uff0c\u6b64\u65f6trade.status == trade.Open</p> </li> <li><p>11\u67085\u65e5\u6536\u76d8\u540e\u89e6\u53d1next\uff0c\u540c\u65f6\u8fd0\u884cself.sell(size=100)</p> </li> <li><p>11\u67086\u65e5\u4f7f\u752811\u67086\u65e5\u7684open\u630211\u67085\u65e5\u7684\u8ba2\u5355\uff08tradeid=3\uff09\uff0c\u6b64\u65f6\u8ba2\u5355\u88abSubmitted &amp; Accepted\uff0c\u540c\u65f6\u8ba2\u5355\u6210\u4ea4Completed\uff0c\u89e6\u53d1notify_order</p> </li> <li><p>11\u67086\u65e5\u6302\u7684\u5356\u5355\u6210\u4ea4\uff0c\u5bfc\u81f4tradeid=3\u7684\u4ea4\u6613\u4ed3\u4f4d\u7531100\u53d8\u4e3a0\uff0c\u6b64\u65f6\u4ea4\u6613\u72b6\u6001\u53d1\u751f\u6539\u53d8\uff0c\u89e6\u53d1notify_trade\uff0c\u6b64\u65f6trade.status == trade.Closed</p> </li> <li><p>11\u67086\u65e5\u6536\u76d8\u540e\u89e6\u53d1next\uff0c\u540c\u65f6\u8fd0\u884cself.buy(size=100)</p> </li> <li><p>......</p> </li> </ol> <ul> <li>coo\u6a21\u5f0f\u7684\u6267\u884c\u987a\u5e8f\u5982\u4e0b\uff1a</li> </ul> <ol> <li><p>11\u67082\u65e5\u6ca1\u6709\u64cd\u4f5c</p> </li> <li><p>11\u67083\u65e5\u5f00\u76d8\u524d\u89e6\u53d1next_open\uff0c\u540c\u65f6\u8fd0\u884cself.buy(size=100, tradeid=1)</p> </li> <li><p>11\u67083\u65e5\u5f00\u76d8\u540e\u4f7f\u752811\u67083\u65e5\u7684open\u630211\u67083\u65e5\u7684\u8ba2\u5355\uff08tradeid=1\uff09\uff0c\u540c\u65f6\u8ba2\u5355\u88abSubmitted &amp; Accepted\uff0c\u540c\u65f6\u8ba2\u5355\u6210\u4ea4Completed\uff0c\u89e6\u53d1notify_order</p> </li> <li><p>11\u67083\u65e5\u6302\u7684\u4e70\u5355\u6210\u4ea4\uff0c\u5bfc\u81f4tradeid=1\u7684\u4ea4\u6613\u7684\u4ed3\u4f4d\u75310\u53d8\u4e3a100\uff0c\u6b64\u65f6\u4ea4\u6613\u72b6\u6001\u53d1\u751f\u6539\u53d8\uff0c\u89e6\u53d1notify_trade\uff0c\u6b64\u65f6trade.status == trade.Open</p> </li> <li><p>11\u67084\u65e5\u5f00\u76d8\u524d\u89e6\u53d1next_open\uff0c\u540c\u65f6\u8fd0\u884cself.sell(size=100, tradeid=1)</p> </li> <li><p>11\u67084\u65e5\u5f00\u76d8\u540e\u4f7f\u752811\u67084\u65e5\u7684open\u630211\u67084\u65e5\u7684\u8ba2\u5355\uff08tradeid=1\uff09\uff0c\u540c\u65f6\u8ba2\u5355\u88abSubmitted &amp; Accepted\uff0c\u540c\u65f6\u8ba2\u5355\u6210\u4ea4Completed\uff0c\u89e6\u53d1notify_order</p> </li> <li><p>11\u67084\u65e5\u6302\u7684\u5356\u5355\u6210\u4ea4\uff0c\u5bfc\u81f4tradeid=1\u7684\u4ea4\u6613\u7684\u4ed3\u4f4d\u7531100\u53d8\u4e3a0\uff0c\u6b64\u65f6\u4ea4\u6613\u72b6\u6001\u53d1\u751f\u6539\u53d8\uff0c\u89e6\u53d1notify_trade\uff0c\u6b64\u65f6trade.status == trade.Close</p> </li> <li><p>11\u67085\u65e5\u5f00\u76d8\u524d\u89e6\u53d1next_open\uff0c\u540c\u65f6\u8fd0\u884cself.buy(size=100, tradeid=3)</p> </li> <li><p>11\u67085\u65e5\u5f00\u76d8\u540e\u4f7f\u752811\u67085\u65e5\u7684open\u630211\u67085\u65e5\u7684\u8ba2\u5355\uff08tradeid=3\uff09\uff0c\u540c\u65f6\u8ba2\u5355\u88abSubmitted &amp; Accepted\uff0c\u540c\u65f6\u8ba2\u5355\u6210\u4ea4Completed\uff0c\u89e6\u53d1notify_order</p> </li> <li><p>11\u67085\u65e5\u6302\u7684\u4e70\u5355\u6210\u4ea4\uff0c\u5bfc\u81f4tradeid=3\u7684\u4ea4\u6613\u7684\u4ed3\u4f4d\u75310\u53d8\u4e3a100\uff0c\u6b64\u65f6\u4ea4\u6613\u72b6\u6001\u53d1\u751f\u6539\u53d8\uff0c\u89e6\u53d1notify_trade\uff0c\u6b64\u65f6trade.status == trade.Open</p> </li> <li><p>11\u67086\u65e5\u5f00\u76d8\u524d\u89e6\u53d1next_open\uff0c\u540c\u65f6\u8fd0\u884cself.sell(size=100, tradeid=3)</p> </li> <li><p>11\u67086\u65e5\u5f00\u76d8\u540e\u4f7f\u752811\u67086\u65e5\u7684open\u630211\u67086\u65e5\u7684\u8ba2\u5355\uff08tradeid=3\uff09\uff0c\u540c\u65f6\u8ba2\u5355\u88abSubmitted &amp; Accepted\uff0c\u540c\u65f6\u8ba2\u5355\u6210\u4ea4Completed\uff0c\u89e6\u53d1notify_order</p> </li> <li><p>11\u67086\u65e5\u6302\u7684\u5356\u5355\u6210\u4ea4\uff0c\u5bfc\u81f4tradeid=3\u7684\u4ea4\u6613\u7684\u4ed3\u4f4d\u7531100\u53d8\u4e3a0\uff0c\u6b64\u65f6\u4ea4\u6613\u72b6\u6001\u53d1\u751f\u6539\u53d8\uff0c\u89e6\u53d1notify_trade\uff0c\u6b64\u65f6trade.status == trade.Close</p> </li> <li><p>......</p> </li> </ol> <ul> <li>\u6b63\u5e38\u6a21\u5f0f\u4e0b\uff0c\u5728next\u91cc\u4ee5\u7d22\u5f150\u8bbf\u95ee\u7684\u5f53\u524dbar\u7684\u6536\u76d8\u4ef7\u3001\u79fb\u52a8\u5e73\u5747\u503c\u7b49\u90fd\u662f\u57fa\u4e8e\u4eca\u65e5\u7684\u6536\u76d8\u4ef7\u3002</li> </ul> <ul> <li>\u6bcf\u8c03\u7528\u4e00\u6b21self.buy() or self.sell()\uff0c\u90fd\u4f1a\u521b\u5efa\u4e00\u7b14\u8ba2\u5355\uff0c\u8ba2\u5355\u6240\u5c5e\u7684trade\u3001\u8ba2\u5355\u7684orderid\u90fd\u53ef\u4ee5\u81ea\u884c\u6307\u5b9a\u3002\u5176\u4e2d\u6240\u5c5etrade\u901a\u8fc7tradeid\u53c2\u6570\u6307\u5b9a\u3002orderid\u662f\u81ea\u5b9a\u4e49\u53c2\u6570\u3002\u5176\u5b9e\u5728\u521b\u5efa\u8ba2\u5355\u7684\u65f6\u5019\u4e5f\u53ef\u4ee5\u81ea\u5df1\u6dfb\u52a0\u4efb\u610f\u53c2\u6570\uff0c\u8fd9\u4e9b\u53c2\u6570\u5728\u5916\u90e8\u8c03\u7528\u7684\u65f6\u5019\uff0c\u4f1a\u88ab\u653e\u5728self.brokers.order[i].info\u8fd9\u4e2adict\u4e2d\u3002\u5728notify\u4e2d\u8c03\u7528\u7684\u65f6\u5019\uff0c\u4f1a\u88ab\u653e\u5728order.info\u4e2d\u3002</li> </ul> In\u00a0[14]: Copied! <pre>class TestStrategy(bt.Strategy):\n    \n    s = '-' * 20\n    \n    def __init__(self):\n        self.close = self.datas[0].close\n        self.volume = self.datas[0].volume\n        self.starting_value = self.broker.getvalue()\n        # \u8bb0\u5f55\u662f\u5426\u4f5c\u5f0a\uff0c\u6ce8\u610f\u5b83\u662f\u5982\u4f55\u53d6\u5f97cerebro\u53c2\u6570\u7684\n        # cheat_on_open: \u5f53\u65e5\u4e0b\u5355\uff0c\u5f53\u65e5\u5f00\u76d8\u4ef7\u6210\u4ea4\n        self.coo = self.broker.p.coo\n        self.coc = self.broker.p.coc\n        \n        # cheat_on_close: \u5f53\u65e5\u4e0b\u5355\uff0c\u5f53\u65e5\u6536\u76d8\u4ef7\u6210\u4ea4\n\n        \n    def log(self, content: str=None, dt: bool=True):\n        if dt:\n            time = self.datas[0].datetime.date(0)\n            if content:\n                print(f'{time}-- {content}')\n            else:\n                print(f'{time}-- ')\n        else:\n            if not content:\n                return\n            else:\n                print(content)\n    \n    \n    def notify_order(self, order):\n        \"\"\"\n        \u6bcf\u6b21\u8ba2\u5355\u72b6\u6001\u53d1\u751f\u6539\u53d8\u65f6\u7684\u56de\u8c03\u51fd\u6570\u3002\u5728\u6bcf\u4e2atick\uff0c\u53ea\u8981\u8ba2\u5355\u72b6\u6001\u53d1\u751f\u6539\u53d8\uff0c\u5c31\u4f1a\u8c03\u7528notify_order\uff0c\u6bcf\u4e2atick\u53ef\u80fd\u4e0d\u6b62\u8c03\u7528\u4e00\u6b21\u3002\n        e.g. \u572811\u67082\u65e5\u4e0b\u5355\u7684\u8ba2\u5355\u572811\u67083\u65e5\u624d\u4f1a\u88abSubmitted\u7b49\u3002\n        \"\"\"\n        \n        if order.status == order.Submitted:  # \u5982\u679corder\u7684\u7c7b\u578b\u4e3aSubmitted\uff0c\u8bf4\u660e\u521a\u521a\u597d\u5230\u7b2c\u4e8c\u5929\u5f00\u76d8\u7684\u65f6\u5019\uff0c\u6211\u4eec\u521a\u63d0\u4ea4order\n            self.log(f'\\n{self.s}\u4ea4\u6613\u65e5{self.datas[0].datetime.date(0)}\u5f00\u76d8{self.s}\\n', dt=False)\n        \n        orderid = order.info['orderid']\n        if order.isbuy():\n            content = f'\u4e70\u5355(orderid: {orderid}, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: {order.tradeid}): '\n        elif order.issell():\n            content = f'\u5356\u5355(orderid: {orderid}, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: {order.tradeid})): '\n        else:\n            content = ''\n        content += \\\n            '\u8ba2\u5355\u4ef7\u683c: {}, \u6267\u884c\u4ef7\u683c: {}, \u4ea4\u6613\u6570\u91cf: {}, ' \\\n            '\u603b\u4ea4\u6613\u989d: {}, \u8ba2\u5355\u7c7b\u578b: {}, \u6267\u884c\u65e5\u671f: {}' .format(order.price,\n                                                           order.executed.price, \n                                                           order.executed.size, \n                                                           order.executed.value,\n                                                           order.getstatusname(), \n                                                           self.datas[0].datetime.date(0))\n        # bt.num2date(order.executed.dt)\n        \n        # self.log(self.bar_executed) \u4e0d\u5b58\u5728\u8fd9\u4e2a\u5c5e\u6027\uff01\u5982\u679c\u8981\u4f7f\u7528\u7684\u8bdd\u9700\u8981\u81ea\u5df1\u5b9a\u4e49\n        self.log(content)\n        \n        if order.status == order.Completed:\n            self.log(f'\\n{self.s}\u4ea4\u6613\u65e5{self.datas[0].datetime.date(0)}\u6536\u76d8{self.s}\\n\\n\\n', dt=False)   \n#         if self.coo:  # \u5982\u679c\u662fcoo\u6a21\u5f0f\uff0c\u90a3\u4e48\u5728\u6bcf\u4e2a\u4ea4\u6613\u65e5\u7684\u5f00\u76d8\u524d\u8c03\u7528next_open\uff0c\u5728\u5f00\u76d8\u7684\u65f6\u5019\u4e0b\u5355\u3002\u5f53\u4e0b\u5355\u5b8c\u6210\uff0c\u8bf4\u660e\n            \n    \n    def notify_trade(self, trade):\n        \"\"\"\n        \u6bcf\u6b21\u4ea4\u6613\u72b6\u6001\u53d1\u751f\u6539\u53d8\u65f6\u7684\u56de\u8c03\u51fd\u6570\uff0c\u53ea\u6709\u4ed3\u4f4d\u4ece0\u53d8\u4e3a\u975e0\u6216\u8005\u4ece\u975e0\u53d8\u4e3a0\uff0c\u624d\u7b97\u662f\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u3002\n        \u6ce8\u610f\uff0c\u4e00\u4e2a\u4ea4\u6613\u7531\u591a\u4e2a\u7684\u8ba2\u5355\u7ec4\u6210\uff0c\u6211\u4eec\u901a\u8fc7\u5728\u4e0b\u5355\u65f6\u89c4\u5b9atradeid\u6765\u51b3\u5b9a\u8ba2\u5355\u5c5e\u4e8e\u7684\u4ea4\u6613\u3002\n        \u4f8b\u5982\uff0cself.sell(size=100, tradeid=1)\u548cself.sell(size=200, tradeid=1)\u548cself.buy(size=300, tradeid=1)\u5c5e\u4e8e\n        \u540c\u4e00\u4e2a\u4ea4\u6613\uff08tradeid=1\u7684\u4ea4\u6613\uff09\u3002\u4e14\u8fd9\u4e09\u4e2a\u8ba2\u5355\u5982\u679c\u6309\u7167\u987a\u5e8f\u4e0b\u5355\uff0c\u90a3\u4e48\u5728self.sell(size=100, tradeid=1)\u65f6\u4f1a\u89e6\u53d1notify_trade\uff0c\n        \u6b64\u65f6trade.status == trade.Open\uff1b\u5728self.buy(size=300, tradeid=1)\u65f6\u4e5f\u4f1a\u89e6\u53d1notify_trade\uff0c\n        \u6b64\u65f6trade.status == trade.Open\n        \u6bcf\u4e2a\u8ba2\u5355\u90fd\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u201c\u5b50\u4ea4\u6613\u201d\uff0c\u6bcf\u4e2a\u8ba2\u5355\u7684\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u90fd\u4f1a\u89e6\u53d1\u4e00\u6b21notify_trade\u51fd\u6570\u3002\n        \n        \"\"\"\n        if trade.status == trade.Created:  \n            # \u4e00\u4e2a\u4ea4\u6613\u88ab\u521b\u5efa\uff0c\u4f46\u662f\u4ed3\u4f4d\u4e3a0\uff0c\u6b64\u65f6\u867d\u7136trade.status == trade.Created\uff0c\u4f46\u662f\u6839\u672c\u4e0d\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\uff0c\n            # \u56e0\u4e3a\u4ed3\u4f4d\u6ca1\u53d8\u3002\n            self.log(f'Trade {trade.tradeid} created')\n        elif trade.status == trade.Open:\n            self.log(f'Trade {trade.tradeid} opened')\n        elif trade.status == trade.Closed:\n            self.log(f'Trade {trade.tradeid} closed')\n            s = '\u6bdb\u6536\u76ca %f, \u6263\u4f63\u540e\u6536\u76ca %f, \u4f63\u91d1 %f' % (trade.pnl, trade.pnlcomm, trade.commission)\n            self.log(f'\u4ea4\u6613\u7ed3\u675f, \u8f93\u51fa\u4ea4\u6613\u4fe1\u606f: {s}')\n        else:\n            self.log(trade.status)\n            \n#         if trade.isclosed:    \n#             self.log(f'\u5f53\u524d\u4ea4\u6613\u5df2\u7ecf\u5173\u95ed')\n#             s = '\u6bdb\u6536\u76ca %f, \u6263\u4f63\u540e\u6536\u76ca %f, \u4f63\u91d1 %f' % (trade.pnl, trade.pnlcomm, trade.commission)\n#             self.log(f'\u4ea4\u6613\u7ed3\u675f, \u8f93\u51fa\u4ea4\u6613\u4fe1\u606f: {s}')\n#         print(trade.Created)\n            \n        \n    def start(self):\n        \"\"\"\n        \u7b56\u7565\u5f00\u59cb\u65f6\u7684\u56de\u8c03\u51fd\u6570\n        \"\"\"\n        \n        self.log('STRATEGY BEGINS.', dt=False)\n        if self.coo:\n            self.log('THIS IS CHEAT ON OPEN MODE.', dt=False)\n        elif self.coc:\n            self.log('THIS IS CHEAT ON CLOSE MODE.', dt=False)\n        else:\n            self.log('THIS IS DEFAULT MODE.', dt=False)\n            \n        self.log(f'STARTING PORTFOLIO VALUE: {self.broker.get_value():.2f}\\n\\n', dt=False)\n        \n        \n    def stop(self):\n        \"\"\"\n        \u7b56\u7565\u7ed3\u675f\u65f6\u7684\u56de\u8c03\u51fd\u6570\n        \"\"\"\n        self.close()\n        self.order_info()\n        \n        self.log('STRATEGY ENDS.', dt=False)\n        self.log(f'FINAL PORTFOLIO VALUE: {self.broker.get_value():.2f}', dt=False)\n        \n        \n    def prenext(self):\n        \"\"\"\n        \u5728\u6700\u5c0f\u5468\u671f\u524d\u7684\u6bcf\u4e2atick\u6267\u884c\u7684\u51fd\u6570\n        \"\"\"\n        self.log('BEFORE THE MINIMUM PERIOD.')\n    \n    def notify_position(self):\n        \"\"\"\n        \u81ea\u5b9a\u4e49\u51fd\u6570\uff0c\u8f93\u51fa\u6301\u4ed3\u60c5\u51b5\n        \"\"\"\n        if self.position:  # \u5982\u679c\u6301\u4ed3position\u7684size\u4e0d\u7b49\u4e8e0\u7684\u8bdd\uff0c\u90a3\u4e48self.position\u4e3aTrue\n            self.log(f'\u5f53\u524d\u6301\u4ed3size\u4e0d\u4e3a0')\n        else:\n            self.log(f'\u5f53\u524d\u6301\u4ed3size\u4e3a0')\n            \n        self.log(f'{self.position}', dt=False)\n        # \u73b0\u91d1 = \n        self.log(f'\u73b0\u91d1: {self.broker.get_cash()}')\n        self.log(f'\u603b\u6301\u4ed3\u4ef7\u503c: {self.broker.get_value()}')\n    \n    def order_info(self):\n        \"\"\"\n        \u81ea\u5b9a\u4e49\u51fd\u6570\uff0c\u6253\u5370\u51faorder\u7684\u4fe1\u606f\n        \"\"\"\n        self.log(f'{self.s}BEGIN OF ORDER INFO{self.s}', dt=False)\n        for order in self.broker.orders:\n            orderid = order.info['orderid']\n            self.log(f'orderid: {orderid}, tradeid: {order.tradeid}, '\n                     f'ref: {order.ref}, status: {order.getstatusname()}')\n        self.log(f'{self.s}END OF ORDER INFO{self.s}', dt=False)            \n        \n    \n    def place_order(self):\n        if self.bar_executed % 2 != 0:\n            self.buy(size=100, \n                     price=200, \n                     exectype=bt.Order.Limit, \n                     tradeid=self.bar_executed,  # tradeid\u662f\u9ed8\u8ba4\u53c2\u6570\uff0c\u53ef\u4ee5\u5728notify_trade\u4e2d\u4f7f\u7528trade.tradeid\u8bbf\u95ee\n                     orderid=self.bar_executed) # \u89c4\u5b9a\u8ba2\u5355\u7684orderid\u7b49\u4e8e\u5f53\u524d\u5904\u7406\u7684\u884c\u7d22\u5f15\uff0c\u5b58\u653e\u5728AutoOrderedDict\u4e2d\n\n            self.log(f'Created a buy order with orderid {self.bar_executed}, tradeid {self.bar_executed}')\n\n        else:\n            # \u6211\u4eec\u603b\u662f\u5148\u4e70\u540e\u5356\uff0c\u6211\u4eec\u5728\u6bcf\u6b21\u5356\u51fa\u7684\u65f6\u5019\u89c4\u5b9atradeid\u4e3a\u4e0a\u4e00\u6b21\u4e70\u5165\u7684tradeid\uff0c\u4f7f\u5f97\u4e0a\u4e00\u6b21\u7684\u4e70\u5165\u4ea4\u6613\u5e73\u4ed3\uff0c\n            # \u5373 trade.status == trade.Closed\n            # orderid\u7b49\u53c2\u6570\u90fd\u662f\u81ea\u5df1\u5b9a\u4e49\u7684\uff0c\u4f1a\u5b58\u653e\u5728order.info\u4e2d\u3002order.info\u662f\u4e00\u4e2aAutoOrderedDict\uff08\u5b57\u5178\uff09\n            self.sell(size=100, \n                      exectype=bt.Order.Market, \n                      tradeid=self.bar_executed - 1,  # tradeid\u662f\u9ed8\u8ba4\u53c2\u6570\uff0c\u53ef\u4ee5\u5728notify_trade\u4e2d\u4f7f\u7528trade.tradeid\u8bbf\u95ee\n                      orderid=self.bar_executed) # orderid\u53ef\u4ee5\u81ea\u5df1\u968f\u4fbf\u5b9a\u4e49\uff0c\u53ef\u4ee5\u91cd\u590d\uff0c\u4e3b\u8981\u76ee\u7684\u662f\u533a\u5206\u8ba2\u5355\uff0c\u5206\u7c7b\u5206\u6790\n\n            self.log(f'Created a sell order with orderid {self.bar_executed}, tradeid {self.bar_executed - 1}')\n            \n    def next(self):\n        \"\"\"\n        \u9664\u4e86coo\u6a21\u5f0f\u4ee5\u5916\uff0c\u6bcf\u4e2atick\u7684\u56de\u8c03\u51fd\u6570\uff0cnext\u51fd\u6570\u5728\u6bcf\u4e2a\u4ea4\u6613\u65e5\u7ed3\u675f\u540e\u88ab\u8c03\u7528\u3002\n        \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u4e0a\u4e00\u4e2a\u4ea4\u6613\u65e5\u4e0b\u7684\u5355\u4f1a\u5728\u8fd9\u4e2a\u4ea4\u6613\u65e5\u88absubmitted\u5e76\u4e14accepted\uff0c\u540c\u65f6\u6309\u7167\u8fd9\u4e2a\u4ea4\u6613\u65e5\u7684open\u4ef7\u683c\u8fdb\u884c\u4e70\u5356\n        \u5373\uff1a\u5982\u679c\u56de\u6d4b\u6570\u636e\u662f\u65e5\u9891\u7684\uff0c\u90a3\u4e48\u4e0a\u4e00\u4e2a\u4ea4\u6613\u65e5\u4e0b\u7684\u5355\uff0c\u5728\u8fd9\u4e2a\u4ea4\u6613\u65e5\u624d\u4f1a\u4ea7\u751f\u8ba2\u5355\u72b6\u6001\u7684\u53d8\u5316\uff0c\u624d\u4f1a\u8c03\u7528notify_order\u51fd\u6570\u8f93\u51falog\n        \u4f8b\u5982\uff0c\u4f7f\u7528self.sell()\u7684\u65e5\u671f\u662f11\u67082\u65e5\uff0c\u90a3\u4e48notify_order\u7684\u8c03\u7528\u4f1a\u572811\u67083\u65e5\n        \u4e5f\u5c31\u662f\u8bf4\uff0c\u8ba2\u5355\u4e0b\u5355\u65f6\u673a\u662f\u4eca\u65e5\u4e0b\u5348\u6536\u76d8\u540e\uff0c\u8ba2\u5355\u6267\u884c\u65f6\u673a\u662f\u660e\u65e5\u5f00\u76d8\uff0c\u4ee5\u5f00\u76d8\u4ef7\u6210\u4ea4\uff08\u8fd9\u662f\u5e02\u4ef7\u5355\u7684\u60c5\u51b5\uff09\u3002\n        \n        e.g. \u6267\u884c\u987a\u5e8f: 11\u67082\u65e5\u6536\u76d8\u540e\u89e6\u53d1next_open\uff0c\u540c\u65f6\u8fd0\u884cself.sell() or self.buy() -&gt; \n                      11\u67083\u65e5\u4f7f\u752811\u67083\u65e5\u7684open\u630211\u67082\u65e5\u7684\u8ba2\u5355\uff0c\u89e6\u53d1notify_order -&gt; \n                      11\u67083\u65e5\u6536\u76d8\u540e\u89e6\u53d1next_open\uff0c\u540c\u65f6\u8fd0\u884cself.sell() or self.buy() -&gt; \n                      11\u67084\u65e5\u4f7f\u752811\u67084\u65e5\u7684open\u630211\u67083\u65e5\u7684\u5355\uff0c\u89e6\u53d1notify_order\n        \"\"\"\n# \u8fd9\u4e2a\u6ce8\u91ca\u6389\u7684\u7248\u672c\u6309\u7167\u65e5\u671f\u5206\u9694\n#         if not self.coo:\n#             if len(self) == 1:\n#                 self.log(f'\\n{self.s}BEGIN OF TRADE DAY {self.datas[0].datetime.date(0)}{self.s}\\n', dt=False)\n#             self.bar_executed = len(self)\n            \n#             if self.bar_executed % 2 != 0:\n#                 self.buy(size=100, price=200, exectype=bt.Order.Limit)  # \u9ed8\u8ba4\u4f7f\u7528open\u4f5c\u4e3a\u5356\u4e00\u8fdb\u884c\u5339\u914d\n#                 self.log(f'Created a buy order.')\n                \n#             else:\n#                 self.sell(size=100, exectype=bt.Order.Market)\n#                 self.log(f'Created a sell order.')\n            \n#             self.order_info()\n                \n#             self.notify_position()\n\n#             self.log(f'\\n{self.s}END OF TRADE DAY {self.datas[0].datetime.date(0)}{self.s}\\n\\n\\n', dt=False)\n#             if len(self) &lt; self.length:\n#                 self.log(f'\\n{self.s}BEGIN OF TRADE DAY {self.datas[0].datetime.date(1)}{self.s}', dt=False)\n\n        # \u6309\u7167\u6700\u672c\u8d28\u7684\u903b\u8f91\u5206\u9694\uff1anext\u51fd\u6570\u7684\u8c03\u7528\u5728\u6bcf\u6b21\u6536\u76d8\u4e4b\u540e\n        if (not self.coc) and (not self.coo):\n             \n            self.log(\n                f'\\n{self.s}\u5f00\u59cb\u4ea4\u6613\u65e5{self.datas[0].datetime.date(0)}\u6536\u76d8\u4e4b\u540e\u7684\u6570\u636e\u67e5\u770b\u4ee5\u53ca\u7b2c\u4e8c\u5929\u7684\u8ba2\u5355\u7684\u4e0b\u5355{self.s}\\n', \n                    dt=False)\n            # \u6700\u540e\u4e00\u5929\uff0811\u670813\u65e5\uff09\u6536\u76d8\u540e\u4e0d\u4e0b\u5355\uff0c\u56e0\u4e3a\u6211\u4eec\u6ca1\u670911\u670814\u65e5\u7684\u6570\u636e\u3002\n            if len(self) &lt; self.length:\n                self.bar_executed = len(self)\n                self.place_order()\n            \n            self.order_info()\n                \n            self.notify_position()\n\n            self.log(f'\\n{self.s}\u7ed3\u675f\u4ea4\u6613\u65e5{self.datas[0].datetime.date(0)}\u6536\u76d8\u4e4b\u540e\u7684\u4e8b\u5b9c{self.s}\\n\\n\\n', dt=False)\n        \n        elif self.coc:\n             \n            self.log(\n                f'\\n{self.s}\u5f00\u59cb\u4ea4\u6613\u65e5{self.datas[0].datetime.date(0)}\u6536\u76d8\u4e4b\u540e\u7684\u6570\u636e\u67e5\u770b\u4ee5\u53ca\u7b2c\u4e8c\u5929\u7684\u8ba2\u5355\u7684\u4e0b\u5355{self.s}\\n', \n                    dt=False)\n            if len(self) &lt; self.length:\n                self.bar_executed = len(self)\n                self.place_order()\n\n            self.order_info()\n                \n            self.notify_position()\n\n            self.log(f'\\n{self.s}\u7ed3\u675f\u4ea4\u6613\u65e5{self.datas[0].datetime.date(0)}\u6536\u76d8\u4e4b\u540e\u7684\u4e8b\u5b9c{self.s}\\n\\n\\n', dt=False)\n            \n        \n        else:\n            pass\n            \n    \n    def next_open(self):\n        \"\"\"\n        \u5f53cheat_on_open\u5f00\u542f\u65f6\u5019\u6bcf\u4e2atick\u7684\u56de\u8c03\u51fd\u6570\uff0c\u5728\u6bcf\u5929\u7684\u5f00\u76d8\u524d\u88ab\u8c03\u7528\u3002\n        \u5982\u679cnext\u51fd\u6570\u548cnext_open\u51fd\u6570\u5747\u5b58\u5728\uff0c\u5373\u4f7f\u5728cheat_on_open\u6a21\u5f0f\u4e0b\uff0c\u4e5f\u4f1a\u4f18\u5148\u8fd0\u884cnext\u51fd\u6570\u3002\n        \u5728\u8fd9\u4e2a\u6a21\u5f0f\u4e0b\uff0c\u6211\u4eec\u5f53\u65e5\u4e0b\u5355\uff0c\u5e76\u4e14\u4f7f\u7528\u5f53\u65e5\u5f00\u76d8\u4ef7\u6210\u4ea4\uff08\u4e0b\u5355\u603b\u662f\u5728next_open\u51fd\u6570\u4e2d\uff09\n        \u6ce8\u610f\uff0c\u5728coo\u6a21\u5f0f\u4e0b\uff0c\u7b2c\u4e00\u4e2a\u4ea4\u6613\u65e5\uff0c\u537311\u67082\u65e5\u4e0d\u8fd0\u884c\u7b56\u7565\uff0c\u572811\u67083\u65e5\u4e0b\u7684\u5355\u6309\u716711\u67083\u65e5\u5f53\u5929\u7684\u5f00\u76d8\u4ef7\u683c\u6210\u4ea4\u3002\u4e4b\u540e\n        \n        \n        \u5f53\u4f60\u5728next_open\u51fd\u6570\u4e2d\u4e0b\u5355\u65f6\uff0cnotify_order\u51fd\u6570\u4f1a\u5728next_open\u51fd\u6570\u4e4b\u540e\u6267\u884c\n        \n        \u6267\u884c\u987a\u5e8f: 11\u67083\u65e5\u5f00\u76d8\u524d\u89e6\u53d1next_open\uff0c \u540c\u65f6\u8fd0\u884cself.sell() or self.buy()-&gt; \n                 11\u67083\u65e5\u4f7f\u752811\u67083\u65e5\u7684open\u630211\u67083\u65e5\u7684\u5355\uff0c\u89e6\u53d1notify_order -&gt; \n                 11\u67084\u65e5\u5f00\u76d8\u524d\u89e6\u53d1next_open\uff0c \u540c\u65f6\u8fd0\u884cself.sell() or self.buy() -&gt; \n                 11\u67084\u65e5\u4f7f\u752811\u67084\u65e5\u7684open\u630211\u67084\u65e5\u7684\u5355\uff0c\u89e6\u53d1notify_order\n        \"\"\"\n        if self.coo:\n            \n            self.log(f'\\n{self.s}\u4ea4\u6613\u65e5{self.datas[0].datetime.date(0)}\u5f00\u76d8\u524d\u7684\u6570\u636e\u67e5\u770b\u4ee5\u53ca\u4e0b\u5355{self.s}\\n', dt=False)\n            self.bar_executed = len(self)\n            self.place_order()\n                \n            self.order_info()\n                \n            self.notify_position()\n            \n            \n            self.log(f'\\n{self.s}\u7ed3\u675f\u4ea4\u6613\u65e5{self.datas[0].datetime.date(0)}\u5f00\u76d8\u524d\u7684\u4e8b\u5b9c{self.s}\\n\\n\\n', dt=False)\n</pre> class TestStrategy(bt.Strategy):          s = '-' * 20          def __init__(self):         self.close = self.datas[0].close         self.volume = self.datas[0].volume         self.starting_value = self.broker.getvalue()         # \u8bb0\u5f55\u662f\u5426\u4f5c\u5f0a\uff0c\u6ce8\u610f\u5b83\u662f\u5982\u4f55\u53d6\u5f97cerebro\u53c2\u6570\u7684         # cheat_on_open: \u5f53\u65e5\u4e0b\u5355\uff0c\u5f53\u65e5\u5f00\u76d8\u4ef7\u6210\u4ea4         self.coo = self.broker.p.coo         self.coc = self.broker.p.coc                  # cheat_on_close: \u5f53\u65e5\u4e0b\u5355\uff0c\u5f53\u65e5\u6536\u76d8\u4ef7\u6210\u4ea4               def log(self, content: str=None, dt: bool=True):         if dt:             time = self.datas[0].datetime.date(0)             if content:                 print(f'{time}-- {content}')             else:                 print(f'{time}-- ')         else:             if not content:                 return             else:                 print(content)               def notify_order(self, order):         \"\"\"         \u6bcf\u6b21\u8ba2\u5355\u72b6\u6001\u53d1\u751f\u6539\u53d8\u65f6\u7684\u56de\u8c03\u51fd\u6570\u3002\u5728\u6bcf\u4e2atick\uff0c\u53ea\u8981\u8ba2\u5355\u72b6\u6001\u53d1\u751f\u6539\u53d8\uff0c\u5c31\u4f1a\u8c03\u7528notify_order\uff0c\u6bcf\u4e2atick\u53ef\u80fd\u4e0d\u6b62\u8c03\u7528\u4e00\u6b21\u3002         e.g. \u572811\u67082\u65e5\u4e0b\u5355\u7684\u8ba2\u5355\u572811\u67083\u65e5\u624d\u4f1a\u88abSubmitted\u7b49\u3002         \"\"\"                  if order.status == order.Submitted:  # \u5982\u679corder\u7684\u7c7b\u578b\u4e3aSubmitted\uff0c\u8bf4\u660e\u521a\u521a\u597d\u5230\u7b2c\u4e8c\u5929\u5f00\u76d8\u7684\u65f6\u5019\uff0c\u6211\u4eec\u521a\u63d0\u4ea4order             self.log(f'\\n{self.s}\u4ea4\u6613\u65e5{self.datas[0].datetime.date(0)}\u5f00\u76d8{self.s}\\n', dt=False)                  orderid = order.info['orderid']         if order.isbuy():             content = f'\u4e70\u5355(orderid: {orderid}, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: {order.tradeid}): '         elif order.issell():             content = f'\u5356\u5355(orderid: {orderid}, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: {order.tradeid})): '         else:             content = ''         content += \\             '\u8ba2\u5355\u4ef7\u683c: {}, \u6267\u884c\u4ef7\u683c: {}, \u4ea4\u6613\u6570\u91cf: {}, ' \\             '\u603b\u4ea4\u6613\u989d: {}, \u8ba2\u5355\u7c7b\u578b: {}, \u6267\u884c\u65e5\u671f: {}' .format(order.price,                                                            order.executed.price,                                                             order.executed.size,                                                             order.executed.value,                                                            order.getstatusname(),                                                             self.datas[0].datetime.date(0))         # bt.num2date(order.executed.dt)                  # self.log(self.bar_executed) \u4e0d\u5b58\u5728\u8fd9\u4e2a\u5c5e\u6027\uff01\u5982\u679c\u8981\u4f7f\u7528\u7684\u8bdd\u9700\u8981\u81ea\u5df1\u5b9a\u4e49         self.log(content)                  if order.status == order.Completed:             self.log(f'\\n{self.s}\u4ea4\u6613\u65e5{self.datas[0].datetime.date(0)}\u6536\u76d8{self.s}\\n\\n\\n', dt=False)    #         if self.coo:  # \u5982\u679c\u662fcoo\u6a21\u5f0f\uff0c\u90a3\u4e48\u5728\u6bcf\u4e2a\u4ea4\u6613\u65e5\u7684\u5f00\u76d8\u524d\u8c03\u7528next_open\uff0c\u5728\u5f00\u76d8\u7684\u65f6\u5019\u4e0b\u5355\u3002\u5f53\u4e0b\u5355\u5b8c\u6210\uff0c\u8bf4\u660e                       def notify_trade(self, trade):         \"\"\"         \u6bcf\u6b21\u4ea4\u6613\u72b6\u6001\u53d1\u751f\u6539\u53d8\u65f6\u7684\u56de\u8c03\u51fd\u6570\uff0c\u53ea\u6709\u4ed3\u4f4d\u4ece0\u53d8\u4e3a\u975e0\u6216\u8005\u4ece\u975e0\u53d8\u4e3a0\uff0c\u624d\u7b97\u662f\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u3002         \u6ce8\u610f\uff0c\u4e00\u4e2a\u4ea4\u6613\u7531\u591a\u4e2a\u7684\u8ba2\u5355\u7ec4\u6210\uff0c\u6211\u4eec\u901a\u8fc7\u5728\u4e0b\u5355\u65f6\u89c4\u5b9atradeid\u6765\u51b3\u5b9a\u8ba2\u5355\u5c5e\u4e8e\u7684\u4ea4\u6613\u3002         \u4f8b\u5982\uff0cself.sell(size=100, tradeid=1)\u548cself.sell(size=200, tradeid=1)\u548cself.buy(size=300, tradeid=1)\u5c5e\u4e8e         \u540c\u4e00\u4e2a\u4ea4\u6613\uff08tradeid=1\u7684\u4ea4\u6613\uff09\u3002\u4e14\u8fd9\u4e09\u4e2a\u8ba2\u5355\u5982\u679c\u6309\u7167\u987a\u5e8f\u4e0b\u5355\uff0c\u90a3\u4e48\u5728self.sell(size=100, tradeid=1)\u65f6\u4f1a\u89e6\u53d1notify_trade\uff0c         \u6b64\u65f6trade.status == trade.Open\uff1b\u5728self.buy(size=300, tradeid=1)\u65f6\u4e5f\u4f1a\u89e6\u53d1notify_trade\uff0c         \u6b64\u65f6trade.status == trade.Open         \u6bcf\u4e2a\u8ba2\u5355\u90fd\u53ef\u4ee5\u7406\u89e3\u4e3a\u4e00\u4e2a\u201c\u5b50\u4ea4\u6613\u201d\uff0c\u6bcf\u4e2a\u8ba2\u5355\u7684\u4ea4\u6613\u72b6\u6001\u6539\u53d8\u90fd\u4f1a\u89e6\u53d1\u4e00\u6b21notify_trade\u51fd\u6570\u3002                  \"\"\"         if trade.status == trade.Created:               # \u4e00\u4e2a\u4ea4\u6613\u88ab\u521b\u5efa\uff0c\u4f46\u662f\u4ed3\u4f4d\u4e3a0\uff0c\u6b64\u65f6\u867d\u7136trade.status == trade.Created\uff0c\u4f46\u662f\u6839\u672c\u4e0d\u4f1a\u8c03\u7528notify_trade\u51fd\u6570\uff0c             # \u56e0\u4e3a\u4ed3\u4f4d\u6ca1\u53d8\u3002             self.log(f'Trade {trade.tradeid} created')         elif trade.status == trade.Open:             self.log(f'Trade {trade.tradeid} opened')         elif trade.status == trade.Closed:             self.log(f'Trade {trade.tradeid} closed')             s = '\u6bdb\u6536\u76ca %f, \u6263\u4f63\u540e\u6536\u76ca %f, \u4f63\u91d1 %f' % (trade.pnl, trade.pnlcomm, trade.commission)             self.log(f'\u4ea4\u6613\u7ed3\u675f, \u8f93\u51fa\u4ea4\u6613\u4fe1\u606f: {s}')         else:             self.log(trade.status)              #         if trade.isclosed:     #             self.log(f'\u5f53\u524d\u4ea4\u6613\u5df2\u7ecf\u5173\u95ed') #             s = '\u6bdb\u6536\u76ca %f, \u6263\u4f63\u540e\u6536\u76ca %f, \u4f63\u91d1 %f' % (trade.pnl, trade.pnlcomm, trade.commission) #             self.log(f'\u4ea4\u6613\u7ed3\u675f, \u8f93\u51fa\u4ea4\u6613\u4fe1\u606f: {s}') #         print(trade.Created)                           def start(self):         \"\"\"         \u7b56\u7565\u5f00\u59cb\u65f6\u7684\u56de\u8c03\u51fd\u6570         \"\"\"                  self.log('STRATEGY BEGINS.', dt=False)         if self.coo:             self.log('THIS IS CHEAT ON OPEN MODE.', dt=False)         elif self.coc:             self.log('THIS IS CHEAT ON CLOSE MODE.', dt=False)         else:             self.log('THIS IS DEFAULT MODE.', dt=False)                      self.log(f'STARTING PORTFOLIO VALUE: {self.broker.get_value():.2f}\\n\\n', dt=False)                       def stop(self):         \"\"\"         \u7b56\u7565\u7ed3\u675f\u65f6\u7684\u56de\u8c03\u51fd\u6570         \"\"\"         self.close()         self.order_info()                  self.log('STRATEGY ENDS.', dt=False)         self.log(f'FINAL PORTFOLIO VALUE: {self.broker.get_value():.2f}', dt=False)                       def prenext(self):         \"\"\"         \u5728\u6700\u5c0f\u5468\u671f\u524d\u7684\u6bcf\u4e2atick\u6267\u884c\u7684\u51fd\u6570         \"\"\"         self.log('BEFORE THE MINIMUM PERIOD.')          def notify_position(self):         \"\"\"         \u81ea\u5b9a\u4e49\u51fd\u6570\uff0c\u8f93\u51fa\u6301\u4ed3\u60c5\u51b5         \"\"\"         if self.position:  # \u5982\u679c\u6301\u4ed3position\u7684size\u4e0d\u7b49\u4e8e0\u7684\u8bdd\uff0c\u90a3\u4e48self.position\u4e3aTrue             self.log(f'\u5f53\u524d\u6301\u4ed3size\u4e0d\u4e3a0')         else:             self.log(f'\u5f53\u524d\u6301\u4ed3size\u4e3a0')                      self.log(f'{self.position}', dt=False)         # \u73b0\u91d1 =          self.log(f'\u73b0\u91d1: {self.broker.get_cash()}')         self.log(f'\u603b\u6301\u4ed3\u4ef7\u503c: {self.broker.get_value()}')          def order_info(self):         \"\"\"         \u81ea\u5b9a\u4e49\u51fd\u6570\uff0c\u6253\u5370\u51faorder\u7684\u4fe1\u606f         \"\"\"         self.log(f'{self.s}BEGIN OF ORDER INFO{self.s}', dt=False)         for order in self.broker.orders:             orderid = order.info['orderid']             self.log(f'orderid: {orderid}, tradeid: {order.tradeid}, '                      f'ref: {order.ref}, status: {order.getstatusname()}')         self.log(f'{self.s}END OF ORDER INFO{self.s}', dt=False)                               def place_order(self):         if self.bar_executed % 2 != 0:             self.buy(size=100,                       price=200,                       exectype=bt.Order.Limit,                       tradeid=self.bar_executed,  # tradeid\u662f\u9ed8\u8ba4\u53c2\u6570\uff0c\u53ef\u4ee5\u5728notify_trade\u4e2d\u4f7f\u7528trade.tradeid\u8bbf\u95ee                      orderid=self.bar_executed) # \u89c4\u5b9a\u8ba2\u5355\u7684orderid\u7b49\u4e8e\u5f53\u524d\u5904\u7406\u7684\u884c\u7d22\u5f15\uff0c\u5b58\u653e\u5728AutoOrderedDict\u4e2d              self.log(f'Created a buy order with orderid {self.bar_executed}, tradeid {self.bar_executed}')          else:             # \u6211\u4eec\u603b\u662f\u5148\u4e70\u540e\u5356\uff0c\u6211\u4eec\u5728\u6bcf\u6b21\u5356\u51fa\u7684\u65f6\u5019\u89c4\u5b9atradeid\u4e3a\u4e0a\u4e00\u6b21\u4e70\u5165\u7684tradeid\uff0c\u4f7f\u5f97\u4e0a\u4e00\u6b21\u7684\u4e70\u5165\u4ea4\u6613\u5e73\u4ed3\uff0c             # \u5373 trade.status == trade.Closed             # orderid\u7b49\u53c2\u6570\u90fd\u662f\u81ea\u5df1\u5b9a\u4e49\u7684\uff0c\u4f1a\u5b58\u653e\u5728order.info\u4e2d\u3002order.info\u662f\u4e00\u4e2aAutoOrderedDict\uff08\u5b57\u5178\uff09             self.sell(size=100,                        exectype=bt.Order.Market,                        tradeid=self.bar_executed - 1,  # tradeid\u662f\u9ed8\u8ba4\u53c2\u6570\uff0c\u53ef\u4ee5\u5728notify_trade\u4e2d\u4f7f\u7528trade.tradeid\u8bbf\u95ee                       orderid=self.bar_executed) # orderid\u53ef\u4ee5\u81ea\u5df1\u968f\u4fbf\u5b9a\u4e49\uff0c\u53ef\u4ee5\u91cd\u590d\uff0c\u4e3b\u8981\u76ee\u7684\u662f\u533a\u5206\u8ba2\u5355\uff0c\u5206\u7c7b\u5206\u6790              self.log(f'Created a sell order with orderid {self.bar_executed}, tradeid {self.bar_executed - 1}')                  def next(self):         \"\"\"         \u9664\u4e86coo\u6a21\u5f0f\u4ee5\u5916\uff0c\u6bcf\u4e2atick\u7684\u56de\u8c03\u51fd\u6570\uff0cnext\u51fd\u6570\u5728\u6bcf\u4e2a\u4ea4\u6613\u65e5\u7ed3\u675f\u540e\u88ab\u8c03\u7528\u3002         \u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0c\u4e0a\u4e00\u4e2a\u4ea4\u6613\u65e5\u4e0b\u7684\u5355\u4f1a\u5728\u8fd9\u4e2a\u4ea4\u6613\u65e5\u88absubmitted\u5e76\u4e14accepted\uff0c\u540c\u65f6\u6309\u7167\u8fd9\u4e2a\u4ea4\u6613\u65e5\u7684open\u4ef7\u683c\u8fdb\u884c\u4e70\u5356         \u5373\uff1a\u5982\u679c\u56de\u6d4b\u6570\u636e\u662f\u65e5\u9891\u7684\uff0c\u90a3\u4e48\u4e0a\u4e00\u4e2a\u4ea4\u6613\u65e5\u4e0b\u7684\u5355\uff0c\u5728\u8fd9\u4e2a\u4ea4\u6613\u65e5\u624d\u4f1a\u4ea7\u751f\u8ba2\u5355\u72b6\u6001\u7684\u53d8\u5316\uff0c\u624d\u4f1a\u8c03\u7528notify_order\u51fd\u6570\u8f93\u51falog         \u4f8b\u5982\uff0c\u4f7f\u7528self.sell()\u7684\u65e5\u671f\u662f11\u67082\u65e5\uff0c\u90a3\u4e48notify_order\u7684\u8c03\u7528\u4f1a\u572811\u67083\u65e5         \u4e5f\u5c31\u662f\u8bf4\uff0c\u8ba2\u5355\u4e0b\u5355\u65f6\u673a\u662f\u4eca\u65e5\u4e0b\u5348\u6536\u76d8\u540e\uff0c\u8ba2\u5355\u6267\u884c\u65f6\u673a\u662f\u660e\u65e5\u5f00\u76d8\uff0c\u4ee5\u5f00\u76d8\u4ef7\u6210\u4ea4\uff08\u8fd9\u662f\u5e02\u4ef7\u5355\u7684\u60c5\u51b5\uff09\u3002                  e.g. \u6267\u884c\u987a\u5e8f: 11\u67082\u65e5\u6536\u76d8\u540e\u89e6\u53d1next_open\uff0c\u540c\u65f6\u8fd0\u884cself.sell() or self.buy() -&gt;                        11\u67083\u65e5\u4f7f\u752811\u67083\u65e5\u7684open\u630211\u67082\u65e5\u7684\u8ba2\u5355\uff0c\u89e6\u53d1notify_order -&gt;                        11\u67083\u65e5\u6536\u76d8\u540e\u89e6\u53d1next_open\uff0c\u540c\u65f6\u8fd0\u884cself.sell() or self.buy() -&gt;                        11\u67084\u65e5\u4f7f\u752811\u67084\u65e5\u7684open\u630211\u67083\u65e5\u7684\u5355\uff0c\u89e6\u53d1notify_order         \"\"\" # \u8fd9\u4e2a\u6ce8\u91ca\u6389\u7684\u7248\u672c\u6309\u7167\u65e5\u671f\u5206\u9694 #         if not self.coo: #             if len(self) == 1: #                 self.log(f'\\n{self.s}BEGIN OF TRADE DAY {self.datas[0].datetime.date(0)}{self.s}\\n', dt=False) #             self.bar_executed = len(self)              #             if self.bar_executed % 2 != 0: #                 self.buy(size=100, price=200, exectype=bt.Order.Limit)  # \u9ed8\u8ba4\u4f7f\u7528open\u4f5c\u4e3a\u5356\u4e00\u8fdb\u884c\u5339\u914d #                 self.log(f'Created a buy order.')                  #             else: #                 self.sell(size=100, exectype=bt.Order.Market) #                 self.log(f'Created a sell order.')              #             self.order_info()                  #             self.notify_position()  #             self.log(f'\\n{self.s}END OF TRADE DAY {self.datas[0].datetime.date(0)}{self.s}\\n\\n\\n', dt=False) #             if len(self) &lt; self.length: #                 self.log(f'\\n{self.s}BEGIN OF TRADE DAY {self.datas[0].datetime.date(1)}{self.s}', dt=False)          # \u6309\u7167\u6700\u672c\u8d28\u7684\u903b\u8f91\u5206\u9694\uff1anext\u51fd\u6570\u7684\u8c03\u7528\u5728\u6bcf\u6b21\u6536\u76d8\u4e4b\u540e         if (not self.coc) and (not self.coo):                           self.log(                 f'\\n{self.s}\u5f00\u59cb\u4ea4\u6613\u65e5{self.datas[0].datetime.date(0)}\u6536\u76d8\u4e4b\u540e\u7684\u6570\u636e\u67e5\u770b\u4ee5\u53ca\u7b2c\u4e8c\u5929\u7684\u8ba2\u5355\u7684\u4e0b\u5355{self.s}\\n',                      dt=False)             # \u6700\u540e\u4e00\u5929\uff0811\u670813\u65e5\uff09\u6536\u76d8\u540e\u4e0d\u4e0b\u5355\uff0c\u56e0\u4e3a\u6211\u4eec\u6ca1\u670911\u670814\u65e5\u7684\u6570\u636e\u3002             if len(self) &lt; self.length:                 self.bar_executed = len(self)                 self.place_order()                          self.order_info()                              self.notify_position()              self.log(f'\\n{self.s}\u7ed3\u675f\u4ea4\u6613\u65e5{self.datas[0].datetime.date(0)}\u6536\u76d8\u4e4b\u540e\u7684\u4e8b\u5b9c{self.s}\\n\\n\\n', dt=False)                  elif self.coc:                           self.log(                 f'\\n{self.s}\u5f00\u59cb\u4ea4\u6613\u65e5{self.datas[0].datetime.date(0)}\u6536\u76d8\u4e4b\u540e\u7684\u6570\u636e\u67e5\u770b\u4ee5\u53ca\u7b2c\u4e8c\u5929\u7684\u8ba2\u5355\u7684\u4e0b\u5355{self.s}\\n',                      dt=False)             if len(self) &lt; self.length:                 self.bar_executed = len(self)                 self.place_order()              self.order_info()                              self.notify_position()              self.log(f'\\n{self.s}\u7ed3\u675f\u4ea4\u6613\u65e5{self.datas[0].datetime.date(0)}\u6536\u76d8\u4e4b\u540e\u7684\u4e8b\u5b9c{self.s}\\n\\n\\n', dt=False)                               else:             pass                       def next_open(self):         \"\"\"         \u5f53cheat_on_open\u5f00\u542f\u65f6\u5019\u6bcf\u4e2atick\u7684\u56de\u8c03\u51fd\u6570\uff0c\u5728\u6bcf\u5929\u7684\u5f00\u76d8\u524d\u88ab\u8c03\u7528\u3002         \u5982\u679cnext\u51fd\u6570\u548cnext_open\u51fd\u6570\u5747\u5b58\u5728\uff0c\u5373\u4f7f\u5728cheat_on_open\u6a21\u5f0f\u4e0b\uff0c\u4e5f\u4f1a\u4f18\u5148\u8fd0\u884cnext\u51fd\u6570\u3002         \u5728\u8fd9\u4e2a\u6a21\u5f0f\u4e0b\uff0c\u6211\u4eec\u5f53\u65e5\u4e0b\u5355\uff0c\u5e76\u4e14\u4f7f\u7528\u5f53\u65e5\u5f00\u76d8\u4ef7\u6210\u4ea4\uff08\u4e0b\u5355\u603b\u662f\u5728next_open\u51fd\u6570\u4e2d\uff09         \u6ce8\u610f\uff0c\u5728coo\u6a21\u5f0f\u4e0b\uff0c\u7b2c\u4e00\u4e2a\u4ea4\u6613\u65e5\uff0c\u537311\u67082\u65e5\u4e0d\u8fd0\u884c\u7b56\u7565\uff0c\u572811\u67083\u65e5\u4e0b\u7684\u5355\u6309\u716711\u67083\u65e5\u5f53\u5929\u7684\u5f00\u76d8\u4ef7\u683c\u6210\u4ea4\u3002\u4e4b\u540e                           \u5f53\u4f60\u5728next_open\u51fd\u6570\u4e2d\u4e0b\u5355\u65f6\uff0cnotify_order\u51fd\u6570\u4f1a\u5728next_open\u51fd\u6570\u4e4b\u540e\u6267\u884c                  \u6267\u884c\u987a\u5e8f: 11\u67083\u65e5\u5f00\u76d8\u524d\u89e6\u53d1next_open\uff0c \u540c\u65f6\u8fd0\u884cself.sell() or self.buy()-&gt;                   11\u67083\u65e5\u4f7f\u752811\u67083\u65e5\u7684open\u630211\u67083\u65e5\u7684\u5355\uff0c\u89e6\u53d1notify_order -&gt;                   11\u67084\u65e5\u5f00\u76d8\u524d\u89e6\u53d1next_open\uff0c \u540c\u65f6\u8fd0\u884cself.sell() or self.buy() -&gt;                   11\u67084\u65e5\u4f7f\u752811\u67084\u65e5\u7684open\u630211\u67084\u65e5\u7684\u5355\uff0c\u89e6\u53d1notify_order         \"\"\"         if self.coo:                          self.log(f'\\n{self.s}\u4ea4\u6613\u65e5{self.datas[0].datetime.date(0)}\u5f00\u76d8\u524d\u7684\u6570\u636e\u67e5\u770b\u4ee5\u53ca\u4e0b\u5355{self.s}\\n', dt=False)             self.bar_executed = len(self)             self.place_order()                              self.order_info()                              self.notify_position()                                       self.log(f'\\n{self.s}\u7ed3\u675f\u4ea4\u6613\u65e5{self.datas[0].datetime.date(0)}\u5f00\u76d8\u524d\u7684\u4e8b\u5b9c{self.s}\\n\\n\\n', dt=False)  In\u00a0[15]: Copied! <pre>def backtrade(df, strategy):\n    cerebro = bt.Cerebro()\n    \n#     cerebro = bt.Cerebro(cheat_on_open=True)\n#     cerebro.broker.set_coc(True)\n#     cerebro.broker.set_coo(True)\n    \n    # for log usage\n    strategy.length = len(df)\n    \n    cerebro.addstrategy(strategy)\n    \n    data = bt.feeds.PandasData(dataname=df, datetime=-1)\n    cerebro.adddata(data)\n    \n    cerebro.broker.setcash(100000.0)\n    cerebro.broker.setcommission(commission=0.001)\n    \n    cerebro.run()\n</pre> def backtrade(df, strategy):     cerebro = bt.Cerebro()      #     cerebro = bt.Cerebro(cheat_on_open=True) #     cerebro.broker.set_coc(True) #     cerebro.broker.set_coo(True)          # for log usage     strategy.length = len(df)          cerebro.addstrategy(strategy)          data = bt.feeds.PandasData(dataname=df, datetime=-1)     cerebro.adddata(data)          cerebro.broker.setcash(100000.0)     cerebro.broker.setcommission(commission=0.001)          cerebro.run() <p>sell.order()\u7684\u65f6\u95f4\u3001next\u7684\u65f6\u95f4\u3001notify_order\u7684\u65f6\u95f4</p> In\u00a0[22]: Copied! <pre>if __name__ == '__main__':\n    backtrade(df_test, TestStrategy)\n</pre> if __name__ == '__main__':     backtrade(df_test, TestStrategy) <pre>STRATEGY BEGINS.\nTHIS IS DEFAULT MODE.\nSTARTING PORTFOLIO VALUE: 100000.00\n\n\n\n--------------------\u5f00\u59cb\u4ea4\u6613\u65e52020-11-02\u6536\u76d8\u4e4b\u540e\u7684\u6570\u636e\u67e5\u770b\u4ee5\u53ca\u7b2c\u4e8c\u5929\u7684\u8ba2\u5355\u7684\u4e0b\u5355--------------------\n\n2020-11-02-- Created a buy order with orderid 1, tradeid 1\n--------------------BEGIN OF ORDER INFO--------------------\n2020-11-02-- orderid: 1, tradeid: 1, ref: 55, status: Submitted\n--------------------END OF ORDER INFO--------------------\n2020-11-02-- \u5f53\u524d\u6301\u4ed3size\u4e3a0\n--- Position Begin\n- Size: 0\n- Price: 0.0\n- Price orig: 0.0\n- Closed: 0\n- Opened: 0\n- Adjbase: None\n--- Position End\n2020-11-02-- \u73b0\u91d1: 100000.0\n2020-11-02-- \u603b\u6301\u4ed3\u4ef7\u503c: 100000.0\n\n--------------------\u7ed3\u675f\u4ea4\u6613\u65e52020-11-02\u6536\u76d8\u4e4b\u540e\u7684\u4e8b\u5b9c--------------------\n\n\n\n\n--------------------\u4ea4\u6613\u65e52020-11-03\u5f00\u76d8--------------------\n\n2020-11-03-- \u4e70\u5355(orderid: 1, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 1): \u8ba2\u5355\u4ef7\u683c: 200, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Submitted, \u6267\u884c\u65e5\u671f: 2020-11-03\n2020-11-03-- \u4e70\u5355(orderid: 1, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 1): \u8ba2\u5355\u4ef7\u683c: 200, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Accepted, \u6267\u884c\u65e5\u671f: 2020-11-03\n2020-11-03-- \u4e70\u5355(orderid: 1, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 1): \u8ba2\u5355\u4ef7\u683c: 200, \u6267\u884c\u4ef7\u683c: 175.01, \u4ea4\u6613\u6570\u91cf: 100, \u603b\u4ea4\u6613\u989d: 17501.0, \u8ba2\u5355\u7c7b\u578b: Completed, \u6267\u884c\u65e5\u671f: 2020-11-03\n\n--------------------\u4ea4\u6613\u65e52020-11-03\u6536\u76d8--------------------\n\n\n\n2020-11-03-- Trade 1 opened\n\n--------------------\u5f00\u59cb\u4ea4\u6613\u65e52020-11-03\u6536\u76d8\u4e4b\u540e\u7684\u6570\u636e\u67e5\u770b\u4ee5\u53ca\u7b2c\u4e8c\u5929\u7684\u8ba2\u5355\u7684\u4e0b\u5355--------------------\n\n2020-11-03-- Created a sell order with orderid 2, tradeid 1\n--------------------BEGIN OF ORDER INFO--------------------\n2020-11-03-- orderid: 1, tradeid: 1, ref: 55, status: Completed\n2020-11-03-- orderid: 2, tradeid: 1, ref: 56, status: Submitted\n--------------------END OF ORDER INFO--------------------\n2020-11-03-- \u5f53\u524d\u6301\u4ed3size\u4e0d\u4e3a0\n--- Position Begin\n- Size: 100\n- Price: 175.01\n- Price orig: 0.0\n- Closed: 0\n- Opened: 100\n- Adjbase: 177.79\n--- Position End\n2020-11-03-- \u73b0\u91d1: 82481.499\n2020-11-03-- \u603b\u6301\u4ed3\u4ef7\u503c: 100260.499\n\n--------------------\u7ed3\u675f\u4ea4\u6613\u65e52020-11-03\u6536\u76d8\u4e4b\u540e\u7684\u4e8b\u5b9c--------------------\n\n\n\n\n--------------------\u4ea4\u6613\u65e52020-11-04\u5f00\u76d8--------------------\n\n2020-11-04-- \u5356\u5355(orderid: 2, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 1)): \u8ba2\u5355\u4ef7\u683c: None, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Submitted, \u6267\u884c\u65e5\u671f: 2020-11-04\n2020-11-04-- \u5356\u5355(orderid: 2, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 1)): \u8ba2\u5355\u4ef7\u683c: None, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Accepted, \u6267\u884c\u65e5\u671f: 2020-11-04\n2020-11-04-- \u5356\u5355(orderid: 2, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 1)): \u8ba2\u5355\u4ef7\u683c: None, \u6267\u884c\u4ef7\u683c: 177.03, \u4ea4\u6613\u6570\u91cf: -100, \u603b\u4ea4\u6613\u989d: 17501.0, \u8ba2\u5355\u7c7b\u578b: Completed, \u6267\u884c\u65e5\u671f: 2020-11-04\n\n--------------------\u4ea4\u6613\u65e52020-11-04\u6536\u76d8--------------------\n\n\n\n2020-11-04-- Trade 1 closed\n2020-11-04-- \u4ea4\u6613\u7ed3\u675f, \u8f93\u51fa\u4ea4\u6613\u4fe1\u606f: \u6bdb\u6536\u76ca 202.000000, \u6263\u4f63\u540e\u6536\u76ca 166.796000, \u4f63\u91d1 35.204000\n\n--------------------\u5f00\u59cb\u4ea4\u6613\u65e52020-11-04\u6536\u76d8\u4e4b\u540e\u7684\u6570\u636e\u67e5\u770b\u4ee5\u53ca\u7b2c\u4e8c\u5929\u7684\u8ba2\u5355\u7684\u4e0b\u5355--------------------\n\n2020-11-04-- Created a buy order with orderid 3, tradeid 3\n--------------------BEGIN OF ORDER INFO--------------------\n2020-11-04-- orderid: 1, tradeid: 1, ref: 55, status: Completed\n2020-11-04-- orderid: 2, tradeid: 1, ref: 56, status: Completed\n2020-11-04-- orderid: 3, tradeid: 3, ref: 57, status: Submitted\n--------------------END OF ORDER INFO--------------------\n2020-11-04-- \u5f53\u524d\u6301\u4ed3size\u4e3a0\n--- Position Begin\n- Size: 0\n- Price: 0.0\n- Price orig: 175.01\n- Closed: -100\n- Opened: 0\n- Adjbase: 177.79\n--- Position End\n2020-11-04-- \u73b0\u91d1: 100166.796\n2020-11-04-- \u603b\u6301\u4ed3\u4ef7\u503c: 100166.796\n\n--------------------\u7ed3\u675f\u4ea4\u6613\u65e52020-11-04\u6536\u76d8\u4e4b\u540e\u7684\u4e8b\u5b9c--------------------\n\n\n\n\n--------------------\u4ea4\u6613\u65e52020-11-05\u5f00\u76d8--------------------\n\n2020-11-05-- \u4e70\u5355(orderid: 3, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 3): \u8ba2\u5355\u4ef7\u683c: 200, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Submitted, \u6267\u884c\u65e5\u671f: 2020-11-05\n2020-11-05-- \u4e70\u5355(orderid: 3, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 3): \u8ba2\u5355\u4ef7\u683c: 200, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Accepted, \u6267\u884c\u65e5\u671f: 2020-11-05\n2020-11-05-- \u4e70\u5355(orderid: 3, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 3): \u8ba2\u5355\u4ef7\u683c: 200, \u6267\u884c\u4ef7\u683c: 180.17, \u4ea4\u6613\u6570\u91cf: 100, \u603b\u4ea4\u6613\u989d: 18017.0, \u8ba2\u5355\u7c7b\u578b: Completed, \u6267\u884c\u65e5\u671f: 2020-11-05\n\n--------------------\u4ea4\u6613\u65e52020-11-05\u6536\u76d8--------------------\n\n\n\n2020-11-05-- Trade 3 opened\n\n--------------------\u5f00\u59cb\u4ea4\u6613\u65e52020-11-05\u6536\u76d8\u4e4b\u540e\u7684\u6570\u636e\u67e5\u770b\u4ee5\u53ca\u7b2c\u4e8c\u5929\u7684\u8ba2\u5355\u7684\u4e0b\u5355--------------------\n\n2020-11-05-- Created a sell order with orderid 4, tradeid 3\n--------------------BEGIN OF ORDER INFO--------------------\n2020-11-05-- orderid: 1, tradeid: 1, ref: 55, status: Completed\n2020-11-05-- orderid: 2, tradeid: 1, ref: 56, status: Completed\n2020-11-05-- orderid: 3, tradeid: 3, ref: 57, status: Completed\n2020-11-05-- orderid: 4, tradeid: 3, ref: 58, status: Submitted\n--------------------END OF ORDER INFO--------------------\n2020-11-05-- \u5f53\u524d\u6301\u4ed3size\u4e0d\u4e3a0\n--- Position Begin\n- Size: 100\n- Price: 180.17\n- Price orig: 0.0\n- Closed: 0\n- Opened: 100\n- Adjbase: 181.35\n--- Position End\n2020-11-05-- \u73b0\u91d1: 82131.779\n2020-11-05-- \u603b\u6301\u4ed3\u4ef7\u503c: 100266.779\n\n--------------------\u7ed3\u675f\u4ea4\u6613\u65e52020-11-05\u6536\u76d8\u4e4b\u540e\u7684\u4e8b\u5b9c--------------------\n\n\n\n\n--------------------\u4ea4\u6613\u65e52020-11-06\u5f00\u76d8--------------------\n\n2020-11-06-- \u5356\u5355(orderid: 4, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 3)): \u8ba2\u5355\u4ef7\u683c: None, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Submitted, \u6267\u884c\u65e5\u671f: 2020-11-06\n2020-11-06-- \u5356\u5355(orderid: 4, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 3)): \u8ba2\u5355\u4ef7\u683c: None, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Accepted, \u6267\u884c\u65e5\u671f: 2020-11-06\n2020-11-06-- \u5356\u5355(orderid: 4, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 3)): \u8ba2\u5355\u4ef7\u683c: None, \u6267\u884c\u4ef7\u683c: 181.67, \u4ea4\u6613\u6570\u91cf: -100, \u603b\u4ea4\u6613\u989d: 18017.0, \u8ba2\u5355\u7c7b\u578b: Completed, \u6267\u884c\u65e5\u671f: 2020-11-06\n\n--------------------\u4ea4\u6613\u65e52020-11-06\u6536\u76d8--------------------\n\n\n\n2020-11-06-- Trade 3 closed\n2020-11-06-- \u4ea4\u6613\u7ed3\u675f, \u8f93\u51fa\u4ea4\u6613\u4fe1\u606f: \u6bdb\u6536\u76ca 150.000000, \u6263\u4f63\u540e\u6536\u76ca 113.816000, \u4f63\u91d1 36.184000\n\n--------------------\u5f00\u59cb\u4ea4\u6613\u65e52020-11-06\u6536\u76d8\u4e4b\u540e\u7684\u6570\u636e\u67e5\u770b\u4ee5\u53ca\u7b2c\u4e8c\u5929\u7684\u8ba2\u5355\u7684\u4e0b\u5355--------------------\n\n2020-11-06-- Created a buy order with orderid 5, tradeid 5\n--------------------BEGIN OF ORDER INFO--------------------\n2020-11-06-- orderid: 1, tradeid: 1, ref: 55, status: Completed\n2020-11-06-- orderid: 2, tradeid: 1, ref: 56, status: Completed\n2020-11-06-- orderid: 3, tradeid: 3, ref: 57, status: Completed\n2020-11-06-- orderid: 4, tradeid: 3, ref: 58, status: Completed\n2020-11-06-- orderid: 5, tradeid: 5, ref: 59, status: Submitted\n--------------------END OF ORDER INFO--------------------\n2020-11-06-- \u5f53\u524d\u6301\u4ed3size\u4e3a0\n--- Position Begin\n- Size: 0\n- Price: 0.0\n- Price orig: 180.17\n- Closed: -100\n- Opened: 0\n- Adjbase: 181.35\n--- Position End\n2020-11-06-- \u73b0\u91d1: 100280.612\n2020-11-06-- \u603b\u6301\u4ed3\u4ef7\u503c: 100280.612\n\n--------------------\u7ed3\u675f\u4ea4\u6613\u65e52020-11-06\u6536\u76d8\u4e4b\u540e\u7684\u4e8b\u5b9c--------------------\n\n\n\n\n--------------------\u4ea4\u6613\u65e52020-11-09\u5f00\u76d8--------------------\n\n2020-11-09-- \u4e70\u5355(orderid: 5, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 5): \u8ba2\u5355\u4ef7\u683c: 200, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Submitted, \u6267\u884c\u65e5\u671f: 2020-11-09\n2020-11-09-- \u4e70\u5355(orderid: 5, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 5): \u8ba2\u5355\u4ef7\u683c: 200, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Accepted, \u6267\u884c\u65e5\u671f: 2020-11-09\n2020-11-09-- \u4e70\u5355(orderid: 5, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 5): \u8ba2\u5355\u4ef7\u683c: 200, \u6267\u884c\u4ef7\u683c: 184.47, \u4ea4\u6613\u6570\u91cf: 100, \u603b\u4ea4\u6613\u989d: 18447.0, \u8ba2\u5355\u7c7b\u578b: Completed, \u6267\u884c\u65e5\u671f: 2020-11-09\n\n--------------------\u4ea4\u6613\u65e52020-11-09\u6536\u76d8--------------------\n\n\n\n2020-11-09-- Trade 5 opened\n\n--------------------\u5f00\u59cb\u4ea4\u6613\u65e52020-11-09\u6536\u76d8\u4e4b\u540e\u7684\u6570\u636e\u67e5\u770b\u4ee5\u53ca\u7b2c\u4e8c\u5929\u7684\u8ba2\u5355\u7684\u4e0b\u5355--------------------\n\n2020-11-09-- Created a sell order with orderid 6, tradeid 5\n--------------------BEGIN OF ORDER INFO--------------------\n2020-11-09-- orderid: 1, tradeid: 1, ref: 55, status: Completed\n2020-11-09-- orderid: 2, tradeid: 1, ref: 56, status: Completed\n2020-11-09-- orderid: 3, tradeid: 3, ref: 57, status: Completed\n2020-11-09-- orderid: 4, tradeid: 3, ref: 58, status: Completed\n2020-11-09-- orderid: 5, tradeid: 5, ref: 59, status: Completed\n2020-11-09-- orderid: 6, tradeid: 5, ref: 60, status: Submitted\n--------------------END OF ORDER INFO--------------------\n2020-11-09-- \u5f53\u524d\u6301\u4ed3size\u4e0d\u4e3a0\n--- Position Begin\n- Size: 100\n- Price: 184.47\n- Price orig: 0.0\n- Closed: 0\n- Opened: 100\n- Adjbase: 185.43\n--- Position End\n2020-11-09-- \u73b0\u91d1: 81815.165\n2020-11-09-- \u603b\u6301\u4ed3\u4ef7\u503c: 100358.165\n\n--------------------\u7ed3\u675f\u4ea4\u6613\u65e52020-11-09\u6536\u76d8\u4e4b\u540e\u7684\u4e8b\u5b9c--------------------\n\n\n\n\n--------------------\u4ea4\u6613\u65e52020-11-10\u5f00\u76d8--------------------\n\n2020-11-10-- \u5356\u5355(orderid: 6, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 5)): \u8ba2\u5355\u4ef7\u683c: None, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Submitted, \u6267\u884c\u65e5\u671f: 2020-11-10\n2020-11-10-- \u5356\u5355(orderid: 6, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 5)): \u8ba2\u5355\u4ef7\u683c: None, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Accepted, \u6267\u884c\u65e5\u671f: 2020-11-10\n2020-11-10-- \u5356\u5355(orderid: 6, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 5)): \u8ba2\u5355\u4ef7\u683c: None, \u6267\u884c\u4ef7\u683c: 187.95, \u4ea4\u6613\u6570\u91cf: -100, \u603b\u4ea4\u6613\u989d: 18447.0, \u8ba2\u5355\u7c7b\u578b: Completed, \u6267\u884c\u65e5\u671f: 2020-11-10\n\n--------------------\u4ea4\u6613\u65e52020-11-10\u6536\u76d8--------------------\n\n\n\n2020-11-10-- Trade 5 closed\n2020-11-10-- \u4ea4\u6613\u7ed3\u675f, \u8f93\u51fa\u4ea4\u6613\u4fe1\u606f: \u6bdb\u6536\u76ca 348.000000, \u6263\u4f63\u540e\u6536\u76ca 310.758000, \u4f63\u91d1 37.242000\n\n--------------------\u5f00\u59cb\u4ea4\u6613\u65e52020-11-10\u6536\u76d8\u4e4b\u540e\u7684\u6570\u636e\u67e5\u770b\u4ee5\u53ca\u7b2c\u4e8c\u5929\u7684\u8ba2\u5355\u7684\u4e0b\u5355--------------------\n\n2020-11-10-- Created a buy order with orderid 7, tradeid 7\n--------------------BEGIN OF ORDER INFO--------------------\n2020-11-10-- orderid: 1, tradeid: 1, ref: 55, status: Completed\n2020-11-10-- orderid: 2, tradeid: 1, ref: 56, status: Completed\n2020-11-10-- orderid: 3, tradeid: 3, ref: 57, status: Completed\n2020-11-10-- orderid: 4, tradeid: 3, ref: 58, status: Completed\n2020-11-10-- orderid: 5, tradeid: 5, ref: 59, status: Completed\n2020-11-10-- orderid: 6, tradeid: 5, ref: 60, status: Completed\n2020-11-10-- orderid: 7, tradeid: 7, ref: 61, status: Submitted\n--------------------END OF ORDER INFO--------------------\n2020-11-10-- \u5f53\u524d\u6301\u4ed3size\u4e3a0\n--- Position Begin\n- Size: 0\n- Price: 0.0\n- Price orig: 184.47\n- Closed: -100\n- Opened: 0\n- Adjbase: 185.43\n--- Position End\n2020-11-10-- \u73b0\u91d1: 100591.37\n2020-11-10-- \u603b\u6301\u4ed3\u4ef7\u503c: 100591.37\n\n--------------------\u7ed3\u675f\u4ea4\u6613\u65e52020-11-10\u6536\u76d8\u4e4b\u540e\u7684\u4e8b\u5b9c--------------------\n\n\n\n\n--------------------\u4ea4\u6613\u65e52020-11-11\u5f00\u76d8--------------------\n\n2020-11-11-- \u4e70\u5355(orderid: 7, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 7): \u8ba2\u5355\u4ef7\u683c: 200, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Submitted, \u6267\u884c\u65e5\u671f: 2020-11-11\n2020-11-11-- \u4e70\u5355(orderid: 7, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 7): \u8ba2\u5355\u4ef7\u683c: 200, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Accepted, \u6267\u884c\u65e5\u671f: 2020-11-11\n2020-11-11-- \u4e70\u5355(orderid: 7, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 7): \u8ba2\u5355\u4ef7\u683c: 200, \u6267\u884c\u4ef7\u683c: 185.87, \u4ea4\u6613\u6570\u91cf: 100, \u603b\u4ea4\u6613\u989d: 18587.0, \u8ba2\u5355\u7c7b\u578b: Completed, \u6267\u884c\u65e5\u671f: 2020-11-11\n\n--------------------\u4ea4\u6613\u65e52020-11-11\u6536\u76d8--------------------\n\n\n\n2020-11-11-- Trade 7 opened\n\n--------------------\u5f00\u59cb\u4ea4\u6613\u65e52020-11-11\u6536\u76d8\u4e4b\u540e\u7684\u6570\u636e\u67e5\u770b\u4ee5\u53ca\u7b2c\u4e8c\u5929\u7684\u8ba2\u5355\u7684\u4e0b\u5355--------------------\n\n2020-11-11-- Created a sell order with orderid 8, tradeid 7\n--------------------BEGIN OF ORDER INFO--------------------\n2020-11-11-- orderid: 1, tradeid: 1, ref: 55, status: Completed\n2020-11-11-- orderid: 2, tradeid: 1, ref: 56, status: Completed\n2020-11-11-- orderid: 3, tradeid: 3, ref: 57, status: Completed\n2020-11-11-- orderid: 4, tradeid: 3, ref: 58, status: Completed\n2020-11-11-- orderid: 5, tradeid: 5, ref: 59, status: Completed\n2020-11-11-- orderid: 6, tradeid: 5, ref: 60, status: Completed\n2020-11-11-- orderid: 7, tradeid: 7, ref: 61, status: Completed\n2020-11-11-- orderid: 8, tradeid: 7, ref: 62, status: Submitted\n--------------------END OF ORDER INFO--------------------\n2020-11-11-- \u5f53\u524d\u6301\u4ed3size\u4e0d\u4e3a0\n--- Position Begin\n- Size: 100\n- Price: 185.87\n- Price orig: 0.0\n- Closed: 0\n- Opened: 100\n- Adjbase: 186.51\n--- Position End\n2020-11-11-- \u73b0\u91d1: 81985.783\n2020-11-11-- \u603b\u6301\u4ed3\u4ef7\u503c: 100636.783\n\n--------------------\u7ed3\u675f\u4ea4\u6613\u65e52020-11-11\u6536\u76d8\u4e4b\u540e\u7684\u4e8b\u5b9c--------------------\n\n\n\n\n--------------------\u4ea4\u6613\u65e52020-11-12\u5f00\u76d8--------------------\n\n2020-11-12-- \u5356\u5355(orderid: 8, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 7)): \u8ba2\u5355\u4ef7\u683c: None, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Submitted, \u6267\u884c\u65e5\u671f: 2020-11-12\n2020-11-12-- \u5356\u5355(orderid: 8, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 7)): \u8ba2\u5355\u4ef7\u683c: None, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Accepted, \u6267\u884c\u65e5\u671f: 2020-11-12\n2020-11-12-- \u5356\u5355(orderid: 8, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 7)): \u8ba2\u5355\u4ef7\u683c: None, \u6267\u884c\u4ef7\u683c: 186.97, \u4ea4\u6613\u6570\u91cf: -100, \u603b\u4ea4\u6613\u989d: 18587.0, \u8ba2\u5355\u7c7b\u578b: Completed, \u6267\u884c\u65e5\u671f: 2020-11-12\n\n--------------------\u4ea4\u6613\u65e52020-11-12\u6536\u76d8--------------------\n\n\n\n2020-11-12-- Trade 7 closed\n2020-11-12-- \u4ea4\u6613\u7ed3\u675f, \u8f93\u51fa\u4ea4\u6613\u4fe1\u606f: \u6bdb\u6536\u76ca 110.000000, \u6263\u4f63\u540e\u6536\u76ca 72.716000, \u4f63\u91d1 37.284000\n\n--------------------\u5f00\u59cb\u4ea4\u6613\u65e52020-11-12\u6536\u76d8\u4e4b\u540e\u7684\u6570\u636e\u67e5\u770b\u4ee5\u53ca\u7b2c\u4e8c\u5929\u7684\u8ba2\u5355\u7684\u4e0b\u5355--------------------\n\n2020-11-12-- Created a buy order with orderid 9, tradeid 9\n--------------------BEGIN OF ORDER INFO--------------------\n2020-11-12-- orderid: 1, tradeid: 1, ref: 55, status: Completed\n2020-11-12-- orderid: 2, tradeid: 1, ref: 56, status: Completed\n2020-11-12-- orderid: 3, tradeid: 3, ref: 57, status: Completed\n2020-11-12-- orderid: 4, tradeid: 3, ref: 58, status: Completed\n2020-11-12-- orderid: 5, tradeid: 5, ref: 59, status: Completed\n2020-11-12-- orderid: 6, tradeid: 5, ref: 60, status: Completed\n2020-11-12-- orderid: 7, tradeid: 7, ref: 61, status: Completed\n2020-11-12-- orderid: 8, tradeid: 7, ref: 62, status: Completed\n2020-11-12-- orderid: 9, tradeid: 9, ref: 63, status: Submitted\n--------------------END OF ORDER INFO--------------------\n2020-11-12-- \u5f53\u524d\u6301\u4ed3size\u4e3a0\n--- Position Begin\n- Size: 0\n- Price: 0.0\n- Price orig: 185.87\n- Closed: -100\n- Opened: 0\n- Adjbase: 186.51\n--- Position End\n2020-11-12-- \u73b0\u91d1: 100664.086\n2020-11-12-- \u603b\u6301\u4ed3\u4ef7\u503c: 100664.086\n\n--------------------\u7ed3\u675f\u4ea4\u6613\u65e52020-11-12\u6536\u76d8\u4e4b\u540e\u7684\u4e8b\u5b9c--------------------\n\n\n\n\n--------------------\u4ea4\u6613\u65e52020-11-13\u5f00\u76d8--------------------\n\n2020-11-13-- \u4e70\u5355(orderid: 9, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 9): \u8ba2\u5355\u4ef7\u683c: 200, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Submitted, \u6267\u884c\u65e5\u671f: 2020-11-13\n2020-11-13-- \u4e70\u5355(orderid: 9, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 9): \u8ba2\u5355\u4ef7\u683c: 200, \u6267\u884c\u4ef7\u683c: 0.0, \u4ea4\u6613\u6570\u91cf: 0, \u603b\u4ea4\u6613\u989d: 0.0, \u8ba2\u5355\u7c7b\u578b: Accepted, \u6267\u884c\u65e5\u671f: 2020-11-13\n2020-11-13-- \u4e70\u5355(orderid: 9, \u6240\u5c5e\u4ea4\u6613\u7684tradeid: 9): \u8ba2\u5355\u4ef7\u683c: 200, \u6267\u884c\u4ef7\u683c: 181.63, \u4ea4\u6613\u6570\u91cf: 100, \u603b\u4ea4\u6613\u989d: 18163.0, \u8ba2\u5355\u7c7b\u578b: Completed, \u6267\u884c\u65e5\u671f: 2020-11-13\n\n--------------------\u4ea4\u6613\u65e52020-11-13\u6536\u76d8--------------------\n\n\n\n2020-11-13-- Trade 9 opened\n\n--------------------\u5f00\u59cb\u4ea4\u6613\u65e52020-11-13\u6536\u76d8\u4e4b\u540e\u7684\u6570\u636e\u67e5\u770b\u4ee5\u53ca\u7b2c\u4e8c\u5929\u7684\u8ba2\u5355\u7684\u4e0b\u5355--------------------\n\n--------------------BEGIN OF ORDER INFO--------------------\n2020-11-13-- orderid: 1, tradeid: 1, ref: 55, status: Completed\n2020-11-13-- orderid: 2, tradeid: 1, ref: 56, status: Completed\n2020-11-13-- orderid: 3, tradeid: 3, ref: 57, status: Completed\n2020-11-13-- orderid: 4, tradeid: 3, ref: 58, status: Completed\n2020-11-13-- orderid: 5, tradeid: 5, ref: 59, status: Completed\n2020-11-13-- orderid: 6, tradeid: 5, ref: 60, status: Completed\n2020-11-13-- orderid: 7, tradeid: 7, ref: 61, status: Completed\n2020-11-13-- orderid: 8, tradeid: 7, ref: 62, status: Completed\n2020-11-13-- orderid: 9, tradeid: 9, ref: 63, status: Completed\n--------------------END OF ORDER INFO--------------------\n2020-11-13-- \u5f53\u524d\u6301\u4ed3size\u4e0d\u4e3a0\n--- Position Begin\n- Size: 100\n- Price: 181.63\n- Price orig: 0.0\n- Closed: 0\n- Opened: 100\n- Adjbase: 180.15\n--- Position End\n2020-11-13-- \u73b0\u91d1: 82482.923\n2020-11-13-- \u603b\u6301\u4ed3\u4ef7\u503c: 100497.923\n\n--------------------\u7ed3\u675f\u4ea4\u6613\u65e52020-11-13\u6536\u76d8\u4e4b\u540e\u7684\u4e8b\u5b9c--------------------\n\n\n\n--------------------BEGIN OF ORDER INFO--------------------\n2020-11-13-- orderid: 1, tradeid: 1, ref: 55, status: Completed\n2020-11-13-- orderid: 2, tradeid: 1, ref: 56, status: Completed\n2020-11-13-- orderid: 3, tradeid: 3, ref: 57, status: Completed\n2020-11-13-- orderid: 4, tradeid: 3, ref: 58, status: Completed\n2020-11-13-- orderid: 5, tradeid: 5, ref: 59, status: Completed\n2020-11-13-- orderid: 6, tradeid: 5, ref: 60, status: Completed\n2020-11-13-- orderid: 7, tradeid: 7, ref: 61, status: Completed\n2020-11-13-- orderid: 8, tradeid: 7, ref: 62, status: Completed\n2020-11-13-- orderid: 9, tradeid: 9, ref: 63, status: Completed\n--------------------END OF ORDER INFO--------------------\nSTRATEGY ENDS.\nFINAL PORTFOLIO VALUE: 100497.92\n</pre> In\u00a0[11]: Copied! <pre>df_test\n</pre> df_test <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\n/Users/wenglongao/work_repo/mkdocs-knowledge-storage/docs/markdown/knowledge/python_knowledge/backtrader.ipynb \u5355\u5143\u683c 22 line 1\n----&gt; &lt;a href='vscode-notebook-cell:/Users/wenglongao/work_repo/mkdocs-knowledge-storage/docs/markdown/knowledge/python_knowledge/backtrader.ipynb#X30sZmlsZQ%3D%3D?line=0'&gt;1&lt;/a&gt; df_test\n\nNameError: name 'df_test' is not defined</pre> <p>\u5728Backtrader\u4e2d\uff0c<code>self.buy</code>\u51fd\u6570\u6709\u4ee5\u4e0b\u53c2\u6570\uff1a</p> <ul> <li><code>data</code>: \u6570\u636e\u5bf9\u8c61\u3002\u9ed8\u8ba4\u503c\u4e3a<code>None</code>\u3002</li> <li><code>size</code>: \u4ea4\u6613\u91cf\u3002\u9ed8\u8ba4\u503c\u4e3a<code>None</code>\u3002</li> <li><code>price</code>: \u4ef7\u683c\u3002\u9ed8\u8ba4\u503c\u4e3a<code>None</code>\u3002</li> <li><code>plimit</code>: \u9650\u4ef7\u5355\u4ef7\u683c\u3002\u9ed8\u8ba4\u503c\u4e3a<code>None</code>\u3002</li> <li><code>exectype</code>: \u6267\u884c\u7c7b\u578b\u3002\u9ed8\u8ba4\u503c\u4e3a<code>bt.Order.Market</code>\u3002</li> <li><code>valid</code>: \u8ba2\u5355\u6709\u6548\u671f\u3002\u9ed8\u8ba4\u503c\u4e3a<code>None</code>\u3002</li> <li><code>tradeid</code>: \u4ea4\u6613ID\u3002\u9ed8\u8ba4\u503c\u4e3a<code>None</code>\u3002</li> <li><code>oca</code>: OCA\u7ec4ID\u3002\u9ed8\u8ba4\u503c\u4e3a<code>None</code>\u3002</li> <li><code>name</code>: \u8ba2\u5355\u540d\u79f0\u3002\u9ed8\u8ba4\u503c\u4e3a<code>None</code>\u3002</li> <li><code>parent</code>: \u7236\u8ba2\u5355\u3002\u9ed8\u8ba4\u503c\u4e3a<code>None</code>\u3002</li> <li><code>transmit</code>: \u662f\u5426\u4f20\u8f93\u8ba2\u5355\u3002\u9ed8\u8ba4\u503c\u4e3a<code>True</code>\u3002</li> <li><code>trailamount</code>: \u8ddf\u8e2a\u6b62\u635f\u91d1\u989d\u3002\u9ed8\u8ba4\u503c\u4e3a<code>None</code>\u3002</li> <li><code>trailpercent</code>: \u8ddf\u8e2a\u6b62\u635f\u767e\u5206\u6bd4\u3002\u9ed8\u8ba4\u503c\u4e3a<code>None</code>\u3002</li> <li><code>args</code>: \u9644\u52a0\u53c2\u6570\u3002\u9ed8\u8ba4\u503c\u4e3a<code>None</code>\u3002</li> <li><code>kwargs</code>: \u9644\u52a0\u5173\u952e\u5b57\u53c2\u6570\u3002\u9ed8\u8ba4\u503c\u4e3a<code>None</code>\u3002</li> </ul> In\u00a0[45]: Copied! <pre>class MyStrategy(bt.Strategy):\n    def next(self):\n        order = self.buy(size=1, exectype=bt.Order.Market, ref=1)\n        print('Order ref:', order.ref)\n\n    def notify_order(self, order):\n        print('Order ref:', order.ref)\n</pre> class MyStrategy(bt.Strategy):     def next(self):         order = self.buy(size=1, exectype=bt.Order.Market, ref=1)         print('Order ref:', order.ref)      def notify_order(self, order):         print('Order ref:', order.ref)  In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/knowledge/code_knowledge/backtrader/#backtrader","title":"\u4f7f\u7528backtrader\u5b9e\u73b0\u4e00\u4e2a\u57fa\u672c\u7b56\u7565\u7684\u56de\u6d4b\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/backtrader/#1","title":"1. \u51c6\u5907\u5386\u53f2\u4ef7\u683c\u6570\u636e\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/backtrader/#2","title":"2. \u5b9a\u4e49\u7b56\u7565\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/backtrader/#21-df","title":"2.1 \u9996\u5148\uff0c\u5148\u7528\u4e00\u4e2a\u7b80\u5355\u7684df\u8fdb\u884c\u6d4b\u8bd5\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/backtrader/#221","title":"2.2.1 \u5173\u4e8e\u6267\u884c\u987a\u5e8f\u7684\u5f52\u7eb3\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/algorithm/%E4%BA%8C%E5%8F%89%E6%A0%91/","title":"\u4e8c\u53c9\u6811\u7684\u5b9a\u4e49","text":"In\u00a0[5]: Copied! <pre>from typing import List\n</pre> from typing import List In\u00a0[2]: Copied! <pre>class TreeNode:\n    def __init__(self, val, left = None, right = None):\n        self.val = val\n        self.left = left\n        self.right = right\n</pre> class TreeNode:     def __init__(self, val, left = None, right = None):         self.val = val         self.left = left         self.right = right In\u00a0[9]: Copied! <pre>node31 = TreeNode(1)\nnode32 = TreeNode(2)\nnode33 = TreeNode(7)\nnode34 = TreeNode(8)\nnode21 = TreeNode(4, left = node31, right = node32)\nnode22 = TreeNode(6, left = node33, right = node34)\nroot = TreeNode(5, left = node21, right = node22)\n</pre> node31 = TreeNode(1) node32 = TreeNode(2) node33 = TreeNode(7) node34 = TreeNode(8) node21 = TreeNode(4, left = node31, right = node32) node22 = TreeNode(6, left = node33, right = node34) root = TreeNode(5, left = node21, right = node22) In\u00a0[18]: Copied! <pre>class Solution:\n    def preorderTraversal(self, root: TreeNode) -&gt; List[int]:\n        if not root:\n            return []\n\n        left = self.preorderTraversal(root.left)\n        right = self.preorderTraversal(root.right)\n\n        return  [root.val] + left +  right\n</pre> class Solution:     def preorderTraversal(self, root: TreeNode) -&gt; List[int]:         if not root:             return []          left = self.preorderTraversal(root.left)         right = self.preorderTraversal(root.right)          return  [root.val] + left +  right In\u00a0[19]: Copied! <pre>Solution().preorderTraversal(root)\n</pre> Solution().preorderTraversal(root) Out[19]: <pre>[5, 4, 1, 2, 6, 7, 8]</pre> In\u00a0[20]: Copied! <pre>for node in [node31, node32, node33, node34]:\n    print(Solution().preorderTraversal(node))\n</pre> for node in [node31, node32, node33, node34]:     print(Solution().preorderTraversal(node)) <pre>[1]\n[2]\n[7]\n[8]\n</pre> In\u00a0[21]: Copied! <pre># \u8fd9\u91cc\u8f93\u51fa\u7684\u5c31\u662fself.preorderTraversal(root.left)\u548cself.preorderTraversal(root.right)\nfor node in [node21, node22]:\n    print(Solution().preorderTraversal(node))\n</pre> # \u8fd9\u91cc\u8f93\u51fa\u7684\u5c31\u662fself.preorderTraversal(root.left)\u548cself.preorderTraversal(root.right) for node in [node21, node22]:     print(Solution().preorderTraversal(node)) <pre>[4, 1, 2]\n[6, 7, 8]\n</pre> In\u00a0[48]: Copied! <pre>l = [1, 2, 3, 4, 5, 0]\n</pre> l = [1, 2, 3, 4, 5, 0]  In\u00a0[35]: Copied! <pre>sorted(l)\n</pre> sorted(l) Out[35]: <pre>[0, 1, 2, 3, 4, 5]</pre> In\u00a0[38]: Copied! <pre>from collections import deque\ndeque([1, 2, 3, 4, 5])[0]\n</pre> from collections import deque deque([1, 2, 3, 4, 5])[0] Out[38]: <pre>1</pre> In\u00a0[49]: Copied! <pre>l.pop()\nl\n</pre> l.pop() l Out[49]: <pre>[1, 2, 3, 4, 5]</pre> In\u00a0[50]: Copied! <pre>l1 = l\nl.append(*l1)\nl\n</pre> l1 = l l.append(*l1) l <pre>\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[50], line 2\n      1 l1 = l\n----&gt; 2 l.append(*l1)\n      3 l\n\nTypeError: list.append() takes exactly one argument (5 given)</pre> In\u00a0[51]: Copied! <pre>from collections import deque\nd = deque([1, 2, 3, 4])\n</pre> from collections import deque d = deque([1, 2, 3, 4]) In\u00a0[53]: Copied! <pre>d.append(None)\nd\n</pre> d.append(None) d Out[53]: <pre>deque([1, 2, 3, 4, None, None])</pre> In\u00a0[55]: Copied! <pre>not d[5]\n</pre> not d[5] Out[55]: <pre>True</pre>"},{"location":"markdown/knowledge/code_knowledge/algorithm/%E4%BA%8C%E5%8F%89%E6%A0%91/","title":"\u4e8c\u53c9\u6811\u7684\u5b9a\u4e49\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/algorithm/%E4%BA%8C%E5%8F%89%E6%A0%91/","title":"\u8282\u70b9\uff0c\u7c7b\u4f3c\u4e8e\u94fe\u8868\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/algorithm/%E4%BA%8C%E5%8F%89%E6%A0%91/","title":"\u624b\u52a8\u5b9a\u4e49\u4e00\u4e2a\u4e8c\u53c9\u6811\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/algorithm/%E4%BA%8C%E5%8F%89%E6%A0%91/","title":"\u4e8c\u53c9\u6811\u7684\u904d\u5386\uff0c\u8fd4\u56de\u7684\u662f\u904d\u5386\u4e4b\u540e\u7684\u5217\u8868\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/algorithm/%E4%BA%8C%E5%8F%89%E6%A0%91/","title":"\u524d\u5e8f\u904d\u5386\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/algorithm/%E5%A0%86/","title":"\u5806","text":"\u5806\u6392\u5e8f\u7684\u590d\u6742\u5ea6\u4e3aO(nlogn)\uff0c\u89e3\u91ca\u5982\u4e0b\uff1a In\u00a0[1]: Copied! <pre>import heapq\n</pre> import heapq In\u00a0[3]: Copied! <pre>heap\n</pre> heap Out[3]: <pre>[5, 7, 21, 15, 10, 24, 27, 45, 17, 30, 36, 50]</pre> In\u00a0[4]: Copied! <pre>array\n</pre> array Out[4]: <pre>[5, 7, 21, 10, 17, 24, 27, 45, 15, 30, 36, 50]</pre> In\u00a0[2]: Copied! <pre>array = [10, 17, 50, 7, 30, 24, 27, 45, 15, 5, 36, 21]\nheap = []\nfor num in array:\n    heapq.heappush(heap, num)\n    print(f'\u63a8\u5165\u7684\u5143\u7d20\u662f: {num}')\n    print(f'\u63a8\u5165\u5143\u7d20\u540e\u7684\u5217\u8868\u662f: {heap}')\n    print('------------------------')\n    \nprint(\"array:\", array)\nprint(\"heap: \", heap)\n\nheapq.heapify(array)\nprint(\"array:\", array)\n</pre> array = [10, 17, 50, 7, 30, 24, 27, 45, 15, 5, 36, 21] heap = [] for num in array:     heapq.heappush(heap, num)     print(f'\u63a8\u5165\u7684\u5143\u7d20\u662f: {num}')     print(f'\u63a8\u5165\u5143\u7d20\u540e\u7684\u5217\u8868\u662f: {heap}')     print('------------------------')      print(\"array:\", array) print(\"heap: \", heap)  heapq.heapify(array) print(\"array:\", array) <pre>\u63a8\u5165\u7684\u5143\u7d20\u662f: 10\n\u63a8\u5165\u5143\u7d20\u540e\u7684\u5217\u8868\u662f: [10]\n------------------------\n\u63a8\u5165\u7684\u5143\u7d20\u662f: 17\n\u63a8\u5165\u5143\u7d20\u540e\u7684\u5217\u8868\u662f: [10, 17]\n------------------------\n\u63a8\u5165\u7684\u5143\u7d20\u662f: 50\n\u63a8\u5165\u5143\u7d20\u540e\u7684\u5217\u8868\u662f: [10, 17, 50]\n------------------------\n\u63a8\u5165\u7684\u5143\u7d20\u662f: 7\n\u63a8\u5165\u5143\u7d20\u540e\u7684\u5217\u8868\u662f: [7, 10, 50, 17]\n------------------------\n\u63a8\u5165\u7684\u5143\u7d20\u662f: 30\n\u63a8\u5165\u5143\u7d20\u540e\u7684\u5217\u8868\u662f: [7, 10, 50, 17, 30]\n------------------------\n\u63a8\u5165\u7684\u5143\u7d20\u662f: 24\n\u63a8\u5165\u5143\u7d20\u540e\u7684\u5217\u8868\u662f: [7, 10, 24, 17, 30, 50]\n------------------------\n\u63a8\u5165\u7684\u5143\u7d20\u662f: 27\n\u63a8\u5165\u5143\u7d20\u540e\u7684\u5217\u8868\u662f: [7, 10, 24, 17, 30, 50, 27]\n------------------------\n\u63a8\u5165\u7684\u5143\u7d20\u662f: 45\n\u63a8\u5165\u5143\u7d20\u540e\u7684\u5217\u8868\u662f: [7, 10, 24, 17, 30, 50, 27, 45]\n------------------------\n\u63a8\u5165\u7684\u5143\u7d20\u662f: 15\n\u63a8\u5165\u5143\u7d20\u540e\u7684\u5217\u8868\u662f: [7, 10, 24, 15, 30, 50, 27, 45, 17]\n------------------------\n\u63a8\u5165\u7684\u5143\u7d20\u662f: 5\n\u63a8\u5165\u5143\u7d20\u540e\u7684\u5217\u8868\u662f: [5, 7, 24, 15, 10, 50, 27, 45, 17, 30]\n------------------------\n\u63a8\u5165\u7684\u5143\u7d20\u662f: 36\n\u63a8\u5165\u5143\u7d20\u540e\u7684\u5217\u8868\u662f: [5, 7, 24, 15, 10, 50, 27, 45, 17, 30, 36]\n------------------------\n\u63a8\u5165\u7684\u5143\u7d20\u662f: 21\n\u63a8\u5165\u5143\u7d20\u540e\u7684\u5217\u8868\u662f: [5, 7, 21, 15, 10, 24, 27, 45, 17, 30, 36, 50]\n------------------------\narray: [10, 17, 50, 7, 30, 24, 27, 45, 15, 5, 36, 21]\nheap:  [5, 7, 21, 15, 10, 24, 27, 45, 17, 30, 36, 50]\narray: [5, 7, 21, 10, 17, 24, 27, 45, 15, 30, 36, 50]\n</pre> In\u00a0[44]: Copied! <pre>print(f'\u539f\u59cb\u5217\u8868\u662f: {array}')\nfor i in range(len(array)):\n    a = heapq.heappop(array)\n    print(f'\u5f39\u51fa\u7684\u5143\u7d20\u662f: {a}')\n    print(f'\u5f39\u51fa\u540e\u7684\u5217\u8868\u662f: {array}')\n    print('------------------------')\n</pre> print(f'\u539f\u59cb\u5217\u8868\u662f: {array}') for i in range(len(array)):     a = heapq.heappop(array)     print(f'\u5f39\u51fa\u7684\u5143\u7d20\u662f: {a}')     print(f'\u5f39\u51fa\u540e\u7684\u5217\u8868\u662f: {array}')     print('------------------------') <pre>\u539f\u59cb\u5217\u8868\u662f: [5, 7, 21, 10, 17, 24, 27, 45, 15, 30, 36, 50]\n\u5f39\u51fa\u7684\u5143\u7d20\u662f: 5\n\u5f39\u51fa\u540e\u7684\u5217\u8868\u662f: [7, 10, 21, 15, 17, 24, 27, 45, 50, 30, 36]\n------------------------\n\u5f39\u51fa\u7684\u5143\u7d20\u662f: 7\n\u5f39\u51fa\u540e\u7684\u5217\u8868\u662f: [10, 15, 21, 36, 17, 24, 27, 45, 50, 30]\n------------------------\n\u5f39\u51fa\u7684\u5143\u7d20\u662f: 10\n\u5f39\u51fa\u540e\u7684\u5217\u8868\u662f: [15, 17, 21, 36, 30, 24, 27, 45, 50]\n------------------------\n\u5f39\u51fa\u7684\u5143\u7d20\u662f: 15\n\u5f39\u51fa\u540e\u7684\u5217\u8868\u662f: [17, 30, 21, 36, 50, 24, 27, 45]\n------------------------\n\u5f39\u51fa\u7684\u5143\u7d20\u662f: 17\n\u5f39\u51fa\u540e\u7684\u5217\u8868\u662f: [21, 30, 24, 36, 50, 45, 27]\n------------------------\n\u5f39\u51fa\u7684\u5143\u7d20\u662f: 21\n\u5f39\u51fa\u540e\u7684\u5217\u8868\u662f: [24, 30, 27, 36, 50, 45]\n------------------------\n\u5f39\u51fa\u7684\u5143\u7d20\u662f: 24\n\u5f39\u51fa\u540e\u7684\u5217\u8868\u662f: [27, 30, 45, 36, 50]\n------------------------\n\u5f39\u51fa\u7684\u5143\u7d20\u662f: 27\n\u5f39\u51fa\u540e\u7684\u5217\u8868\u662f: [30, 36, 45, 50]\n------------------------\n\u5f39\u51fa\u7684\u5143\u7d20\u662f: 30\n\u5f39\u51fa\u540e\u7684\u5217\u8868\u662f: [36, 50, 45]\n------------------------\n\u5f39\u51fa\u7684\u5143\u7d20\u662f: 36\n\u5f39\u51fa\u540e\u7684\u5217\u8868\u662f: [45, 50]\n------------------------\n\u5f39\u51fa\u7684\u5143\u7d20\u662f: 45\n\u5f39\u51fa\u540e\u7684\u5217\u8868\u662f: [50]\n------------------------\n\u5f39\u51fa\u7684\u5143\u7d20\u662f: 50\n\u5f39\u51fa\u540e\u7684\u5217\u8868\u662f: []\n------------------------\n</pre> In\u00a0[11]: Copied! <pre>d = {'1': 10, '2': 17, '3': 50, '4': 7, '5': 30, '6': 24, '7': 27, '8': 45, '9': 15, '10': 5, '11': 36, '12': 21}\nheap = []\nfor key, freq in d.items():\n    heapq.heappush(heap, (freq, key))\nheap\n</pre> d = {'1': 10, '2': 17, '3': 50, '4': 7, '5': 30, '6': 24, '7': 27, '8': 45, '9': 15, '10': 5, '11': 36, '12': 21} heap = [] for key, freq in d.items():     heapq.heappush(heap, (freq, key)) heap Out[11]: <pre>[(5, '10'),\n (7, '4'),\n (21, '12'),\n (15, '9'),\n (10, '1'),\n (24, '6'),\n (27, '7'),\n (45, '8'),\n (17, '2'),\n (30, '5'),\n (36, '11'),\n (50, '3')]</pre> In\u00a0[59]: Copied! <pre>array = [10, 17, 50, 7, 30, 24, 27, 45, 15, 5, 36, 21]\nd = {'1': 10, '2': 17, '3': 50, '4': 7, '5': 30, '6': 24, '7': 27, '8': 45, '9': 15, '10': 5, '11': 36, '12': 21}\n</pre> array = [10, 17, 50, 7, 30, 24, 27, 45, 15, 5, 36, 21] d = {'1': 10, '2': 17, '3': 50, '4': 7, '5': 30, '6': 24, '7': 27, '8': 45, '9': 15, '10': 5, '11': 36, '12': 21} In\u00a0[58]: Copied! <pre># \u76f4\u63a5\u901a\u8fc7heapq\u5185\u7f6e\u65b9\u6cd5\u53d6\u6700\u503c\nprint(heapq.nlargest(3, array))\nprint(heapq.nsmallest(3, array))\n</pre> # \u76f4\u63a5\u901a\u8fc7heapq\u5185\u7f6e\u65b9\u6cd5\u53d6\u6700\u503c print(heapq.nlargest(3, array)) print(heapq.nsmallest(3, array)) <pre>[50, 45, 36]\n[5, 7, 10]\n</pre> In\u00a0[60]: Copied! <pre>print(heapq.nlargest(3, d))\nprint(heapq.nsmallest(3, d))\n</pre> print(heapq.nlargest(3, d)) print(heapq.nsmallest(3, d)) <pre>['9', '8', '7']\n['1', '10', '11']\n</pre>"},{"location":"markdown/knowledge/code_knowledge/algorithm/%E5%A0%86/","title":"\u5806\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/algorithm/%E5%A0%86/","title":"\u5806\u662f\u4e00\u79cd\u5b8c\u5168\u4e8c\u53c9\u6811\u3002\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/algorithm/%E5%A0%86/#pythonheapifyheapq","title":"python\u4e2d\u53ef\u4ee5\u7528heapify\u5b9e\u73b0\u5c0f\u9876\u5806\u548c\u5927\u9876\u5806\uff0c\u53c2\u8003heapq\u4ecb\u7ecd\u3002\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/algorithm/%E5%A0%86/#1-n","title":"1. \u6392\u5e8f\u9700\u8981\u904d\u5386n\u6b21\uff0c\u6bcf\u6b21\u53d6\u51fa\u5806\u9876\u5143\u7d20\u540e\u5c06\u5806\u5c3e\u5143\u7d20\u653e\u5230\u4e4b\u524d\u5806\u9876\u7684\u4f4d\u7f6e\uff0c\u7136\u540e\u5bf9\u5269\u4e0b\u7684\u5143\u7d20\u8fdb\u884c\u91cd\u6392\u3002\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/algorithm/%E5%A0%86/#2-olognon","title":"2. \u5bf9\u6bcf\u4e00\u6b21\u91cd\u6392\uff0c\u9664\u4e86\u7b2c\u4e00\u6b21\u4ee5\u5916\u590d\u6742\u5ea6\u4e3aO(logn)\uff0c\u56e0\u4e3a\u53ea\u9700\u8981\u5c06\u5806\u9876\u5143\u7d20\u5411\u4e0b\u904d\u5386\u4e8c\u53c9\u6811\u7684\u6df1\u5ea6\u5373\u53ef\u3002\u7b2c\u4e00\u6b21\u91cd\u6392\u56e0\u4e3a\u8981\u904d\u5386\u6240\u6709\u7684\u5143\u7d20\uff0c\u6240\u4ee5\u590d\u6742\u5ea6\u4e3aO(n)\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/algorithm/%E5%A0%86/#n-logn","title":"\u56e0\u6b64\uff0c\u603b\u4f53\u590d\u6742\u5ea6\u4e3an * logn\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/algorithm/%E5%A0%86/#heappop","title":"heappop\u65b9\u6cd5\u5f39\u51fa\u5806\u9876\u5143\u7d20\uff0c\u7136\u540e\u91cd\u65b0\u5bf9\u5269\u4e0b\u5143\u7d20\u8fdb\u884c\u5806\u6784\u9020\u3002\u5806\u6392\u5e8f\u5177\u4f53\u539f\u7406\u53c2\u8003\u8fd9\u7bc7\u6587\u7ae0\u3002\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/algorithm/%E5%A0%86/#heappushtupletuple","title":"\u5982\u679cheappush\u7684\u662ftuple\uff0c\u90a3\u4e48\u6309\u7167tuple\u7684\u7b2c\u4e00\u4e2a\u5143\u7d20\u8fdb\u884c\u5806\u6784\u9020\u3002\u8fd9\u91cc\u5806\u6784\u9020\u6307\u7684\u662f\u5bf9\u5806\u5143\u7d20\u8fdb\u884c\u6392\u5217\uff0c\u4f7f\u5176\u6ee1\u8db3\u5c0f\u9876\u5806\u7684\u6027\u8d28\u3002\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/algorithm/%E5%A0%86/","title":"\u53d6\u6700\u5927\u6700\u5c0f\u503c\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/pandas/pandas_knowledge/","title":"pandas\u76f8\u5173\u77e5\u8bc6","text":""},{"location":"markdown/knowledge/code_knowledge/pandas/pandas_knowledge/#groupby","title":"groupby","text":"<ol> <li> <p>\u673a\u5236\u8be6\u89e3</p> <p>\u6bcf\u4e00\u4e2agroupby\u5bf9\u8c61\u90fd\u53ef\u4ee5\u5f53\u4f5c\u662f\u4e00\u4e2a\u5217\u8868\uff0c\u5217\u8868\u91cc\u6bcf\u4e2a\u5143\u7d20\u90fd\u662f\u4e00\u4e2a\u5143\u7ec4\uff0c\u6bcf\u4e2a\u5143\u7ec4\u5305\u542b\u4e24\u4e2a\u5143\u7d20\uff0c \u5206\u522b\u4e3agroupby\u7684key\u548c\u8fd9\u4e2akey\u5bf9\u5e94\u7684dataframe 2. groupby\u4e4b\u540e\u53ef\u4ee5\u7528<code>[['column_name']]</code>\u5c06\u7279\u5b9a\u7684\u5217\u62ff\u51fa\u6765\uff0c\u540c\u65f6\u4e0d\u6539\u53d8groupby\u5bf9\u8c61\u7684\u7ed3\u6784 (\u90fd\u662fDataFrameGroupBy)\uff1b<code>['column_name']</code>\u53d6\u51fa\u7684\u5bf9\u8c61\u7ed3\u6784\u662fSeriesGroupBy \u4f8b\u5982\uff1a</p> </li> <li> <p>agg\u51fd\u6570\uff1a\u7528\u4e8e\u805a\u5408\u672c\u8d28\u4e0a\uff1aagg\u91cc\u9762\u7684\u5143\u7d20\u662f\u4e00\u4e2adict\uff0ckey\u4ee3\u8868\u8981\u5bf9df\u64cd\u4f5c\u7684columns\uff0c \u6ca1\u6709key\u5c31\u9ed8\u8ba4\u6240\u6709\u7684columns\uff1bvalue\u4ee3\u8868\u8981\u64cd\u4f5c\u7684\u51fd\u6570 \uff0c\u53ef\u4ee5\u662flist\u7ed3\u6784\u3002\u5982\u679c\u5355\u72ec\u4f20\u5165\u4e00\u4e2alist\uff0c\u5c31\u4ee3\u8868 \u5bf9\u6240\u6709\u7684columns\u90fd\u91c7\u7528\u4e86list\u91cc\u9762\u7684\u51fd\u6570\u64cd\u4f5c</p> </li> <li>\u7b80\u6d01\u5199\u6cd5\uff1a\u76f4\u63a5\u4f7f\u7528mean()\u7b49\u65b9\u6cd5\u76f8\u5f53\u4e8e\u5bf9\u6240\u6709\u5217\u90fd\u4f7f\u7528\u8fd9\u4e2a\u65b9\u6cd5 \u4e24\u8005\u7b49\u4ef7\u3002</li> <li>\u5229\u7528agg\u65b9\u6cd5\u76f8\u5f53\u4e8e\u5bf9groupby\u5bf9\u8c61\u7684\u6bcf\u4e00\u4e2agroup\u64cd\u4f5c\uff0c\u7136\u540e\u518d\u628a\u7ed3\u679c\u805a\u5408\u3002 DataFrameGroupBy\u5bf9\u8c61\u7684\u6bcf\u4e00\u4e2agroup\u64cd\u4f5c\u5b8c\u53ef\u4ee5\u5f53\u4f5c\u4e00\u4e2aDataFrame SeriesGroupBy\u5bf9\u8c61\u7684\u6bcf\u4e00\u4e2agroup\u64cd\u4f5c\u5b8c\u53ef\u4ee5\u5f53\u4f5c\u4e00\u4e2aSeriesGroupBy</li> <li>\u91cd\u70b9\uff1a\u7406\u89e3mean\uff0csum\uff0cmedian\uff0ccount\u7b49\u65b9\u6cd5\u65e2\u53ef\u4ee5\u5bf9DataFrame\u64cd\u4f5c\u4e5f\u53ef\u4ee5\u5bf9Series\u64cd\u4f5c</li> </ol>"},{"location":"markdown/knowledge/code_knowledge/pandas/pandas_knowledge/#_1","title":"\u5e38\u7528\u65b9\u6cd5\u79ef\u7d2f","text":"<ol> <li>unstack\u51fd\u6570</li> <li>div\u65b9\u6cd5</li> <li>applymap \u5c06\u51fd\u6570\u4f5c\u7528\u4e8edataframe\u7684\u6bcf\u4e00\u4e2a\u5143\u7d20</li> <li>resample \u4f8b\u5b50\u89c1datetime_relevant.ipynb resample\u7684rule\u53c2\u8003\u8fd9\u4e2a\u94fe\u63a5 resample doc</li> <li><code>df['column'].is_unique</code> \u8fd4\u56debool\u503c\uff0c\u5224\u65adcolumn\u4e2d\u662f\u5426\u6709\u91cd\u590d\u5143\u7d20</li> <li><code>df.sort_index(ascending=True)</code> \u5c06df\u6309\u7167index\u5347\u5e8f\u6392\u5e8f</li> <li><code>wine.fillna({'alcohol': 10, 'magnesium': 100}, inplace=True)</code> fillna\u53ef\u4ee5\u4f20\u5165\u4e00\u4e2a\u5b57\u5178</li> <li><code>df['column'].value_counts().count()</code> \u67e5\u770bcolumn\u4e2d\u603b\u5171\u6709\u51e0\u79cd\u5143\u7d20\uff0c\u7b49\u4ef7\u4e8e<code>df['columns'].nunique()</code></li> <li><code>df.values[18]</code> values\u65b9\u6cd5\u53ef\u4ee5\u5f97\u5230\u67d0\u4e00\u884c\u7684\u6240\u6709\u5c5e\u6027</li> <li><code>df.loc[:, 'school': 'guardian']</code> loc\u65b9\u6cd5\u4e5f\u53ef\u4ee5\u6309\u7167\u539f\u5148columns\u7684\u987a\u5e8f\u5207\u7247\u4ece\u4e00\u4e2acolumn\u5230\u53e6\u5916\u4e00\u4e2acolumn\u7684df</li> <li>idxmax \u5bf9\u4e8e\u6bcf\u4e2acolumn\uff0c\u8fd4\u56de\u8fd9\u4e2acolumn\u6700\u5927\u7684\u503c\u6240\u5bf9\u5e94\u7684index \u6216\u8005\u5bf9\u4e8e\u6bcf\u4e2aindex\uff0c\u8fd4\u56de\u8fd9\u4e2aindex\u6700\u5927\u7684\u503c\u5bf9\u5e94\u7684column</li> <li><code>df['owners'] = np.random.randint(low=15000, high=73001, size=cars.shape[0])</code> \u5e38\u89c1\u7684\u968f\u673a\u6570column\u751f\u6210\u65b9\u6cd5</li> <li><code>df.sort_index(ascending=True)</code> \u6309\u7167index\u5347\u5e8f\u6392\u5e8f</li> <li><code>df.index.get_level_values(0)</code> \u5f53df\u662fmulti-index\u7684\u65f6\u5019\u53d6\u51fa\u7b2c\u4e00\u5c42index</li> </ol>"},{"location":"markdown/knowledge/code_knowledge/python_basic/datetime_relevant/","title":"datetime \u76f8\u5173\u77e5\u8bc6\u603b\u7ed3","text":"In\u00a0[1]: Copied! <pre># datetime\u7c7b\u578b\u6570\u636e\nfrom datetime import datetime\n# \u6700\u591a\u53ef\u4ee5\u5230\u5fae\u5999\u4f4d\nd = datetime(2023, 7, 13, 17, 57, 13, 12)\nfor i in tuple([d, d.year, d.month, d.day, d.hour, d.minute, d.second, d.microsecond]):\n    print(i)\n</pre> # datetime\u7c7b\u578b\u6570\u636e from datetime import datetime # \u6700\u591a\u53ef\u4ee5\u5230\u5fae\u5999\u4f4d d = datetime(2023, 7, 13, 17, 57, 13, 12) for i in tuple([d, d.year, d.month, d.day, d.hour, d.minute, d.second, d.microsecond]):     print(i) <pre>2023-07-13 17:57:13.000012\n2023\n7\n13\n17\n57\n13\n12\n</pre> In\u00a0[2]: Copied! <pre># date\u7c7b\u578b\u6570\u636e\nimport datetime\nd = datetime.date(2023, 7, 13)\nfor i in tuple([d, d.year, d.month, d.day]):\n    print(i)\n</pre> # date\u7c7b\u578b\u6570\u636e import datetime d = datetime.date(2023, 7, 13) for i in tuple([d, d.year, d.month, d.day]):     print(i) <pre>2023-07-13\n2023\n7\n13\n</pre> In\u00a0[3]: Copied! <pre>import datetime\nd = datetime.time(17, 57, 25)\nfor i in tuple([d, d.hour, d.minute, d.second]):\n    print(i)\n</pre> import datetime d = datetime.time(17, 57, 25) for i in tuple([d, d.hour, d.minute, d.second]):     print(i) <pre>17:57:25\n17\n57\n25\n</pre> In\u00a0[4]: Copied! <pre># 1. datetime\u8f6c\u53d8\u4e3a\u5b57\u7b26\u4e32\n</pre> # 1. datetime\u8f6c\u53d8\u4e3a\u5b57\u7b26\u4e32 In\u00a0[5]: Copied! <pre>from datetime import datetime\nd = datetime(2023, 7, 13, 17, 57, 13)\nprint(type(d))\n# \u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528str()\u8f6c\u6362\nd_str = str(d)\nprint(type(d_str))\nd_str\n</pre> from datetime import datetime d = datetime(2023, 7, 13, 17, 57, 13) print(type(d)) # \u53ef\u4ee5\u76f4\u63a5\u4f7f\u7528str()\u8f6c\u6362 d_str = str(d) print(type(d_str)) d_str <pre>&lt;class 'datetime.datetime'&gt;\n&lt;class 'str'&gt;\n</pre> Out[5]: <pre>'2023-07-13 17:57:13'</pre> In\u00a0[6]: Copied! <pre># 2. \u4f7f\u7528 strftime \u5c06 datetime \u8f6c\u6362\u4e3a str\n</pre> # 2. \u4f7f\u7528 strftime \u5c06 datetime \u8f6c\u6362\u4e3a str In\u00a0[7]: Copied! <pre>from datetime import datetime\nd = datetime(2023, 7, 13, 17, 57, 13)\n# \u4f7f\u7528\u5360\u4f4d\u7b26\u63a7\u5236\u8f93\u51fa\u683c\u5f0f\nd_str = d.strftime('%Y-%m-%d %H:%M:%S')\nd_str\n</pre> from datetime import datetime d = datetime(2023, 7, 13, 17, 57, 13) # \u4f7f\u7528\u5360\u4f4d\u7b26\u63a7\u5236\u8f93\u51fa\u683c\u5f0f d_str = d.strftime('%Y-%m-%d %H:%M:%S') d_str Out[7]: <pre>'2023-07-13 17:57:13'</pre> In\u00a0[8]: Copied! <pre># \u8fd9\u79cd\u5199\u6cd5\u4e5f\u53ef\u4ee5\nfrom datetime import datetime\nd = datetime(2023, 7, 13, 17, 57, 13)\nd_str_1 = datetime.strftime(d, '%Y-%m-%d %H:%M:%S')\nd_str_1\n</pre> # \u8fd9\u79cd\u5199\u6cd5\u4e5f\u53ef\u4ee5 from datetime import datetime d = datetime(2023, 7, 13, 17, 57, 13) d_str_1 = datetime.strftime(d, '%Y-%m-%d %H:%M:%S') d_str_1 Out[8]: <pre>'2023-07-13 17:57:13'</pre> In\u00a0[9]: Copied! <pre># 3. \u4f7f\u7528 strptime \u5c06 str \u8f6c\u6362\u4e3a datetime\n</pre> # 3. \u4f7f\u7528 strptime \u5c06 str \u8f6c\u6362\u4e3a datetime In\u00a0[10]: Copied! <pre>from datetime import datetime\nd = datetime.strptime(d_str, '%Y-%m-%d %H:%M:%S')\nd\n</pre> from datetime import datetime d = datetime.strptime(d_str, '%Y-%m-%d %H:%M:%S') d Out[10]: <pre>datetime.datetime(2023, 7, 13, 17, 57, 13)</pre> In\u00a0[11]: Copied! <pre>import pandas as pd\n#date_rang\u5feb\u901f\u521b\u5efa\u65e5\u671f\u8303\u56f4\nd_range =pd.date_range(start='20211025', end='20220214') #\u4f7f\u7528\u4e86start\u548cend\u4e24\u4e2a\u53c2\u6570\nd_range\n</pre> import pandas as pd #date_rang\u5feb\u901f\u521b\u5efa\u65e5\u671f\u8303\u56f4 d_range =pd.date_range(start='20211025', end='20220214') #\u4f7f\u7528\u4e86start\u548cend\u4e24\u4e2a\u53c2\u6570 d_range Out[11]: <pre>DatetimeIndex(['2021-10-25', '2021-10-26', '2021-10-27', '2021-10-28',\n               '2021-10-29', '2021-10-30', '2021-10-31', '2021-11-01',\n               '2021-11-02', '2021-11-03',\n               ...\n               '2022-02-05', '2022-02-06', '2022-02-07', '2022-02-08',\n               '2022-02-09', '2022-02-10', '2022-02-11', '2022-02-12',\n               '2022-02-13', '2022-02-14'],\n              dtype='datetime64[ns]', length=113, freq='D')</pre> In\u00a0[12]: Copied! <pre># \u9891\u7387\u4e3a\u5341\u5929\nd_range_2 =pd.date_range(start='20211025', end='20220214', freq='10D')\nd_range_2\n</pre> # \u9891\u7387\u4e3a\u5341\u5929 d_range_2 =pd.date_range(start='20211025', end='20220214', freq='10D') d_range_2 Out[12]: <pre>DatetimeIndex(['2021-10-25', '2021-11-04', '2021-11-14', '2021-11-24',\n               '2021-12-04', '2021-12-14', '2021-12-24', '2022-01-03',\n               '2022-01-13', '2022-01-23', '2022-02-02', '2022-02-12'],\n              dtype='datetime64[ns]', freq='10D')</pre> In\u00a0[13]: Copied! <pre># \u9891\u7387\u4e3a\u4e00\u4e2a\u6708\nd_range_3 =pd.date_range(start='20211025',end='20220214', freq='M')\nd_range_3\n</pre> # \u9891\u7387\u4e3a\u4e00\u4e2a\u6708 d_range_3 =pd.date_range(start='20211025',end='20220214', freq='M') d_range_3 Out[13]: <pre>DatetimeIndex(['2021-10-31', '2021-11-30', '2021-12-31', '2022-01-31'], dtype='datetime64[ns]', freq='M')</pre> In\u00a0[14]: Copied! <pre>#\u4f7f\u7528start\u3001end\u3001periods\u4e09\u4e2a\u53c2\u6570\nd_range_4 = pd.date_range(start='20211025', periods=10, freq='2D')\nd_range_4\n</pre> #\u4f7f\u7528start\u3001end\u3001periods\u4e09\u4e2a\u53c2\u6570 d_range_4 = pd.date_range(start='20211025', periods=10, freq='2D') d_range_4 Out[14]: <pre>DatetimeIndex(['2021-10-25', '2021-10-27', '2021-10-29', '2021-10-31',\n               '2021-11-02', '2021-11-04', '2021-11-06', '2021-11-08',\n               '2021-11-10', '2021-11-12'],\n              dtype='datetime64[ns]', freq='2D')</pre> In\u00a0[15]: Copied! <pre># d_range\u8f6c\u6362\u4e3apd.Series\npd.Series(d_range)\n</pre> # d_range\u8f6c\u6362\u4e3apd.Series pd.Series(d_range) Out[15]: <pre>0     2021-10-25\n1     2021-10-26\n2     2021-10-27\n3     2021-10-28\n4     2021-10-29\n         ...    \n108   2022-02-10\n109   2022-02-11\n110   2022-02-12\n111   2022-02-13\n112   2022-02-14\nLength: 113, dtype: datetime64[ns]</pre> In\u00a0[16]: Copied! <pre>import pandas as pd\nd_range_x =pd.date_range(start='20211025', end='20220214', freq='H')\ndf = pd.DataFrame(data=d_range_x, columns=['date'])\ndf.head()\n</pre> import pandas as pd d_range_x =pd.date_range(start='20211025', end='20220214', freq='H') df = pd.DataFrame(data=d_range_x, columns=['date']) df.head() Out[16]: date 0 2021-10-25 00:00:00 1 2021-10-25 01:00:00 2 2021-10-25 02:00:00 3 2021-10-25 03:00:00 4 2021-10-25 04:00:00 In\u00a0[17]: Copied! <pre>df['date_str'] = df['date'].dt.strftime('%Y-%m-%d')\ndf['date_str'].iloc[0]\n</pre> df['date_str'] = df['date'].dt.strftime('%Y-%m-%d') df['date_str'].iloc[0] Out[17]: <pre>'2021-10-25'</pre> In\u00a0[18]: Copied! <pre>df['date_strp'] = df['date_str'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\ndf['date_strp'].iloc[0]\n</pre> df['date_strp'] = df['date_str'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d')) df['date_strp'].iloc[0] Out[18]: <pre>Timestamp('2021-10-25 00:00:00')</pre> pd.to_datetime\u5c06str\u8f6c\u6362\u4e3aTimestamp In\u00a0[19]: Copied! <pre>df['date_1'] = pd.to_datetime(df['date_str'])\ndf['date_1'].iloc[0]\n</pre> df['date_1'] = pd.to_datetime(df['date_str']) df['date_1'].iloc[0] Out[19]: <pre>Timestamp('2021-10-25 00:00:00')</pre> In\u00a0[20]: Copied! <pre># pd.to_pydatetime\u5c06Timestamp\u8f6c\u4e3adatetime\u7c7b\u578b\ndf['date_2'] = df['date_1'].apply(lambda x: x.to_pydatetime())\ndf['date_2'].iloc[0]\n</pre> # pd.to_pydatetime\u5c06Timestamp\u8f6c\u4e3adatetime\u7c7b\u578b df['date_2'] = df['date_1'].apply(lambda x: x.to_pydatetime()) df['date_2'].iloc[0] Out[20]: <pre>Timestamp('2021-10-25 00:00:00')</pre> In\u00a0[21]: Copied! <pre>df['date_2'].iloc[0].to_pydatetime()\n</pre> df['date_2'].iloc[0].to_pydatetime() Out[21]: <pre>datetime.datetime(2021, 10, 25, 0, 0)</pre> In\u00a0[22]: Copied! <pre># \u6ce8\u610f\u5728dataframe\u91cc\u9762\uff0ctimestamp\u7c7b\u578b\u5c31\u7528\u6765\u8868\u793adatetime\u7c7b\u578b\n</pre> # \u6ce8\u610f\u5728dataframe\u91cc\u9762\uff0ctimestamp\u7c7b\u578b\u5c31\u7528\u6765\u8868\u793adatetime\u7c7b\u578b In\u00a0[23]: Copied! <pre># \u8fd9\u4e2a\u4f8b\u5b50\u53ef\u4ee5\u8bf4\u660e\ndf['new'] = datetime(2023, 7, 13)\ndf['new'].iloc[0]\n</pre> # \u8fd9\u4e2a\u4f8b\u5b50\u53ef\u4ee5\u8bf4\u660e df['new'] = datetime(2023, 7, 13) df['new'].iloc[0] Out[23]: <pre>Timestamp('2023-07-13 00:00:00')</pre> \u76f4\u63a5\u7531str\u521b\u5efaTimestamp\u6570\u636e In\u00a0[24]: Copied! <pre>time_stamp = pd.Timestamp('2021-10-25 19:33:55')\ntime_stamp\n</pre> time_stamp = pd.Timestamp('2021-10-25 19:33:55') time_stamp Out[24]: <pre>Timestamp('2021-10-25 19:33:55')</pre> In\u00a0[25]: Copied! <pre># \u4e5f\u53ef\u4ee5\u6839\u636e\u65f6\u95f4\u76f4\u63a5\u521b\u5efa\npd.Timestamp(2021, 10, 25, 19, 33, 55, 12)\n</pre> # \u4e5f\u53ef\u4ee5\u6839\u636e\u65f6\u95f4\u76f4\u63a5\u521b\u5efa pd.Timestamp(2021, 10, 25, 19, 33, 55, 12) Out[25]: <pre>Timestamp('2021-10-25 19:33:55.000012')</pre> \u521b\u5efa\u4e00\u4e2a\u671f\u95f4\u5bf9\u8c61 In\u00a0[26]: Copied! <pre>year_period = pd.Period('2023')\nyear_period, year_period.start_time, year_period.end_time\n</pre> year_period = pd.Period('2023') year_period, year_period.start_time, year_period.end_time Out[26]: <pre>(Period('2023', 'A-DEC'),\n Timestamp('2023-01-01 00:00:00'),\n Timestamp('2023-12-31 23:59:59.999999999'))</pre> In\u00a0[27]: Copied! <pre>month_period = pd.Period('2023-07')\nmonth_period, month_period.start_time, month_period.end_time\n</pre> month_period = pd.Period('2023-07') month_period, month_period.start_time, month_period.end_time Out[27]: <pre>(Period('2023-07', 'M'),\n Timestamp('2023-07-01 00:00:00'),\n Timestamp('2023-07-31 23:59:59.999999999'))</pre> In\u00a0[28]: Copied! <pre>day_period = pd.Period('2023-07-01')\nday_period, day_period.start_time, day_period.end_time\n</pre> day_period = pd.Period('2023-07-01') day_period, day_period.start_time, day_period.end_time Out[28]: <pre>(Period('2023-07-01', 'D'),\n Timestamp('2023-07-01 00:00:00'),\n Timestamp('2023-07-01 23:59:59.999999999'))</pre> In\u00a0[29]: Copied! <pre>df = df.set_index('date')\ndf.head()\n</pre> df = df.set_index('date') df.head() Out[29]: date_str date_strp date_1 date_2 new date 2021-10-25 00:00:00 2021-10-25 2021-10-25 2021-10-25 2021-10-25 2023-07-13 2021-10-25 01:00:00 2021-10-25 2021-10-25 2021-10-25 2021-10-25 2023-07-13 2021-10-25 02:00:00 2021-10-25 2021-10-25 2021-10-25 2021-10-25 2023-07-13 2021-10-25 03:00:00 2021-10-25 2021-10-25 2021-10-25 2021-10-25 2023-07-13 2021-10-25 04:00:00 2021-10-25 2021-10-25 2021-10-25 2021-10-25 2023-07-13 In\u00a0[30]: Copied! <pre># \u5728df\u7684\u7d22\u5f15\u662fdatetime\u7ed3\u6784\u540e\uff0c\u53ef\u4ee5\u4f7f\u7528at_time\u6765\u67e5\u627e\u4f4d\u4e8e\u4e00\u5929\u4e2d\u7279\u5b9a\u65f6\u95f4\u7684\u6570\u636e\ndf.at_time(time='9:00')\n</pre> # \u5728df\u7684\u7d22\u5f15\u662fdatetime\u7ed3\u6784\u540e\uff0c\u53ef\u4ee5\u4f7f\u7528at_time\u6765\u67e5\u627e\u4f4d\u4e8e\u4e00\u5929\u4e2d\u7279\u5b9a\u65f6\u95f4\u7684\u6570\u636e df.at_time(time='9:00') Out[30]: date_str date_strp date_1 date_2 new date 2021-10-25 09:00:00 2021-10-25 2021-10-25 2021-10-25 2021-10-25 2023-07-13 2021-10-26 09:00:00 2021-10-26 2021-10-26 2021-10-26 2021-10-26 2023-07-13 2021-10-27 09:00:00 2021-10-27 2021-10-27 2021-10-27 2021-10-27 2023-07-13 2021-10-28 09:00:00 2021-10-28 2021-10-28 2021-10-28 2021-10-28 2023-07-13 2021-10-29 09:00:00 2021-10-29 2021-10-29 2021-10-29 2021-10-29 2023-07-13 ... ... ... ... ... ... 2022-02-09 09:00:00 2022-02-09 2022-02-09 2022-02-09 2022-02-09 2023-07-13 2022-02-10 09:00:00 2022-02-10 2022-02-10 2022-02-10 2022-02-10 2023-07-13 2022-02-11 09:00:00 2022-02-11 2022-02-11 2022-02-11 2022-02-11 2023-07-13 2022-02-12 09:00:00 2022-02-12 2022-02-12 2022-02-12 2022-02-12 2023-07-13 2022-02-13 09:00:00 2022-02-13 2022-02-13 2022-02-13 2022-02-13 2023-07-13 <p>112 rows \u00d7 5 columns</p> resample is only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex In\u00a0[31]: Copied! <pre>df['new'] = 1\ndf['year'] = df['date_1'].dt.year\ndf['year'] = df['date_1'].dt.year\n</pre> df['new'] = 1 df['year'] = df['date_1'].dt.year df['year'] = df['date_1'].dt.year In\u00a0[32]: Copied! <pre># Downsample\ndf.resample('D').agg({'new': 'sum'})\n</pre> # Downsample df.resample('D').agg({'new': 'sum'}) Out[32]: new date 2021-10-25 24 2021-10-26 24 2021-10-27 24 2021-10-28 24 2021-10-29 24 ... ... 2022-02-10 24 2022-02-11 24 2022-02-12 24 2022-02-13 24 2022-02-14 1 <p>113 rows \u00d7 1 columns</p> In\u00a0[33]: Copied! <pre># Upsample\ndf.resample('30S').bfill()\n</pre> # Upsample df.resample('30S').bfill() Out[33]: date_str date_strp date_1 date_2 new year date 2021-10-25 00:00:00 2021-10-25 2021-10-25 2021-10-25 2021-10-25 1 2021 2021-10-25 00:00:30 2021-10-25 2021-10-25 2021-10-25 2021-10-25 1 2021 2021-10-25 00:01:00 2021-10-25 2021-10-25 2021-10-25 2021-10-25 1 2021 2021-10-25 00:01:30 2021-10-25 2021-10-25 2021-10-25 2021-10-25 1 2021 2021-10-25 00:02:00 2021-10-25 2021-10-25 2021-10-25 2021-10-25 1 2021 ... ... ... ... ... ... ... 2022-02-13 23:58:00 2022-02-14 2022-02-14 2022-02-14 2022-02-14 1 2022 2022-02-13 23:58:30 2022-02-14 2022-02-14 2022-02-14 2022-02-14 1 2022 2022-02-13 23:59:00 2022-02-14 2022-02-14 2022-02-14 2022-02-14 1 2022 2022-02-13 23:59:30 2022-02-14 2022-02-14 2022-02-14 2022-02-14 1 2022 2022-02-14 00:00:00 2022-02-14 2022-02-14 2022-02-14 2022-02-14 1 2022 <p>322561 rows \u00d7 6 columns</p> In\u00a0[34]: Copied! <pre>df.resample('D').max()\n</pre> df.resample('D').max() Out[34]: date_str date_strp date_1 date_2 new year date 2021-10-25 2021-10-25 2021-10-25 2021-10-25 2021-10-25 1 2021 2021-10-26 2021-10-26 2021-10-26 2021-10-26 2021-10-26 1 2021 2021-10-27 2021-10-27 2021-10-27 2021-10-27 2021-10-27 1 2021 2021-10-28 2021-10-28 2021-10-28 2021-10-28 2021-10-28 1 2021 2021-10-29 2021-10-29 2021-10-29 2021-10-29 2021-10-29 1 2021 ... ... ... ... ... ... ... 2022-02-10 2022-02-10 2022-02-10 2022-02-10 2022-02-10 1 2022 2022-02-11 2022-02-11 2022-02-11 2022-02-11 2022-02-11 1 2022 2022-02-12 2022-02-12 2022-02-12 2022-02-12 2022-02-12 1 2022 2022-02-13 2022-02-13 2022-02-13 2022-02-13 2022-02-13 1 2022 2022-02-14 2022-02-14 2022-02-14 2022-02-14 2022-02-14 1 2022 <p>113 rows \u00d7 6 columns</p> In\u00a0[35]: Copied! <pre>index = pd.date_range('1/1/2000', periods=9, freq='T')\nseries = pd.Series(range(9), index=index)\nseries\n</pre> index = pd.date_range('1/1/2000', periods=9, freq='T') series = pd.Series(range(9), index=index) series Out[35]: <pre>2000-01-01 00:00:00    0\n2000-01-01 00:01:00    1\n2000-01-01 00:02:00    2\n2000-01-01 00:03:00    3\n2000-01-01 00:04:00    4\n2000-01-01 00:05:00    5\n2000-01-01 00:06:00    6\n2000-01-01 00:07:00    7\n2000-01-01 00:08:00    8\nFreq: T, dtype: int64</pre> In\u00a0[36]: Copied! <pre>series.resample('3T').sum()\n</pre> series.resample('3T').sum() Out[36]: <pre>2000-01-01 00:00:00     3\n2000-01-01 00:03:00    12\n2000-01-01 00:06:00    21\nFreq: 3T, dtype: int64</pre> In\u00a0[37]: Copied! <pre>series.resample('3T', label='right').sum()\n</pre> series.resample('3T', label='right').sum() Out[37]: <pre>2000-01-01 00:03:00     3\n2000-01-01 00:06:00    12\n2000-01-01 00:09:00    21\nFreq: 3T, dtype: int64</pre> In\u00a0[38]: Copied! <pre>import numpy as np\ndef custom_resampler(arraylike):\n    return np.sum(arraylike) + 5\n\nseries.resample('3T').apply(custom_resampler)\n</pre> import numpy as np def custom_resampler(arraylike):     return np.sum(arraylike) + 5  series.resample('3T').apply(custom_resampler) Out[38]: <pre>2000-01-01 00:00:00     8\n2000-01-01 00:03:00    17\n2000-01-01 00:06:00    26\nFreq: 3T, dtype: int64</pre> In\u00a0[39]: Copied! <pre>series.resample('30S').asfreq()\n</pre> series.resample('30S').asfreq() Out[39]: <pre>2000-01-01 00:00:00    0.0\n2000-01-01 00:00:30    NaN\n2000-01-01 00:01:00    1.0\n2000-01-01 00:01:30    NaN\n2000-01-01 00:02:00    2.0\n2000-01-01 00:02:30    NaN\n2000-01-01 00:03:00    3.0\n2000-01-01 00:03:30    NaN\n2000-01-01 00:04:00    4.0\n2000-01-01 00:04:30    NaN\n2000-01-01 00:05:00    5.0\n2000-01-01 00:05:30    NaN\n2000-01-01 00:06:00    6.0\n2000-01-01 00:06:30    NaN\n2000-01-01 00:07:00    7.0\n2000-01-01 00:07:30    NaN\n2000-01-01 00:08:00    8.0\nFreq: 30S, dtype: float64</pre> In\u00a0[41]: Copied! <pre># end of today\n</pre> # end of today In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/knowledge/code_knowledge/python_basic/datetime_relevant/#datetime","title":"datetime \u76f8\u5173\u77e5\u8bc6\u603b\u7ed3\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/datetime_relevant/#1-datetime","title":"1. datetime\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/datetime_relevant/#1","title":"1. \u521b\u5efa\u65e5\u671f\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/datetime_relevant/#2-datetime","title":"2. datetime\u4e0e\u5b57\u7b26\u4e32\u76f8\u5173\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/datetime_relevant/#2-pandas","title":"2. pandas \u5904\u7406\u65f6\u95f4\u6570\u636e\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/datetime_relevant/#1-pddate_range","title":"1. pd.date_range\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/datetime_relevant/#2-strftimedatetime-str","title":"2. strftime\uff1adatetime \u8f6c str\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/datetime_relevant/#3-strptimestr-datetime","title":"3. strptime\uff1astr \u8f6c datetime\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/datetime_relevant/#4-pdto_datetime","title":"4. pd.to_datetime\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/datetime_relevant/#5-pdtimestamp","title":"5. pd.Timestamp\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/datetime_relevant/#6-pdperiod","title":"6. pd.Period\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/datetime_relevant/#7-datetimeindex","title":"7. datetimeindex\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/datetime_relevant/#8-resample","title":"8. resample\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/python_knowledge/","title":"Python knowledge","text":"<ol> <li>typing\u7684\u4f7f\u7528</li> <li>Counter\u5bf9\u8c61</li> <li>defaultdict\u5bf9\u8c61</li> <li>str.join</li> <li>str.split</li> <li>\u5e38\u89c1\u6570\u7ec4\u7528\u6cd5</li> <li>\u6df1\u6d45\u590d\u5236</li> </ol>"},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/","title":"\u5bf9\u8c61\u5f15\u7528\u3001\u53ef\u53d8\u6027","text":"In\u00a0[1]: Copied! <pre>result = [1, 2]\nvalue = []\nvalue.append(result)\nprint(value)\nresult.pop()\nprint(value)\n</pre> result = [1, 2] value = [] value.append(result) print(value) result.pop() print(value) <pre>[[1, 2]]\n[[1]]\n</pre> In\u00a0[44]: Copied! <pre>result = [1, 2]\nvalue = []\nvalue.append(result.copy())\nprint(value)\nresult.pop()\nprint(value)\n</pre> result = [1, 2] value = [] value.append(result.copy()) print(value) result.pop() print(value) <pre>[[1, 2]]\n[[1, 2]]\n</pre> In\u00a0[5]: Copied! <pre>def fun1(result):\n    result = result + 1\nresult = 0\nfun1(result)\nresult\n</pre> def fun1(result):     result = result + 1 result = 0 fun1(result) result Out[5]: <pre>0</pre> In\u00a0[6]: Copied! <pre>def fun2(result):\n    result.append(1)\nresult = []\nfun2(result)\nresult\n</pre> def fun2(result):     result.append(1) result = [] fun2(result) result Out[6]: <pre>[1]</pre> In\u00a0[43]: Copied! <pre>result\n</pre> result Out[43]: <pre>[1]</pre> In\u00a0[36]: Copied! <pre># reslt \u548c result.copy()\u5728\u5185\u5b58\u4e2d\u7684\u5730\u5740\u4e0d\u4e00\u6837\uff0c\u56e0\u6b64result.copy()\u662f\u91cd\u65b0\u5f00\u62d3\u4e86\u4e00\u5757\u5185\u5b58\u5730\u5740\u3002\nid(result), id(result.copy())\n</pre> # reslt \u548c result.copy()\u5728\u5185\u5b58\u4e2d\u7684\u5730\u5740\u4e0d\u4e00\u6837\uff0c\u56e0\u6b64result.copy()\u662f\u91cd\u65b0\u5f00\u62d3\u4e86\u4e00\u5757\u5185\u5b58\u5730\u5740\u3002 id(result), id(result.copy()) Out[36]: <pre>(140292556937024, 140292556923712)</pre> In\u00a0[40]: Copied! <pre># result\u548cresult1\u90fd\u76f8\u5f53\u4e8e\u5bf9\u8c61[1]\u4e0a\u7684\u4e00\u4e2a\u201c\u6807\u7b7e\u201d\uff0c\u6307\u4ee3\u540c\u4e00\u4e2a\u5bf9\u8c61\uff0c\u5219\u5185\u5b58\u5730\u5740\u76f8\u540c\u3002\nresult1 = result\nid(result), id(result1)\n</pre> # result\u548cresult1\u90fd\u76f8\u5f53\u4e8e\u5bf9\u8c61[1]\u4e0a\u7684\u4e00\u4e2a\u201c\u6807\u7b7e\u201d\uff0c\u6307\u4ee3\u540c\u4e00\u4e2a\u5bf9\u8c61\uff0c\u5219\u5185\u5b58\u5730\u5740\u76f8\u540c\u3002 result1 = result id(result), id(result1) Out[40]: <pre>(140292556937024, 140292556937024)</pre> In\u00a0[48]: Copied! <pre>result = [1, 2]\nvalue = []\nvalue.append(result)\n</pre> result = [1, 2] value = [] value.append(result) In\u00a0[53]: Copied! <pre># \u4e24\u8005\u5730\u5740\u76f8\u540c\uff0c\u4e3a[1, 2]\u4e0a\u7684\u4e24\u4e2a\u6807\u7b7e\u3002\u5219\u6539\u53d8\u5176\u4e2d\u4e00\u4e2a\u4e5f\u4f1a\u5bfc\u81f4\u53e6\u5916\u4e00\u4e2a\u53d1\u751f\u6539\u53d8\nid(result), id(value[0])\n</pre> # \u4e24\u8005\u5730\u5740\u76f8\u540c\uff0c\u4e3a[1, 2]\u4e0a\u7684\u4e24\u4e2a\u6807\u7b7e\u3002\u5219\u6539\u53d8\u5176\u4e2d\u4e00\u4e2a\u4e5f\u4f1a\u5bfc\u81f4\u53e6\u5916\u4e00\u4e2a\u53d1\u751f\u6539\u53d8 id(result), id(value[0]) Out[53]: <pre>(140293642742592, 140293642742592)</pre> In\u00a0[62]: Copied! <pre># \u53ef\u4ee5\u770b\u5230\uff0c\u4e24\u8005\u5730\u5740\u4e0d\u4e00\u6837\uff0c\u540c\u7406\u53ef\u89e3\u91ca\u4e3a\u4f55result\u7684\u503c\u4e0d\u53d1\u751f\u6539\u53d8\u3002\ndef fun1(result):\n    result = result + 1\n    print('\u51fd\u6570\u5185\u90e8\u7684\u53c2\u6570\u7684\u5730\u5740\u4e3a: %d'%id(result))\nresult = 0\nprint('\u51fd\u6570\u5916\u90e8\u7684\u53d8\u91cf\u7684\u5730\u5740\u4e3a: %d'%id(result))\nfun1(result)\nresult\n</pre> # \u53ef\u4ee5\u770b\u5230\uff0c\u4e24\u8005\u5730\u5740\u4e0d\u4e00\u6837\uff0c\u540c\u7406\u53ef\u89e3\u91ca\u4e3a\u4f55result\u7684\u503c\u4e0d\u53d1\u751f\u6539\u53d8\u3002 def fun1(result):     result = result + 1     print('\u51fd\u6570\u5185\u90e8\u7684\u53c2\u6570\u7684\u5730\u5740\u4e3a: %d'%id(result)) result = 0 print('\u51fd\u6570\u5916\u90e8\u7684\u53d8\u91cf\u7684\u5730\u5740\u4e3a: %d'%id(result)) fun1(result) result <pre>\u51fd\u6570\u5916\u90e8\u7684\u53d8\u91cf\u7684\u5730\u5740\u4e3a: 140293630388496\n\u51fd\u6570\u5185\u90e8\u7684\u53c2\u6570\u7684\u5730\u5740\u4e3a: 140293630388528\n</pre> Out[62]: <pre>0</pre> In\u00a0[123]: Copied! <pre>a = 1\na1 = a\nprint(id(a), id(a1))\na1 = 2\nprint(a, a1)\nprint(id(a), id(a1))\n</pre> a = 1 a1 = a print(id(a), id(a1)) a1 = 2 print(a, a1) print(id(a), id(a1)) <pre>140293630388528 140293630388528\n1 2\n140293630388528 140293630388560\n</pre> In\u00a0[124]: Copied! <pre>a = 1\na1 = a\nprint(id(a), id(a1))\na1 += 1\nprint(a, a1)\nprint(id(a), id(a1))\n</pre> a = 1 a1 = a print(id(a), id(a1)) a1 += 1 print(a, a1) print(id(a), id(a1)) <pre>140293630388528 140293630388528\n1 2\n140293630388528 140293630388560\n</pre> In\u00a0[129]: Copied! <pre>a = [1, 2]\na1 = a\nprint(id(a), id(a1))\na1 = [1, 2, 3]\nprint(a, a1)\nprint(id(a), id(a1))\n</pre> a = [1, 2] a1 = a print(id(a), id(a1)) a1 = [1, 2, 3] print(a, a1) print(id(a), id(a1)) <pre>140292825725184 140292825725184\n[1, 2] [1, 2, 3]\n140292825725184 140292825730752\n</pre> In\u00a0[127]: Copied! <pre>a = [1, 2]\na1 = a\nprint(id(a), id(a1))\na1.append(3)\nprint(a, a1)\nprint(id(a), id(a1))\n</pre> a = [1, 2] a1 = a print(id(a), id(a1)) a1.append(3) print(a, a1) print(id(a), id(a1)) <pre>140292825806272 140292825806272\n[1, 2, 3] [1, 2, 3]\n140292825806272 140292825806272\n</pre> In\u00a0[111]: Copied! <pre>list([1, 2, 3])\n</pre> list([1, 2, 3]) Out[111]: <pre>[1, 2, 3]</pre> In\u00a0[89]: Copied! <pre># result1\u548cresult3\u662f[1, 2, 3]\u5bf9\u8c61\u7684\u4e24\u4e2a\u522b\u540d\uff0c\u800cresult2\u7ed1\u5b9a\u4e86\u53e6\u5916\u4e00\u4e2a\u5177\u6709\u76f8\u540c\u7684\u503c\u7684\u5bf9\u8c61\nresult1 = [1, 2, 3]\nresult3 = result1\nresult2 = [1, 2, 3]\n</pre> # result1\u548cresult3\u662f[1, 2, 3]\u5bf9\u8c61\u7684\u4e24\u4e2a\u522b\u540d\uff0c\u800cresult2\u7ed1\u5b9a\u4e86\u53e6\u5916\u4e00\u4e2a\u5177\u6709\u76f8\u540c\u7684\u503c\u7684\u5bf9\u8c61 result1 = [1, 2, 3] result3 = result1 result2 = [1, 2, 3] In\u00a0[90]: Copied! <pre>result1 == result2, result1 == result3\n</pre> result1 == result2, result1 == result3 Out[90]: <pre>(True, True)</pre> In\u00a0[91]: Copied! <pre># is \u76f4\u63a5\u6bd4\u8f83\u4e24\u8005id\nresult1 is result2\n</pre> # is \u76f4\u63a5\u6bd4\u8f83\u4e24\u8005id result1 is result2 Out[91]: <pre>False</pre> In\u00a0[92]: Copied! <pre>id(result1), id(result2), id(result3)\n</pre> id(result1), id(result2), id(result3) Out[92]: <pre>(140292825588160, 140292959857152, 140292825588160)</pre> <p>\u6df1\u6d45\u590d\u5236</p> In\u00a0[2]: Copied! <pre>import copy\na = [1, 2, 3, [1, 2, 3]]\n# copy.copy()\u505a\u6d45\u590d\u5236\nb = copy.copy(a)\nid(a), id(b)\n</pre> import copy a = [1, 2, 3, [1, 2, 3]] # copy.copy()\u505a\u6d45\u590d\u5236 b = copy.copy(a) id(a), id(b) Out[2]: <pre>(140210285827136, 140211093628800)</pre> In\u00a0[3]: Copied! <pre>print(b)\na[3].pop()\nprint(a)\nprint(b)\n</pre> print(b) a[3].pop() print(a) print(b) <pre>[1, 2, 3, [1, 2, 3]]\n[1, 2, 3, [1, 2]]\n[1, 2, 3, [1, 2]]\n</pre> In\u00a0[5]: Copied! <pre>a = [1, 2, 3, [1, 2, 3]]\n# copy.copy()\u505a\u6d45\u590d\u5236\nb = copy.deepcopy(a)\nid(a), id(b)\n</pre> a = [1, 2, 3, [1, 2, 3]] # copy.copy()\u505a\u6d45\u590d\u5236 b = copy.deepcopy(a) id(a), id(b) Out[5]: <pre>(140210285878464, 140210285876096)</pre> In\u00a0[6]: Copied! <pre>print(b)\na[3].pop()\nprint(a)\nprint(b)\n</pre> print(b) a[3].pop() print(a) print(b) <pre>[1, 2, 3, [1, 2, 3]]\n[1, 2, 3, [1, 2]]\n[1, 2, 3, [1, 2, 3]]\n</pre> In\u00a0[80]: Copied! <pre>t = tuple([1, [1, 2]])\nt[1]\n</pre> t = tuple([1, [1, 2]]) t[1] Out[80]: <pre>[1, 2]</pre> In\u00a0[81]: Copied! <pre>t[1].append(3)\nt\n</pre> t[1].append(3) t Out[81]: <pre>(1, [1, 2, 3])</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/","title":"\u5bf9\u8c61\u5f15\u7528\u3001\u53ef\u53d8\u6027\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/","title":"\u5148\u770b\u51e0\u4e2a\u4f8b\u5b50\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/","title":"\u5bf9\u4e0a\u4f8b\u7684\u89e3\u91ca\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/","title":"\u518d\u770b\u51e0\u4e2a\u4f8b\u5b50\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/","title":"\u5bf9\u4e0d\u53ef\u53d8\u5bf9\u8c61\u91cd\u65b0\u8d4b\u503c\uff0c\u6539\u53d8\u5185\u5b58\u5730\u5740\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/","title":"\u5bf9\u4e0d\u53ef\u53d8\u5bf9\u8c61\u4f7f\u7528+=\uff0c\u6539\u53d8\u5185\u5b58\u5730\u5740\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/","title":"\u5bf9\u53ef\u53d8\u5bf9\u8c61\u91cd\u65b0\u8d4b\u503c\uff0c\u5373\u5c06\u53d8\u91cf\u7684\u5f15\u7528\u6539\u4e3a\u53e6\u5916\u4e00\u4e2a\u5bf9\u8c61\uff0c\u4f1a\u6539\u53d8\u53d8\u91cf\u5bf9\u5e94\u5bf9\u8c61\u7684\u5185\u5b58\u5730\u5740\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/","title":"\u5bf9\u53ef\u53d8\u5bf9\u8c61\u7684\u4fee\u6539\u4e0d\u4f1a\u6539\u53d8\u53d8\u91cf\u5bf9\u5e94\u7684\u5bf9\u8c61\u7684\u5185\u5b58\u5730\u5740\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/#is","title":"\u5173\u4e8e == \u548c is\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/#is","title":"== \u6bd4\u8f83\u503c\uff0cis \u6bd4\u8f83\u5185\u5b58\u5730\u5740\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/","title":"\u6df1\u590d\u5236\u3001\u6d45\u590d\u5236\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/#1","title":"1. \u6d45\u590d\u5236\uff0c\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u6807\u7b7e\uff0c\u65b0\u7684\u6807\u7b7e\u4e5f\u4f1a\u6307\u5411\u539f\u59cb\u5bf9\u8c61\uff0c\u5219\u6539\u53d8\u539f\u5148\u5bf9\u8c61\u4e5f\u4f1a\u6539\u53d8\u65b0\u7684\u5bf9\u8c61\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/#2","title":"2. \u6df1\u590d\u5236\uff0c\u5c06\u539f\u6765\u6807\u7b7e\u7684\u5bf9\u8c61\u590d\u5236\u4e00\u4efd\uff0c\u540c\u65f6\u4f7f\u7528\u65b0\u7684\u6807\u7b7e\u6307\u5411\u8fd9\u4e2a\u65b0\u7684\u5bf9\u8c61\u3002\u5219\u6539\u53d8\u539f\u6765\u7684\u5bf9\u8c61\u4e0d\u4f1a\u6539\u53d8\u65b0\u7684\u590d\u5236\u51fa\u7684\u5bf9\u8c61\u3002\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/","title":"\u5173\u4e8e\u5143\u7ec4\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/","title":"\u603b\u7ed3\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/#python","title":"\u9700\u8981\u7406\u89e3\u7684\u5730\u65b9\uff1apython\u4e2d\u53d8\u91cf\u53ef\u4ee5\u770b\u505a\u662f\u5bf9\u8c61\u7684\u5f15\u7528\uff0c\u6216\u8005\u8bf4\u662f\u5bf9\u8c61\u7684\u6807\u7b7e\u3002\u800c\u5bf9\u4e8e\u53d8\u91cf\u7684\u64cd\u4f5c\u53ef\u4ee5\u7406\u89e3\u4e3a\u5229\u7528\u8fd9\u4e2a\u53d8\u91cf\u5bf9\u53d8\u91cf\u6240\u5f15\u7528\u7684\u5bf9\u8c61\u8fdb\u884c\u64cd\u4f5c\u3002\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E3%80%81%E5%8F%AF%E5%8F%98%E6%80%A7/#a-1-2-aappend31-2a1-2append","title":"\u4f8b\u5982\uff0ca = [1, 2], a.append(3)\u662f\u5229\u7528[1, 2]\u5bf9\u8c61\u7684\u6807\u7b7ea\u5bf9[1, 2]\u5bf9\u8c61\u8fdb\u884cappend\u7684\u64cd\u4f5c\u3002\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/","title":"1. Super\u7528\u6cd5","text":"<p>\u9996\u5148\u660e\u786e\uff0cself\u4ee3\u8868\u4e86\u7c7b\u7684\u4e00\u4e2a\u5b9e\u4f8b</p> <p>super\u7684\u4f5c\u7528\u4e00\u822c\u5305\u62ec\u4ee5\u4e0b\u4e24\u70b9\uff1a</p> <ul> <li>\u7528\u6765\u5728\u5b50\u7c7b\u4e2d\u8c03\u7528\u7236\u7c7b\u7684\u65b9\u6cd5</li> <li>\u591a\u7528\u4e8e\u591a\u7ee7\u627f\u95ee\u9898\u4e2d\uff0c\u89e3\u51b3\u67e5\u627e\u987a\u5e8f\uff08MRO\uff09\u3001\u91cd\u590d\u8c03\u7528\uff08\u94bb\u77f3\u7ee7\u627f\uff09\u7b49\u79cd\u79cd\u95ee\u9898</li> </ul> <p>B\u662fA\u7684\u5b50\u7c7b\uff0c\u6211\u4eec\u5728B\u4e2d\u53ef\u4ee5\u76f4\u63a5\u8c03\u7528A\u7684\u65b9\u6cd5\u3002A.funxx(self)\u4e2dself\u6307\u4ee3B\u7684\u5b9e\u4f8b\u5bf9\u8c61b\uff0c\u8868\u793a\u5b9e\u4f8b\u5bf9\u8c61b\u901a\u8fc7A\u7c7b\u540d\u8c03\u7528\u65b9\u6cd5funxx()\u3002</p> In\u00a0[99]: Copied! <pre>class A:\n    def funxx(self):\n        print(f'\u8f93\u5165A\u7684funxx\u65b9\u6cd5\u7684\u5b9e\u4f8b: {self}')\n        print(\"\u6267\u884c A \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\")\n \n        \nclass B(A):\n    def funxx(self):\n        print(f'B\u7684\u5b9e\u4f8bb: {self}')\n        A.funxx(self)       # \u901a\u8fc7\u7c7b\u540d\u8c03\u7528\u7236\u7c7b\u4e2d\u7684\u540c\u540d\u65b9\u6cd5\uff0cself \u53c2\u6570\u4ee3\u8868 B \u7c7b\u7684\u5b9e\u4f8b\u5bf9\u8c61 b\n        print(\"\u6267\u884c B \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\")\n\n        \nb = B()\nprint(f'\u6211\u4eec\u5b9a\u4e49\u7684\u5b9e\u4f8bb: {b}')\nb.funxx()\n</pre> class A:     def funxx(self):         print(f'\u8f93\u5165A\u7684funxx\u65b9\u6cd5\u7684\u5b9e\u4f8b: {self}')         print(\"\u6267\u884c A \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\")            class B(A):     def funxx(self):         print(f'B\u7684\u5b9e\u4f8bb: {self}')         A.funxx(self)       # \u901a\u8fc7\u7c7b\u540d\u8c03\u7528\u7236\u7c7b\u4e2d\u7684\u540c\u540d\u65b9\u6cd5\uff0cself \u53c2\u6570\u4ee3\u8868 B \u7c7b\u7684\u5b9e\u4f8b\u5bf9\u8c61 b         print(\"\u6267\u884c B \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\")           b = B() print(f'\u6211\u4eec\u5b9a\u4e49\u7684\u5b9e\u4f8bb: {b}') b.funxx()  <pre>\u6211\u4eec\u5b9a\u4e49\u7684\u5b9e\u4f8bb: &lt;__main__.B object at 0x7fb948465a30&gt;\nB\u7684\u5b9e\u4f8bb: &lt;__main__.B object at 0x7fb948465a30&gt;\n\u8f93\u5165A\u7684funxx\u65b9\u6cd5\u7684\u5b9e\u4f8b: &lt;__main__.B object at 0x7fb948465a30&gt;\n\u6267\u884c A \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\n\u6267\u884c B \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\n</pre> <ul> <li>\u53ef\u4ee5\u770b\u51fa\uff0c\u4e09\u4e2a\u5b9e\u4f8b\u5185\u5b58\u5730\u5740\u76f8\u540c\uff0c\u8bf4\u660e\u4e3a\u540c\u4e00\u4e2a\u5bf9\u8c61\u3002</li> </ul> <p>\u672c\u8d28\u4e0a\uff0c\u5b9e\u4f8b\u65b9\u6cd5\u5c31\u662f\u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3a\u5b9e\u4f8b\u7684\u65b9\u6cd5\u3002\u6211\u4eec\u53ef\u4ee5\u5148\u628a\u5b9e\u4f8b\u65b9\u6cd5\u62ff\u51fa\u6765\uff0c\u5f53\u4f5c\u4e00\u4e2a\u4e0d\u540c\u7684\u8f93\u5165\u4e00\u4e2a\u5b9e\u4f8b\u7684\u51fd\u6570\uff1b\u6216\u8005\u901a\u8fc7\u7279\u6b8a\u7684\"\u5b9e\u4f8bx.\u65b9\u6cd5()\"\u7684\u5f62\u5f0f\u6307\u5b9a\u8f93\u5165\u65b9\u6cd5\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3a\u5b9e\u4f8bx\u3002</p> <ul> <li>\u6709\u5982\u4e0b\u4e24\u79cd\u5199\u6cd5\uff1a</li> </ul> In\u00a0[217]: Copied! <pre># \u5148\u62ff\u51faA.funxx()\uff0c\u8fd9\u662f\u4e00\u4e2a\u63a5\u53d7\u53c2\u6570\u4e3a\u4e00\u4e2a\u5b9e\u4f8b\u7684\u51fd\u6570\uff0c\u6211\u4eec\u8f93\u5165\u5b9e\u4f8bA()\nA.funxx(A())\n</pre> # \u5148\u62ff\u51faA.funxx()\uff0c\u8fd9\u662f\u4e00\u4e2a\u63a5\u53d7\u53c2\u6570\u4e3a\u4e00\u4e2a\u5b9e\u4f8b\u7684\u51fd\u6570\uff0c\u6211\u4eec\u8f93\u5165\u5b9e\u4f8bA() A.funxx(A()) <pre>\u8f93\u5165A\u7684funxx\u65b9\u6cd5\u7684\u5b9e\u4f8b: &lt;__main__.A object at 0x7fb9500eda90&gt;\n\u6267\u884c A \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\n</pre> In\u00a0[219]: Copied! <pre># \u8fd9\u662f\u901a\u5e38\u7684\u5199\u6cd5\uff0c\u76f4\u63a5\u6307\u5b9afunxx()\u63a5\u53d7\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3a\u5b9e\u4f8bA()\nA().funxx()\n</pre> # \u8fd9\u662f\u901a\u5e38\u7684\u5199\u6cd5\uff0c\u76f4\u63a5\u6307\u5b9afunxx()\u63a5\u53d7\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3a\u5b9e\u4f8bA() A().funxx() <pre>\u8f93\u5165A\u7684funxx\u65b9\u6cd5\u7684\u5b9e\u4f8b: &lt;__main__.A object at 0x7fb9500ed700&gt;\n\u6267\u884c A \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\n</pre> <p>\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7super\u51fd\u6570\u8c03\u7528\u3002super\u5f15\u7528\u7236\u7c7b\u800c\u4e0d\u5fc5\u663e\u5f0f\u5730\u6307\u5b9a\u5b83\u4eec\u7684\u540d\u79f0\uff0c\u4ece\u800c\u4ee4\u4ee3\u7801\u66f4\u6613\u7ef4\u62a4\u3002</p> <p>super\u5177\u6709\u4e24\u4e2a\u53c2\u6570\uff0c\u5176\u4e2d\uff1a</p> <ul> <li>\u7b2c\u4e00\u4e2a\u53c2\u6570\u5219\u7ed9\u51fa\u641c\u7d22\u76ee\u6807\u65b9\u6cd5\u7684\u8303\u56f4\u3002</li> <li>\u7b2c\u4e8c\u4e2a\u53c2\u6570\u7ed9\u51fa MRO\uff08\u65b9\u6cd5\u89e3\u6790\u987a\u5e8f\uff09\uff0c\u4e5f\u5c31\u662f\u641c\u7d22\u76ee\u6807\u65b9\u6cd5\u7684\u987a\u5e8f\u3002</li> </ul> <p>\u5177\u4f53\u6765\u770b\uff1a</p> <ul> <li><p>\u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3a\u4e00\u4e2a\u7c7b\uff0c\u6307\u5b9a\u4e86\u4ece\u8fd9\u4e2a\u7c7b\u7684\u4e0b\u4e00\u4e2a\u7236\u7c7b\uff08MRO\u94fe\u6761\u4e0a\u6700\u8fd1\u7684\u7236\u7c7b\uff09\u5f00\u59cb\u627e\u3002</p> </li> <li><p>\u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e3a\u4e00\u4e2a\u7c7b\u6216\u8005\u5b9e\u4f8b\uff0c\u5982\u679c\u662f\u7c7b\uff0c\u8fd9\u4e2a\u7c7b\u6240\u5728\u7684MRO\u94fe\u6761\u5c06\u6210\u4e3a\u641c\u7d22\u76ee\u6807\u65b9\u6cd5\u7684\u987a\u5e8f\uff1b\u5982\u679c\u662f\u5b9e\u4f8b\uff0c\u8fd9\u4e2a\u5b9e\u4f8b\u6240\u5728\u7684MRO\u94fe\u6761\u5c06\u6210\u4e3a\u641c\u7d22\u76ee\u6807\u65b9\u6cd5\u7684\u987a\u5e8f\u3002</p> </li> <li><p>\u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e00\u822c\u4e3aself\uff0c\u4ee3\u8868\u4e86\u4ece\u8c03\u7528super\u65b9\u6cd5\u7684\u8fd9\u4e2a\u7c7b\u7684\u5b9e\u4f8b\u3002\u8fd9\u4e2a\u5b9e\u4f8b\u6240\u5728\u7684\u7c7b\uff08\u4e5f\u5c31\u662f\u8c03\u7528super\u65b9\u6cd5\u7684\u7c7b\uff09\u6240\u5728\u7684MRO\u94fe\u6761\u5c06\u6210\u4e3a\u641c\u7d22\u76ee\u6807\u65b9\u6cd5\u7684\u987a\u5e8f\u3002</p> </li> </ul> <p>super\u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570\uff08super(type, obj): obj must be an instance or subtype of type\uff09\uff1a</p> <ul> <li>\u5982\u679c\u662f\u5b9e\u4f8b\uff0c\u5219\u4e00\u5b9a\u8981\u662fsuper\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u7684\u7c7b\u6216\u8005\u5176\u5b50\u7c7b\u7684\u5b9e\u4f8b</li> <li>\u5982\u679c\u662f\u7c7b\uff0c\u5219\u4e00\u5b9a\u8981\u662f\u8c03\u7528super\u7684\u7c7b\u672c\u8eab\u6216\u8005\u5b50\u7c7b</li> </ul> <ul> <li>\u53ef\u4ee5\u8fd9\u6837\u7406\u89e3\uff1a\u5982\u679csuper\u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570\u662f\u7c7b\uff0c\u90a3\u4e48super\u8fd4\u56de\u7684\u4e5f\u662f\u4e00\u4e2a\u7c7b\uff1b\u7b2c\u4e8c\u4e2a\u53c2\u6570\u662f\u5b9e\u4f8b\uff0c\u5219super\u8fd4\u56de\u7684\u4e5f\u662f\u4e00\u4e2a\u5b9e\u4f8b</li> </ul> <p>super\u65b9\u6cd5\u6cbf\u7740\u7b2c\u4e8c\u4e2a\u53c2\u6570\u6307\u5b9a\u7684MRO\u94fe\u6761\uff0c\u4ece\u7b2c\u4e00\u4e2a\u53c2\u6570\u7684\u4e0b\u4e00\u4e2a\u7236\u7c7b\u5f00\u59cb\u641c\u7d22\u8282\u70b9\uff0c\u8fd4\u56de\u79bb\u7684\u6700\u8fd1\u7684\u8282\u70b9\uff08\u53ef\u80fd\u662f\u5b9e\u4f8b\u4e5f\u53ef\u80fd\u662f\u7c7b\uff09</p> <p>\u56e0\u6b64\uff0c\u6211\u4eec\u4f7f\u7528super\u65b9\u6cd5\u6539\u5199\u4e0a\u9762\u7684\u4ee3\u7801\uff1a</p> In\u00a0[204]: Copied! <pre>class A:\n    def funxx(self):\n        print(f'\u8f93\u5165A\u7684funxx\u65b9\u6cd5\u7684\u5b9e\u4f8b: {self}')\n        print(\"\u6267\u884c A \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\")\n \n        \nclass B(A):\n    def funxx(self):\n        print(f'B\u7684\u5b9e\u4f8bb: {self}')\n        super(B, self).funxx()       # \u901a\u8fc7\u7c7b\u540d\u8c03\u7528\u7236\u7c7b\u4e2d\u7684\u540c\u540d\u65b9\u6cd5\uff0cself \u53c2\u6570\u4ee3\u8868 B \u7c7b\u7684\u5b9e\u4f8b\u5bf9\u8c61 b\n        print(\"\u6267\u884c B \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\")\n\n        \nb = B()\nprint(f'\u6211\u4eec\u5b9a\u4e49\u7684\u5b9e\u4f8bb: {b}')\nb.funxx()\n</pre> class A:     def funxx(self):         print(f'\u8f93\u5165A\u7684funxx\u65b9\u6cd5\u7684\u5b9e\u4f8b: {self}')         print(\"\u6267\u884c A \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\")            class B(A):     def funxx(self):         print(f'B\u7684\u5b9e\u4f8bb: {self}')         super(B, self).funxx()       # \u901a\u8fc7\u7c7b\u540d\u8c03\u7528\u7236\u7c7b\u4e2d\u7684\u540c\u540d\u65b9\u6cd5\uff0cself \u53c2\u6570\u4ee3\u8868 B \u7c7b\u7684\u5b9e\u4f8b\u5bf9\u8c61 b         print(\"\u6267\u884c B \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\")           b = B() print(f'\u6211\u4eec\u5b9a\u4e49\u7684\u5b9e\u4f8bb: {b}') b.funxx() <pre>\u6211\u4eec\u5b9a\u4e49\u7684\u5b9e\u4f8bb: &lt;__main__.B object at 0x7fb9500ed700&gt;\nB\u7684\u5b9e\u4f8bb: &lt;__main__.B object at 0x7fb9500ed700&gt;\n\u8f93\u5165A\u7684funxx\u65b9\u6cd5\u7684\u5b9e\u4f8b: &lt;__main__.B object at 0x7fb9500ed700&gt;\n\u6267\u884c A \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\n\u6267\u884c B \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\n</pre> <p>\u8fd9\u91ccsuper(B, self)\u4e2d\u7684\u53c2\u6570\u8bf4\u660e\uff1a</p> <ul> <li>\u7b2c\u4e00\u4e2a\u53c2\u6570B\u8868\u793a\u4eceB\u7684\u4e0b\u4e00\u4e2a\u8282\u70b9\u5f00\u59cb\u641c\u7d22\uff0c\u5373\u4ece\u79bbB\u7684\u6700\u8fd1\u7684\u7236\u7c7b\u5f00\u59cb\u641c\u7d22\uff0c\u4e00\u76f4\u5411\u4e0a\u641c\u7d22\u5230\u6839\u8282\u70b9\u3002</li> <li>\u7b2c\u4e8c\u4e2a\u53c2\u6570self\u4ee3\u8868\u4e86\u5b9e\u4f8bb\uff0c\u8868\u793a\u5176\u6240\u5728\u7c7b\u7684\u7ee7\u627f\u987a\u5e8f\uff08MRO\uff09\u4e3a\uff1aB\u2192A\u2192object\u3002\u6240\u4ee5\u8c03\u7528\u65f6\u662f\u5728 B \u7684\u7236\u7c7b A \u4e2d\u5bfb\u627e\uff0c\u5982\u627e\u4e0d\u5230\u76ee\u6807\u65b9\u6cd5\u5219\u4f1a\u5728\u66f4\u4e0a\u4e00\u5c42\u7684object\u4e2d\u5bfb\u627e\u3002\u6ce8\u610f\u8fd9\u91cc\u6211\u4eec\u901a\u8fc7\u5b9e\u4f8bb\u7ed9\u51fa\u7ee7\u627f\u987a\u5e8f</li> </ul> <p>\u8fd8\u53ef\u4ee5\u5199\u6210\u5982\u4e0b\u7b49\u4ef7\u5f62\u5f0f\u3002super(B, B)\u8fd4\u56de\u7684\u662f\u7b2c\u4e8c\u4e2a\u53c2\u6570</p> In\u00a0[205]: Copied! <pre>class A:\n    def funxx(self):\n        print(f'\u8f93\u5165A\u7684funxx\u65b9\u6cd5\u7684\u5b9e\u4f8b: {self}')\n        print(\"\u6267\u884c A \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\")\n \n        \nclass B(A):\n    def funxx(self):\n        print(f'B\u7684\u5b9e\u4f8bb: {self}')\n        super(B, B).funxx(self)       # \u901a\u8fc7\u7c7b\u540d\u8c03\u7528\u7236\u7c7b\u4e2d\u7684\u540c\u540d\u65b9\u6cd5\uff0cself \u53c2\u6570\u4ee3\u8868 B \u7c7b\u7684\u5b9e\u4f8b\u5bf9\u8c61 b\n        print(\"\u6267\u884c B \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\")\n\n        \nb = B()\nprint(f'\u6211\u4eec\u5b9a\u4e49\u7684\u5b9e\u4f8bb: {b}')\nb.funxx()\n</pre> class A:     def funxx(self):         print(f'\u8f93\u5165A\u7684funxx\u65b9\u6cd5\u7684\u5b9e\u4f8b: {self}')         print(\"\u6267\u884c A \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\")            class B(A):     def funxx(self):         print(f'B\u7684\u5b9e\u4f8bb: {self}')         super(B, B).funxx(self)       # \u901a\u8fc7\u7c7b\u540d\u8c03\u7528\u7236\u7c7b\u4e2d\u7684\u540c\u540d\u65b9\u6cd5\uff0cself \u53c2\u6570\u4ee3\u8868 B \u7c7b\u7684\u5b9e\u4f8b\u5bf9\u8c61 b         print(\"\u6267\u884c B \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\")           b = B() print(f'\u6211\u4eec\u5b9a\u4e49\u7684\u5b9e\u4f8bb: {b}') b.funxx()  <pre>\u6211\u4eec\u5b9a\u4e49\u7684\u5b9e\u4f8bb: &lt;__main__.B object at 0x7fb9500ed910&gt;\nB\u7684\u5b9e\u4f8bb: &lt;__main__.B object at 0x7fb9500ed910&gt;\n\u8f93\u5165A\u7684funxx\u65b9\u6cd5\u7684\u5b9e\u4f8b: &lt;__main__.B object at 0x7fb9500ed910&gt;\n\u6267\u884c A \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\n\u6267\u884c B \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\n</pre> <p>\u5982\u679c\u4e0d\u6307\u5b9asuper\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\uff0c\u5219\u7b2c\u4e00\u4e2a\u53c2\u6570\u9ed8\u8ba4\u4e3a\u5f53\u524d\u8c03\u7528super\u7684\u7c7b(class)\uff1b\u4e0d\u6307\u5b9a\u7b2c\u4e8c\u4e2a\u53c2\u6570\u5219\u7b2c\u4e8c\u4e2a\u53c2\u6570\u9ed8\u8ba4\u4e3aself\u3002\u56e0\u6b64\uff0c\u4e0a\u8ff0\u4ee3\u7801\u7b49\u4ef7\u4e8e\uff1a</p> In\u00a0[55]: Copied! <pre>class A:\n    def funxx(self):\n        print(\"\u6267\u884c A \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\")\n \n        \nclass B(A):\n    def funxx(self):\n        print(__class__)\n        super().funxx()       # \u901a\u8fc7\u7c7b\u540d\u8c03\u7528\u7236\u7c7b\u4e2d\u7684\u540c\u540d\u65b9\u6cd5\uff0cself \u53c2\u6570\u4ee3\u8868 B \u7c7b\u7684\u5b9e\u4f8b\u5bf9\u8c61 b\n        print(\"\u6267\u884c B \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\")\n\n        \nb = B()\nb.funxx()\n</pre> class A:     def funxx(self):         print(\"\u6267\u884c A \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\")            class B(A):     def funxx(self):         print(__class__)         super().funxx()       # \u901a\u8fc7\u7c7b\u540d\u8c03\u7528\u7236\u7c7b\u4e2d\u7684\u540c\u540d\u65b9\u6cd5\uff0cself \u53c2\u6570\u4ee3\u8868 B \u7c7b\u7684\u5b9e\u4f8b\u5bf9\u8c61 b         print(\"\u6267\u884c B \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\")           b = B() b.funxx()  <pre>&lt;class '__main__.B'&gt;\n\u6267\u884c A \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\n\u6267\u884c B \u4e2d\u7684 funxx \u65b9\u6cd5 ... ...\n</pre> <p>\u518d\u770b\u4e00\u4e2a\u4f8b\u5b50\uff1a</p> In\u00a0[112]: Copied! <pre>class A:\n    def funxx(self):\n        print(\"\u627e\u5230 funxx() \u4f4d\u4e8e A \u4e2d...\")\n \nclass B(A):\n    pass\n \n \nclass C(A):\n    def funxx(self):\n        print(\"\u627e\u5230 funxx() \u4f4d\u4e8e C \u4e2d...\")\n \n \nclass D(A):\n    pass\n \n \nclass E(B, C):\n    pass\n \n \nclass F(E, D):\n    def funff(self):\n        print(\"\u6267\u884c F \u4e2d\u7684 funff()...\")\n        super(E, self).funxx()\n \n        \nprint(f\"F \u7c7b\u7684 MRO : {F.__mro__}\")\nf = F()\nf.funff()\n</pre> class A:     def funxx(self):         print(\"\u627e\u5230 funxx() \u4f4d\u4e8e A \u4e2d...\")   class B(A):     pass     class C(A):     def funxx(self):         print(\"\u627e\u5230 funxx() \u4f4d\u4e8e C \u4e2d...\")     class D(A):     pass     class E(B, C):     pass     class F(E, D):     def funff(self):         print(\"\u6267\u884c F \u4e2d\u7684 funff()...\")         super(E, self).funxx()            print(f\"F \u7c7b\u7684 MRO : {F.__mro__}\") f = F() f.funff() <pre>F \u7c7b\u7684 MRO : (&lt;class '__main__.F'&gt;, &lt;class '__main__.E'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.D'&gt;, &lt;class '__main__.A'&gt;, &lt;class 'object'&gt;)\n\u6267\u884c F \u4e2d\u7684 funff()...\n\u627e\u5230 funxx() \u4f4d\u4e8e C \u4e2d...\n</pre> <p>\u5728\u8fd9\u4e2a\u4f8b\u5b50\u4e2d\uff0cF \u7c7b\u7684 MRO\uff1aF\u2192E\u2192B\u2192C\u2192D\u2192A\u2192object\uff0csuper(E, self)\u8868\u793a\u4eceE\u7c7b\u7684\u4e0b\u4e00\u4e2a\u8282\u70b9\u5f00\u59cb\u627e\uff0c\u7ee7\u627f\u987a\u5e8f\u7531self\u6307\u5b9a\uff0c\u4ee3\u8868f\u6240\u5728\u7684\u7c7bF\u7684MRO\u94fe\u6761\u4e3a\u641c\u7d22\u94fe\u6761\u3002\u5148\u5728B\u4e2d\u5bfb\u627e\uff0c\u6ca1\u6709\u627e\u5230\uff0c\u7136\u540e\u5728C\u4e2d\u5bfb\u627e\uff0c\u627e\u5230\u4e86\uff0c\u5e76\u4e14\u8fd0\u884cC().funxx\u3002</p> <p>\u5982\u679c\u6211\u4eec\u6539\u53d8super\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3aD\uff0c\u90a3\u4e48\u5c31\u4f1a\u4eceD\u5f00\u59cb\u5bfb\u627e\uff1a</p> In\u00a0[142]: Copied! <pre>class A:\n    def funxx(self):\n        print(\"\u627e\u5230 funxx() \u4f4d\u4e8e A \u4e2d...\")\n \nclass B(A):\n    pass\n \n \nclass C(A):\n    def funxx(self):\n        print(\"\u627e\u5230 funxx() \u4f4d\u4e8e C \u4e2d...\")\n \n \nclass D(A):\n    pass\n \n \nclass E(B, C):\n    pass\n \n \nclass F(E, D):\n    def funff(self):\n        print(\"\u6267\u884c F \u4e2d\u7684 funff()...\")\n        super(D, self).funxx()\n \n        \nprint(f\"F \u7c7b\u7684 MRO : {F.__mro__}\")\nf = F()\nf.funff()\n</pre> class A:     def funxx(self):         print(\"\u627e\u5230 funxx() \u4f4d\u4e8e A \u4e2d...\")   class B(A):     pass     class C(A):     def funxx(self):         print(\"\u627e\u5230 funxx() \u4f4d\u4e8e C \u4e2d...\")     class D(A):     pass     class E(B, C):     pass     class F(E, D):     def funff(self):         print(\"\u6267\u884c F \u4e2d\u7684 funff()...\")         super(D, self).funxx()            print(f\"F \u7c7b\u7684 MRO : {F.__mro__}\") f = F() f.funff() <pre>F \u7c7b\u7684 MRO : (&lt;class '__main__.F'&gt;, &lt;class '__main__.E'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.D'&gt;, &lt;class '__main__.A'&gt;, &lt;class 'object'&gt;)\n\u6267\u884c F \u4e2d\u7684 funff()...\n\u627e\u5230 funxx() \u4f4d\u4e8e A \u4e2d...\n</pre> <p>\u6ce8\u610f\uff0csuper\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u7c7b\u6700\u597d\u662f\u8c03\u7528super\u7684\u7c7b\u672c\u8eab\u6216\u8005\u7236\u7c7b\u3002\u5426\u5219\u4ece\u5b50\u7c7b\u5f00\u59cb\u627e\uff0c\u4f1a\u627e\u5230\u8c03\u7528super\u7684\u7c7b\u7684\u65b9\u6cd5\uff0c\u7136\u540e\u53c8\u4f1a\u8fdb\u5165super\u51fd\u6570\uff0c\u51fa\u73b0\u65e0\u9650\u9012\u5f52\u5e76\u4e14\u6ea2\u51fa\u7684\u60c5\u51b5\uff0c\u9664\u975e\u4f7f\u7528super\u7684\u65b9\u6cd5\u548csuper\u8c03\u7528\u7684\u7236\u65b9\u6cd5\u540d\u79f0\u4e0d\u540c\u3002</p> In\u00a0[240]: Copied! <pre>class A:\n    def funxx(self):\n        print(\"\u627e\u5230 funxx() \u4f4d\u4e8e A \u4e2d...\")\n \nclass B(A):\n    pass\n \n \nclass C(A):\n    def funxx(self):\n        print(\"\u627e\u5230 funxx() \u4f4d\u4e8e C \u4e2d...\")\n \n \nclass D(A):\n    pass\n \n \nclass E(B, C):\n    def funxx(self):\n        super(F, F()).funxx()\n \n \nclass F(E, D):\n    def funff(self):\n        print(\"\u6267\u884c F \u4e2d\u7684 funff()...\")\n        super(F, self).funxx()\n\n        \nprint(f\"F \u7c7b\u7684 MRO : {F.__mro__}\")\ne = E()\ne.funxx()\n</pre> class A:     def funxx(self):         print(\"\u627e\u5230 funxx() \u4f4d\u4e8e A \u4e2d...\")   class B(A):     pass     class C(A):     def funxx(self):         print(\"\u627e\u5230 funxx() \u4f4d\u4e8e C \u4e2d...\")     class D(A):     pass     class E(B, C):     def funxx(self):         super(F, F()).funxx()     class F(E, D):     def funff(self):         print(\"\u6267\u884c F \u4e2d\u7684 funff()...\")         super(F, self).funxx()           print(f\"F \u7c7b\u7684 MRO : {F.__mro__}\") e = E() e.funxx() <pre>F \u7c7b\u7684 MRO : (&lt;class '__main__.F'&gt;, &lt;class '__main__.E'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.D'&gt;, &lt;class '__main__.A'&gt;, &lt;class 'object'&gt;)\n</pre> <pre>\n---------------------------------------------------------------------------\nRecursionError                            Traceback (most recent call last)\nCell In[240], line 31\n     29 print(f\"F \u7c7b\u7684 MRO : {F.__mro__}\")\n     30 e = E()\n---&gt; 31 e.funxx()\n\nCell In[240], line 20, in E.funxx(self)\n     19 def funxx(self):\n---&gt; 20     super(F, F()).funxx()\n\nCell In[240], line 20, in E.funxx(self)\n     19 def funxx(self):\n---&gt; 20     super(F, F()).funxx()\n\n    [... skipping similar frames: E.funxx at line 20 (2970 times)]\n\nCell In[240], line 20, in E.funxx(self)\n     19 def funxx(self):\n---&gt; 20     super(F, F()).funxx()\n\nRecursionError: maximum recursion depth exceeded while calling a Python object</pre> <p>\u6b64\u5904\u51fa\u73b0\u4e86\u65e0\u9650\u9012\u5f52\u6ea2\u51fa\u7684\u60c5\u51b5</p> <p>super\u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570\uff08super(type, obj): obj must be an instance or subtype of type\uff09\uff1a</p> <ul> <li>\u5982\u679c\u662f\u5b9e\u4f8b\uff0c\u5219\u4e00\u5b9a\u8981\u662fsuper\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u7684\u7c7b\u6216\u8005\u5176\u5b50\u7c7b\u7684\u5b9e\u4f8b</li> <li>\u5982\u679c\u662f\u7c7b\uff0c\u5219\u4e00\u5b9a\u8981\u662f\u8c03\u7528super\u7684\u7c7b\u672c\u8eab\u6216\u8005\u5b50\u7c7b</li> </ul> In\u00a0[243]: Copied! <pre>class A:\n    def funxx(self):\n        print(\"\u627e\u5230 funxx() \u4f4d\u4e8e A \u4e2d...\")\n \nclass B(A):\n    pass\n \n \nclass C(A):\n    def funxx(self):\n        print(\"\u627e\u5230 funxx() \u4f4d\u4e8e C \u4e2d...\")\n \n \nclass D(A):\n    pass\n \n\nclass E(B, C):\n    def funxx(self):\n        print(super(E, F) == C)\n        print(super(E, E))\n        print(super(E, F).funxx)\n        super(E, F()).funxx()\n \n \nclass F(E, D):\n    def funff(self):\n        print(\"\u6267\u884c F \u4e2d\u7684 funff()...\")\n        super(F, self).funxx()\n \n        \nprint(f\"F \u7c7b\u7684 MRO : {F.__mro__}\")\ne = E()\ne.funxx()\n</pre> class A:     def funxx(self):         print(\"\u627e\u5230 funxx() \u4f4d\u4e8e A \u4e2d...\")   class B(A):     pass     class C(A):     def funxx(self):         print(\"\u627e\u5230 funxx() \u4f4d\u4e8e C \u4e2d...\")     class D(A):     pass    class E(B, C):     def funxx(self):         print(super(E, F) == C)         print(super(E, E))         print(super(E, F).funxx)         super(E, F()).funxx()     class F(E, D):     def funff(self):         print(\"\u6267\u884c F \u4e2d\u7684 funff()...\")         super(F, self).funxx()            print(f\"F \u7c7b\u7684 MRO : {F.__mro__}\") e = E() e.funxx() <pre>F \u7c7b\u7684 MRO : (&lt;class '__main__.F'&gt;, &lt;class '__main__.E'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.D'&gt;, &lt;class '__main__.A'&gt;, &lt;class 'object'&gt;)\nFalse\n&lt;super: &lt;class 'E'&gt;, &lt;E object&gt;&gt;\n&lt;function C.funxx at 0x7fb948856e50&gt;\n\u627e\u5230 funxx() \u4f4d\u4e8e C \u4e2d...\n</pre> In\u00a0[234]: Copied! <pre>class A:\n    def __init__(self):\n        print(\"\u6253\u5370\u5c5e\u6027 a\")\n \nclass B(A):\n    def __init__(self):\n        print(\"\u6253\u5370\u5c5e\u6027 b\")\n        A.__init__(self)\n \n   \nclass C(A):\n    def __init__(self):\n        print(\"\u6253\u5370\u5c5e\u6027 c\")\n        A.__init__(self)\n\n   \nclass D(B, C):\n    def __init__(self):\n        print(\"\u6253\u5370\u5c5e\u6027 d\")\n        B.__init__(self)\n        C.__init__(self)\n    \nd = D()\nprint(D.__mro__)\n</pre> class A:     def __init__(self):         print(\"\u6253\u5370\u5c5e\u6027 a\")   class B(A):     def __init__(self):         print(\"\u6253\u5370\u5c5e\u6027 b\")         A.__init__(self)       class C(A):     def __init__(self):         print(\"\u6253\u5370\u5c5e\u6027 c\")         A.__init__(self)      class D(B, C):     def __init__(self):         print(\"\u6253\u5370\u5c5e\u6027 d\")         B.__init__(self)         C.__init__(self)      d = D() print(D.__mro__) <pre>\u6253\u5370\u5c5e\u6027 d\n\u6253\u5370\u5c5e\u6027 b\n\u6253\u5370\u5c5e\u6027 a\n\u6253\u5370\u5c5e\u6027 c\n\u6253\u5370\u5c5e\u6027 a\n(&lt;class '__main__.D'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;class 'object'&gt;)\n</pre> <p>\u56e0\u4e3a B\uff0cC \u90fd\u7ee7\u627f\u81ea A\uff0c\u6240\u4ee5\u5f53 D \u5728\u5b9e\u4f8b\u5316\u65f6\uff0cA \u7684\u6784\u9020\u51fd\u6570\u88ab\u6267\u884c\u4e86\u4e24\u6b21\u3002\u8fd9\u5c31\u662f\u6240\u8c13\u7684\u91cd\u590d\u8c03\u7528\u95ee\u9898\u3002\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528super\u51fd\u6570\u89e3\u51b3\u3002</p> In\u00a0[302]: Copied! <pre>class A:\n    def __init__(self):\n        print(\"\u6253\u5370\u5c5e\u6027 a\", self)\n \n   \nclass B(A):\n    def __init__(self):\n        print(\"\u6253\u5370\u5c5e\u6027 b\", self)\n        super().__init__()  # super() \u7b49\u540c\u4e8e super(B, self)\n \n   \nclass C(A):\n    def __init__(self):\n        print(\"\u6253\u5370\u5c5e\u6027 c\", self)\n        super().__init__()  # super() \u7b49\u540c\u4e8e super(C, self)\n \n \nclass D(B, C):\n    def __init__(self):\n        print(\"\u6253\u5370\u5c5e\u6027 d\", self)\n        super(D, self).__init__()\n \n   \nd = D()\n</pre> class A:     def __init__(self):         print(\"\u6253\u5370\u5c5e\u6027 a\", self)       class B(A):     def __init__(self):         print(\"\u6253\u5370\u5c5e\u6027 b\", self)         super().__init__()  # super() \u7b49\u540c\u4e8e super(B, self)       class C(A):     def __init__(self):         print(\"\u6253\u5370\u5c5e\u6027 c\", self)         super().__init__()  # super() \u7b49\u540c\u4e8e super(C, self)     class D(B, C):     def __init__(self):         print(\"\u6253\u5370\u5c5e\u6027 d\", self)         super(D, self).__init__()       d = D() <pre>\u6253\u5370\u5c5e\u6027 d &lt;__main__.D object at 0x7fb9485061f0&gt;\n\u6253\u5370\u5c5e\u6027 b &lt;__main__.D object at 0x7fb9485061f0&gt;\n\u6253\u5370\u5c5e\u6027 c &lt;__main__.D object at 0x7fb9485061f0&gt;\n\u6253\u5370\u5c5e\u6027 a &lt;__main__.D object at 0x7fb9485061f0&gt;\n</pre> <p>\u67e5\u770b\u8f93\u51fa\u7ed3\u679c\u6211\u4eec\u53d1\u73b0\u867d\u7136\u89e3\u51b3\u4e86\u91cd\u590d\u8c03\u7528\u95ee\u9898\uff0c\u4f46\u662f\u8f93\u51fa\u7ed3\u679c\u7684\u987a\u5e8f\u597d\u50cf\u4e0e\u6211\u4eec\u60f3\u7684\u6709\u6240\u533a\u522b\u3002\u6211\u4eec\u7684\u60ef\u6027\u601d\u7ef4\u662f\uff1a\u5148\u6267\u884c D \u7c7b\u7684__init__() \u65b9\u6cd5\uff0c\u63a5\u7740\u8c03\u7528 B \u7c7b\u7684__init__() \u65b9\u6cd5\uff0cB \u7c7b\u7684\u6784\u9020\u65b9\u6cd5\u4e2d\u53c8\u8c03\u7528\u4e86\u7236\u7c7b A \u7684__init__() \u65b9\u6cd5\uff0c\u7136\u540e\u518d\u662f\u8c03\u7528 C \u7c7b\u7684__init__() \u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4e5f\u8c03\u7528\u4e86\u7236\u7c7bA\u7684__init__() \u65b9\u6cd5\u3002\u6240\u4ee5\u6267\u884c\u7684\u7ed3\u679c\u5e94\u8be5\u662f\uff1a\u6253\u5370\u5c5e\u6027 d\uff0c\u6253\u5370\u5c5e\u6027 b\uff0c\u6253\u5370\u5c5e\u6027 a\uff0c\u6253\u5370\u5c5e\u6027 c\u3002</p> <p>\u4e3a\u4f55\u7ed3\u679c\u4e0d\u662f\u6211\u4eec\u60f3\u7684\u90a3\u6837\u5462\uff0c\u9996\u5148\u6211\u4eec\u8981\u77e5\u9053 D \u7c7b\u4e2d\u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570 self \u4e3a D \u7684\u5b9e\u4f8b d\uff0c\u5b83\u63d0\u4f9b\u7684 MRO \u4e3a\uff1aD\u2192B\u2192C\u2192A\u2192object\u3002\u6240\u4ee5 D \u7c7b\u4e2d\u7684 super() \u51fd\u6570\u4ea7\u751f\u7684\u662f d \u7684\u4ee3\u7406\u5bf9\u8c61\uff0c\u5f53\u5176\u8c03\u7528\u7236\u7c7b B \u7684__init__() \u65f6\uff0cB \u7684 super() \u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570\u4e3a D \u4e2d\u7684 super object\uff0c\u5176\u6240\u63d0\u4f9b\u7684 MRO \u4f9d\u65e7\u4e3a\uff1aD\u2192B\u2192C\u2192A\u2192object\u3002\u4e5f\u5c31\u662f\u8bf4 B \u4e2d\u7684 super() \u8c03\u7528\u7684\u662f\u5b83\u7684\u4e0a\u4e00\u7ea7 C \u4e2d\u7684__init__() \uff0c\u800c\u4e0d\u662f A \u4e2d\u7684__init__()\u3002\u6240\u4ee5\u6267\u884c\u7684\u7ed3\u679c\u662f\uff1a\u6253\u5370\u5c5e\u6027 d\uff0c\u6253\u5370\u5c5e\u6027 b\uff0c\u6253\u5370\u5c5e\u6027 c\uff0c\u6253\u5370\u5c5e\u6027 a\u3002</p> <p>\u5f53\u7136\uff0c\u4e5f\u53ef\u4ee5\u5b9e\u73b0\u4e00\u4e2a\u91cd\u590d\u7684\u6548\u679c\uff1a</p> In\u00a0[304]: Copied! <pre>class A:\n    def __init__(self):\n        print(\"\u6253\u5370\u5c5e\u6027 a\", self)\n \n   \nclass B(A):\n    def __init__(self):\n        print(\"\u6253\u5370\u5c5e\u6027 b\", self)\n        super(C, self).__init__()  # super() \u7b49\u540c\u4e8e super(B, self)\n        super(B, self).__init__()\n \n   \nclass C(A):\n    def __init__(self):\n        print(\"\u6253\u5370\u5c5e\u6027 c\", self)\n        super().__init__()  # super() \u7b49\u540c\u4e8e super(C, self)\n \n \nclass D(B, C):\n    def __init__(self):\n        print(\"\u6253\u5370\u5c5e\u6027 d\", self)\n        super(D, self).__init__()\n \n   \nd = D()\n</pre> class A:     def __init__(self):         print(\"\u6253\u5370\u5c5e\u6027 a\", self)       class B(A):     def __init__(self):         print(\"\u6253\u5370\u5c5e\u6027 b\", self)         super(C, self).__init__()  # super() \u7b49\u540c\u4e8e super(B, self)         super(B, self).__init__()       class C(A):     def __init__(self):         print(\"\u6253\u5370\u5c5e\u6027 c\", self)         super().__init__()  # super() \u7b49\u540c\u4e8e super(C, self)     class D(B, C):     def __init__(self):         print(\"\u6253\u5370\u5c5e\u6027 d\", self)         super(D, self).__init__()       d = D() <pre>\u6253\u5370\u5c5e\u6027 d &lt;__main__.D object at 0x7fb948524610&gt;\n\u6253\u5370\u5c5e\u6027 b &lt;__main__.D object at 0x7fb948524610&gt;\n\u6253\u5370\u5c5e\u6027 a &lt;__main__.D object at 0x7fb948524610&gt;\n\u6253\u5370\u5c5e\u6027 c &lt;__main__.D object at 0x7fb948524610&gt;\n\u6253\u5370\u5c5e\u6027 a &lt;__main__.D object at 0x7fb948524610&gt;\n</pre> <p>\u548c\u5b9e\u4f8b\u65b9\u6cd5\u7684\u7528\u6cd5\u5b8c\u5168\u76f8\u540c\u3002\u53ea\u9700\u8bb0\u4f4f\uff1a</p> <ul> <li>super\u7684\u7b2c\u4e8c\u4e2a\u53c2\u6570\u662f\u5b9e\u4f8b\uff0c\u5c31\u53ef\u4ee5\u7406\u89e3\u4e3a\u8fd4\u56de\u7684\u662f\u5b9e\u4f8b\uff1b\u7b2c\u4e8c\u4e2a\u53c2\u6570\u662f\u7c7b\u5c31\u53ef\u4ee5\u7406\u89e3\u4e3a\u8fd4\u56de\u7684\u662f\u7c7b\u3002</li> </ul> <p>\u4f8b1\uff1a\u6b64\u5904\u6cbf\u7740\u7c7bC\u7684MRO\u94fe\u6761\uff0c\u4ece\u8ddd\u79bbB\u7684\u6700\u8fd1\u7684\u7236\u7c7bA\u5f00\u59cb\u641c\u7d22\u3002</p> In\u00a0[292]: Copied! <pre>class A:\n    @classmethod\n    def hello(cls):\n        print(\"Hello from A\")\nclass B(A):\n    @classmethod\n    def hello(cls):\n        print('Hello from B')\nclass C(B):\n    @classmethod\n    def hello(cls):\n        super(B, B).hello()\n</pre> class A:     @classmethod     def hello(cls):         print(\"Hello from A\") class B(A):     @classmethod     def hello(cls):         print('Hello from B') class C(B):     @classmethod     def hello(cls):         super(B, B).hello() In\u00a0[293]: Copied! <pre>C().hello()\n</pre> C().hello() <pre>Hello from A\n</pre> <p>\u4f8b2\uff1a\u6ce8\u610f\u5230\u7c7b\u65b9\u6cd5\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\u4e5f\u53ef\u4ee5\u4f20\u5165\u5b9e\u4f8b\uff08\u6b64\u65f6\u4f1a\u628a\u5b9e\u4f8b\u5bf9\u5e94\u7684\u7c7b\u4f20\u9012\u7ed9\u7c7b\u65b9\u6cd5\u7684\u7b2c\u4e00\u4e2a\u53c2\u6570\uff09\uff1a</p> In\u00a0[273]: Copied! <pre>class A:\n    @classmethod\n    def hello(cls):\n        print(\"Hello from A\")\nclass B(A):\n    @classmethod\n    def hello(cls):\n        print('Hello from B')\nclass C(B):\n    @classmethod\n    def hello(cls):\n        super(B, C()).hello()\n</pre> class A:     @classmethod     def hello(cls):         print(\"Hello from A\") class B(A):     @classmethod     def hello(cls):         print('Hello from B') class C(B):     @classmethod     def hello(cls):         super(B, C()).hello() In\u00a0[274]: Copied! <pre>C().hello()\n</pre> C().hello() <pre>Hello from A\n</pre> <p>\u9759\u6001\u65b9\u6cd5\u540c\u7406</p> In\u00a0[277]: Copied! <pre>class A:\n    @staticmethod\n    def hello():\n        print(\"Hello from A\")\nclass B(A):\n    @staticmethod\n    def hello():\n        print('Hello from B')\nclass C(B):\n    @staticmethod\n    def hello():\n        super(B, C).hello()\n</pre> class A:     @staticmethod     def hello():         print(\"Hello from A\") class B(A):     @staticmethod     def hello():         print('Hello from B') class C(B):     @staticmethod     def hello():         super(B, C).hello() In\u00a0[278]: Copied! <pre>C().hello()\n</pre> C().hello() <pre>Hello from A\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/knowledge/code_knowledge/python_basic/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/#1-super","title":"1. Super\u7528\u6cd5\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/#1-1","title":"1. 1 \u5728\u5b50\u7c7b\u4e2d\u8c03\u7528\u7236\u7c7b\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/#12","title":"1.2 \u91cd\u590d\u8c03\u7528\u95ee\u9898\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/python_basic/%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/#13-super","title":"1.3 \u7c7b\u65b9\u6cd5\u548c\u9759\u6001\u65b9\u6cd5\u4e2dsuper\u7684\u7528\u6cd5\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/pytorch/pytorch_knowledge/","title":"Pytorch\u76f8\u5173\u77e5\u8bc6","text":"<ol> <li>torch.einsum</li> </ol>"},{"location":"markdown/knowledge/code_knowledge/visualization/plotly/","title":"Plotly","text":"In\u00a0[3]: Copied! <pre>from IPython.display import HTML\n</pre> from IPython.display import HTML In\u00a0[1]: Copied! <pre>import plotly.express as px\nfig = px.bar(x=[\"a\", \"b\", \"c\"], y=[1, 3, 2])\nfig.show()\n</pre> import plotly.express as px fig = px.bar(x=[\"a\", \"b\", \"c\"], y=[1, 3, 2]) fig.show() In\u00a0[2]: Copied! <pre>import plotly.graph_objects as go\nimport numpy as np\n\nN = 1000\nt = np.linspace(0, 10, 100)\ny = np.sin(t)\n\nfig = go.Figure(data=go.Scatter(x=t, y=y, mode='markers'))\n\nfig.show()\n</pre> import plotly.graph_objects as go import numpy as np  N = 1000 t = np.linspace(0, 10, 100) y = np.sin(t)  fig = go.Figure(data=go.Scatter(x=t, y=y, mode='markers'))  fig.show() In\u00a0[4]: Copied! <pre>HTML(fig.to_html())\n</pre> HTML(fig.to_html()) Out[4]: In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/Matplotlib_examples/","title":"\u5165\u95e8: \u4f7f\u7528Matplotlib\u5feb\u901f\u753b\u56fe\uff08\u4ee5\u6298\u7ebf\u56fe\u4e3a\u4f8b\uff09","text":"In\u00a0[19]: Copied! <pre>import math\nimport copy\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\n</pre> import math import copy  import pandas as pd import numpy as np import matplotlib.pyplot as plt import matplotlib In\u00a0[20]: Copied! <pre># \u4e00\u4e9b\u57fa\u672c\u8bbe\u7f6e\n# \u8bbe\u7f6e\u652f\u6301\u4e2d\u6587\u5b57\u4f53\uff08\u9ed1\u4f53\uff09\nmatplotlib.rcParams['font.family'] = ['Heiti TC']\n# \u8bbe\u7f6e\u56fe\u7247\u6e05\u6670\u5ea6\uff08200dpi: 200\u50cf\u7d20\u6bcf\u82f1\u5bf8\uff09\nmatplotlib.rcParams['figure.dpi'] = 200\n# \u56fe\u753b\u9762\u677f\u8c03\u6574\u4e3a\u767d\u8272\nmatplotlib.rcParams['axes.facecolor']='white'\nmatplotlib.rcParams['savefig.facecolor']='white'\n</pre> # \u4e00\u4e9b\u57fa\u672c\u8bbe\u7f6e # \u8bbe\u7f6e\u652f\u6301\u4e2d\u6587\u5b57\u4f53\uff08\u9ed1\u4f53\uff09 matplotlib.rcParams['font.family'] = ['Heiti TC'] # \u8bbe\u7f6e\u56fe\u7247\u6e05\u6670\u5ea6\uff08200dpi: 200\u50cf\u7d20\u6bcf\u82f1\u5bf8\uff09 matplotlib.rcParams['figure.dpi'] = 200 # \u56fe\u753b\u9762\u677f\u8c03\u6574\u4e3a\u767d\u8272 matplotlib.rcParams['axes.facecolor']='white' matplotlib.rcParams['savefig.facecolor']='white' In\u00a0[21]: Copied! <pre># \u521d\u59cb\u5316\u6570\u636e\nseasons = [1,2,3,4]   # \u5b63\u5ea6\nstock1 = [4,8,2,6]    # \u80a1\u79681\u6bcf\u4e2a\u5b63\u5ea6\u5bf9\u5e94\u7684\u80a1\u4ef7\nstock2 = [10,12,5,3]  # \u80a1\u79682\u6bcf\u4e2a\u5b63\u5ea6\u5bf9\u5e94\u7684\u80a1\u4ef7\n\n#\u8f6c\u5316\u6570\u636e\u4e3aNumpy\u6570\u7ec4\uff08\u53ef\u8df3\u8fc7\uff09\nseasons = np.array(seasons)\nstock1 = np.array(stock1)\nstock2 = np.array(stock2)\n</pre> # \u521d\u59cb\u5316\u6570\u636e seasons = [1,2,3,4]   # \u5b63\u5ea6 stock1 = [4,8,2,6]    # \u80a1\u79681\u6bcf\u4e2a\u5b63\u5ea6\u5bf9\u5e94\u7684\u80a1\u4ef7 stock2 = [10,12,5,3]  # \u80a1\u79682\u6bcf\u4e2a\u5b63\u5ea6\u5bf9\u5e94\u7684\u80a1\u4ef7  #\u8f6c\u5316\u6570\u636e\u4e3aNumpy\u6570\u7ec4\uff08\u53ef\u8df3\u8fc7\uff09 seasons = np.array(seasons) stock1 = np.array(stock1) stock2 = np.array(stock2) In\u00a0[22]: Copied! <pre># \u753b\u51fa\u4e24\u4e2a\u80a1\u4ef7\u7684\u6298\u73b0\u56fe\nplt.plot(seasons, stock1)\nplt.plot(seasons, stock2)\n# plt.savefig(\"images/pic1_1.png\")\nplt.show()\n</pre> # \u753b\u51fa\u4e24\u4e2a\u80a1\u4ef7\u7684\u6298\u73b0\u56fe plt.plot(seasons, stock1) plt.plot(seasons, stock2) # plt.savefig(\"images/pic1_1.png\") plt.show()                      Figure                  In\u00a0[23]: Copied! <pre># \u6539\u8fdb\u6298\u7ebf\u56fe\n# \u6539\u8fdb1: \u6307\u5b9a\u6298\u7ebf\u56fe\u683c\u5f0f\nplt.plot(seasons, stock1, \"ro--\", label=\"\u80a1\u7968\u4ee3\u7801: abc\")\nplt.plot(seasons, stock2, \"b^--\", label=\"\u80a1\u7968\u4ee3\u7801: def\")\n# plot\u7b2c\u4e09\u4e2a\u53c2\u6570: fmt = '[marker][line][color]'\n# \u6539\u8fdb2: \u6dfb\u52a0\u6807\u9898\uff0c\u6a2a\u7eb5\u5750\u6807\u8f74\u6807\u6ce8\uff0c\u56fe\u6807\nplt.title(\"\u6298\u7ebf\u56fe\")  # \u6dfb\u52a0\u6807\u9898\nplt.xlabel(\"\u5b63\u5ea6\")  # x\u8f74\nplt.ylabel(\"\u5e73\u5747\u80a1\u4ef7\")  # y\u8f74\nplt.legend()  # \u6dfb\u52a0\u53ef\u89c6\u5316\u56fe\u4f8b\n# plt.savefig(\"images/pic1_2.png\")\nplt.show()\n</pre> # \u6539\u8fdb\u6298\u7ebf\u56fe # \u6539\u8fdb1: \u6307\u5b9a\u6298\u7ebf\u56fe\u683c\u5f0f plt.plot(seasons, stock1, \"ro--\", label=\"\u80a1\u7968\u4ee3\u7801: abc\") plt.plot(seasons, stock2, \"b^--\", label=\"\u80a1\u7968\u4ee3\u7801: def\") # plot\u7b2c\u4e09\u4e2a\u53c2\u6570: fmt = '[marker][line][color]' # \u6539\u8fdb2: \u6dfb\u52a0\u6807\u9898\uff0c\u6a2a\u7eb5\u5750\u6807\u8f74\u6807\u6ce8\uff0c\u56fe\u6807 plt.title(\"\u6298\u7ebf\u56fe\")  # \u6dfb\u52a0\u6807\u9898 plt.xlabel(\"\u5b63\u5ea6\")  # x\u8f74 plt.ylabel(\"\u5e73\u5747\u80a1\u4ef7\")  # y\u8f74 plt.legend()  # \u6dfb\u52a0\u53ef\u89c6\u5316\u56fe\u4f8b # plt.savefig(\"images/pic1_2.png\") plt.show()                      Figure                  In\u00a0[24]: Copied! <pre># \u6539\u8fdb2: \n# \u8c03\u6574\u6a2a\u7eb5\u5750\u6807\u8f74\u523b\u5ea6\nplt.plot(seasons, stock1,\n         \"ro--\", label=\"\u80a1\u7968\u4ee3\u7801: abc\")\nplt.plot(seasons, stock2,\n         \"b^-\", label=\"\u80a1\u7968\u4ee3\u7801: def\")\nplt.title(\"\u6298\u7ebf\u56fe\")\nplt.xlabel(\"\u5b63\u5ea6\")\nplt.ylabel(\"\u5e73\u5747\u80a1\u4ef7\")\nplt.legend()\n# \u8bbe\u7f6ex/y\u5750\u6807\u523b\u5ea6\nplt.xticks([1, 2, 3, 4])\nplt.yticks(np.arange(2, 13, 1))\n# \u6dfb\u52a0\u7f51\u683c\u4e0e\u8f85\u52a9\u7ebf\nplt.grid()\n# plt.savefig(\"images/pic1_3.png\")\nplt.show()\n</pre> # \u6539\u8fdb2:  # \u8c03\u6574\u6a2a\u7eb5\u5750\u6807\u8f74\u523b\u5ea6 plt.plot(seasons, stock1,          \"ro--\", label=\"\u80a1\u7968\u4ee3\u7801: abc\") plt.plot(seasons, stock2,          \"b^-\", label=\"\u80a1\u7968\u4ee3\u7801: def\") plt.title(\"\u6298\u7ebf\u56fe\") plt.xlabel(\"\u5b63\u5ea6\") plt.ylabel(\"\u5e73\u5747\u80a1\u4ef7\") plt.legend() # \u8bbe\u7f6ex/y\u5750\u6807\u523b\u5ea6 plt.xticks([1, 2, 3, 4]) plt.yticks(np.arange(2, 13, 1)) # \u6dfb\u52a0\u7f51\u683c\u4e0e\u8f85\u52a9\u7ebf plt.grid() # plt.savefig(\"images/pic1_3.png\") plt.show()                      Figure                  In\u00a0[37]: Copied! <pre># \u6539\u8fdb3: \u6dfb\u52a0\u4e00\u4e2a\u7eff\u8272\u65b9\u5757\u5f3a\u8c03\u4e24\u4e2a\u80a1\u7968\u7684\u80a1\u4ef7\u5728\u7b2c4\u5b63\u5ea6\u53cd\u8f6c\nimport matplotlib.patches as patches\n\n# \u521b\u5efa\u4e00\u4e2a\u957f\u65b9\u4f53\u5bf9\u8c61\nrect = patches.Rectangle((2.5, 1.5), 2, 5, \n                         linewidth=1, edgecolor='g',\n                         facecolor='none')\n\nplt.plot(seasons, stock1,\n         \"ro--\", label=\"\u80a1\u7968\u4ee3\u7801: abc\")\nplt.plot(seasons, stock2,\n         \"b^-\", label=\"\u80a1\u7968\u4ee3\u7801: def\")\nplt.title(\"\u6298\u7ebf\u56fe\")\nplt.xlabel(\"\u5b63\u5ea6\")\nplt.ylabel(\"\u5e73\u5747\u80a1\u4ef7\")\n\n# \u6dfb\u52a0\u957f\u65b9\u4f53\nplt.gca().add_patch(rect)\n\nplt.legend()\nplt.xticks([1, 2, 3, 4])\nplt.xticks\nplt.yticks(np.arange(2, 13, 1))\nplt.grid()\n# plt.savefig(\"images/pic1_4.png\")\nplt.show()\n</pre> # \u6539\u8fdb3: \u6dfb\u52a0\u4e00\u4e2a\u7eff\u8272\u65b9\u5757\u5f3a\u8c03\u4e24\u4e2a\u80a1\u7968\u7684\u80a1\u4ef7\u5728\u7b2c4\u5b63\u5ea6\u53cd\u8f6c import matplotlib.patches as patches  # \u521b\u5efa\u4e00\u4e2a\u957f\u65b9\u4f53\u5bf9\u8c61 rect = patches.Rectangle((2.5, 1.5), 2, 5,                           linewidth=1, edgecolor='g',                          facecolor='none')  plt.plot(seasons, stock1,          \"ro--\", label=\"\u80a1\u7968\u4ee3\u7801: abc\") plt.plot(seasons, stock2,          \"b^-\", label=\"\u80a1\u7968\u4ee3\u7801: def\") plt.title(\"\u6298\u7ebf\u56fe\") plt.xlabel(\"\u5b63\u5ea6\") plt.ylabel(\"\u5e73\u5747\u80a1\u4ef7\")  # \u6dfb\u52a0\u957f\u65b9\u4f53 plt.gca().add_patch(rect)  plt.legend() plt.xticks([1, 2, 3, 4]) plt.xticks plt.yticks(np.arange(2, 13, 1)) plt.grid() # plt.savefig(\"images/pic1_4.png\") plt.show()                      Figure                  In\u00a0[26]: Copied! <pre># \u6539\u8fdb4: \u6539\u53d8\u65f6\u95f4\u8f74\u7684\u73b0\u5b9e\u8303\u56f4\u81f3\u4e0a\u4e00\u5f20\u56fe\u7247\u7684\u7eff\u8272\u6846\u4e2d\nplt.plot(seasons, stock1, \"ro--\", label=\"\u80a1\u7968\u4ee3\u7801: abc\")\nplt.plot(seasons, stock2, \"b^-\", label=\"\u80a1\u7968\u4ee3\u7801: def\")\nplt.title(\"\u6298\u7ebf\u56fe\")\nplt.xlabel(\"\u5b63\u5ea6\")\nplt.ylabel(\"\u5e73\u5747\u80a1\u4ef7\")\nplt.legend()\n\nplt.xticks([1, 2, 3, 4])\nplt.yticks(np.arange(2, 13, 1))\nplt.xlim(2.5, 4.5)\nplt.ylim(1.5, 6.5)\nplt.grid()\n# plt.savefig(\"images/pic1_5.png\")\nplt.show()\n</pre> # \u6539\u8fdb4: \u6539\u53d8\u65f6\u95f4\u8f74\u7684\u73b0\u5b9e\u8303\u56f4\u81f3\u4e0a\u4e00\u5f20\u56fe\u7247\u7684\u7eff\u8272\u6846\u4e2d plt.plot(seasons, stock1, \"ro--\", label=\"\u80a1\u7968\u4ee3\u7801: abc\") plt.plot(seasons, stock2, \"b^-\", label=\"\u80a1\u7968\u4ee3\u7801: def\") plt.title(\"\u6298\u7ebf\u56fe\") plt.xlabel(\"\u5b63\u5ea6\") plt.ylabel(\"\u5e73\u5747\u80a1\u4ef7\") plt.legend()  plt.xticks([1, 2, 3, 4]) plt.yticks(np.arange(2, 13, 1)) plt.xlim(2.5, 4.5) plt.ylim(1.5, 6.5) plt.grid() # plt.savefig(\"images/pic1_5.png\") plt.show() <pre>\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nFile ~/anaconda3/envs/leoweng3.0.2/lib/python3.9/site-packages/IPython/core/formatters.py:974, in MimeBundleFormatter.__call__(self, obj, include, exclude)\n    971     method = get_real_method(obj, self.print_method)\n    973     if method is not None:\n--&gt; 974         return method(include=include, exclude=exclude)\n    975     return None\n    976 else:\n\nFile ~/anaconda3/envs/leoweng3.0.2/lib/python3.9/site-packages/ipympl/backend_nbagg.py:336, in Canvas._repr_mimebundle_(self, **kwargs)\n    333     plaintext = plaintext[:110] + '\u2026'\n    335 buf = io.BytesIO()\n--&gt; 336 self.figure.savefig(buf, format='png', dpi='figure')\n    338 base64_image = b64encode(buf.getvalue()).decode('utf-8')\n    339 self._data_url = f'data:image/png;base64,{base64_image}'\n\nFile ~/anaconda3/envs/leoweng3.0.2/lib/python3.9/site-packages/matplotlib/figure.py:3378, in Figure.savefig(self, fname, transparent, **kwargs)\n   3374     for ax in self.axes:\n   3375         stack.enter_context(\n   3376             ax.patch._cm_set(facecolor='none', edgecolor='none'))\n-&gt; 3378 self.canvas.print_figure(fname, **kwargs)\n\nFile ~/anaconda3/envs/leoweng3.0.2/lib/python3.9/site-packages/matplotlib/backend_bases.py:2366, in FigureCanvasBase.print_figure(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\n   2362 try:\n   2363     # _get_renderer may change the figure dpi (as vector formats\n   2364     # force the figure dpi to 72), so we need to set it again here.\n   2365     with cbook._setattr_cm(self.figure, dpi=dpi):\n-&gt; 2366         result = print_method(\n   2367             filename,\n   2368             facecolor=facecolor,\n   2369             edgecolor=edgecolor,\n   2370             orientation=orientation,\n   2371             bbox_inches_restore=_bbox_inches_restore,\n   2372             **kwargs)\n   2373 finally:\n   2374     if bbox_inches and restore_bbox:\n\nFile ~/anaconda3/envs/leoweng3.0.2/lib/python3.9/site-packages/matplotlib/backend_bases.py:2232, in FigureCanvasBase._switch_canvas_and_return_print_method.&lt;locals&gt;.&lt;lambda&gt;(*args, **kwargs)\n   2228     optional_kws = {  # Passed by print_figure for other renderers.\n   2229         \"dpi\", \"facecolor\", \"edgecolor\", \"orientation\",\n   2230         \"bbox_inches_restore\"}\n   2231     skip = optional_kws - {*inspect.signature(meth).parameters}\n-&gt; 2232     print_method = functools.wraps(meth)(lambda *args, **kwargs: meth(\n   2233         *args, **{k: v for k, v in kwargs.items() if k not in skip}))\n   2234 else:  # Let third-parties do as they see fit.\n   2235     print_method = meth\n\nFile ~/anaconda3/envs/leoweng3.0.2/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:509, in FigureCanvasAgg.print_png(self, filename_or_obj, metadata, pil_kwargs)\n    462 def print_png(self, filename_or_obj, *, metadata=None, pil_kwargs=None):\n    463     \"\"\"\n    464     Write the figure to a PNG file.\n    465 \n   (...)\n    507         *metadata*, including the default 'Software' key.\n    508     \"\"\"\n--&gt; 509     self._print_pil(filename_or_obj, \"png\", pil_kwargs, metadata)\n\nFile ~/anaconda3/envs/leoweng3.0.2/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:457, in FigureCanvasAgg._print_pil(self, filename_or_obj, fmt, pil_kwargs, metadata)\n    452 def _print_pil(self, filename_or_obj, fmt, pil_kwargs, metadata=None):\n    453     \"\"\"\n    454     Draw the canvas, then save it using `.image.imsave` (to which\n    455     *pil_kwargs* and *metadata* are forwarded).\n    456     \"\"\"\n--&gt; 457     FigureCanvasAgg.draw(self)\n    458     mpl.image.imsave(\n    459         filename_or_obj, self.buffer_rgba(), format=fmt, origin=\"upper\",\n    460         dpi=self.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n\nFile ~/anaconda3/envs/leoweng3.0.2/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:400, in FigureCanvasAgg.draw(self)\n    396 # Acquire a lock on the shared font cache.\n    397 with RendererAgg.lock, \\\n    398      (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n    399       else nullcontext()):\n--&gt; 400     self.figure.draw(self.renderer)\n    401     # A GUI class may be need to update a window using this draw, so\n    402     # don't forget to call the superclass.\n    403     super().draw()\n\nFile ~/anaconda3/envs/leoweng3.0.2/lib/python3.9/site-packages/matplotlib/artist.py:95, in _finalize_rasterization.&lt;locals&gt;.draw_wrapper(artist, renderer, *args, **kwargs)\n     93 @wraps(draw)\n     94 def draw_wrapper(artist, renderer, *args, **kwargs):\n---&gt; 95     result = draw(artist, renderer, *args, **kwargs)\n     96     if renderer._rasterizing:\n     97         renderer.stop_rasterizing()\n\nFile ~/anaconda3/envs/leoweng3.0.2/lib/python3.9/site-packages/matplotlib/artist.py:72, in allow_rasterization.&lt;locals&gt;.draw_wrapper(artist, renderer)\n     69     if artist.get_agg_filter() is not None:\n     70         renderer.start_filter()\n---&gt; 72     return draw(artist, renderer)\n     73 finally:\n     74     if artist.get_agg_filter() is not None:\n\nFile ~/anaconda3/envs/leoweng3.0.2/lib/python3.9/site-packages/matplotlib/figure.py:3175, in Figure.draw(self, renderer)\n   3172         # ValueError can occur when resizing a window.\n   3174 self.patch.draw(renderer)\n-&gt; 3175 mimage._draw_list_compositing_images(\n   3176     renderer, self, artists, self.suppressComposite)\n   3178 for sfig in self.subfigs:\n   3179     sfig.draw(renderer)\n\nFile ~/anaconda3/envs/leoweng3.0.2/lib/python3.9/site-packages/matplotlib/image.py:131, in _draw_list_compositing_images(renderer, parent, artists, suppress_composite)\n    129 if not_composite or not has_images:\n    130     for a in artists:\n--&gt; 131         a.draw(renderer)\n    132 else:\n    133     # Composite any adjacent images together\n    134     image_group = []\n\nFile ~/anaconda3/envs/leoweng3.0.2/lib/python3.9/site-packages/matplotlib/artist.py:72, in allow_rasterization.&lt;locals&gt;.draw_wrapper(artist, renderer)\n     69     if artist.get_agg_filter() is not None:\n     70         renderer.start_filter()\n---&gt; 72     return draw(artist, renderer)\n     73 finally:\n     74     if artist.get_agg_filter() is not None:\n\nFile ~/anaconda3/envs/leoweng3.0.2/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:470, in Axes3D.draw(self, renderer)\n    466 zorder_offset = max(axis.get_zorder()\n    467                     for axis in self._axis_map.values()) + 1\n    468 collection_zorder = patch_zorder = zorder_offset\n--&gt; 470 for artist in sorted(collections_and_patches,\n    471                      key=lambda artist: artist.do_3d_projection(),\n    472                      reverse=True):\n    473     if isinstance(artist, mcoll.Collection):\n    474         artist.zorder = collection_zorder\n\nFile ~/anaconda3/envs/leoweng3.0.2/lib/python3.9/site-packages/mpl_toolkits/mplot3d/axes3d.py:471, in Axes3D.draw.&lt;locals&gt;.&lt;lambda&gt;(artist)\n    466 zorder_offset = max(axis.get_zorder()\n    467                     for axis in self._axis_map.values()) + 1\n    468 collection_zorder = patch_zorder = zorder_offset\n    470 for artist in sorted(collections_and_patches,\n--&gt; 471                      key=lambda artist: artist.do_3d_projection(),\n    472                      reverse=True):\n    473     if isinstance(artist, mcoll.Collection):\n    474         artist.zorder = collection_zorder\n\nAttributeError: 'Rectangle' object has no attribute 'do_3d_projection'</pre> <pre>Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous view', 'arrow-left', 'back'), ('Forward', 'Forward to next view', 'arrow-right', 'forward'), ('Pan', 'Left button pans, Right button zooms\\nx/y fixes axis, CTRL fixes aspect', 'arrows', 'pan'), ('Zoom', 'Zoom to rectangle\\nx/y fixes axis', 'square-o', 'zoom'), ('Download', 'Download plot', 'floppy-o', 'save_figure')]))</pre> In\u00a0[28]: Copied! <pre># \u4f8b\u5b502: plt.plot()\u51fd\u6570\u4e2d\u7684\u5feb\u6377\u683c\u5f0f\u5b57\u7b26\u5b57\u7b26\u8bf4\u660e\n# \u53c2\u8003: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\n# \u70b9\u7b26\u53f7 + \u989c\u8272 + \u8fde\u7ebf\u7b26\u53f7\nplt.figure(figsize=(9,4))\nplt.plot(list(range(5)), [5]*5, 'r.-', label=\"(r.-)\\t\\t\\t \u7ea2\u8272,\\t \u5c0f\u5706\u70b9,\\t \u76f4\u7ebf\")\nplt.plot(list(range(5)), [4]*5, 'go--', label=\"(go--)\u7eff\u8272,\\t \u5927\u5706\u70b9,\\t \u865a\u7ebf\")\nplt.plot(list(range(5)), [3]*5, 'k+-.', label=\"(k+-.) \u9ed1\u8272,\\t \u5341\u5b57\u70b9,\\t \u70b9\u865a\u7ebf\")\nplt.plot(list(range(5)), [2]*5, 'c*:', label=\"(c*:)\\t\\t\u9752\u8272,\\t \u661f\u53f7,\\t \u5bc6\u96c6\u70b9\u7ebf\")\nplt.plot(list(range(5)), [1]*5, 'bs', label=\"(bs)\\t\\t \u84dd\u8272,\\t \u65b9\u5757,\\t (\u4e0d\u8fde\u7ebf)\")\nplt.annotate(\"\u66f4\u591a\u683c\u5f0f\u8bf7\u53c2\u8003:\\n https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\",\n            xy=(0.0, 4.1), fontsize=14)\nplt.legend(loc='lower right', prop={'size': 18}) # bbox_to_anchor=(1, -0.1)\n# plt.savefig(\"images/pic2_1.png\")\nplt.show()\n</pre> # \u4f8b\u5b502: plt.plot()\u51fd\u6570\u4e2d\u7684\u5feb\u6377\u683c\u5f0f\u5b57\u7b26\u5b57\u7b26\u8bf4\u660e # \u53c2\u8003: https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html # \u70b9\u7b26\u53f7 + \u989c\u8272 + \u8fde\u7ebf\u7b26\u53f7 plt.figure(figsize=(9,4)) plt.plot(list(range(5)), [5]*5, 'r.-', label=\"(r.-)\\t\\t\\t \u7ea2\u8272,\\t \u5c0f\u5706\u70b9,\\t \u76f4\u7ebf\") plt.plot(list(range(5)), [4]*5, 'go--', label=\"(go--)\u7eff\u8272,\\t \u5927\u5706\u70b9,\\t \u865a\u7ebf\") plt.plot(list(range(5)), [3]*5, 'k+-.', label=\"(k+-.) \u9ed1\u8272,\\t \u5341\u5b57\u70b9,\\t \u70b9\u865a\u7ebf\") plt.plot(list(range(5)), [2]*5, 'c*:', label=\"(c*:)\\t\\t\u9752\u8272,\\t \u661f\u53f7,\\t \u5bc6\u96c6\u70b9\u7ebf\") plt.plot(list(range(5)), [1]*5, 'bs', label=\"(bs)\\t\\t \u84dd\u8272,\\t \u65b9\u5757,\\t (\u4e0d\u8fde\u7ebf)\") plt.annotate(\"\u66f4\u591a\u683c\u5f0f\u8bf7\u53c2\u8003:\\n https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html\",             xy=(0.0, 4.1), fontsize=14) plt.legend(loc='lower right', prop={'size': 18}) # bbox_to_anchor=(1, -0.1) # plt.savefig(\"images/pic2_1.png\") plt.show()                      Figure                  In\u00a0[29]: Copied! <pre># \u753b\u4e24\u4e2a\u56fe\uff08\u4e24\u4e2a\u5750\u6807\u7cfbAxes\uff0c\u4e00\u4e2a\u753b\u9762Figure\uff09\n# Matlab\u8bed\u6cd5\uff08\u6a2a\u5411\u6392\u5217\uff09\nplt.figure(figsize=(9, 3)) # \u753b\u9762\u5927\u5c0f(\u957f 9 \u82f1\u5bf8, \u9ad8 3 \u82f1\u5bf8)\nplt.subplot(121)  # 1\u884c2\u5217\u7b2c1\u4e2a\u56fe\nplt.bar(seasons, stock1, label=\"\u80a1\u7968\u4ee3\u7801: abc\")\nplt.subplot(122)  # 1\u884c2\u5217\u7b2c2\u4e2a\u56fe\nplt.plot(seasons, stock2, \"b^--\", label=\"\u80a1\u7968\u4ee3\u7801: def\")\n# plt.savefig(\"images/pic2_2.png\")\nplt.show()\n</pre> # \u753b\u4e24\u4e2a\u56fe\uff08\u4e24\u4e2a\u5750\u6807\u7cfbAxes\uff0c\u4e00\u4e2a\u753b\u9762Figure\uff09 # Matlab\u8bed\u6cd5\uff08\u6a2a\u5411\u6392\u5217\uff09 plt.figure(figsize=(9, 3)) # \u753b\u9762\u5927\u5c0f(\u957f 9 \u82f1\u5bf8, \u9ad8 3 \u82f1\u5bf8) plt.subplot(121)  # 1\u884c2\u5217\u7b2c1\u4e2a\u56fe plt.bar(seasons, stock1, label=\"\u80a1\u7968\u4ee3\u7801: abc\") plt.subplot(122)  # 1\u884c2\u5217\u7b2c2\u4e2a\u56fe plt.plot(seasons, stock2, \"b^--\", label=\"\u80a1\u7968\u4ee3\u7801: def\") # plt.savefig(\"images/pic2_2.png\") plt.show()                      Figure                  In\u00a0[31]: Copied! <pre># \u753b\u4e24\u4e2a\u56fe\uff08\u4e24\u4e2a\u5750\u6807\u7cfbAxes\uff0c\u4e00\u4e2a\u753b\u9762Figure\uff09\n# Matlab\u8bed\u6cd5\uff08\u7eb5\u5411\u6392\u5217\uff09\nplt.figure(figsize=(6, 6))\nplt.subplot(211)\nplt.bar(seasons, stock1, label=\"\u80a1\u7968\u4ee3\u7801: abc\")\nplt.subplot(212)\nplt.plot(seasons, stock2, \"b^--\", label=\"\u80a1\u7968\u4ee3\u7801: def\")\n# plt.savefig(\"images/pic2_3.png\")\nplt.show()\n</pre> # \u753b\u4e24\u4e2a\u56fe\uff08\u4e24\u4e2a\u5750\u6807\u7cfbAxes\uff0c\u4e00\u4e2a\u753b\u9762Figure\uff09 # Matlab\u8bed\u6cd5\uff08\u7eb5\u5411\u6392\u5217\uff09 plt.figure(figsize=(6, 6)) plt.subplot(211) plt.bar(seasons, stock1, label=\"\u80a1\u7968\u4ee3\u7801: abc\") plt.subplot(212) plt.plot(seasons, stock2, \"b^--\", label=\"\u80a1\u7968\u4ee3\u7801: def\") # plt.savefig(\"images/pic2_3.png\") plt.show()                      Figure                  In\u00a0[42]: Copied! <pre># \u9762\u5411\u5bf9\u8c61(Object-oriented programming)\u7cbe\u786e\u8bed\u6cd5\n# fig: \u753b\u9762; axes: 2\u884c2\u5217\u5750\u6807\u7cfb\uff08\u50a8\u5b58\u5728numpy\u6570\u7ec4\u4e2d\uff09\nfig, axes = plt.subplots(2, 2, figsize=(6, 6))\naxes[0, 0].bar(seasons, stock1)  # \u5de6\u4e0a\u89d2(0\u884c0\u5217)\u5750\u6807\u7cfb\naxes[0, 1].plot(seasons, stock2, \"b^--\")  # \u53f3\u4e0a\u89d2(0\u884c1\u5217)\u5750\u6807\u7cfb\nax = axes[1, 0]  # \u5de6\u4e0b\u89d2(1\u884c0\u5217)\u5750\u6807\u7cfb\n# \u5de6\u4e0b\u89d2\u753b\u6563\u70b9\u56fe(scatterplots)\nax.scatter(seasons, # \u5b63\u5ea6\uff08\u6a2a\u5750\u6807\uff09\n           stock2-stock1,  # \u80a1\u7968\u5dee\u4ef7\uff08\u7eb5\u5750\u6807\uff09\n           s=[10, 20, 50, 100], # size\u5b57\u7b26\u5927\u5c0f\n           c=['r', 'b', 'c', 'y']) # color\u989c\u8272\n\naxes[0, 0].set_title(\"\u80a1\u79681\")  # \u5de6\u4e0a\u89d2(0\u884c0\u5217)\u6807\u9898\naxes[0, 1].set_title(\"\u80a1\u79682\")  # \u53f3\u4e0a\u89d2(0\u884c1\u5217)\u6807\u9898\nax.set_ylabel(\"\u5dee\u4ef7(\u80a1\u79681-\u80a1\u79682)\")  # \u5de6\u4e0b\u89d2(1\u884c0\u5217)y\u8f74\u6807\u6ce8\n# plt.savefig(\"images/pic2_4.png\")\nplt.show()\n</pre> # \u9762\u5411\u5bf9\u8c61(Object-oriented programming)\u7cbe\u786e\u8bed\u6cd5 # fig: \u753b\u9762; axes: 2\u884c2\u5217\u5750\u6807\u7cfb\uff08\u50a8\u5b58\u5728numpy\u6570\u7ec4\u4e2d\uff09 fig, axes = plt.subplots(2, 2, figsize=(6, 6)) axes[0, 0].bar(seasons, stock1)  # \u5de6\u4e0a\u89d2(0\u884c0\u5217)\u5750\u6807\u7cfb axes[0, 1].plot(seasons, stock2, \"b^--\")  # \u53f3\u4e0a\u89d2(0\u884c1\u5217)\u5750\u6807\u7cfb ax = axes[1, 0]  # \u5de6\u4e0b\u89d2(1\u884c0\u5217)\u5750\u6807\u7cfb # \u5de6\u4e0b\u89d2\u753b\u6563\u70b9\u56fe(scatterplots) ax.scatter(seasons, # \u5b63\u5ea6\uff08\u6a2a\u5750\u6807\uff09            stock2-stock1,  # \u80a1\u7968\u5dee\u4ef7\uff08\u7eb5\u5750\u6807\uff09            s=[10, 20, 50, 100], # size\u5b57\u7b26\u5927\u5c0f            c=['r', 'b', 'c', 'y']) # color\u989c\u8272  axes[0, 0].set_title(\"\u80a1\u79681\")  # \u5de6\u4e0a\u89d2(0\u884c0\u5217)\u6807\u9898 axes[0, 1].set_title(\"\u80a1\u79682\")  # \u53f3\u4e0a\u89d2(0\u884c1\u5217)\u6807\u9898 ax.set_ylabel(\"\u5dee\u4ef7(\u80a1\u79681-\u80a1\u79682)\")  # \u5de6\u4e0b\u89d2(1\u884c0\u5217)y\u8f74\u6807\u6ce8 # plt.savefig(\"images/pic2_4.png\") plt.show()                      Figure                  In\u00a0[45]: Copied! <pre># \u6539\u8fdb1: \u53bb\u6389\u591a\u4f59\u7684\u5750\u6807\u7cfb\n# \u9762\u5411\u5bf9\u8c61(Object-oriented programming)\u7cbe\u786e\u8bed\u6cd5\nfig, axes = plt.subplots(2, 2, figsize=(6, 6),\n                        facecolor=\"yellow\",  # \u753b\u9762\u80cc\u666f\u6539\u4e3a\u7070\u8272\n                        sharex=True, sharey=True)  # \u5171\u4eabxy\u8f74\u5750\u6807\u7cfb\naxes[0, 0].bar(seasons, stock1)\naxes[0, 1].plot(seasons, stock2, \"b^--\")\nax = axes[1, 0]\nax.plot(seasons, stock2-stock1, \"--\", color=\"black\")\nax.scatter(seasons, stock2-stock1, \n           s=[10, 20, 50, 100],\n           c=['r', 'b', 'c', 'y'])\nax.set_ylabel(\"\u5dee\u4ef7(\u80a1\u79681-\u80a1\u79682)\")\naxes[0, 0].set_title(\"\u80a1\u79681\")\naxes[0, 1].set_title(\"\u80a1\u79682\")\n\n# \u53ef\u4ee5\u5220\u9664\u6700\u540e\u4e00\u4e2a\u5750\u6807\u7cfb\naxes[1, 1].remove()\naxes[0, 0].plot(seasons, stock1, 'r+-')\nfig.suptitle(\"\u80a1\u7968\u5206\u6790\u56fe\")\nfig.supylabel(\"\u80a1\u4ef7\")\nfig.supxlabel(\"\u5b63\u5ea6\")\n# plt.savefig(\"images/pic2_5.png\", facecolor=fig.get_facecolor()) # \u6ce8: \u4fdd\u5b58\u56fe\u7247\u5e95\u8272\u8981\u91cd\u65b0\u8bbe\u7f6e\n</pre> # \u6539\u8fdb1: \u53bb\u6389\u591a\u4f59\u7684\u5750\u6807\u7cfb # \u9762\u5411\u5bf9\u8c61(Object-oriented programming)\u7cbe\u786e\u8bed\u6cd5 fig, axes = plt.subplots(2, 2, figsize=(6, 6),                         facecolor=\"yellow\",  # \u753b\u9762\u80cc\u666f\u6539\u4e3a\u7070\u8272                         sharex=True, sharey=True)  # \u5171\u4eabxy\u8f74\u5750\u6807\u7cfb axes[0, 0].bar(seasons, stock1) axes[0, 1].plot(seasons, stock2, \"b^--\") ax = axes[1, 0] ax.plot(seasons, stock2-stock1, \"--\", color=\"black\") ax.scatter(seasons, stock2-stock1,             s=[10, 20, 50, 100],            c=['r', 'b', 'c', 'y']) ax.set_ylabel(\"\u5dee\u4ef7(\u80a1\u79681-\u80a1\u79682)\") axes[0, 0].set_title(\"\u80a1\u79681\") axes[0, 1].set_title(\"\u80a1\u79682\")  # \u53ef\u4ee5\u5220\u9664\u6700\u540e\u4e00\u4e2a\u5750\u6807\u7cfb axes[1, 1].remove() axes[0, 0].plot(seasons, stock1, 'r+-') fig.suptitle(\"\u80a1\u7968\u5206\u6790\u56fe\") fig.supylabel(\"\u80a1\u4ef7\") fig.supxlabel(\"\u5b63\u5ea6\") # plt.savefig(\"images/pic2_5.png\", facecolor=fig.get_facecolor()) # \u6ce8: \u4fdd\u5b58\u56fe\u7247\u5e95\u8272\u8981\u91cd\u65b0\u8bbe\u7f6e Out[45]: <pre>Text(0.5, 0.01, '\u5b63\u5ea6')</pre>                      Figure                  In\u00a0[18]: Copied! <pre># \u6539\u8fdb2: \u5229\u7528\u53f3\u4e0b\u89d2\u753b\u4e00\u4e2a3d\u56fe\u753b\n# \u9762\u5411\u5bf9\u8c61OOP\u7cbe\u786e\u8bed\u6cd5\nfig, axes = plt.subplots(2, 2, figsize=(6, 6),\n                        facecolor=\"grey\",\n                        sharex=True, sharey=True)\naxes[0, 0].bar(seasons, stock1)\naxes[0, 1].plot(seasons, stock2, \"b^--\")\nax = axes[1, 0]\nax.scatter(seasons, stock2-stock1,\n           s=[10, 20, 50, 100],\n           c=['r', 'b', 'c', 'y'])\nax.plot(seasons, stock2-stock1, \"--\", color=\"black\")\nax.set_ylabel(\"\u5dee\u4ef7(\u80a1\u79681-\u80a1\u79682)\")\naxes[0, 0].plot(seasons, stock1, 'r+-')\nfig.suptitle(\"\u80a1\u7968\u5206\u6790\u56fe\")\nfig.supylabel(\"\u80a1\u4ef7\")\nfig.supxlabel(\"\u5b63\u5ea6\")\naxes[0, 0].set_title(\"\u80a1\u79681\")\naxes[0, 1].set_title(\"\u80a1\u79682\")\n\n# \u5220\u9664\u53f3\u4e0b\u89d2\u5750\u6807\u7cfb\naxes[1, 1].remove()\n# \u91cd\u65b0\u6dfb\u52a0\u53f3\u4e0b\u89d2\u5750\u6807\u7cfb\uff08\u6539\u53d8\u4e3a\u4e09\u7ef4\u5750\u6807\u7cfb\uff09\nax = fig.add_subplot(2, 2, 4, \n                     projection='3d', facecolor=\"grey\")\nax.stem(seasons, stock1, stock2-stock1)\nax.stem(seasons, stock1, stock2-stock1, \n        linefmt='k--', basefmt='k--', \n        bottom=10, orientation='y')\nax.plot_surface(np.array([1,1,4,4]).reshape(2,2),\n                np.array([2.5,10,2.5,10]).reshape(2,2),\n                np.array([0]*4).reshape(2,2), \n                alpha=0.2, color='red')\nax.plot_surface(np.array([1,1,4,4]).reshape(2,2),\n                np.array([10]*4).reshape(2,2),\n                np.array([-2.5,8,-2.5,8]).reshape(2,2),\n                alpha=0.2, color='black')\nax.set_xlabel(\"\u5b63\u5ea6(x)\")\nax.set_ylabel(\"\u80a1\u79681(y)\")\nax.set_zlabel(\"\u5dee\u4ef7(z)\")\n# plt.savefig(\"images/pic2_6.png\", facecolor=fig.get_facecolor())\nplt.show()\n</pre> # \u6539\u8fdb2: \u5229\u7528\u53f3\u4e0b\u89d2\u753b\u4e00\u4e2a3d\u56fe\u753b # \u9762\u5411\u5bf9\u8c61OOP\u7cbe\u786e\u8bed\u6cd5 fig, axes = plt.subplots(2, 2, figsize=(6, 6),                         facecolor=\"grey\",                         sharex=True, sharey=True) axes[0, 0].bar(seasons, stock1) axes[0, 1].plot(seasons, stock2, \"b^--\") ax = axes[1, 0] ax.scatter(seasons, stock2-stock1,            s=[10, 20, 50, 100],            c=['r', 'b', 'c', 'y']) ax.plot(seasons, stock2-stock1, \"--\", color=\"black\") ax.set_ylabel(\"\u5dee\u4ef7(\u80a1\u79681-\u80a1\u79682)\") axes[0, 0].plot(seasons, stock1, 'r+-') fig.suptitle(\"\u80a1\u7968\u5206\u6790\u56fe\") fig.supylabel(\"\u80a1\u4ef7\") fig.supxlabel(\"\u5b63\u5ea6\") axes[0, 0].set_title(\"\u80a1\u79681\") axes[0, 1].set_title(\"\u80a1\u79682\")  # \u5220\u9664\u53f3\u4e0b\u89d2\u5750\u6807\u7cfb axes[1, 1].remove() # \u91cd\u65b0\u6dfb\u52a0\u53f3\u4e0b\u89d2\u5750\u6807\u7cfb\uff08\u6539\u53d8\u4e3a\u4e09\u7ef4\u5750\u6807\u7cfb\uff09 ax = fig.add_subplot(2, 2, 4,                       projection='3d', facecolor=\"grey\") ax.stem(seasons, stock1, stock2-stock1) ax.stem(seasons, stock1, stock2-stock1,          linefmt='k--', basefmt='k--',          bottom=10, orientation='y') ax.plot_surface(np.array([1,1,4,4]).reshape(2,2),                 np.array([2.5,10,2.5,10]).reshape(2,2),                 np.array([0]*4).reshape(2,2),                  alpha=0.2, color='red') ax.plot_surface(np.array([1,1,4,4]).reshape(2,2),                 np.array([10]*4).reshape(2,2),                 np.array([-2.5,8,-2.5,8]).reshape(2,2),                 alpha=0.2, color='black') ax.set_xlabel(\"\u5b63\u5ea6(x)\") ax.set_ylabel(\"\u80a1\u79681(y)\") ax.set_zlabel(\"\u5dee\u4ef7(z)\") # plt.savefig(\"images/pic2_6.png\", facecolor=fig.get_facecolor()) plt.show()                      Figure                  In\u00a0[10]: Copied! <pre># \u6539\u8fdb3: \u5750\u6807\u7cfb\u6539\u53d8\u80cc\u666f\u989c\u8272\uff0c\u4e0e3D\u56fe\u7247\u4e2d\u7684\u6295\u5f71\u6784\u6210\u5bf9\u5e94\u5173\u7cfb\n# \u9762\u5411\u5bf9\u8c61OOP\u7cbe\u786e\u8bed\u6cd5\nfig, axes = plt.subplots(2, 2, figsize=(6, 6),\n                        facecolor=\"grey\",\n                        sharex=True, sharey=True,\n                        frameon=True)\naxes[0, 0].bar(seasons, stock1)\naxes[0, 1].plot(seasons, stock2, \"b^--\")\nax = axes[1, 0]\nax.scatter(seasons, stock2-stock1, \n                   s=[10, 20, 50, 100],\n                   c=['r', 'b', 'c', 'y'])\nax.plot(seasons, stock2-stock1, \"--\", color=\"black\")\nax.set_ylabel(\"\u5dee\u4ef7(\u80a1\u79681-\u80a1\u79682)\")\naxes[0, 0].plot(seasons, stock1, 'r+-')\nfig.suptitle(\"\u80a1\u7968\u5206\u6790\u56fe\")\nfig.supylabel(\"\u80a1\u4ef7\")\nfig.supxlabel(\"\u5b63\u5ea6\")\naxes[0, 0].set_title(\"\u80a1\u79681\")\naxes[0, 1].set_title(\"\u80a1\u79682\")\n\naxes[1, 1].remove()\nax = fig.add_subplot(2, 2, 4, \n                     projection='3d', facecolor=\"grey\")\nax.stem(seasons, stock1, stock2-stock1)\nax.stem(seasons, stock1, stock2-stock1, \n        linefmt='k--', basefmt='k--', \n        bottom=10, orientation='y')\nax.plot_surface(np.array([1,1,4,4]).reshape(2,2),\n                np.array([2.5,10,2.5,10]).reshape(2,2),\n                np.array([0]*4).reshape(2,2), \n                alpha=0.2, color='red')\nax.plot_surface(np.array([1,1,4,4]).reshape(2,2),\n                np.array([10]*4).reshape(2,2),\n                np.array([-2.5,8,-2.5,8]).reshape(2,2),\n                alpha=0.2, color='black')\nax.set_xlabel(\"\u5b63\u5ea6(x)\")\nax.set_ylabel(\"\u80a1\u79681(y)\")\nax.set_zlabel(\"\u5dee\u4ef7(z)\")\n\n# \u6539\u53d8\u5750\u6807\u7cfb\u7684\u80cc\u666f\u989c\u8272\uff08\u5728\u753b\u56fe\u540e\u6539\u53d8\u5c5e\u6027\uff0cOOP\uff09\naxes[1, 0].set_facecolor('grey')\naxes[1, 0].patch.set_alpha(0.2)\naxes[0, 0].set_facecolor('red')\naxes[0, 0].patch.set_alpha(0.2)\nplt.tight_layout()\n\n# plt.savefig(\"images/pic2_7.png\", facecolor=fig.get_facecolor())\nplt.show()\n</pre> # \u6539\u8fdb3: \u5750\u6807\u7cfb\u6539\u53d8\u80cc\u666f\u989c\u8272\uff0c\u4e0e3D\u56fe\u7247\u4e2d\u7684\u6295\u5f71\u6784\u6210\u5bf9\u5e94\u5173\u7cfb # \u9762\u5411\u5bf9\u8c61OOP\u7cbe\u786e\u8bed\u6cd5 fig, axes = plt.subplots(2, 2, figsize=(6, 6),                         facecolor=\"grey\",                         sharex=True, sharey=True,                         frameon=True) axes[0, 0].bar(seasons, stock1) axes[0, 1].plot(seasons, stock2, \"b^--\") ax = axes[1, 0] ax.scatter(seasons, stock2-stock1,                     s=[10, 20, 50, 100],                    c=['r', 'b', 'c', 'y']) ax.plot(seasons, stock2-stock1, \"--\", color=\"black\") ax.set_ylabel(\"\u5dee\u4ef7(\u80a1\u79681-\u80a1\u79682)\") axes[0, 0].plot(seasons, stock1, 'r+-') fig.suptitle(\"\u80a1\u7968\u5206\u6790\u56fe\") fig.supylabel(\"\u80a1\u4ef7\") fig.supxlabel(\"\u5b63\u5ea6\") axes[0, 0].set_title(\"\u80a1\u79681\") axes[0, 1].set_title(\"\u80a1\u79682\")  axes[1, 1].remove() ax = fig.add_subplot(2, 2, 4,                       projection='3d', facecolor=\"grey\") ax.stem(seasons, stock1, stock2-stock1) ax.stem(seasons, stock1, stock2-stock1,          linefmt='k--', basefmt='k--',          bottom=10, orientation='y') ax.plot_surface(np.array([1,1,4,4]).reshape(2,2),                 np.array([2.5,10,2.5,10]).reshape(2,2),                 np.array([0]*4).reshape(2,2),                  alpha=0.2, color='red') ax.plot_surface(np.array([1,1,4,4]).reshape(2,2),                 np.array([10]*4).reshape(2,2),                 np.array([-2.5,8,-2.5,8]).reshape(2,2),                 alpha=0.2, color='black') ax.set_xlabel(\"\u5b63\u5ea6(x)\") ax.set_ylabel(\"\u80a1\u79681(y)\") ax.set_zlabel(\"\u5dee\u4ef7(z)\")  # \u6539\u53d8\u5750\u6807\u7cfb\u7684\u80cc\u666f\u989c\u8272\uff08\u5728\u753b\u56fe\u540e\u6539\u53d8\u5c5e\u6027\uff0cOOP\uff09 axes[1, 0].set_facecolor('grey') axes[1, 0].patch.set_alpha(0.2) axes[0, 0].set_facecolor('red') axes[0, 0].patch.set_alpha(0.2) plt.tight_layout()  # plt.savefig(\"images/pic2_7.png\", facecolor=fig.get_facecolor()) plt.show()                      Figure                  In\u00a0[46]: Copied! <pre>fig, axes = plt.subplots(2, 2, figsize=(6, 6),\n                        facecolor=\"grey\",\n                        sharex=True, sharey=True,\n                        frameon=True)\naxes[0, 0].bar(seasons, stock1)\naxes[0, 1].plot(seasons, stock2, \"b^--\")\n\nax = axes[1, 0]\nax.scatter(seasons, stock2-stock1, \n                   s=[10, 20, 50, 100],\n                   c=['r', 'b', 'c', 'y'])\nax.plot(seasons, stock2-stock1, \"--\", color=\"black\")\n</pre> fig, axes = plt.subplots(2, 2, figsize=(6, 6),                         facecolor=\"grey\",                         sharex=True, sharey=True,                         frameon=True) axes[0, 0].bar(seasons, stock1) axes[0, 1].plot(seasons, stock2, \"b^--\")  ax = axes[1, 0] ax.scatter(seasons, stock2-stock1,                     s=[10, 20, 50, 100],                    c=['r', 'b', 'c', 'y']) ax.plot(seasons, stock2-stock1, \"--\", color=\"black\") Out[46]: <pre>[&lt;matplotlib.lines.Line2D at 0x7fd46314a340&gt;]</pre>                      Figure                  In\u00a0[15]: Copied! <pre>stock1, stock2\n</pre> stock1, stock2 Out[15]: <pre>(array([4, 8, 2, 6]), array([10, 12,  5,  3]))</pre> In\u00a0[3]: Copied! <pre># \u6b65\u9aa4 1. \u5bfc\u5165\u5305\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl  # \u6574\u4e2a\u5305\nimport numpy as np\n</pre> # \u6b65\u9aa4 1. \u5bfc\u5165\u5305 import matplotlib.pyplot as plt import matplotlib as mpl  # \u6574\u4e2a\u5305 import numpy as np In\u00a0[4]: Copied! <pre># \u6b65\u9aa4 2. \u67e5\u8be2\u6240\u6709\u753b\u56fe\u6574\u4f53\u98ce\u683c\n# print(plt.style.available)\nplt.style.use('default')  # \u9ed8\u8ba4\u98ce\u683c\nplt.plot(np.random.randn(50))\nplt.title(\"default style\")\n# plt.savefig(\"images/style_1.png\", facecolor=plt.gcf().get_facecolor())\nplt.show()\n\nplt.style.use('ggplot')\nplt.plot(np.random.randn(50))\nplt.title(\"ggplot style\")\n# plt.savefig(\"images/style_2.png\", facecolor=plt.gcf().get_facecolor())\nplt.show()\n\nplt.style.use('seaborn-dark')\nplt.plot(np.random.randn(50))\nplt.title(\"seaborn-dark\")\n# plt.gcf().savefig(\"images/style_3.png\", facecolor=plt.gcf().get_facecolor())\nplt.show()\nplt.style.use('default')  # \u91cd\u65b0\u8bbe\u7f6e\u56de\u9ed8\u8ba4\u98ce\u683c\n</pre> # \u6b65\u9aa4 2. \u67e5\u8be2\u6240\u6709\u753b\u56fe\u6574\u4f53\u98ce\u683c # print(plt.style.available) plt.style.use('default')  # \u9ed8\u8ba4\u98ce\u683c plt.plot(np.random.randn(50)) plt.title(\"default style\") # plt.savefig(\"images/style_1.png\", facecolor=plt.gcf().get_facecolor()) plt.show()  plt.style.use('ggplot') plt.plot(np.random.randn(50)) plt.title(\"ggplot style\") # plt.savefig(\"images/style_2.png\", facecolor=plt.gcf().get_facecolor()) plt.show()  plt.style.use('seaborn-dark') plt.plot(np.random.randn(50)) plt.title(\"seaborn-dark\") # plt.gcf().savefig(\"images/style_3.png\", facecolor=plt.gcf().get_facecolor()) plt.show() plt.style.use('default')  # \u91cd\u65b0\u8bbe\u7f6e\u56de\u9ed8\u8ba4\u98ce\u683c In\u00a0[5]: Copied! <pre># \u67e5\u8be2\u5f53\u524d\u7684\u4e00\u4e9b\u753b\u56fe\u5c5e\u6027\u8bbe\u7f6e\nprint(mpl.rcParams.get('figure.figsize'))  # \u5f53\u524d\u56fe\u753b\u5927\u5c0f\uff08\u957f*\u9ad8\uff09\uff08\u82f1\u5bf8\uff09\nprint(mpl.rcParams.get('font.size'))  # \u5f53\u524d\u5b57\u4f53\u5927\u5c0f\n</pre> # \u67e5\u8be2\u5f53\u524d\u7684\u4e00\u4e9b\u753b\u56fe\u5c5e\u6027\u8bbe\u7f6e print(mpl.rcParams.get('figure.figsize'))  # \u5f53\u524d\u56fe\u753b\u5927\u5c0f\uff08\u957f*\u9ad8\uff09\uff08\u82f1\u5bf8\uff09 print(mpl.rcParams.get('font.size'))  # \u5f53\u524d\u5b57\u4f53\u5927\u5c0f <pre>[6.4, 4.8]\n10.0\n</pre> In\u00a0[12]: Copied! <pre># \u4f8b\u5b50\uff1a\u67e5\u8be2\u5f53\u524d\u4f60\u7684\u8ba1\u7b97\u673a\u4e2dmatplotlib\u7684\u53ef\u7528\u5b57\u4f53\nimport matplotlib.font_manager as fm\n\nfm._load_fontmanager(try_read_cache=False)\nfpaths = fm.findSystemFonts(fontpaths=None)\n# print(fpaths)\nexempt_lst = [\"NISC18030.ttf\", \"Emoji\"]\nskip=False\nfor i in fpaths:\n    # print(i)\n    for ft in exempt_lst:\n        if ft in i:\n            skip=True\n    if skip==True:\n        skip=False\n        continue\n    f = matplotlib.font_manager.get_font(i)\n    print(f.family_name)\n</pre> # \u4f8b\u5b50\uff1a\u67e5\u8be2\u5f53\u524d\u4f60\u7684\u8ba1\u7b97\u673a\u4e2dmatplotlib\u7684\u53ef\u7528\u5b57\u4f53 import matplotlib.font_manager as fm  fm._load_fontmanager(try_read_cache=False) fpaths = fm.findSystemFonts(fontpaths=None) # print(fpaths) exempt_lst = [\"NISC18030.ttf\", \"Emoji\"] skip=False for i in fpaths:     # print(i)     for ft in exempt_lst:         if ft in i:             skip=True     if skip==True:         skip=False         continue     f = matplotlib.font_manager.get_font(i)     print(f.family_name) <pre>Zapf Dingbats\nSTIXNonUnicode\nNoto Sans Newa\nNoto Sans Old Turkic\nNoto Sans Hatran\nNoto Sans Miao\nNoto Sans Ugaritic\nApple Symbols\n.Aqua Kana\nArial Unicode MS\nHerculanum\nBodoni Ornaments\n.SF NS Mono\nNoto Sans Chakma\nMishafi\nSTIXIntegralsSm\nCorsiva Hebrew\nKannada MN\nNoto Sans Pau Cin Hau\nNoto Sans Pahawh Hmong\nHiragino Sans\nNoto Sans Kaithi\nNoto Sans Mongolian\nPingFang HK\nNoto Sans Syriac\nArial Unicode MS\nSTIXGeneral\nSTIXIntegralsD\nArial\nTrebuchet MS\nTimes New Roman\nKhmer MN\nNoto Sans Buhid\nGurmukhi MN\nLuminari\nSTIXNonUnicode\nTimes New Roman\nNoto Sans Glagolitic\nSTIXIntegralsSm\nNoto Sans Rejang\nSTIXSizeTwoSym\nWaseem\nSTIXIntegralsD\nNoto Sans Sundanese\nSTIXSizeFiveSym\nSTIXVariants\nApple SD Gothic Neo\nNoto Sans Bhaiksuki\nHoefler Text\nCharter\nTrebuchet MS\nSTIXGeneral\nNoto Sans Linear B\nNoto Serif Ahom\nNoto Sans Elbasan\nNoto Sans Mahajani\nNoto Sans Tai Le\nBaghdad\nNoto Sans Hanunoo\nSTIXSizeFourSym\nSukhumvit Set\nNoto Sans Inscriptional Pahlavi\nNoto Sans Myanmar\nComic Sans MS\nNoto Sans Warang Citi\nApple Chancery\nSkia\nHiragino Sans\nNoto Sans Bamum\nAppleMyungjo\nHeiti TC\nDidot\n.New York\nGujarati MT\nNoto Sans Lisu\nNoto Sans Inscriptional Parthian\nArial\nBodoni 72 Oldstyle\nNoto Sans Ogham\nNoto Sans Lydian\nArial Narrow\nNoto Sans Kayah Li\nKohinoor Telugu\nApple Braille\nHiragino Sans\nSeravek\nApple Braille\nCourier New\nSinhala Sangam MN\n.SF Compact\nMarion\nNoto Sans Kannada\nNoto Sans Carian\nNoto Sans Tagbanwa\nMuna\nComic Sans MS\n.LastResort\nKohinoor Bangla\nHeiti TC\nWingdings\nCourier New\nAvenir Next Condensed\nAppleGothic\nBig Caslon\nBodoni 72\nSTIXSizeOneSym\nSTIXIntegralsUpD\nSTIXIntegralsUp\nKrungthep\nNoto Sans Lepcha\nNoto Sans Hanifi Rohingya\nIowan Old Style\nTimes\n.SF Compact Rounded\nAthelas\nNoto Sans Bassa Vah\nKufiStandardGK\nVerdana\nDiwan Kufi\nGill Sans\nNoto Sans Old Italic\nNoto Sans Old Hungarian\nRaanana\nNoto Sans Buginese\nNoto Sans Osmanya\nDIN Alternate\nNoto Sans Meroitic\nAyuthaya\nVerdana\nSTIXIntegralsUp\nSTIXSizeTwoSym\nRockwell\nTrattatello\n.SF NS Rounded\nOriya Sangam MN\nSignPainter\nNoto Sans Caucasian Albanian\nTamil Sangam MN\nNoto Sans PhagsPa\nNoto Sans Oriya\nNoto Sans Brahmi\nNoto Sans Thaana\nNoto Sans Duployan\nCopperplate\nNoto Sans Sharada\nNoto Sans Yi\nNoto Sans Khudawadi\nThonburi\nInaiMathi\nArial Narrow\nKannada Sangam MN\nTrebuchet MS\nSystem Font\nPapyrus\nApple Braille\nNoto Serif Myanmar\nTamil MN\nTahoma\nKohinoor Devanagari\nNoto Sans Tifinagh\nNoto Sans Osage\nDevanagari Sangam MN\nNoto Sans Kharoshthi\nCourier New\nMyanmar MN\nSilom\nHiragino Sans\nNoto Sans Mende Kikakui\nSTIXSizeThreeSym\nCochin\nPlantagenet Cherokee\nNoto Sans Tai Viet\n.Keyboard\nNoto Sans Psalter Pahlavi\nHiragino Sans\nNoto Sans Tai Tham\nNoto Sans Adlam\nMukta Mahee\nArial Narrow\nNoteworthy\n.New York\nHiragino Sans\nAcademy Engraved LET\nChalkduster\nTahoma\nSTIXIntegralsUpSm\nSnell Roundhand\nNoto Sans Ol Chiki\nAndale Mono\nTimes New Roman\nChalkboard SE\nHoefler Text\nBeirut\nNoto Sans Linear A\nSTIXIntegralsUpSm\nNoto Sans Phoenician\nSTIXNonUnicode\nNoto Sans Samaritan\nCourier New\nHiragino Sans\nNoto Sans Modi\nGujarati Sangam MN\nSinhala MN\nNoto Sans Meetei Mayek\nHiragino Sans GB\nEuphemia UCAS\nDevanagari MT\nBrush Script MT\nDamascus\nDIN Condensed\nKhmer Sangam MN\nGeeza Pro\nSTIXGeneral\nArial Narrow\n.SF NS Mono\nNoto Sans Cypriot\nVerdana\nNoto Sans Imperial Aramaic\nOptima\nNoto Sans Khojki\nNoto Sans Limbu\nSongti SC\nNoto Sans Gothic\nVerdana\nGeorgia\nNoto Sans Coptic\nNoto Sans Old Permic\nPalatino\nKokonor\n.SF Compact\nITF Devanagari\nKailasa\nPT Mono\nHelvetica Neue\nSTIXVariants\nAmerican Typewriter\nApple Braille\nNoto Sans Armenian\nTrebuchet MS\nGurmukhi MT\nWingdings 3\nArial Hebrew\nNoto Sans Sora Sompeng\nNoto Sans Egyptian Hieroglyphs\nNoto Sans Old North Arabian\nShree Devanagari 714\nBangla Sangam MN\nNoto Sans Javanese\nNoto Sans Runic\nSymbol\nNoto Sans Takri\nLucida Grande\nHiragino Sans\nMalayalam MN\nZapfino\nSTIXSizeOneSym\nNoto Sans Siddham\nBradley Hand\nNew Peninim MT\nSTIXSizeFourSym\nGeorgia\nArial\nApple Braille\nNoto Sans Wancho\nSathu\nNoto Sans Multani\nTelugu Sangam MN\nNoto Sans Marchen\nAl Bayan\nNoto Sans Mandaic\nBangla MN\nPT Serif\nNoto Sans Syloti Nagri\nSavoye LET\nHelvetica\nSTIXIntegralsUpD\nMishafi Gold\nHiragino Maru Gothic Pro\nMicrosoft Sans Serif\nGurmukhi Sangam MN\nTimes New Roman\nChalkboard\nNoto Sans Shavian\nSTIXNonUnicode\nNoto Sans Avestan\nNoto Serif Balinese\nSana\nNoto Sans Tirhuta\n.Arabic UI Text\nMarker Felt\nSTIXSizeThreeSym\nFarisi\nAl Tarikh\nKohinoor Gujarati\nSuperclarendon\nKefa\nBodoni 72 Smallcaps\nMshtakan\nNoto Sans Cham\nNoto Sans Nabataean\nFarah\nDecoType Naskh\nNoto Sans Lycian\nArial\nPT Serif Caption\nBaskerville\nNoto Sans NKo\nHiragino Sans\nNoto Sans Old Persian\nSTIXGeneral\nOriya MN\nHiragino Sans\nSystem Font\nArial Rounded MT Bold\nNoto Sans Cuneiform\nTelugu MN\nGalvji\nAvenir\nMenlo\n.Arabic UI Display\nPhosphate\nMyanmar Sangam MN\nNoto Sans Vai\nArial Black\nDiwan Thuluth\nNoto Sans New Tai Lue\nFutura\nNoto Sans Tagalog\nParty LET\nLao Sangam MN\nLao MN\nNoto Nastaliq Urdu\nWingdings 2\nAvenir Next\nNadeem\nAl Nile\nHiragino Mincho ProN\nMalayalam Sangam MN\nNoto Sans Manichaean\nPT Sans\nWebdings\nNoto Sans Palmyrene\nImpact\nNoto Sans Batak\nNoto Sans Old South Arabian\nGeorgia\nNoto Sans Saurashtra\nGeorgia\nNoto Sans Mro\n</pre> In\u00a0[5]: Copied! <pre>import matplotlib as mpl\n# step 2. \u4e00\u4e9b\u5e38\u7528\u8bbe\u5b9a\u53c2\u6570\n# \u8bbe\u7f6e\u5b57\u4f53(\u4e3b\u8981\u5b57\u4f53/\u6570\u5b66\u516c\u5f0f\u5b57\u7b26\u96c6)\nrc = {\"font.family\" : \"Times New Roman\",  # \u9ed8\u8ba4\u5b57\u4f53\n      \"mathtext.fontset\" : \"stix\",  # \u6570\u5b66\u5b57\u7b26\u96c6\n      }\nmpl.rcParams.update(rc) # \u6839\u636edict\u4e00\u6b21\u6027\u66f4\u65b0\u5f88\u591a\u53c2\u6570\n# \u8bbe\u7f6e\u56fe\u7247\u6e05\u6670\u5ea6\uff08300dpi\uff09\nmpl.rcParams['figure.dpi'] = 300\n# \u56fe\u753b\u9762\u677f\u8c03\u6574\u4e3a\u767d\u8272\nmpl.rcParams['axes.facecolor'] = 'white'\nmpl.rcParams['savefig.facecolor'] = 'white'\n# Figure\u81ea\u52a8\u8c03\u6574\u683c\u5f0f\nplt.rcParams['figure.constrained_layout.use'] = True\n</pre> import matplotlib as mpl # step 2. \u4e00\u4e9b\u5e38\u7528\u8bbe\u5b9a\u53c2\u6570 # \u8bbe\u7f6e\u5b57\u4f53(\u4e3b\u8981\u5b57\u4f53/\u6570\u5b66\u516c\u5f0f\u5b57\u7b26\u96c6) rc = {\"font.family\" : \"Times New Roman\",  # \u9ed8\u8ba4\u5b57\u4f53       \"mathtext.fontset\" : \"stix\",  # \u6570\u5b66\u5b57\u7b26\u96c6       } mpl.rcParams.update(rc) # \u6839\u636edict\u4e00\u6b21\u6027\u66f4\u65b0\u5f88\u591a\u53c2\u6570 # \u8bbe\u7f6e\u56fe\u7247\u6e05\u6670\u5ea6\uff08300dpi\uff09 mpl.rcParams['figure.dpi'] = 300 # \u56fe\u753b\u9762\u677f\u8c03\u6574\u4e3a\u767d\u8272 mpl.rcParams['axes.facecolor'] = 'white' mpl.rcParams['savefig.facecolor'] = 'white' # Figure\u81ea\u52a8\u8c03\u6574\u683c\u5f0f plt.rcParams['figure.constrained_layout.use'] = True In\u00a0[16]: Copied! <pre># \u4f8b\u5b50. \u4e2d\u82f1\u6587/\u6570\u5b66\u7b26\u53f7\u6df7\u6392\nfig, ax = plt.subplots()\n# \u5355\u72ec\u6dfb\u52a0\u5b57\u4f53\nst_font = fm.FontProperties(fname=\"/System/Library/Fonts/Supplemental/Songti.ttc\")\n# \u6ce8(\u7406\u8bba\u4e0a): SC: \u7b80\u4f53\u4e2d\u6587; TC: \u7e41\u4f53\u4e2d\u6587;\n# \u5b9e\u9645\u4e0a\u4e00\u822c\u5e94\u8be5\u662f\u4f7f\u7528Heiti TC\u5373\u53ef\uff08\u6240\u89c1\u5373\u6240\u5f97\uff09\nax.set_xlabel(r'\u4e4c\u9f9f\u70cf\u9f9c/\u5bc6\u5ea6$\\mathrm{kg/m}^3$',\n              fontname = 'Heiti TC', fontsize=20)  # \u5355\u72ec\u6307\u5b9a\u5b57\u4f53\u5927\u5c0f\u4e0e\u683c\u5f0f\nax.text(0.2, 0.8, r'\u4e4c\u9f9f\u70cf\u9f9c/\u9ed1\u4f53 $\\mathrm{Times New Roman}$',\n        fontname='Heiti TC', fontsize=20)\n# \u76ee\u524d\u5176\u4ed6\u5b57\u4f53\u652f\u6301\u4e5f\u6bd4\u8f83\u6709\u9650\u3002\u3002\u3002\u5982\u8fd9\u91cc\u5b8b\u4f53\u6ca1\u6709\u7e41\u4f53\nax.text(0.2, 0.6, r'\u4e4c\u9f9f\u70cf\u9f9c/\u5b8b\u4f53 $Times New Roman$', \n        fontproperties=st_font, fontsize=30)\nplt.ylim(0.5, 0.9)\n\n# plt.savefig(\"images/pic3_1.png\", facecolor=fig.get_facecolor())\nplt.show()\n</pre> # \u4f8b\u5b50. \u4e2d\u82f1\u6587/\u6570\u5b66\u7b26\u53f7\u6df7\u6392 fig, ax = plt.subplots() # \u5355\u72ec\u6dfb\u52a0\u5b57\u4f53 st_font = fm.FontProperties(fname=\"/System/Library/Fonts/Supplemental/Songti.ttc\") # \u6ce8(\u7406\u8bba\u4e0a): SC: \u7b80\u4f53\u4e2d\u6587; TC: \u7e41\u4f53\u4e2d\u6587; # \u5b9e\u9645\u4e0a\u4e00\u822c\u5e94\u8be5\u662f\u4f7f\u7528Heiti TC\u5373\u53ef\uff08\u6240\u89c1\u5373\u6240\u5f97\uff09 ax.set_xlabel(r'\u4e4c\u9f9f\u70cf\u9f9c/\u5bc6\u5ea6$\\mathrm{kg/m}^3$',               fontname = 'Heiti TC', fontsize=20)  # \u5355\u72ec\u6307\u5b9a\u5b57\u4f53\u5927\u5c0f\u4e0e\u683c\u5f0f ax.text(0.2, 0.8, r'\u4e4c\u9f9f\u70cf\u9f9c/\u9ed1\u4f53 $\\mathrm{Times New Roman}$',         fontname='Heiti TC', fontsize=20) # \u76ee\u524d\u5176\u4ed6\u5b57\u4f53\u652f\u6301\u4e5f\u6bd4\u8f83\u6709\u9650\u3002\u3002\u3002\u5982\u8fd9\u91cc\u5b8b\u4f53\u6ca1\u6709\u7e41\u4f53 ax.text(0.2, 0.6, r'\u4e4c\u9f9f\u70cf\u9f9c/\u5b8b\u4f53 $Times New Roman$',          fontproperties=st_font, fontsize=30) plt.ylim(0.5, 0.9)  # plt.savefig(\"images/pic3_1.png\", facecolor=fig.get_facecolor()) plt.show() <pre>Font 'default' does not have a glyph for '\\u70cf' [U+70cf], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u9f9c' [U+9f9c], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u70cf' [U+70cf], substituting with a dummy symbol.\nFont 'default' does not have a glyph for '\\u9f9c' [U+9f9c], substituting with a dummy symbol.\n</pre> In\u00a0[19]: Copied! <pre># \u4e09\u4e2a\u201c\u4e09\u89d2\u51fd\u6570\u201d\nx = np.linspace(0, 10, 100)\ny1 = np.cos(x)\ny2 = np.sin(x)\ny3 = np.tanh(x) # tanh\u51fd\u6570\n</pre> # \u4e09\u4e2a\u201c\u4e09\u89d2\u51fd\u6570\u201d x = np.linspace(0, 10, 100) y1 = np.cos(x) y2 = np.sin(x) y3 = np.tanh(x) # tanh\u51fd\u6570 In\u00a0[21]: Copied! <pre># \u753b\u65f6\u95f4\u5e8f\u5217\u66f2\u7ebf\n# \u8f93\u5165/\u8f93\u51fa\u90fd\u5305\u542b\u5750\u6807\u8f74\u53d8\u91cf\ndef plot_time_series(x, y, fmt, lab=\"\", ax=None):\n    if ax is None:\n        fig, ax = plt.subplot()\n    ax.plot(x, y, fmt, label=lab)\n    # x\u8f74\u56fa\u6709\u683c\u5f0f\n    ax.set_xlabel(\"time\")\n    ax.xaxis.set_major_locator(plt.MultipleLocator(np.pi / 2))\n    ax.xaxis.set_minor_locator(plt.MultipleLocator(np.pi / 4))\n    labs = ax.xaxis.get_ticklabels()\n    ax.xaxis.set_ticklabels([r\"{:.2f}$\\pi$\".format(i/2) for i, l in enumerate(labs)])\n    return ax\n\n# \u4e24\u4e2a\u5750\u6807\u5468\nfig, axes = plt.subplots(2, 1, figsize=(6, 3),\n                         sharex=True, facecolor=\"white\")\n# \u5728\u7b2c\u4e00\u4e2a\u5750\u6807\u5468\u753b\u4e24\u6761\u7ebf\nplot_time_series(x, y1, 'b-', r'$y=sin(x)$', ax=axes[0])\nplot_time_series(x, y2, 'r:', r'$y=cos(x)$', ax=axes[0])\n# \u5728\u7b2c\u4e8c\u4e2a\u5750\u6807\u5468\u753b\u4e00\u6761\u7ebf\nplot_time_series(x, y3, 'g--', ax=axes[1])\n\n# plt.savefig(\"images/pic3_2.png\", facecolor=fig.get_facecolor())\nplt.show()\n</pre> # \u753b\u65f6\u95f4\u5e8f\u5217\u66f2\u7ebf # \u8f93\u5165/\u8f93\u51fa\u90fd\u5305\u542b\u5750\u6807\u8f74\u53d8\u91cf def plot_time_series(x, y, fmt, lab=\"\", ax=None):     if ax is None:         fig, ax = plt.subplot()     ax.plot(x, y, fmt, label=lab)     # x\u8f74\u56fa\u6709\u683c\u5f0f     ax.set_xlabel(\"time\")     ax.xaxis.set_major_locator(plt.MultipleLocator(np.pi / 2))     ax.xaxis.set_minor_locator(plt.MultipleLocator(np.pi / 4))     labs = ax.xaxis.get_ticklabels()     ax.xaxis.set_ticklabels([r\"{:.2f}$\\pi$\".format(i/2) for i, l in enumerate(labs)])     return ax  # \u4e24\u4e2a\u5750\u6807\u5468 fig, axes = plt.subplots(2, 1, figsize=(6, 3),                          sharex=True, facecolor=\"white\") # \u5728\u7b2c\u4e00\u4e2a\u5750\u6807\u5468\u753b\u4e24\u6761\u7ebf plot_time_series(x, y1, 'b-', r'$y=sin(x)$', ax=axes[0]) plot_time_series(x, y2, 'r:', r'$y=cos(x)$', ax=axes[0]) # \u5728\u7b2c\u4e8c\u4e2a\u5750\u6807\u5468\u753b\u4e00\u6761\u7ebf plot_time_series(x, y3, 'g--', ax=axes[1])  # plt.savefig(\"images/pic3_2.png\", facecolor=fig.get_facecolor()) plt.show() <pre>/var/folders/71/d5xhvtkn215cb3g26qsjh5q00000gn/T/ipykernel_25617/2196136604.py:12: UserWarning: FixedFormatter should only be used together with FixedLocator\n  ax.xaxis.set_ticklabels([r\"{:.2f}$\\pi$\".format(i/2) for i, l in enumerate(labs)])\n</pre> In\u00a0[23]: Copied! <pre># \u62d3\u5c55\uff1a\u5f88\u591a\u683c\u5f0f\u53ef\u4ee5\u540e\u671f\u518d\u51fd\u6570\u5916\u5904\u7406\ndef plot_time_series(x, y, fmt, lab=\"\", ax=None):\n    if ax is None:\n        fig, ax = plt.subplot()\n    ax.plot(x, y, fmt, label=lab)\n    # x\u8f74\u56fa\u6709\u683c\u5f0f\n    ax.set_xlabel(\"time\")\n    ax.xaxis.set_major_locator(plt.MultipleLocator(np.pi / 2))\n    ax.xaxis.set_minor_locator(plt.MultipleLocator(np.pi / 4))\n    labs = ax.xaxis.get_ticklabels()\n    ax.xaxis.set_ticklabels([r\"{:.2f}$\\pi$\".format(i/2) for i, l in enumerate(labs)])\n    return ax\n\nfig, axes = plt.subplots(2, 1, figsize=(6, 3), \n                         sharex=True, facecolor=\"white\")\nplot_time_series(x, y1, 'b-', r'$y=sin(x)$', axes[0])\nplot_time_series(x, y2, 'r:', r'$y=cos(x)$', axes[0])\nplot_time_series(x, y3, 'g--', ax=axes[1])\n\n# \u540e\u671f\u8c03\u6574\u683c\u5f0f/\u6dfb\u52a0\u5185\u5bb9/\u7f8e\u5316...\naxes[0].set_xlabel(\"\")\naxes[0].legend(loc=\"upper right\")\naxes[1].legend(loc=\"upper right\")\naxes[0].grid()\naxes[1].grid()\n\n# plt.savefig(\"images/pic3_3.png\", facecolor=fig.get_facecolor())\nplt.show()\n</pre> # \u62d3\u5c55\uff1a\u5f88\u591a\u683c\u5f0f\u53ef\u4ee5\u540e\u671f\u518d\u51fd\u6570\u5916\u5904\u7406 def plot_time_series(x, y, fmt, lab=\"\", ax=None):     if ax is None:         fig, ax = plt.subplot()     ax.plot(x, y, fmt, label=lab)     # x\u8f74\u56fa\u6709\u683c\u5f0f     ax.set_xlabel(\"time\")     ax.xaxis.set_major_locator(plt.MultipleLocator(np.pi / 2))     ax.xaxis.set_minor_locator(plt.MultipleLocator(np.pi / 4))     labs = ax.xaxis.get_ticklabels()     ax.xaxis.set_ticklabels([r\"{:.2f}$\\pi$\".format(i/2) for i, l in enumerate(labs)])     return ax  fig, axes = plt.subplots(2, 1, figsize=(6, 3),                           sharex=True, facecolor=\"white\") plot_time_series(x, y1, 'b-', r'$y=sin(x)$', axes[0]) plot_time_series(x, y2, 'r:', r'$y=cos(x)$', axes[0]) plot_time_series(x, y3, 'g--', ax=axes[1])  # \u540e\u671f\u8c03\u6574\u683c\u5f0f/\u6dfb\u52a0\u5185\u5bb9/\u7f8e\u5316... axes[0].set_xlabel(\"\") axes[0].legend(loc=\"upper right\") axes[1].legend(loc=\"upper right\") axes[0].grid() axes[1].grid()  # plt.savefig(\"images/pic3_3.png\", facecolor=fig.get_facecolor()) plt.show() <pre>/var/folders/71/d5xhvtkn215cb3g26qsjh5q00000gn/T/ipykernel_25617/3644634002.py:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n  ax.xaxis.set_ticklabels([r\"{:.2f}$\\pi$\".format(i/2) for i, l in enumerate(labs)])\nNo artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n</pre> In\u00a0[24]: Copied! <pre># \u540e\u671f\u8c03\u6574\nfig, axes = plt.subplots(2, 1, figsize=(6, 3),\n                         sharex=True, facecolor=\"white\")\nplot_time_series(x, y1, 'b-', r'$y=sin(x)$', axes[0])\nplot_time_series(x, y2, 'r:', r'$y=cos(x)$', axes[0])\nplot_time_series(x, y3, 'g--', ax=axes[1])\n# \u8c03\u6574\u683c\u5f0f/\u6dfb\u52a0\u5185\u5bb9/\u7f8e\u5316...\naxes[0].set_xlabel(\"\")\n# \u8865\u5145\u56fe\u793a\naxes[1].lines[0].set_label(r\"$y=tanh(x)$\")\naxes[0].legend(loc=\"upper right\")\naxes[1].legend(loc=\"upper right\")\naxes[0].grid()\naxes[1].grid()\n\nplt.savefig(\"images/pic3_4.png\", facecolor=fig.get_facecolor())\nplt.show()\n</pre> # \u540e\u671f\u8c03\u6574 fig, axes = plt.subplots(2, 1, figsize=(6, 3),                          sharex=True, facecolor=\"white\") plot_time_series(x, y1, 'b-', r'$y=sin(x)$', axes[0]) plot_time_series(x, y2, 'r:', r'$y=cos(x)$', axes[0]) plot_time_series(x, y3, 'g--', ax=axes[1]) # \u8c03\u6574\u683c\u5f0f/\u6dfb\u52a0\u5185\u5bb9/\u7f8e\u5316... axes[0].set_xlabel(\"\") # \u8865\u5145\u56fe\u793a axes[1].lines[0].set_label(r\"$y=tanh(x)$\") axes[0].legend(loc=\"upper right\") axes[1].legend(loc=\"upper right\") axes[0].grid() axes[1].grid()  plt.savefig(\"images/pic3_4.png\", facecolor=fig.get_facecolor()) plt.show() <pre>/var/folders/71/d5xhvtkn215cb3g26qsjh5q00000gn/T/ipykernel_25617/3644634002.py:11: UserWarning: FixedFormatter should only be used together with FixedLocator\n  ax.xaxis.set_ticklabels([r\"{:.2f}$\\pi$\".format(i/2) for i, l in enumerate(labs)])\n</pre> In\u00a0[8]: Copied! <pre>import matplotlib.pyplot as plt\nfrom matplotlib import cm\nfrom matplotlib.ticker import LinearLocator\nimport numpy as np\n</pre> import matplotlib.pyplot as plt from matplotlib import cm from matplotlib.ticker import LinearLocator import numpy as np In\u00a0[9]: Copied! <pre>%matplotlib widget\n\n# \u4ea4\u4e92\u5f0f\u753b\u56fe\n\nfig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n# Make data.\nX = np.arange(-5, 5, 0.25)\nY = np.arange(-5, 5, 0.25)\nX, Y = np.meshgrid(X, Y)\nR = np.sqrt(X**2 + Y**2)\nZ = np.sin(R)\n\n# Plot the surface.\nsurf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,\n                       linewidth=0, antialiased=False)\n\n# Customize the z axis.\nax.set_zlim(-1.01, 1.01)\nax.zaxis.set_major_locator(LinearLocator(10))\n# A StrMethodFormatter is used automatically\nax.zaxis.set_major_formatter('{x:.02f}')\n\n# Add a color bar which maps values to colors.\nfig.colorbar(surf, shrink=0.5, aspect=5)\n\n# plt.savefig(\"images/pic3_5.png\", facecolor=fig.get_facecolor())\nplt.show()\n</pre> %matplotlib widget  # \u4ea4\u4e92\u5f0f\u753b\u56fe  fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"}) # Make data. X = np.arange(-5, 5, 0.25) Y = np.arange(-5, 5, 0.25) X, Y = np.meshgrid(X, Y) R = np.sqrt(X**2 + Y**2) Z = np.sin(R)  # Plot the surface. surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,                        linewidth=0, antialiased=False)  # Customize the z axis. ax.set_zlim(-1.01, 1.01) ax.zaxis.set_major_locator(LinearLocator(10)) # A StrMethodFormatter is used automatically ax.zaxis.set_major_formatter('{x:.02f}')  # Add a color bar which maps values to colors. fig.colorbar(surf, shrink=0.5, aspect=5)  # plt.savefig(\"images/pic3_5.png\", facecolor=fig.get_facecolor()) plt.show()                      Figure                  In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/Matplotlib_examples/#matplotlib","title":"Matplotlib \u753b\u56fe\u57fa\u7840\u4e0e\u6838\u5fc3\u903b\u8f91\u00b6","text":"<ol> <li>\u6765\u6e90\uff08Matlab\u903b\u8f91\uff09</li> <li>\u753b\u56fe\u903b\u8f91\uff08Matlab\u8bed\u6cd5/OOP\u8bed\u6cd5\uff09</li> <li>\u5e94\u7528\u65b9\u6cd5/\u6d41\u7a0b\uff08\u81ea\u5b9a\u4e49\u51fd\u6570/\u64cd\u4f5c\u6d41\u7a0b\uff09</li> <li>\u81ea\u5b66/\u603b\u7ed3\uff08\u4e0d\u540c\uff09</li> </ol>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/Matplotlib_examples/#1-1","title":"1-1. \u63d0\u7eb2\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/Matplotlib_examples/#1-2-mpl","title":"1-2. mpl\u7684\u8d77\u6e90\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/Matplotlib_examples/#matplotlib","title":"\u5165\u95e8: \u4f7f\u7528Matplotlib\u5feb\u901f\u753b\u56fe\uff08\u4ee5\u6298\u7ebf\u56fe\u4e3a\u4f8b\uff09\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/Matplotlib_examples/#matplotlib","title":"Matplotlib\u4e2d\u66f4\u591a\u7684\u4e00\u4e9b\u56fe\u753b\u7c7b\u578b\uff08\u6298\u7ebf\u56fe\uff0c\u997c\u56fe\uff0c\u7b49\u7b49\uff09\u00b6","text":"<ul> <li>https://matplotlib.org/stable/plot_types/index.html</li> </ul>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/Matplotlib_examples/#matlab","title":"\u6309\u7167Matlab\u7684\u98ce\u683c\u753b\u56fe\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/Matplotlib_examples/","title":"\u4e09.\u5e38\u7528\u5de5\u4f5c\u6d41\u7a0b\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/Matplotlib_examples/#2","title":"\u5de5\u4f5c\u6d41\u7a0b2: \u91cd\u590d\u4f7f\u4ee3\u7801\uff08\u4f7f\u7528\u51fd\u6570\uff09\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/matplotlib_note/","title":"matplotlib\u7684\u4e00\u4e9b\u7b14\u8bb0","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/matplotlib_note/#_1","title":"\u603b\u7ed3","text":"<p>\u5728matplotlib\u4e2d\uff0c\u5bf9\u4e8e\u5750\u6807\u8f74\u3001\u56fe\u7247\u6846\u67b6\u7684\u64cd\u4f5c\u901a\u5e38\u653e\u5728fig\u3001axes\u7684\u5c5e\u6027\u4e2d\uff0c\u5bf9\u4e8e \u56fe\u7247\u672c\u8eab\uff0c\u4f8b\u5982\u67f1\u72b6\u56fe\u7684\u67f1\u5b50\u3001\u6298\u7ebf\u56fe\u7684\u7ebf\u7684\u64cd\u4f5c\u4e00\u822c\u5728axes.bar\u7b49\u7684\u5c5e\u6027\u4e2d\u3002</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/matplotlib_relevant/","title":"\u5173\u4e8ematplotlib\u7684\u77e5\u8bc6","text":"In\u00a0[17]: Copied! <pre>import math\nimport copy\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom itertools import product\n</pre> import math import copy  import pandas as pd import numpy as np import matplotlib.pyplot as plt import matplotlib from itertools import product In\u00a0[18]: Copied! <pre># \u521d\u59cb\u5316\u6570\u636e\nseasons = [1,2,3,4]   # \u5b63\u5ea6\nstock1 = [4,8,2,6]    # \u80a1\u79681\u6bcf\u4e2a\u5b63\u5ea6\u5bf9\u5e94\u7684\u80a1\u4ef7\nstock2 = [10,12,5,3]  # \u80a1\u79682\u6bcf\u4e2a\u5b63\u5ea6\u5bf9\u5e94\u7684\u80a1\u4ef7\n\n#\u8f6c\u5316\u6570\u636e\u4e3aNumpy\u6570\u7ec4\uff08\u53ef\u8df3\u8fc7\uff09\nseasons = np.array(seasons)\nstock1 = np.array(stock1)\nstock2 = np.array(stock2)\n</pre> # \u521d\u59cb\u5316\u6570\u636e seasons = [1,2,3,4]   # \u5b63\u5ea6 stock1 = [4,8,2,6]    # \u80a1\u79681\u6bcf\u4e2a\u5b63\u5ea6\u5bf9\u5e94\u7684\u80a1\u4ef7 stock2 = [10,12,5,3]  # \u80a1\u79682\u6bcf\u4e2a\u5b63\u5ea6\u5bf9\u5e94\u7684\u80a1\u4ef7  #\u8f6c\u5316\u6570\u636e\u4e3aNumpy\u6570\u7ec4\uff08\u53ef\u8df3\u8fc7\uff09 seasons = np.array(seasons) stock1 = np.array(stock1) stock2 = np.array(stock2) In\u00a0[19]: Copied! <pre># \u4e00\u4e9b\u57fa\u672c\u8bbe\u7f6e\n# \u8bbe\u7f6e\u652f\u6301\u4e2d\u6587\u5b57\u4f53\uff08\u9ed1\u4f53\uff09\nmatplotlib.rcParams['font.family'] = ['Heiti TC']\n# \u8bbe\u7f6e\u56fe\u7247\u6e05\u6670\u5ea6\uff08200dpi: 200\u50cf\u7d20\u6bcf\u82f1\u5bf8\uff09\nmatplotlib.rcParams['figure.dpi'] = 200\n# \u56fe\u753b\u9762\u677f\u8c03\u6574\u4e3a\u767d\u8272\nmatplotlib.rcParams['axes.facecolor']='white'\nmatplotlib.rcParams['savefig.facecolor']='white'\n</pre> # \u4e00\u4e9b\u57fa\u672c\u8bbe\u7f6e # \u8bbe\u7f6e\u652f\u6301\u4e2d\u6587\u5b57\u4f53\uff08\u9ed1\u4f53\uff09 matplotlib.rcParams['font.family'] = ['Heiti TC'] # \u8bbe\u7f6e\u56fe\u7247\u6e05\u6670\u5ea6\uff08200dpi: 200\u50cf\u7d20\u6bcf\u82f1\u5bf8\uff09 matplotlib.rcParams['figure.dpi'] = 200 # \u56fe\u753b\u9762\u677f\u8c03\u6574\u4e3a\u767d\u8272 matplotlib.rcParams['axes.facecolor']='white' matplotlib.rcParams['savefig.facecolor']='white' <ol> <li>Axis\uff1a\u5355\u4e2a\u5750\u6807\u8f74</li> <li>Axes\uff1a\u5750\u6807\u7cfb\uff0c\u5305\u542b\u591a\u4e2a\u5750\u6807\u8f74</li> <li>Figure\uff1a\u6574\u4e2a\u56fe\uff0c\u53ef\u4ee5\u5305\u542b\u591a\u4e2a\u5750\u6807\u7cfb</li> <li>Artist\uff1a\u753b\u9762\u4e2d\u7684\u4e00\u4e2a\u5bf9\u8c61\uff08\u5982\u56fe\u793a\u3001\u5750\u6807\u8f74\u3001\u8fb9\u6846\u7b49\u7b49\uff09</li> </ol> In\u00a0[4]: Copied! <pre># \u53ef\u4ee5\u5355\u72ec\u521b\u5efafigure\u3001axes\u5bf9\u8c61\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7plt.subplots\u540c\u65f6\u521b\u5efa\uff0c\u4e00\u822c\u6211\u4eec\u9009\u62e9\u540c\u65f6\u521b\u5efa\nfig = plt.figure()\naxes = plt.subplot()\nfig1, axes1 = plt.subplots()\ntype(fig), type(axes), type(fig1), type(axes1)\n</pre> # \u53ef\u4ee5\u5355\u72ec\u521b\u5efafigure\u3001axes\u5bf9\u8c61\uff0c\u4e5f\u53ef\u4ee5\u901a\u8fc7plt.subplots\u540c\u65f6\u521b\u5efa\uff0c\u4e00\u822c\u6211\u4eec\u9009\u62e9\u540c\u65f6\u521b\u5efa fig = plt.figure() axes = plt.subplot() fig1, axes1 = plt.subplots() type(fig), type(axes), type(fig1), type(axes1) Out[4]: <pre>(matplotlib.figure.Figure,\n matplotlib.axes._axes.Axes,\n matplotlib.figure.Figure,\n matplotlib.axes._axes.Axes)</pre> In\u00a0[20]: Copied! <pre>fig, axes = plt.subplots(nrows=5,\n                         ncols=2, \n                         figsize=[10,20], # \u5bbd\u5ea6\u548c\u9ad8\u5ea6\n                         facecolor=\"green\",\n                         linewidth=5,  # \u56fe\u50cf\u7684\u8fb9\u6846\u5bbd\u5ea6\n                         edgecolor=\"blue\", # \u56fe\u50cf\u8fb9\u6846\u7684\u989c\u8272\n                         dpi=120, # \u56fe\u50cf\u5206\u8fa8\u7387\uff0c\u9ed8\u8ba4\u4e3a100\n                         layout='constrained',\n                         sharex=False, # \u5171\u4eabx\u8f74\u5750\u6807\u7cfb\n                         sharey=False) # \u5171\u4eaby\u8f74\u5750\u6807\u7cfb\n</pre> fig, axes = plt.subplots(nrows=5,                          ncols=2,                           figsize=[10,20], # \u5bbd\u5ea6\u548c\u9ad8\u5ea6                          facecolor=\"green\",                          linewidth=5,  # \u56fe\u50cf\u7684\u8fb9\u6846\u5bbd\u5ea6                          edgecolor=\"blue\", # \u56fe\u50cf\u8fb9\u6846\u7684\u989c\u8272                          dpi=120, # \u56fe\u50cf\u5206\u8fa8\u7387\uff0c\u9ed8\u8ba4\u4e3a100                          layout='constrained',                          sharex=False, # \u5171\u4eabx\u8f74\u5750\u6807\u7cfb                          sharey=False) # \u5171\u4eaby\u8f74\u5750\u6807\u7cfb \u6ce8\u610f\uff0c\u753b\u56fe\u7684\u5f88\u591a\u53c2\u6570\u90fd\u53ef\u4ee5\u901a\u8fc7rcParams\u6765\u8bbe\u7f6e\uff0c\u5e76\u4e14\u6709\u9ed8\u8ba4\u503c\u3002 In\u00a0[21]: Copied! <pre>matplotlib.rcParams['axes.titlesize'], matplotlib.rcParams[\"axes.titlelocation\"], \\\nmatplotlib.rcParams[\"axes.titley\"], matplotlib.rcParams[\"axes.titlecolor\"], \n</pre> matplotlib.rcParams['axes.titlesize'], matplotlib.rcParams[\"axes.titlelocation\"], \\ matplotlib.rcParams[\"axes.titley\"], matplotlib.rcParams[\"axes.titlecolor\"],  Out[21]: <pre>('large', 'left', None, 'blue')</pre> In\u00a0[22]: Copied! <pre># \u53ef\u4ee5\u6539\u53d8\u53c2\u6570\u4ece\u800c\u6539\u53d8\u683c\u5f0f\uff0c\u4f8b\u5982\u6539\u53d8\u56fe\u50cf\u6807\u9898\u9ed8\u8ba4\u4f4d\u7f6e\nmatplotlib.rcParams[\"axes.titlelocation\"] = 'left'\n</pre> # \u53ef\u4ee5\u6539\u53d8\u53c2\u6570\u4ece\u800c\u6539\u53d8\u683c\u5f0f\uff0c\u4f8b\u5982\u6539\u53d8\u56fe\u50cf\u6807\u9898\u9ed8\u8ba4\u4f4d\u7f6e matplotlib.rcParams[\"axes.titlelocation\"] = 'left' In\u00a0[23]: Copied! <pre># \u67e5\u770b\u76ee\u524d\u56fe\u7247\u7684\u5750\u6807\naxes[0, 0].get_xticks(), axes[0, 0].get_yticks()\n</pre> # \u67e5\u770b\u76ee\u524d\u56fe\u7247\u7684\u5750\u6807 axes[0, 0].get_xticks(), axes[0, 0].get_yticks() Out[23]: <pre>(array([0. , 0.2, 0.4, 0.6, 0.8, 1. ]), array([0. , 0.2, 0.4, 0.6, 0.8, 1. ]))</pre> In\u00a0[24]: Copied! <pre>axes[0, 1]\n</pre> axes[0, 1] Out[24]: <pre>&lt;Axes: &gt;</pre> In\u00a0[67]: Copied! <pre># \u4e3a\u4e86\u907f\u514d\u91cd\u53e0\uff0c\u5728\u753b\u56fe\u4e4b\u524d\u5148\u5c06\u5b50\u56fe\u6e05\u7a7a\uff0c\u53ea\u7559\u4e0b\u5750\u6807\u8f74\nfor i, j in product([0],[0, 1]):\n    axes[i, j].clear()\n\ncolor = ['red', 'yellow', 'blue', 'black']\n# fontdict\u7528\u6765\u6539\u53d8title\u683c\u5f0f\uff0c\u9ed8\u8ba4\u503c\u5982\u4e0b\uff1a\nmatplotlib.rcParams[\"axes.titlecolor\"] = 'blue'\nfontdict = {'fontsize': matplotlib.rcParams['axes.titlesize'],\n            'fontweight': matplotlib.rcParams['axes.titleweight'],\n            'color': matplotlib.rcParams['axes.titlecolor'],\n            'verticalalignment': 'baseline',\n            'horizontalalignment': 'left'} \ntick_label=['\u7b2c\u4e00\u5b63\u5ea6', '\u7b2c\u4e8c\u5b63\u5ea6', '\u7b2c\u4e09\u5b63\u5ea6', '\u7b2c\u56db\u5b63\u5ea6']\nlabel=['\u4e00\u5b63\u5ea6', '\u4e8c\u5b63\u5ea6', '\u4e09\u5b63\u5ea6', '\u56db\u5b63\u5ea6']\nx = axes[0, 0].bar(x=seasons, # bar\u7684x\u5750\u6807\n                   height=stock1, \n                   width=0.5, # bar\u7684\u5bbd\u5ea6\n                   color=color, # bar\u7684\u989c\u8272\n                   bottom=[7, 2, 3, 8], # \u8868\u793abar\u7684\u5e95\u7aef\u8d77\u59cb\u5750\u6807\uff0c\u8fd9\u91cc\u53ea\u662f\u4e3e\u4e00\u4e2a\u4f8b\u5b50\uff0c\u4e0d\u591f\u7f8e\u89c2\n                   align='center', # \u8868\u793abar\u5728x\u8f74\u4e0a\u7684\u4f4d\u7f6e\n                   linewidth=1,  # bar\u7684\u8fb9\u6846\u5bbd\u5ea6\n                   edgecolor='green', # bar\u7684\u8fb9\u6846\u989c\u8272\n                   label=label # \u6bcf\u4e2abar\u7684\u6807\u7b7e\uff0c\u7528\u6765\u663e\u793a\u56fe\u4f8b\n                   )\n\n# https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_title.html\n# \u6807\u9898\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574rcParams\u53c2\u6570\u6765\u6539\u53d8\uff0c\u4e5f\u53ef\u4ee5\u76f4\u63a5\u6307\u5b9a\u53c2\u6570\u6765\u8c03\u6574\u5355\u5e45\u56fe\u7684\u53c2\u6570\u3002\naxes[0, 0].set_title(label='\u80a1\u79681',\n                     fontdict=fontdict)\naxes[0, 0].set_ylabel('\u80a1\u7968\u4ef7\u683c')\naxes[0, 0].set_xlabel('\u5b63\u5ea6')\n\naxes[0, 0].bar_label(container=x,\n                     labels=label, #\u6307\u5b9a\u6807\u7b7e\u5185\u5bb9\uff0c\u5982\u679c\u4e0d\u6307\u5b9a\uff0c\u90a3\u4e48\u9ed8\u8ba4bar\u7684\u6570\u503c\u5927\u5c0f\u4f5c\u4e3a\u6807\u7b7e\n                     padding=3) # \u6807\u7b7e\u8ddd\u79bbbar\u7684\u4f4d\u7f6e\n# tick\u4ee3\u8868\u5750\u6807\u8f74\u4e0a\u7684\u4e00\u4e2a\u201c\u77ed\u7ebf\u201d\u3002set_xticks\u53ef\u4ee5\u8bbe\u7f6e\u5750\u6807\u8f74\u4e0a\u201c\u77ed\u7ebf\u201d\u7684\u4f4d\u7f6e\u4ee5\u53ca\u540d\u79f0\u3002\n# \u6ce8\u610f\uff1a\u8fd9\u4e00\u6b65\u6700\u597d\u4fdd\u8bc1xticks\u548cbar\u7684x\u53c2\u6570\u4f4d\u7f6e\u76f8\u540c\uff0c\u540c\u65f6\u5efa\u8bae\uff1a\u6807\u7b7e\u5728\u8fd9\u91cc\u6307\u5b9a\uff0c\u4e0d\u5728bar\u91cc\u9762\u6307\u5b9a\naxes[0, 0].set_xticks(ticks=np.arange(len(seasons)) + 1,\n                      labels=tick_label,\n                      rotation='horizontal',\n                      fontsize='medium')\n# \u8bbe\u7f6ex\u8f74\u8303\u56f4\naxes[0, 0].set_xlim(left=0, # \u5de6\u4fa7\u9650\u5236\n              right=len(seasons) + 1) # \u53f3\u4fa7\u9650\u5236\n\n\n# \u6ce8\u610f\uff1a\u4e4b\u524d\u5728bar\u51fd\u6570\u7684\u53c2\u6570\u4e2d\u9700\u8981\u6307\u5b9alabel\uff0c\u8fd9\u91cc\u624d\u80fd\u663e\u793a\u56fe\u4f8b\n# label\u548ctick_label\u53ef\u4ee5\u4e0d\u4e00\u6837\uff0c\u5206\u522b\u4ee3\u8868\u6bcf\u4e2abar\u7684\u6807\u7b7e\uff08\u7528\u4e8e\u56fe\u4f8b\uff09\u4ee5\u53ca\u5750\u6807\u8f74\u4e0a\u7684\u5750\u6807\u7684\u540d\u79f0\u3002\n# https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.legend.html\naxes[0, 0].legend(title='\u5b63\u5ea6', \n                  loc='best',\n                  fontsize='x-small',\n                  markerfirst=False) # \u56fe\u4f8b\u548clabel\u7684\u76f8\u5bf9\u4f4d\u7f6e\n\naxes[0, 1].bar(x=seasons, # bar\u7684x\u5750\u6807\n               height=stock1, \n               width=0.5, # bar\u7684\u5bbd\u5ea6\n               color=color, # bar\u7684\u989c\u8272\n               bottom=[7, 2, 3, 8], # \u8868\u793abar\u7684\u5e95\u7aef\u8d77\u59cb\u5750\u6807\uff0c\u8fd9\u91cc\u53ea\u662f\u4e3e\u4e00\u4e2a\u4f8b\u5b50\uff0c\u4e0d\u591f\u7f8e\u89c2\n               align='center', # \u8868\u793abar\u5728x\u8f74\u4e0a\u7684\u4f4d\u7f6e\n               linewidth=1,  # bar\u7684\u8fb9\u6846\u5bbd\u5ea6\n               edgecolor='green', # bar\u7684\u8fb9\u6846\u989c\u8272\n               )\n\n# \u76f4\u63a5\u6307\u5b9a\u90e8\u5206\u53c2\u6570\naxes[0, 1].set_title(label='\u80a1\u79681',\n                     loc='center',\n                     fontdict=fontdict,\n                     y=1)   # \u6807\u9898\u7684y\u5750\u6807\u4f4d\u7f6e \naxes[0, 1].set_ylabel(ylabel='\u80a1\u7968\u4ef7\u683c')\naxes[0, 1].set_xlabel(xlabel='\u5b63\u5ea6')\n\nfig\n</pre> # \u4e3a\u4e86\u907f\u514d\u91cd\u53e0\uff0c\u5728\u753b\u56fe\u4e4b\u524d\u5148\u5c06\u5b50\u56fe\u6e05\u7a7a\uff0c\u53ea\u7559\u4e0b\u5750\u6807\u8f74 for i, j in product([0],[0, 1]):     axes[i, j].clear()  color = ['red', 'yellow', 'blue', 'black'] # fontdict\u7528\u6765\u6539\u53d8title\u683c\u5f0f\uff0c\u9ed8\u8ba4\u503c\u5982\u4e0b\uff1a matplotlib.rcParams[\"axes.titlecolor\"] = 'blue' fontdict = {'fontsize': matplotlib.rcParams['axes.titlesize'],             'fontweight': matplotlib.rcParams['axes.titleweight'],             'color': matplotlib.rcParams['axes.titlecolor'],             'verticalalignment': 'baseline',             'horizontalalignment': 'left'}  tick_label=['\u7b2c\u4e00\u5b63\u5ea6', '\u7b2c\u4e8c\u5b63\u5ea6', '\u7b2c\u4e09\u5b63\u5ea6', '\u7b2c\u56db\u5b63\u5ea6'] label=['\u4e00\u5b63\u5ea6', '\u4e8c\u5b63\u5ea6', '\u4e09\u5b63\u5ea6', '\u56db\u5b63\u5ea6'] x = axes[0, 0].bar(x=seasons, # bar\u7684x\u5750\u6807                    height=stock1,                     width=0.5, # bar\u7684\u5bbd\u5ea6                    color=color, # bar\u7684\u989c\u8272                    bottom=[7, 2, 3, 8], # \u8868\u793abar\u7684\u5e95\u7aef\u8d77\u59cb\u5750\u6807\uff0c\u8fd9\u91cc\u53ea\u662f\u4e3e\u4e00\u4e2a\u4f8b\u5b50\uff0c\u4e0d\u591f\u7f8e\u89c2                    align='center', # \u8868\u793abar\u5728x\u8f74\u4e0a\u7684\u4f4d\u7f6e                    linewidth=1,  # bar\u7684\u8fb9\u6846\u5bbd\u5ea6                    edgecolor='green', # bar\u7684\u8fb9\u6846\u989c\u8272                    label=label # \u6bcf\u4e2abar\u7684\u6807\u7b7e\uff0c\u7528\u6765\u663e\u793a\u56fe\u4f8b                    )  # https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_title.html # \u6807\u9898\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574rcParams\u53c2\u6570\u6765\u6539\u53d8\uff0c\u4e5f\u53ef\u4ee5\u76f4\u63a5\u6307\u5b9a\u53c2\u6570\u6765\u8c03\u6574\u5355\u5e45\u56fe\u7684\u53c2\u6570\u3002 axes[0, 0].set_title(label='\u80a1\u79681',                      fontdict=fontdict) axes[0, 0].set_ylabel('\u80a1\u7968\u4ef7\u683c') axes[0, 0].set_xlabel('\u5b63\u5ea6')  axes[0, 0].bar_label(container=x,                      labels=label, #\u6307\u5b9a\u6807\u7b7e\u5185\u5bb9\uff0c\u5982\u679c\u4e0d\u6307\u5b9a\uff0c\u90a3\u4e48\u9ed8\u8ba4bar\u7684\u6570\u503c\u5927\u5c0f\u4f5c\u4e3a\u6807\u7b7e                      padding=3) # \u6807\u7b7e\u8ddd\u79bbbar\u7684\u4f4d\u7f6e # tick\u4ee3\u8868\u5750\u6807\u8f74\u4e0a\u7684\u4e00\u4e2a\u201c\u77ed\u7ebf\u201d\u3002set_xticks\u53ef\u4ee5\u8bbe\u7f6e\u5750\u6807\u8f74\u4e0a\u201c\u77ed\u7ebf\u201d\u7684\u4f4d\u7f6e\u4ee5\u53ca\u540d\u79f0\u3002 # \u6ce8\u610f\uff1a\u8fd9\u4e00\u6b65\u6700\u597d\u4fdd\u8bc1xticks\u548cbar\u7684x\u53c2\u6570\u4f4d\u7f6e\u76f8\u540c\uff0c\u540c\u65f6\u5efa\u8bae\uff1a\u6807\u7b7e\u5728\u8fd9\u91cc\u6307\u5b9a\uff0c\u4e0d\u5728bar\u91cc\u9762\u6307\u5b9a axes[0, 0].set_xticks(ticks=np.arange(len(seasons)) + 1,                       labels=tick_label,                       rotation='horizontal',                       fontsize='medium') # \u8bbe\u7f6ex\u8f74\u8303\u56f4 axes[0, 0].set_xlim(left=0, # \u5de6\u4fa7\u9650\u5236               right=len(seasons) + 1) # \u53f3\u4fa7\u9650\u5236   # \u6ce8\u610f\uff1a\u4e4b\u524d\u5728bar\u51fd\u6570\u7684\u53c2\u6570\u4e2d\u9700\u8981\u6307\u5b9alabel\uff0c\u8fd9\u91cc\u624d\u80fd\u663e\u793a\u56fe\u4f8b # label\u548ctick_label\u53ef\u4ee5\u4e0d\u4e00\u6837\uff0c\u5206\u522b\u4ee3\u8868\u6bcf\u4e2abar\u7684\u6807\u7b7e\uff08\u7528\u4e8e\u56fe\u4f8b\uff09\u4ee5\u53ca\u5750\u6807\u8f74\u4e0a\u7684\u5750\u6807\u7684\u540d\u79f0\u3002 # https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.legend.html axes[0, 0].legend(title='\u5b63\u5ea6',                    loc='best',                   fontsize='x-small',                   markerfirst=False) # \u56fe\u4f8b\u548clabel\u7684\u76f8\u5bf9\u4f4d\u7f6e  axes[0, 1].bar(x=seasons, # bar\u7684x\u5750\u6807                height=stock1,                 width=0.5, # bar\u7684\u5bbd\u5ea6                color=color, # bar\u7684\u989c\u8272                bottom=[7, 2, 3, 8], # \u8868\u793abar\u7684\u5e95\u7aef\u8d77\u59cb\u5750\u6807\uff0c\u8fd9\u91cc\u53ea\u662f\u4e3e\u4e00\u4e2a\u4f8b\u5b50\uff0c\u4e0d\u591f\u7f8e\u89c2                align='center', # \u8868\u793abar\u5728x\u8f74\u4e0a\u7684\u4f4d\u7f6e                linewidth=1,  # bar\u7684\u8fb9\u6846\u5bbd\u5ea6                edgecolor='green', # bar\u7684\u8fb9\u6846\u989c\u8272                )  # \u76f4\u63a5\u6307\u5b9a\u90e8\u5206\u53c2\u6570 axes[0, 1].set_title(label='\u80a1\u79681',                      loc='center',                      fontdict=fontdict,                      y=1)   # \u6807\u9898\u7684y\u5750\u6807\u4f4d\u7f6e  axes[0, 1].set_ylabel(ylabel='\u80a1\u7968\u4ef7\u683c') axes[0, 1].set_xlabel(xlabel='\u5b63\u5ea6')  fig Out[67]: In\u00a0[26]: Copied! <pre># \u67e5\u770b\u76ee\u524d\u56fe\u7247\u7684\u5750\u6807\naxes[1, 0].get_xticks(), axes[1, 0].get_yticks()\n</pre> # \u67e5\u770b\u76ee\u524d\u56fe\u7247\u7684\u5750\u6807 axes[1, 0].get_xticks(), axes[1, 0].get_yticks() Out[26]: <pre>(array([0. , 0.2, 0.4, 0.6, 0.8, 1. ]), array([0. , 0.2, 0.4, 0.6, 0.8, 1. ]))</pre> In\u00a0[27]: Copied! <pre># \u4e3a\u4e86\u907f\u514d\u91cd\u53e0\uff0c\u5728\u753b\u56fe\u4e4b\u524d\u5148\u5c06\u5b50\u56fe\u6e05\u7a7a\uff0c\u53ea\u7559\u4e0b\u5750\u6807\u8f74\nfor i, j in product([1],[0, 1]):\n    axes[i, j].clear()\n\ntick_label=['\u7b2c\u4e00\u5b63\u5ea6', '\u7b2c\u4e8c\u5b63\u5ea6', '\u7b2c\u4e09\u5b63\u5ea6', '\u7b2c\u56db\u5b63\u5ea6']\nlabel=['\u4e00\u5b63\u5ea6', '\u4e8c\u5b63\u5ea6', '\u4e09\u5b63\u5ea6', '\u56db\u5b63\u5ea6']\n\n# https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.plot.html\n# \u6ce8\u610f\uff0caxes.plot\u7684\u8bed\u6cd5\u4e0d\u5305\u542b\u53c2\u6570\u540d\u79f0\naxes[1, 0].plot(seasons, # x\u5750\u6807\n                stock1, # y\u5750\u6807\n                'o-b', # fmt = '[marker][line][color]'\n                label='stock1',\n                linewidth=2,\n                markersize=8)\naxes[1, 0].plot(seasons, # x\u5750\u6807\n                stock2, # y\u5750\u6807\n                'o-r', # fmt = '[marker][line][color]'\n                label='stock2',\n                linewidth=2,\n                markersize=10,\n                markeredgewidth=0,   # \u6807\u8bb0\u70b9\u8fb9\u6846\u7684\u5927\u5c0f\n                markerfacecolor='blue') # \u5982\u679c\u5c06\u8fb9\u6846\u8bbe\u7f6e\u4e3a0\uff0c\u90a3\u4e48face\u7684\u989c\u8272\u5c31\u662f\u6807\u8bb0\u70b9\u7684\u989c\u8272\n\naxes[1, 0].set_ylabel(ylabel='\u80a1\u7968\u4ef7\u683c')\naxes[1, 0].set_xlabel(xlabel='\u5b63\u5ea6')\n\naxes[1, 0].legend(title='\u5b63\u5ea6', \n                  loc='best',\n                  fontsize='small',\n                  markerfirst=False) # \u56fe\u4f8b\u548clabel\u7684\u76f8\u5bf9\u4f4d\u7f6e\naxes[1, 0].set_xticks(ticks=np.arange(len(seasons)) + 1,\n                      labels=tick_label)\n\n# \u6dfb\u52a0\u6587\u672c\u7684\u4f4d\u7f6e\u5c31\u662f\u6807\u8bb0\u70b9marker\u7684\u4f4d\u7f6e\uff0c\u7531x\uff0cy\u5750\u6807\u51b3\u5b9a\nfor x, y in zip(axes[1, 0].get_xticks(), stock1):\n    axes[1, 0].text(x, y, \n                    s='(%.0d, %.0d)' %(x, y), \n                    size=10)\nfor x, y in zip(axes[1, 0].get_xticks(), stock2):\n    axes[1, 0].text(x, y, \n                    s='(%.0d, %.0d)' %(x, y), \n                    size=12,\n                    horizontalalignment='center',\n                    verticalalignment='baseline')\n# axes[1, 1].remove()\nfig\n</pre> # \u4e3a\u4e86\u907f\u514d\u91cd\u53e0\uff0c\u5728\u753b\u56fe\u4e4b\u524d\u5148\u5c06\u5b50\u56fe\u6e05\u7a7a\uff0c\u53ea\u7559\u4e0b\u5750\u6807\u8f74 for i, j in product([1],[0, 1]):     axes[i, j].clear()  tick_label=['\u7b2c\u4e00\u5b63\u5ea6', '\u7b2c\u4e8c\u5b63\u5ea6', '\u7b2c\u4e09\u5b63\u5ea6', '\u7b2c\u56db\u5b63\u5ea6'] label=['\u4e00\u5b63\u5ea6', '\u4e8c\u5b63\u5ea6', '\u4e09\u5b63\u5ea6', '\u56db\u5b63\u5ea6']  # https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.plot.html # \u6ce8\u610f\uff0caxes.plot\u7684\u8bed\u6cd5\u4e0d\u5305\u542b\u53c2\u6570\u540d\u79f0 axes[1, 0].plot(seasons, # x\u5750\u6807                 stock1, # y\u5750\u6807                 'o-b', # fmt = '[marker][line][color]'                 label='stock1',                 linewidth=2,                 markersize=8) axes[1, 0].plot(seasons, # x\u5750\u6807                 stock2, # y\u5750\u6807                 'o-r', # fmt = '[marker][line][color]'                 label='stock2',                 linewidth=2,                 markersize=10,                 markeredgewidth=0,   # \u6807\u8bb0\u70b9\u8fb9\u6846\u7684\u5927\u5c0f                 markerfacecolor='blue') # \u5982\u679c\u5c06\u8fb9\u6846\u8bbe\u7f6e\u4e3a0\uff0c\u90a3\u4e48face\u7684\u989c\u8272\u5c31\u662f\u6807\u8bb0\u70b9\u7684\u989c\u8272  axes[1, 0].set_ylabel(ylabel='\u80a1\u7968\u4ef7\u683c') axes[1, 0].set_xlabel(xlabel='\u5b63\u5ea6')  axes[1, 0].legend(title='\u5b63\u5ea6',                    loc='best',                   fontsize='small',                   markerfirst=False) # \u56fe\u4f8b\u548clabel\u7684\u76f8\u5bf9\u4f4d\u7f6e axes[1, 0].set_xticks(ticks=np.arange(len(seasons)) + 1,                       labels=tick_label)  # \u6dfb\u52a0\u6587\u672c\u7684\u4f4d\u7f6e\u5c31\u662f\u6807\u8bb0\u70b9marker\u7684\u4f4d\u7f6e\uff0c\u7531x\uff0cy\u5750\u6807\u51b3\u5b9a for x, y in zip(axes[1, 0].get_xticks(), stock1):     axes[1, 0].text(x, y,                      s='(%.0d, %.0d)' %(x, y),                      size=10) for x, y in zip(axes[1, 0].get_xticks(), stock2):     axes[1, 0].text(x, y,                      s='(%.0d, %.0d)' %(x, y),                      size=12,                     horizontalalignment='center',                     verticalalignment='baseline') # axes[1, 1].remove() fig Out[27]: In\u00a0[28]: Copied! <pre>axes[1, 1].text(0.6, 0.4, \n                    s='(%.0f, %.0f)' %(0.6, 0.4), \n                    size=10)\nfig\n</pre> axes[1, 1].text(0.6, 0.4,                      s='(%.0f, %.0f)' %(0.6, 0.4),                      size=10) fig Out[28]: In\u00a0[29]: Copied! <pre># \u4e3a\u4e86\u907f\u514d\u91cd\u53e0\uff0c\u5728\u753b\u56fe\u4e4b\u524d\u5148\u5c06\u5b50\u56fe\u6e05\u7a7a\uff0c\u53ea\u7559\u4e0b\u5750\u6807\u8f74\n# axes\u88abremove\u540e\uff0cclear\u81ea\u52a8\u4e0d\u6267\u884c\nfor i, j in product([2],[0, 1]):\n    axes[i, j].clear()\n\ntick_label=['\u7b2c\u4e00\u5b63\u5ea6', '\u7b2c\u4e8c\u5b63\u5ea6', '\u7b2c\u4e09\u5b63\u5ea6', '\u7b2c\u56db\u5b63\u5ea6']\nlabel=['\u4e00\u5b63\u5ea6', '\u4e8c\u5b63\u5ea6', '\u4e09\u5b63\u5ea6', '\u56db\u5b63\u5ea6']\n\n# https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.plot.html\n# \u6ce8\u610f\uff0caxes.plot\u7684\u8bed\u6cd5\u4e0d\u5305\u542b\u53c2\u6570\u540d\u79f0\naxes[2, 0].scatter(x=seasons, # x\u5750\u6807\n                   y=stock1, # y\u5750\u6807\n                   s=[10, 20, 50, 100], # \u6563\u70b9\u7684\u5927\u5c0f\n                   c=['r', 'b', 'c', 'y']) # \u6563\u70b9\u7684\u989c\u8272\naxes[2, 0].scatter(x=seasons, # x\u5750\u6807\n                   y=stock2, # y\u5750\u6807\n                   s=[10, 20, 50, 100], # \u6563\u70b9\u7684\u5927\u5c0f\n                   c=['r', 'b', 'c', 'y']) # \u6563\u70b9\u7684\u989c\u8272\n\naxes[2, 0].set_ylabel(ylabel='\u80a1\u7968\u4ef7\u683c')\naxes[2, 0].set_xlabel(xlabel='\u5b63\u5ea6')\n\naxes[2, 0].set_xticks(ticks=np.arange(len(seasons)) + 1,\n                      labels=tick_label)\n\nfig\n</pre> # \u4e3a\u4e86\u907f\u514d\u91cd\u53e0\uff0c\u5728\u753b\u56fe\u4e4b\u524d\u5148\u5c06\u5b50\u56fe\u6e05\u7a7a\uff0c\u53ea\u7559\u4e0b\u5750\u6807\u8f74 # axes\u88abremove\u540e\uff0cclear\u81ea\u52a8\u4e0d\u6267\u884c for i, j in product([2],[0, 1]):     axes[i, j].clear()  tick_label=['\u7b2c\u4e00\u5b63\u5ea6', '\u7b2c\u4e8c\u5b63\u5ea6', '\u7b2c\u4e09\u5b63\u5ea6', '\u7b2c\u56db\u5b63\u5ea6'] label=['\u4e00\u5b63\u5ea6', '\u4e8c\u5b63\u5ea6', '\u4e09\u5b63\u5ea6', '\u56db\u5b63\u5ea6']  # https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.plot.html # \u6ce8\u610f\uff0caxes.plot\u7684\u8bed\u6cd5\u4e0d\u5305\u542b\u53c2\u6570\u540d\u79f0 axes[2, 0].scatter(x=seasons, # x\u5750\u6807                    y=stock1, # y\u5750\u6807                    s=[10, 20, 50, 100], # \u6563\u70b9\u7684\u5927\u5c0f                    c=['r', 'b', 'c', 'y']) # \u6563\u70b9\u7684\u989c\u8272 axes[2, 0].scatter(x=seasons, # x\u5750\u6807                    y=stock2, # y\u5750\u6807                    s=[10, 20, 50, 100], # \u6563\u70b9\u7684\u5927\u5c0f                    c=['r', 'b', 'c', 'y']) # \u6563\u70b9\u7684\u989c\u8272  axes[2, 0].set_ylabel(ylabel='\u80a1\u7968\u4ef7\u683c') axes[2, 0].set_xlabel(xlabel='\u5b63\u5ea6')  axes[2, 0].set_xticks(ticks=np.arange(len(seasons)) + 1,                       labels=tick_label)  fig Out[29]: In\u00a0[30]: Copied! <pre># \u4e3a\u4e86\u907f\u514d\u91cd\u53e0\uff0c\u5728\u753b\u56fe\u4e4b\u524d\u5148\u5c06\u5b50\u56fe\u6e05\u7a7a\uff0c\u53ea\u7559\u4e0b\u5750\u6807\u8f74\n# axes\u88abremove\u540e\uff0cclear\u81ea\u52a8\u4e0d\u6267\u884c\nfor i, j in product([3],[0, 1]):\n    axes[i, j].clear()\n\nlabels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\nsizes = [15, 30, 45, 10]\naxes[3, 0].pie(x=sizes, \n               labels=labels,\n               autopct='%1.2f%%', # \u81ea\u52a8\u8ba1\u7b97\u767e\u5206\u6bd4\u5e76\u663e\u793a\uff0c\u4f20\u5165\u4e00\u4e2aformat func\u6765\u63a7\u5236\u767e\u5206\u6bd4\u663e\u793a\u7684\u683c\u5f0f\n               labeldistance=0.6, # label\u7684\u4f4d\u7f6e\n               pctdistance=1.25) # \u767e\u5206\u6bd4\u7684\u4f4d\u7f6e\n\nexplode=[0, 0.1, 0.2, 0]\naxes[3, 1].pie(x=sizes, \n               labels=labels,\n               autopct='%1.2f%%', # \u81ea\u52a8\u8ba1\u7b97\u767e\u5206\u6bd4\u5e76\u663e\u793a\uff0c\u4f20\u5165\u4e00\u4e2aformat func\u6765\u63a7\u5236\u767e\u5206\u6bd4\u663e\u793a\u7684\u683c\u5f0f\n               labeldistance=0.6, # label\u7684\u4f4d\u7f6e\n               pctdistance=1.25,\n               explode=explode, # \u5206\u88c2\n               shadow=True, # \u5206\u88c2\u540e\u7684\u9634\u5f71\n               startangle=-90) # \u997c\u56fe\u7b2c\u4e00\u5757\u9006\u65f6\u9488\u65cb\u8f6c\u7684\u5f00\u59cb\u89d2\u5ea6\uff0c\u9ed8\u8ba4\u4e3a0\u5ea6\uff0c\u8d1f\u6570\u4ee3\u8868\u987a\u65f6\u9488\nfig\n</pre> # \u4e3a\u4e86\u907f\u514d\u91cd\u53e0\uff0c\u5728\u753b\u56fe\u4e4b\u524d\u5148\u5c06\u5b50\u56fe\u6e05\u7a7a\uff0c\u53ea\u7559\u4e0b\u5750\u6807\u8f74 # axes\u88abremove\u540e\uff0cclear\u81ea\u52a8\u4e0d\u6267\u884c for i, j in product([3],[0, 1]):     axes[i, j].clear()  labels = 'Frogs', 'Hogs', 'Dogs', 'Logs' sizes = [15, 30, 45, 10] axes[3, 0].pie(x=sizes,                 labels=labels,                autopct='%1.2f%%', # \u81ea\u52a8\u8ba1\u7b97\u767e\u5206\u6bd4\u5e76\u663e\u793a\uff0c\u4f20\u5165\u4e00\u4e2aformat func\u6765\u63a7\u5236\u767e\u5206\u6bd4\u663e\u793a\u7684\u683c\u5f0f                labeldistance=0.6, # label\u7684\u4f4d\u7f6e                pctdistance=1.25) # \u767e\u5206\u6bd4\u7684\u4f4d\u7f6e  explode=[0, 0.1, 0.2, 0] axes[3, 1].pie(x=sizes,                 labels=labels,                autopct='%1.2f%%', # \u81ea\u52a8\u8ba1\u7b97\u767e\u5206\u6bd4\u5e76\u663e\u793a\uff0c\u4f20\u5165\u4e00\u4e2aformat func\u6765\u63a7\u5236\u767e\u5206\u6bd4\u663e\u793a\u7684\u683c\u5f0f                labeldistance=0.6, # label\u7684\u4f4d\u7f6e                pctdistance=1.25,                explode=explode, # \u5206\u88c2                shadow=True, # \u5206\u88c2\u540e\u7684\u9634\u5f71                startangle=-90) # \u997c\u56fe\u7b2c\u4e00\u5757\u9006\u65f6\u9488\u65cb\u8f6c\u7684\u5f00\u59cb\u89d2\u5ea6\uff0c\u9ed8\u8ba4\u4e3a0\u5ea6\uff0c\u8d1f\u6570\u4ee3\u8868\u987a\u65f6\u9488 fig Out[30]: In\u00a0[52]: Copied! <pre># Create a random number generator with a fixed seed for reproducibility\nrng = np.random.default_rng(19680801)\nN_points = 100000\nn_bins = 200\n# Generate two normal distributions\ndist1 = rng.standard_normal(N_points)\ndist2 = 0.4 * rng.standard_normal(N_points) + 5\n</pre> # Create a random number generator with a fixed seed for reproducibility rng = np.random.default_rng(19680801) N_points = 100000 n_bins = 200 # Generate two normal distributions dist1 = rng.standard_normal(N_points) dist2 = 0.4 * rng.standard_normal(N_points) + 5 In\u00a0[53]: Copied! <pre>dist1, dist2\n</pre> dist1, dist2 Out[53]: <pre>(array([-0.98584721,  0.05040332,  0.96828412, ..., -0.0276232 ,\n         1.18599853,  0.48812025]),\n array([4.66841858, 5.35434074, 5.08634525, ..., 4.90661828, 5.66887405,\n        4.93344686]))</pre> In\u00a0[58]: Copied! <pre># \u4e3a\u4e86\u907f\u514d\u91cd\u53e0\uff0c\u5728\u753b\u56fe\u4e4b\u524d\u5148\u5c06\u5b50\u56fe\u6e05\u7a7a\uff0c\u53ea\u7559\u4e0b\u5750\u6807\u8f74\nfor i, j in product([4],[0, 1]):\n    axes[i, j].clear()\n\naxes[4, 0].hist(x=dist1, # \u6570\u636e\n                bins=n_bins,  # \u76f4\u65b9\u56fe\u7684\u76f4\u65b9\u4e2a\u6570\n                range=(0, 5), # \u76f4\u65b9\u56fe\u6570\u636e\u70b9\u7684\u8303\u56f4\n                density=True, # \u662f\u5426\u8981\u628a\u7eb5\u5750\u6807\u7684\u9891\u6570\u8f6c\u6362\u4e3a\u6982\u7387\uff08\u9891\u6570/\u603b\u6570)\n               )\naxes[4, 1].hist(dist1, bins=n_bins)\nfig\n</pre> # \u4e3a\u4e86\u907f\u514d\u91cd\u53e0\uff0c\u5728\u753b\u56fe\u4e4b\u524d\u5148\u5c06\u5b50\u56fe\u6e05\u7a7a\uff0c\u53ea\u7559\u4e0b\u5750\u6807\u8f74 for i, j in product([4],[0, 1]):     axes[i, j].clear()  axes[4, 0].hist(x=dist1, # \u6570\u636e                 bins=n_bins,  # \u76f4\u65b9\u56fe\u7684\u76f4\u65b9\u4e2a\u6570                 range=(0, 5), # \u76f4\u65b9\u56fe\u6570\u636e\u70b9\u7684\u8303\u56f4                 density=True, # \u662f\u5426\u8981\u628a\u7eb5\u5750\u6807\u7684\u9891\u6570\u8f6c\u6362\u4e3a\u6982\u7387\uff08\u9891\u6570/\u603b\u6570)                ) axes[4, 1].hist(dist1, bins=n_bins) fig Out[58]: In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[16]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# data from https://allisonhorst.github.io/palmerpenguins/\n\nspecies = (\n    \"Adelie\\n $\\\\mu=$3700.66g\",\n    \"Chinstrap\\n $\\\\mu=$3733.09g\",\n    \"Gentoo\\n $\\\\mu=5076.02g$\",\n)\nweight_counts = {\n    \"Below\": np.array([70, 31, 58]),\n    \"Above\": np.array([82, 37, 66]),\n}\nwidth = 0.5\n\nfig, ax = plt.subplots()\nbottom = np.zeros(3)\n\nfor boolean, weight_count in weight_counts.items():\n    p = ax.bar(species, weight_count, width, label=boolean, bottom=bottom)\n    bottom += weight_count\n\nax.set_title(\"Number of penguins with above average body mass\")\nax.legend(loc=\"upper right\")\n\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # data from https://allisonhorst.github.io/palmerpenguins/  species = (     \"Adelie\\n $\\\\mu=$3700.66g\",     \"Chinstrap\\n $\\\\mu=$3733.09g\",     \"Gentoo\\n $\\\\mu=5076.02g$\", ) weight_counts = {     \"Below\": np.array([70, 31, 58]),     \"Above\": np.array([82, 37, 66]), } width = 0.5  fig, ax = plt.subplots() bottom = np.zeros(3)  for boolean, weight_count in weight_counts.items():     p = ax.bar(species, weight_count, width, label=boolean, bottom=bottom)     bottom += weight_count  ax.set_title(\"Number of penguins with above average body mass\") ax.legend(loc=\"upper right\")  plt.show() In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/matplotlib_relevant/#matplotlib","title":"\u5173\u4e8ematplotlib\u7684\u77e5\u8bc6\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/matplotlib_relevant/#1","title":"1. \u5bf9\u8c61\u7ed3\u6784\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/matplotlib_relevant/","title":"\u5bf9\u8c61\u7c7b\u578b\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/matplotlib_relevant/#2510-axes-figure","title":"\u57fa\u7840\u6784\u9020\u5e38\u7528\u53c2\u6570\uff0c\u6784\u90202*5=10\u4e2a axes \u7684 figure\uff1a\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/matplotlib_relevant/#1","title":"1. \u67f1\u72b6\u56fe\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/matplotlib_relevant/#2","title":"2. \u6298\u7ebf\u56fe\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/matplotlib_relevant/#3","title":"3. \u6563\u70b9\u56fe\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/matplotlib_relevant/#4","title":"4. \u997c\u56fe\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/matplotlib_relevant/#5","title":"5. \u76f4\u65b9\u56fe\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/matplotlib_relevant/#2","title":"2. \u4e00\u4e9b\u4f8b\u5b50\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/matplotlib_relevant/#1-stacked-bar-chart","title":"1. stacked bar chart\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/","title":"Quick start guide","text":"In\u00a0[2]: Copied! <pre>import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\n</pre> import matplotlib as mpl import matplotlib.pyplot as plt import numpy as np In\u00a0[2]: Copied! <pre>fig, ax = plt.subplots()  # Create a figure containing a single axes.\nax.plot([1, 2, 3, 4], [1, 4, 2, 3])  # Plot some data on the axes.\n</pre> fig, ax = plt.subplots()  # Create a figure containing a single axes. ax.plot([1, 2, 3, 4], [1, 4, 2, 3])  # Plot some data on the axes. Out[2]: <pre>[&lt;matplotlib.lines.Line2D at 0x7fb23855e040&gt;]</pre> In\u00a0[5]: Copied! <pre>type(fig)\n</pre> type(fig) Out[5]: <pre>matplotlib.figure.Figure</pre> In\u00a0[6]: Copied! <pre>fig = plt.figure() \ntype(fig)\n</pre> fig = plt.figure()  type(fig) Out[6]: <pre>matplotlib.figure.Figure</pre> <pre>&lt;Figure size 640x480 with 0 Axes&gt;</pre> <p>Note that to get this Figure to display, you may have to call <code>plt.show()</code>, depending on your backend.  For more details of Figures and backends, see <code>figure_explanation</code>.</p> In\u00a0[15]: Copied! <pre># fig = plt.figure()  # an empty figure with no Axes\nfig, ax = plt.subplots()  # a figure with a single Axes\nfig, axs = plt.subplots(2, 2)  # a figure with a 2x2 grid of Axes\n# a figure with one axes on the left, and two on the right:\n# fig, axs = plt.subplot_mosaic([['left', 'right_top'],\n#                                ['left', 'right_bottom']])\n</pre> # fig = plt.figure()  # an empty figure with no Axes fig, ax = plt.subplots()  # a figure with a single Axes fig, axs = plt.subplots(2, 2)  # a figure with a 2x2 grid of Axes # a figure with one axes on the left, and two on the right: # fig, axs = plt.subplot_mosaic([['left', 'right_top'], #                                ['left', 'right_bottom']]) In\u00a0[20]: Copied! <pre>b = np.matrix([[1, 2], [3, 4]])\nb_asarray = np.asarray(b)\nb_asarray\n</pre> b = np.matrix([[1, 2], [3, 4]]) b_asarray = np.asarray(b) b_asarray Out[20]: <pre>array([[1, 2],\n       [3, 4]])</pre> In\u00a0[3]: Copied! <pre>np.random.seed(19680801)  # seed the random number generator.\ndata = {'a': np.arange(50),\n        'c': np.random.randint(0, 50, 50),\n        'd': np.random.randn(50)}\ndata['b'] = data['a'] + 10 * np.random.randn(50)\ndata['d'] = np.abs(data['d']) * 100\n\nfig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained')\nax.scatter('a', 'b', c='c', s='d', data=data)\nax.set_xlabel('entry a')\nax.set_ylabel('entry b')\n</pre> np.random.seed(19680801)  # seed the random number generator. data = {'a': np.arange(50),         'c': np.random.randint(0, 50, 50),         'd': np.random.randn(50)} data['b'] = data['a'] + 10 * np.random.randn(50) data['d'] = np.abs(data['d']) * 100  fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained') ax.scatter('a', 'b', c='c', s='d', data=data) ax.set_xlabel('entry a') ax.set_ylabel('entry b') Out[3]: <pre>Text(0, 0.5, 'entry b')</pre> In\u00a0[5]: Copied! <pre>type(ax)\n</pre> type(ax) Out[5]: <pre>matplotlib.axes._axes.Axes</pre> In\u00a0[10]: Copied! <pre>plt.subplots()\n</pre> plt.subplots() Out[10]: <pre>(&lt;Figure size 640x480 with 1 Axes&gt;, &lt;Axes: &gt;)</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>np.random.seed(19680801)  # seed the random number generator.\ndata = {'a': np.arange(50),\n        'c': np.random.randint(0, 50, 50),\n        'd': np.random.randn(50)}\ndata['b'] = data['a'] + 10 * np.random.randn(50)\ndata['d'] = np.abs(data['d']) * 100\n\nfig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained')\nax.scatter('a', 'b', c='c', s='d', data=data)\nax.set_xlabel('entry a')\nax.set_ylabel('entry b')\n</pre> np.random.seed(19680801)  # seed the random number generator. data = {'a': np.arange(50),         'c': np.random.randint(0, 50, 50),         'd': np.random.randn(50)} data['b'] = data['a'] + 10 * np.random.randn(50) data['d'] = np.abs(data['d']) * 100  fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained') ax.scatter('a', 'b', c='c', s='d', data=data) ax.set_xlabel('entry a') ax.set_ylabel('entry b') In\u00a0[\u00a0]: Copied! <pre>x = np.linspace(0, 2, 100)  # Sample data.\n\n# Note that even in the OO-style, we use `.pyplot.figure` to create the Figure.\nfig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained')\nax.plot(x, x, label='linear')  # Plot some data on the axes.\nax.plot(x, x**2, label='quadratic')  # Plot more data on the axes...\nax.plot(x, x**3, label='cubic')  # ... and some more.\nax.set_xlabel('x label')  # Add an x-label to the axes.\nax.set_ylabel('y label')  # Add a y-label to the axes.\nax.set_title(\"Simple Plot\")  # Add a title to the axes.\nax.legend()  # Add a legend.\n</pre> x = np.linspace(0, 2, 100)  # Sample data.  # Note that even in the OO-style, we use `.pyplot.figure` to create the Figure. fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained') ax.plot(x, x, label='linear')  # Plot some data on the axes. ax.plot(x, x**2, label='quadratic')  # Plot more data on the axes... ax.plot(x, x**3, label='cubic')  # ... and some more. ax.set_xlabel('x label')  # Add an x-label to the axes. ax.set_ylabel('y label')  # Add a y-label to the axes. ax.set_title(\"Simple Plot\")  # Add a title to the axes. ax.legend()  # Add a legend. <p>or the pyplot-style:</p> In\u00a0[\u00a0]: Copied! <pre>x = np.linspace(0, 2, 100)  # Sample data.\n\nplt.figure(figsize=(5, 2.7), layout='constrained')\nplt.plot(x, x, label='linear')  # Plot some data on the (implicit) axes.\nplt.plot(x, x**2, label='quadratic')  # etc.\nplt.plot(x, x**3, label='cubic')\nplt.xlabel('x label')\nplt.ylabel('y label')\nplt.title(\"Simple Plot\")\nplt.legend()\n</pre> x = np.linspace(0, 2, 100)  # Sample data.  plt.figure(figsize=(5, 2.7), layout='constrained') plt.plot(x, x, label='linear')  # Plot some data on the (implicit) axes. plt.plot(x, x**2, label='quadratic')  # etc. plt.plot(x, x**3, label='cubic') plt.xlabel('x label') plt.ylabel('y label') plt.title(\"Simple Plot\") plt.legend() <p>(In addition, there is a third approach, for the case when embedding Matplotlib in a GUI application, which completely drops pyplot, even for figure creation. See the corresponding section in the gallery for more info: <code>user_interfaces</code>.)</p> <p>Matplotlib's documentation and examples use both the OO and the pyplot styles. In general, we suggest using the OO style, particularly for complicated plots, and functions and scripts that are intended to be reused as part of a larger project. However, the pyplot style can be very convenient for quick interactive work.</p> Note<p>You may find older examples that use the ``pylab`` interface,    via ``from pylab import *``. This approach is strongly deprecated.</p> In\u00a0[\u00a0]: Copied! <pre>def my_plotter(ax, data1, data2, param_dict):\n    \"\"\"\n    A helper function to make a graph.\n    \"\"\"\n    out = ax.plot(data1, data2, **param_dict)\n    return out\n</pre> def my_plotter(ax, data1, data2, param_dict):     \"\"\"     A helper function to make a graph.     \"\"\"     out = ax.plot(data1, data2, **param_dict)     return out <p>which you would then use twice to populate two subplots:</p> In\u00a0[\u00a0]: Copied! <pre>data1, data2, data3, data4 = np.random.randn(4, 100)  # make 4 random data sets\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(5, 2.7))\nmy_plotter(ax1, data1, data2, {'marker': 'x'})\nmy_plotter(ax2, data3, data4, {'marker': 'o'})\n</pre> data1, data2, data3, data4 = np.random.randn(4, 100)  # make 4 random data sets fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(5, 2.7)) my_plotter(ax1, data1, data2, {'marker': 'x'}) my_plotter(ax2, data3, data4, {'marker': 'o'}) <p>Note that if you want to install these as a python package, or any other customizations you could use one of the many templates on the web; Matplotlib has one at mpl-cookiecutter</p> In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(figsize=(5, 2.7))\nx = np.arange(len(data1))\nax.plot(x, np.cumsum(data1), color='blue', linewidth=3, linestyle='--')\nl, = ax.plot(x, np.cumsum(data2), color='orange', linewidth=2)\nl.set_linestyle(':')\n</pre> fig, ax = plt.subplots(figsize=(5, 2.7)) x = np.arange(len(data1)) ax.plot(x, np.cumsum(data1), color='blue', linewidth=3, linestyle='--') l, = ax.plot(x, np.cumsum(data2), color='orange', linewidth=2) l.set_linestyle(':') In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(figsize=(5, 2.7))\nax.scatter(data1, data2, s=50, facecolor='C0', edgecolor='k')\n</pre> fig, ax = plt.subplots(figsize=(5, 2.7)) ax.scatter(data1, data2, s=50, facecolor='C0', edgecolor='k') In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(figsize=(5, 2.7))\nax.plot(data1, 'o', label='data1')\nax.plot(data2, 'd', label='data2')\nax.plot(data3, 'v', label='data3')\nax.plot(data4, 's', label='data4')\nax.legend()\n</pre> fig, ax = plt.subplots(figsize=(5, 2.7)) ax.plot(data1, 'o', label='data1') ax.plot(data2, 'd', label='data2') ax.plot(data3, 'v', label='data3') ax.plot(data4, 's', label='data4') ax.legend() In\u00a0[\u00a0]: Copied! <pre>mu, sigma = 115, 15\nx = mu + sigma * np.random.randn(10000)\nfig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained')\n# the histogram of the data\nn, bins, patches = ax.hist(x, 50, density=True, facecolor='C0', alpha=0.75)\n\nax.set_xlabel('Length [cm]')\nax.set_ylabel('Probability')\nax.set_title('Aardvark lengths\\n (not really)')\nax.text(75, .025, r'$\\mu=115,\\ \\sigma=15$')\nax.axis([55, 175, 0, 0.03])\nax.grid(True)\n</pre> mu, sigma = 115, 15 x = mu + sigma * np.random.randn(10000) fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained') # the histogram of the data n, bins, patches = ax.hist(x, 50, density=True, facecolor='C0', alpha=0.75)  ax.set_xlabel('Length [cm]') ax.set_ylabel('Probability') ax.set_title('Aardvark lengths\\n (not really)') ax.text(75, .025, r'$\\mu=115,\\ \\sigma=15$') ax.axis([55, 175, 0, 0.03]) ax.grid(True) <p>All of the <code>~.Axes.text</code> functions return a <code>matplotlib.text.Text</code> instance.  Just as with lines above, you can customize the properties by passing keyword arguments into the text functions::</p> <p>t = ax.set_xlabel('my data', fontsize=14, color='red')</p> <p>These properties are covered in more detail in :doc:<code>/tutorials/text/text_props</code>.</p> In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(figsize=(5, 2.7))\n\nt = np.arange(0.0, 5.0, 0.01)\ns = np.cos(2 * np.pi * t)\nline, = ax.plot(t, s, lw=2)\n\nax.annotate('local max', xy=(2, 1), xytext=(3, 1.5),\n            arrowprops=dict(facecolor='black', shrink=0.05))\n\nax.set_ylim(-2, 2)\n</pre> fig, ax = plt.subplots(figsize=(5, 2.7))  t = np.arange(0.0, 5.0, 0.01) s = np.cos(2 * np.pi * t) line, = ax.plot(t, s, lw=2)  ax.annotate('local max', xy=(2, 1), xytext=(3, 1.5),             arrowprops=dict(facecolor='black', shrink=0.05))  ax.set_ylim(-2, 2) <p>In this basic example, both xy and xytext are in data coordinates. There are a variety of other coordinate systems one can choose -- see <code>annotations-tutorial</code> and <code>plotting-guide-annotation</code> for details.  More examples also can be found in :doc:<code>/gallery/text_labels_and_annotations/annotation_demo</code>.</p> In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(figsize=(5, 2.7))\nax.plot(np.arange(len(data1)), data1, label='data1')\nax.plot(np.arange(len(data2)), data2, label='data2')\nax.plot(np.arange(len(data3)), data3, 'd', label='data3')\nax.legend()\n</pre> fig, ax = plt.subplots(figsize=(5, 2.7)) ax.plot(np.arange(len(data1)), data1, label='data1') ax.plot(np.arange(len(data2)), data2, label='data2') ax.plot(np.arange(len(data3)), data3, 'd', label='data3') ax.legend() <p>Legends in Matplotlib are quite flexible in layout, placement, and what Artists they can represent. They are discussed in detail in :doc:<code>/tutorials/intermediate/legend_guide</code>.</p> In\u00a0[\u00a0]: Copied! <pre>fig, axs = plt.subplots(1, 2, figsize=(5, 2.7), layout='constrained')\nxdata = np.arange(len(data1))  # make an ordinal for this\ndata = 10**data1\naxs[0].plot(xdata, data)\n\naxs[1].set_yscale('log')\naxs[1].plot(xdata, data)\n</pre> fig, axs = plt.subplots(1, 2, figsize=(5, 2.7), layout='constrained') xdata = np.arange(len(data1))  # make an ordinal for this data = 10**data1 axs[0].plot(xdata, data)  axs[1].set_yscale('log') axs[1].plot(xdata, data) <p>The scale sets the mapping from data values to spacing along the Axis. This happens in both directions, and gets combined into a transform, which is the way that Matplotlib maps from data coordinates to Axes, Figure, or screen coordinates.  See :doc:<code>/tutorials/advanced/transforms_tutorial</code>.</p> In\u00a0[\u00a0]: Copied! <pre>fig, axs = plt.subplots(2, 1, layout='constrained')\naxs[0].plot(xdata, data1)\naxs[0].set_title('Automatic ticks')\n\naxs[1].plot(xdata, data1)\naxs[1].set_xticks(np.arange(0, 100, 30), ['zero', '30', 'sixty', '90'])\naxs[1].set_yticks([-1.5, 0, 1.5])  # note that we don't need to specify labels\naxs[1].set_title('Manual ticks')\n</pre> fig, axs = plt.subplots(2, 1, layout='constrained') axs[0].plot(xdata, data1) axs[0].set_title('Automatic ticks')  axs[1].plot(xdata, data1) axs[1].set_xticks(np.arange(0, 100, 30), ['zero', '30', 'sixty', '90']) axs[1].set_yticks([-1.5, 0, 1.5])  # note that we don't need to specify labels axs[1].set_title('Manual ticks') <p>Different scales can have different locators and formatters; for instance the log-scale above uses <code>~.LogLocator</code> and <code>~.LogFormatter</code>. See :doc:<code>/gallery/ticks/tick-locators</code> and :doc:<code>/gallery/ticks/tick-formatters</code> for other formatters and locators and information for writing your own.</p> In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained')\ndates = np.arange(np.datetime64('2021-11-15'), np.datetime64('2021-12-25'),\n                  np.timedelta64(1, 'h'))\ndata = np.cumsum(np.random.randn(len(dates)))\nax.plot(dates, data)\ncdf = mpl.dates.ConciseDateFormatter(ax.xaxis.get_major_locator())\nax.xaxis.set_major_formatter(cdf)\n</pre> fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained') dates = np.arange(np.datetime64('2021-11-15'), np.datetime64('2021-12-25'),                   np.timedelta64(1, 'h')) data = np.cumsum(np.random.randn(len(dates))) ax.plot(dates, data) cdf = mpl.dates.ConciseDateFormatter(ax.xaxis.get_major_locator()) ax.xaxis.set_major_formatter(cdf) <p>For more information see the date examples (e.g. :doc:<code>/gallery/text_labels_and_annotations/date</code>)</p> <p>For strings, we get categorical plotting (see: :doc:<code>/gallery/lines_bars_and_markers/categorical_variables</code>).</p> In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained')\ncategories = ['turnips', 'rutabaga', 'cucumber', 'pumpkins']\n\nax.bar(categories, np.random.rand(len(categories)))\n</pre> fig, ax = plt.subplots(figsize=(5, 2.7), layout='constrained') categories = ['turnips', 'rutabaga', 'cucumber', 'pumpkins']  ax.bar(categories, np.random.rand(len(categories))) <p>One caveat about categorical plotting is that some methods of parsing text files return a list of strings, even if the strings all represent numbers or dates.  If you pass 1000 strings, Matplotlib will think you meant 1000 categories and will add 1000 ticks to your plot!</p> In\u00a0[\u00a0]: Copied! <pre>fig, (ax1, ax3) = plt.subplots(1, 2, figsize=(7, 2.7), layout='constrained')\nl1, = ax1.plot(t, s)\nax2 = ax1.twinx()\nl2, = ax2.plot(t, range(len(t)), 'C1')\nax2.legend([l1, l2], ['Sine (left)', 'Straight (right)'])\n\nax3.plot(t, s)\nax3.set_xlabel('Angle [rad]')\nax4 = ax3.secondary_xaxis('top', functions=(np.rad2deg, np.deg2rad))\nax4.set_xlabel('Angle [\u00b0]')\n</pre> fig, (ax1, ax3) = plt.subplots(1, 2, figsize=(7, 2.7), layout='constrained') l1, = ax1.plot(t, s) ax2 = ax1.twinx() l2, = ax2.plot(t, range(len(t)), 'C1') ax2.legend([l1, l2], ['Sine (left)', 'Straight (right)'])  ax3.plot(t, s) ax3.set_xlabel('Angle [rad]') ax4 = ax3.secondary_xaxis('top', functions=(np.rad2deg, np.deg2rad)) ax4.set_xlabel('Angle [\u00b0]') In\u00a0[\u00a0]: Copied! <pre>X, Y = np.meshgrid(np.linspace(-3, 3, 128), np.linspace(-3, 3, 128))\nZ = (1 - X/2 + X**5 + Y**3) * np.exp(-X**2 - Y**2)\n\nfig, axs = plt.subplots(2, 2, layout='constrained')\npc = axs[0, 0].pcolormesh(X, Y, Z, vmin=-1, vmax=1, cmap='RdBu_r')\nfig.colorbar(pc, ax=axs[0, 0])\naxs[0, 0].set_title('pcolormesh()')\n\nco = axs[0, 1].contourf(X, Y, Z, levels=np.linspace(-1.25, 1.25, 11))\nfig.colorbar(co, ax=axs[0, 1])\naxs[0, 1].set_title('contourf()')\n\npc = axs[1, 0].imshow(Z**2 * 100, cmap='plasma',\n                          norm=mpl.colors.LogNorm(vmin=0.01, vmax=100))\nfig.colorbar(pc, ax=axs[1, 0], extend='both')\naxs[1, 0].set_title('imshow() with LogNorm()')\n\npc = axs[1, 1].scatter(data1, data2, c=data3, cmap='RdBu_r')\nfig.colorbar(pc, ax=axs[1, 1], extend='both')\naxs[1, 1].set_title('scatter()')\n</pre> X, Y = np.meshgrid(np.linspace(-3, 3, 128), np.linspace(-3, 3, 128)) Z = (1 - X/2 + X**5 + Y**3) * np.exp(-X**2 - Y**2)  fig, axs = plt.subplots(2, 2, layout='constrained') pc = axs[0, 0].pcolormesh(X, Y, Z, vmin=-1, vmax=1, cmap='RdBu_r') fig.colorbar(pc, ax=axs[0, 0]) axs[0, 0].set_title('pcolormesh()')  co = axs[0, 1].contourf(X, Y, Z, levels=np.linspace(-1.25, 1.25, 11)) fig.colorbar(co, ax=axs[0, 1]) axs[0, 1].set_title('contourf()')  pc = axs[1, 0].imshow(Z**2 * 100, cmap='plasma',                           norm=mpl.colors.LogNorm(vmin=0.01, vmax=100)) fig.colorbar(pc, ax=axs[1, 0], extend='both') axs[1, 0].set_title('imshow() with LogNorm()')  pc = axs[1, 1].scatter(data1, data2, c=data3, cmap='RdBu_r') fig.colorbar(pc, ax=axs[1, 1], extend='both') axs[1, 1].set_title('scatter()') In\u00a0[\u00a0]: Copied! <pre>fig, axd = plt.subplot_mosaic([['upleft', 'right'],\n                               ['lowleft', 'right']], layout='constrained')\naxd['upleft'].set_title('upleft')\naxd['lowleft'].set_title('lowleft')\naxd['right'].set_title('right')\n</pre> fig, axd = plt.subplot_mosaic([['upleft', 'right'],                                ['lowleft', 'right']], layout='constrained') axd['upleft'].set_title('upleft') axd['lowleft'].set_title('lowleft') axd['right'].set_title('right') <p>Matplotlib has quite sophisticated tools for arranging Axes: See :doc:<code>/tutorials/intermediate/arranging_axes</code> and :doc:<code>/gallery/subplots_axes_and_figures/mosaic</code>.</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#quick-start-guide","title":"Quick start guide\u00b6","text":"<p>This tutorial covers some basic usage patterns and best practices to help you get started with Matplotlib.</p> <p>.. redirect-from:: /tutorials/introductory/usage</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#a-simple-example","title":"A simple example\u00b6","text":"<p>Matplotlib graphs your data on <code>.Figure</code>\\s (e.g., windows, Jupyter widgets, etc.), each of which can contain one or more <code>~.axes.Axes</code>, an area where points can be specified in terms of x-y coordinates (or theta-r in a polar plot, x-y-z in a 3D plot, etc.).  The simplest way of creating a Figure with an Axes is using <code>.pyplot.subplots</code>. We can then use <code>.Axes.plot</code> to draw some data on the Axes:</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#parts-of-a-figure","title":"Parts of a Figure\u00b6","text":"<p>Here are the components of a Matplotlib Figure.</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#classmatplotlibfigurefigure","title":":class:<code>~matplotlib.figure.Figure</code>\u00b6","text":"<p>The whole figure.  The Figure keeps track of all the child :class:<code>~matplotlib.axes.Axes</code>, a group of 'special' Artists (titles, figure legends, colorbars, etc), and even nested subfigures.</p> <p>The easiest way to create a new Figure is with pyplot::</p> <p>fig = plt.figure()  # an empty figure with no Axes fig, ax = plt.subplots()  # a figure with a single Axes fig, axs = plt.subplots(2, 2)  # a figure with a 2x2 grid of Axes</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#a-figure-with-one-axes-on-the-left-and-two-on-the-right","title":"a figure with one axes on the left, and two on the right:\u00b6","text":"<p>fig, axs = plt.subplot_mosaic([['left', 'right_top'], ['left', 'right_bottom']])</p> <p>It is often convenient to create the Axes together with the Figure, but you can also manually add Axes later on.  Note that many :doc:<code>Matplotlib backends &lt;/users/explain/backends&gt;</code> support zooming and panning on figure windows.</p> <p>For more on Figures, see <code>figure_explanation</code>.</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#classmatplotlibaxesaxes","title":":class:<code>~matplotlib.axes.Axes</code>\u00b6","text":"<p>An Axes is an Artist attached to a Figure that contains a region for plotting data, and usually includes two (or three in the case of 3D) :class:<code>~matplotlib.axis.Axis</code> objects (be aware of the difference between Axes and Axis) that provide ticks and tick labels to provide scales for the data in the Axes. Each :class:<code>~.axes.Axes</code> also has a title (set via :meth:<code>~matplotlib.axes.Axes.set_title</code>), an x-label (set via :meth:<code>~matplotlib.axes.Axes.set_xlabel</code>), and a y-label set via :meth:<code>~matplotlib.axes.Axes.set_ylabel</code>).</p> <p>The :class:<code>~.axes.Axes</code> class and its member functions are the primary entry point to working with the OOP interface, and have most of the plotting methods defined on them (e.g. <code>ax.plot()</code>, shown above, uses the <code>~.Axes.plot</code> method)</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#classmatplotlibaxisaxis","title":":class:<code>~matplotlib.axis.Axis</code>\u00b6","text":"<p>These objects set the scale and limits and generate ticks (the marks on the Axis) and ticklabels (strings labeling the ticks).  The location of the ticks is determined by a <code>~matplotlib.ticker.Locator</code> object and the ticklabel strings are formatted by a <code>~matplotlib.ticker.Formatter</code>.  The combination of the correct <code>.Locator</code> and <code>.Formatter</code> gives very fine control over the tick locations and labels.</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#classmatplotlibartistartist","title":":class:<code>~matplotlib.artist.Artist</code>\u00b6","text":"<p>Basically, everything visible on the Figure is an Artist (even <code>.Figure</code>, <code>Axes &lt;.axes.Axes&gt;</code>, and <code>~.axis.Axis</code> objects).  This includes <code>.Text</code> objects, <code>.Line2D</code> objects, :mod:<code>.collections</code> objects, <code>.Patch</code> objects, etc. When the Figure is rendered, all of the Artists are drawn to the canvas.  Most Artists are tied to an Axes; such an Artist cannot be shared by multiple Axes, or moved from one to another.</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#types-of-inputs-to-plotting-functions","title":"Types of inputs to plotting functions\u00b6","text":"<p>Plotting functions expect <code>numpy.array</code> or <code>numpy.ma.masked_array</code> as input, or objects that can be passed to <code>numpy.asarray</code>. Classes that are similar to arrays ('array-like') such as <code>pandas</code> data objects and <code>numpy.matrix</code> may not work as intended.  Common convention is to convert these to <code>numpy.array</code> objects prior to plotting. For example, to convert a <code>numpy.matrix</code> ::</p> <p>b = np.matrix([[1, 2], [3, 4]]) b_asarray = np.asarray(b)</p> <p>Most methods will also parse an addressable object like a dict, a <code>numpy.recarray</code>, or a <code>pandas.DataFrame</code>.  Matplotlib allows you to provide the <code>data</code> keyword argument and generate plots passing the strings corresponding to the x and y variables.</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#coding-styles","title":"Coding styles\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#the-explicit-and-the-implicit-interfaces","title":"The explicit and the implicit interfaces\u00b6","text":"<p>As noted above, there are essentially two ways to use Matplotlib:</p> <ul> <li>Explicitly create Figures and Axes, and call methods on them (the \"object-oriented (OO) style\").</li> <li>Rely on pyplot to implicitly create and manage the Figures and Axes, and use pyplot functions for plotting.</li> </ul> <p>See <code>api_interfaces</code> for an explanation of the tradeoffs between the implicit and explicit interfaces.</p> <p>So one can use the OO-style</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#making-a-helper-functions","title":"Making a helper functions\u00b6","text":"<p>If you need to make the same plots over and over again with different data sets, or want to easily wrap Matplotlib methods, use the recommended signature function below.</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#styling-artists","title":"Styling Artists\u00b6","text":"<p>Most plotting methods have styling options for the Artists, accessible either when a plotting method is called, or from a \"setter\" on the Artist.  In the plot below we manually set the color, linewidth, and linestyle of the Artists created by <code>~.Axes.plot</code>, and we set the linestyle of the second line after the fact with <code>~.Line2D.set_linestyle</code>.</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#colors","title":"Colors\u00b6","text":"<p>Matplotlib has a very flexible array of colors that are accepted for most Artists; see the :doc:<code>colors tutorial &lt;/tutorials/colors/colors&gt;</code> for a list of specifications. Some Artists will take multiple colors.  i.e. for a <code>~.Axes.scatter</code> plot, the edge of the markers can be different colors from the interior:</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#linewidths-linestyles-and-markersizes","title":"Linewidths, linestyles, and markersizes\u00b6","text":"<p>Line widths are typically in typographic points (1 pt = 1/72 inch) and available for Artists that have stroked lines.  Similarly, stroked lines can have a linestyle.  See the :doc:<code>linestyles example &lt;/gallery/lines_bars_and_markers/linestyles&gt;</code>.</p> <p>Marker size depends on the method being used.  <code>~.Axes.plot</code> specifies markersize in points, and is generally the \"diameter\" or width of the marker.  <code>~.Axes.scatter</code> specifies markersize as approximately proportional to the visual area of the marker.  There is an array of markerstyles available as string codes (see :mod:<code>~.matplotlib.markers</code>), or users can define their own <code>~.MarkerStyle</code> (see :doc:<code>/gallery/lines_bars_and_markers/marker_reference</code>):</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#labelling-plots","title":"Labelling plots\u00b6","text":""},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#axes-labels-and-text","title":"Axes labels and text\u00b6","text":"<p><code>~.Axes.set_xlabel</code>, <code>~.Axes.set_ylabel</code>, and <code>~.Axes.set_title</code> are used to add text in the indicated locations (see :doc:<code>/tutorials/text/text_intro</code> for more discussion).  Text can also be directly added to plots using <code>~.Axes.text</code>:</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#using-mathematical-expressions-in-text","title":"Using mathematical expressions in text\u00b6","text":"<p>Matplotlib accepts TeX equation expressions in any text expression. For example to write the expression $\\sigma_i=15$ in the title, you can write a TeX expression surrounded by dollar signs::</p> <pre><code>ax.set_title(r'$\\sigma_i=15$')</code></pre> <p>where the <code>r</code> preceding the title string signifies that the string is a raw string and not to treat backslashes as python escapes. Matplotlib has a built-in TeX expression parser and layout engine, and ships its own math fonts \u2013 for details see :doc:<code>/tutorials/text/mathtext</code>.  You can also use LaTeX directly to format your text and incorporate the output directly into your display figures or saved postscript \u2013 see :doc:<code>/tutorials/text/usetex</code>.</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#annotations","title":"Annotations\u00b6","text":"<p>We can also annotate points on a plot, often by connecting an arrow pointing to xy, to a piece of text at xytext:</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#legends","title":"Legends\u00b6","text":"<p>Often we want to identify lines or markers with a <code>.Axes.legend</code>:</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#axis-scales-and-ticks","title":"Axis scales and ticks\u00b6","text":"<p>Each Axes has two (or three) <code>~.axis.Axis</code> objects representing the x- and y-axis. These control the scale of the Axis, the tick locators and the tick formatters. Additional Axes can be attached to display further Axis objects.</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#scales","title":"Scales\u00b6","text":"<p>In addition to the linear scale, Matplotlib supplies non-linear scales, such as a log-scale.  Since log-scales are used so much there are also direct methods like <code>~.Axes.loglog</code>, <code>~.Axes.semilogx</code>, and <code>~.Axes.semilogy</code>.  There are a number of scales (see :doc:<code>/gallery/scales/scales</code> for other examples).  Here we set the scale manually:</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#tick-locators-and-formatters","title":"Tick locators and formatters\u00b6","text":"<p>Each Axis has a tick locator and formatter that choose where along the Axis objects to put tick marks.  A simple interface to this is <code>~.Axes.set_xticks</code>:</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#plotting-dates-and-strings","title":"Plotting dates and strings\u00b6","text":"<p>Matplotlib can handle plotting arrays of dates and arrays of strings, as well as floating point numbers.  These get special locators and formatters as appropriate.  For dates:</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#additional-axis-objects","title":"Additional Axis objects\u00b6","text":"<p>Plotting data of different magnitude in one chart may require an additional y-axis. Such an Axis can be created by using <code>~.Axes.twinx</code> to add a new Axes with an invisible x-axis and a y-axis positioned at the right (analogously for <code>~.Axes.twiny</code>). See :doc:<code>/gallery/subplots_axes_and_figures/two_scales</code> for another example.</p> <p>Similarly, you can add a <code>~.Axes.secondary_xaxis</code> or <code>~.Axes.secondary_yaxis</code> having a different scale than the main Axis to represent the data in different scales or units. See :doc:<code>/gallery/subplots_axes_and_figures/secondary_axis</code> for further examples.</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#color-mapped-data","title":"Color mapped data\u00b6","text":"<p>Often we want to have a third dimension in a plot represented by a colors in a colormap. Matplotlib has a number of plot types that do this:</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#colormaps","title":"Colormaps\u00b6","text":"<p>These are all examples of Artists that derive from  <code>~.ScalarMappable</code> objects.  They all can set a linear mapping between vmin and vmax into the colormap specified by cmap.  Matplotlib has many colormaps to choose from (:doc:<code>/tutorials/colors/colormaps</code>) you can make your own (:doc:<code>/tutorials/colors/colormap-manipulation</code>) or download as third-party packages.</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#normalizations","title":"Normalizations\u00b6","text":"<p>Sometimes we want a non-linear mapping of the data to the colormap, as in the <code>LogNorm</code> example above.  We do this by supplying the ScalarMappable with the norm argument instead of vmin and vmax. More normalizations are shown at :doc:<code>/tutorials/colors/colormapnorms</code>.</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#colorbars","title":"Colorbars\u00b6","text":"<p>Adding a <code>~.Figure.colorbar</code> gives a key to relate the color back to the underlying data. Colorbars are figure-level Artists, and are attached to a ScalarMappable (where they get their information about the norm and colormap) and usually steal space from a parent Axes.  Placement of colorbars can be complex: see :doc:<code>/gallery/subplots_axes_and_figures/colorbar_placement</code> for details.  You can also change the appearance of colorbars with the extend keyword to add arrows to the ends, and shrink and aspect to control the size.  Finally, the colorbar will have default locators and formatters appropriate to the norm.  These can be changed as for other Axis objects.</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#working-with-multiple-figures-and-axes","title":"Working with multiple Figures and Axes\u00b6","text":"<p>You can open multiple Figures with multiple calls to <code>fig = plt.figure()</code> or <code>fig2, ax = plt.subplots()</code>.  By keeping the object references you can add Artists to either Figure.</p> <p>Multiple Axes can be added a number of ways, but the most basic is <code>plt.subplots()</code> as used above.  One can achieve more complex layouts, with Axes objects spanning columns or rows, using <code>~.pyplot.subplot_mosaic</code>.</p>"},{"location":"markdown/knowledge/code_knowledge/visualization/matplotlib/quick_start/#more-reading","title":"More reading\u00b6","text":"<p>For more plot types see :doc:<code>Plot types &lt;/plot_types/index&gt;</code> and the :doc:<code>API reference &lt;/api/index&gt;</code>, in particular the :doc:<code>Axes API &lt;/api/axes_api&gt;</code>.</p>"},{"location":"markdown/knowledge/deep_learning_notebook/CNN/","title":"CNN","text":"In\u00a0[2]: Copied! <pre>%matplotlib inline\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import CIFAR10\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom IPython.display import Image\n</pre> %matplotlib inline import os import numpy as np import matplotlib.pyplot as plt import torch from torch.utils.data import DataLoader from torchvision.datasets import CIFAR10 import torchvision import torchvision.transforms as transforms import torch.nn as nn import torch.nn.functional as F from IPython.display import Image In\u00a0[8]: Copied! <pre>Image(filename='./data/CNN_inout.png')\n</pre> Image(filename='./data/CNN_inout.png') Out[8]: <p>\u8fd9\u91cc\u7684<code>B</code>\u4ee3\u8868<code>batch size</code>\uff0c<code>Cin</code>\u4ee3\u8868\u8f93\u5165\u901a\u9053\u6570\uff0c<code>H\u3001W</code>\u4ee3\u8868\u6bcf\u4e2a\u901a\u9053\u7684\u4e8c\u7ef4\u56fe\u50cf\u7684\u9ad8\u5ea6\u548c\u5bbd\u5ea6</p> In\u00a0[33]: Copied! <pre>transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\nbatch_size = 4\n\ntrainset = CIFAR10(root='./data', train=True, download=False, transform=transform)\ntrainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n\ntestset = CIFAR10(root='./data', train=False, download=False, transform=transform)\ntestloader = DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n</pre> transform = transforms.Compose(     [transforms.ToTensor(),      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  batch_size = 4  trainset = CIFAR10(root='./data', train=True, download=False, transform=transform) trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)  testset = CIFAR10(root='./data', train=False, download=False, transform=transform) testloader = DataLoader(testset, batch_size=batch_size,                                          shuffle=False, num_workers=2)  classes = ('plane', 'car', 'bird', 'cat',            'deer', 'dog', 'frog', 'horse', 'ship', 'truck') In\u00a0[85]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\n\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\n# \u8fd9\u91cc\u7684iter\u51fd\u6570\u5c06trainloader\u8f6c\u6362\u4e3a\u8fed\u4ee3\u5668\u3002\n# imsages, label\u83b7\u53d6\u7684\u662f\u8fed\u4ee3\u5668\u7684\u4e0b\u4e00\u6761\u6570\u636e\uff0c\u5728\u8fd9\u91cc\u4e5f\u5c31\u662f\u4e00\u4e2a\u5c0f\u6279\u91cf\ndataiter = iter(trainloader)\nimsages, labels = next(dataiter)\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n</pre> import matplotlib.pyplot as plt import numpy as np  # functions to show an image   def imshow(img):     img = img / 2 + 0.5     # unnormalize     npimg = img.numpy()     plt.imshow(np.transpose(npimg, (1, 2, 0)))     plt.show()   # get some random training images # \u8fd9\u91cc\u7684iter\u51fd\u6570\u5c06trainloader\u8f6c\u6362\u4e3a\u8fed\u4ee3\u5668\u3002 # imsages, label\u83b7\u53d6\u7684\u662f\u8fed\u4ee3\u5668\u7684\u4e0b\u4e00\u6761\u6570\u636e\uff0c\u5728\u8fd9\u91cc\u4e5f\u5c31\u662f\u4e00\u4e2a\u5c0f\u6279\u91cf dataiter = iter(trainloader) imsages, labels = next(dataiter)  # show images imshow(torchvision.utils.make_grid(images)) # print labels print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size))) <pre>plane ship  ship  cat  \n</pre> In\u00a0[87]: Copied! <pre>X_train_batch, y_train_batch = next(iter(trainloader))\nX_test_batch, y_test_batch = next(iter(testloader))\n</pre> X_train_batch, y_train_batch = next(iter(trainloader)) X_test_batch, y_test_batch = next(iter(testloader)) In\u00a0[82]: Copied! <pre># images\u662f\u56db\u7ef4\u5f20\u91cf\uff0c\u8fd9\u4e5f\u662f\u56fe\u50cf\u6570\u636e\u7684\u4e00\u822c\u5f62\u5f0f\uff0c\u8868\u793a(\u6279\u91cf\u5927\u5c0f\uff0c\u901a\u9053\u6570\uff0c\u9ad8\u5ea6\uff0c\u5bbd\u5ea6)\u3002\n# \u901a\u9053\u6570\u4e3a3\u4ee3\u8868\u4e86RGB\u4e09\u539f\u8272\uff0c\u9ad8\u5ea6\u5bbd\u5ea6\u5747\u4e3a32\u4ee3\u8868\u4e86\u6bcf\u4e2a\u56fe\u50cf\u662f\u753132*32\u4e2a\u50cf\u7d20\u70b9\u6784\u6210\u7684\nprint(f' \u8bad\u7ec3\u96c6\u957f\u5ea6\u4e3a{len(trainset)}, \u6d4b\u8bd5\u96c6\u957f\u5ea6\u4e3a{len(testset)}\\n',\n      f'\u603b\u5171\u5206\u6210\u4e86{len(trainloader)}\u4e2a\u5c0f\u6279\u91cf, \u6bcf\u4e2a\u5c0f\u6279\u91cf\u5305\u542b{len(X_train_batch)}\u4e2a\u6837\u672c\\n',\n      f'\u8bad\u7ec3\u96c6\u5c0f\u6279\u91cf\u4e2d\u6837\u672c\u5f62\u72b6\u662f{X_train_batch.shape}, \u6807\u7b7e\u5f62\u72b6\u662f{y_train_batch.shape}\\n',\n      f'\u6d4b\u8bd5\u96c6\u5c0f\u6279\u91cf\u4e2d\u6837\u672c\u5f62\u72b6\u662f{X_test_batch.shape}, \u6807\u7b7e\u5f62\u72b6\u662f{y_test_batch.shape}')\n</pre> # images\u662f\u56db\u7ef4\u5f20\u91cf\uff0c\u8fd9\u4e5f\u662f\u56fe\u50cf\u6570\u636e\u7684\u4e00\u822c\u5f62\u5f0f\uff0c\u8868\u793a(\u6279\u91cf\u5927\u5c0f\uff0c\u901a\u9053\u6570\uff0c\u9ad8\u5ea6\uff0c\u5bbd\u5ea6)\u3002 # \u901a\u9053\u6570\u4e3a3\u4ee3\u8868\u4e86RGB\u4e09\u539f\u8272\uff0c\u9ad8\u5ea6\u5bbd\u5ea6\u5747\u4e3a32\u4ee3\u8868\u4e86\u6bcf\u4e2a\u56fe\u50cf\u662f\u753132*32\u4e2a\u50cf\u7d20\u70b9\u6784\u6210\u7684 print(f' \u8bad\u7ec3\u96c6\u957f\u5ea6\u4e3a{len(trainset)}, \u6d4b\u8bd5\u96c6\u957f\u5ea6\u4e3a{len(testset)}\\n',       f'\u603b\u5171\u5206\u6210\u4e86{len(trainloader)}\u4e2a\u5c0f\u6279\u91cf, \u6bcf\u4e2a\u5c0f\u6279\u91cf\u5305\u542b{len(X_train_batch)}\u4e2a\u6837\u672c\\n',       f'\u8bad\u7ec3\u96c6\u5c0f\u6279\u91cf\u4e2d\u6837\u672c\u5f62\u72b6\u662f{X_train_batch.shape}, \u6807\u7b7e\u5f62\u72b6\u662f{y_train_batch.shape}\\n',       f'\u6d4b\u8bd5\u96c6\u5c0f\u6279\u91cf\u4e2d\u6837\u672c\u5f62\u72b6\u662f{X_test_batch.shape}, \u6807\u7b7e\u5f62\u72b6\u662f{y_test_batch.shape}') <pre> \u8bad\u7ec3\u96c6\u957f\u5ea6\u4e3a50000, \u6d4b\u8bd5\u96c6\u957f\u5ea6\u4e3a10000\n \u603b\u5171\u5206\u6210\u4e8612500\u4e2a\u5c0f\u6279\u91cf, \u6bcf\u4e2a\u5c0f\u6279\u91cf\u5305\u542b4\u4e2a\u6837\u672c\n \u8bad\u7ec3\u96c6\u5c0f\u6279\u91cf\u4e2d\u6837\u672c\u5f62\u72b6\u662ftorch.Size([4, 3, 32, 32]), \u6807\u7b7e\u5f62\u72b6\u662ftorch.Size([4])\n \u6d4b\u8bd5\u96c6\u5c0f\u6279\u91cf\u4e2d\u6837\u672c\u5f62\u72b6\u662ftorch.Size([4, 3, 32, 32]), \u6807\u7b7e\u5f62\u72b6\u662ftorch.Size([4])\n</pre> In\u00a0[89]: Copied! <pre># y_train_batch(\u6807\u7b7e)\u4ee3\u8868classes\u4e2d\u5bf9\u5e94\u7d22\u5f15\u7684\u7c7b\u522b\ny_train_batch\n</pre> # y_train_batch(\u6807\u7b7e)\u4ee3\u8868classes\u4e2d\u5bf9\u5e94\u7d22\u5f15\u7684\u7c7b\u522b y_train_batch Out[89]: <pre>tensor([3, 8, 2, 7])</pre> In\u00a0[90]: Copied! <pre>classes\n</pre> classes Out[90]: <pre>('plane',\n 'car',\n 'bird',\n 'cat',\n 'deer',\n 'dog',\n 'frog',\n 'horse',\n 'ship',\n 'truck')</pre> <ul> <li>\u5bf9\u6bcf\u4e2a\u5c0f\u6279\u91cf\u7684\u8bad\u7ec3\uff0c\u8f93\u5165\u5f62\u72b6\u4e3a``</li> <li><code>in_channels</code>\u4ee3\u8868\u8f93\u5165\u7684\u901a\u9053\u6570\uff0c\u5728\u6b64\u4f8b\u4e2d\u8f93\u5165\u7684\u901a\u9053\u6570\u4e3a3\uff0c\u5219<code>in_channel</code>\u53c2\u6570\u5fc5\u987b\u7531\u8f93\u5165\u7684\u5f62\u72b6\u786e\u5b9a\uff0c\u5426\u5219\u4f1a\u62a5\u9519\u3002\u5373\uff1a<code>\u6211\u4eec\u9700\u8981\u4fdd\u8bc1 in_channels = input.shape[1]</code></li> <li><code>out_channels</code>\u4ee3\u8868\u8f93\u51fa\u7684\u901a\u9053\u6570\uff0c\u5bf9\u4e8e\u56db\u7ef4\u5f20\u91cf\uff0c\u6838\u51fd\u6570\u6709\u51e0\u4e2a\u77e9\u9635\u7ec4\uff0c\u5c31\u6709\u51e0\u4e2a\u8f93\u51fa\u901a\u9053\uff0c\u8f93\u51fa\u901a\u9053\u6570\u91cf\u53ef\u4ee5\u6307\u5b9a\u3002</li> <li>\u5982\u679c\u8f93\u5165\u6837\u672c\u7684\u6279\u91cf\u5927\u5c0f\u5927\u4e8e1\uff0c\u5219\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u8f93\u5165\u7684\u6837\u672c\uff0c\u90fd\u4f1a\u8fdb\u884c\u4e00\u6b21\u5377\u79ef\u3002\u5373\u8f93\u51fa\u7684\u6279\u91cf\u6570 = \u8f93\u5165\u7684\u6279\u91cf\u6570 output.shape[0] = input.shape[0]\u3002</li> <li>Conv2d\u5b9a\u4e49\u7684\u6838\u51fd\u6570\u6700\u591a\u662f\u4e00\u4e2a\u56db\u7ef4\u5f20\u91cf\uff0c\u5f62\u72b6\u4e3a<code>(\u8f93\u51fa\u901a\u9053\u6570Cin, \u8f93\u5165\u901a\u9053\u6570Cout\uff0c\u5377\u79ef\u6838\u9ad8\u5ea6k1\uff0c\u5377\u79ef\u6838\u8de8\u5ea6k2)</code>\u3002</li> </ul> In\u00a0[176]: Copied! <pre>class CNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(5, 5), stride=1)  # \u8f93\u5165\u901a\u9053\u4e3a3\uff0c\u8f93\u51fa\u901a\u9053\u4e3a6\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5), stride=1)  # \u8f93\u5165\u901a\u9053\u4e3a6\uff0c\u8f93\u51fa\u901a\u9053\u4e3a16\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = torch.flatten(x, 1) # flatten all dimensions except batch\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)  # \u6700\u7ec8\u7684\u8f93\u51fa\u7684\u5f62\u72b6\uff1a(\u6837\u672c\u6570, 10), 10\u4ee3\u8868\u5206\u7c7b\u95ee\u9898\u7684\u7c7b\u522b\u6570\n        return x\n\n    # def forward(self, x):\n        \n    #     # \u5377\u79ef\u90e8\u5206\n    #     ## \u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42\n    #     print('=====\u7b2c\u4e00\u6b21\u5377\u79ef\u4ee5\u53ca\u6c47\u805a\u8fd0\u7b97\u5f00\u59cb========')\n    #     x = self.conv1(x)\n    #     print(\"Output shape after conv1:\", x.shape)  # \u6253\u5370conv1\u5c42\u7684\u8f93\u51fa\u5f62\u72b6\n    #     x = F.relu(x)\n    #     print(\"Output shape after relu1:\", x.shape)  # \u6253\u5370relu1\u5c42\u7684\u8f93\u51fa\u5f62\u72b6\n    #     ## \u7b2c\u4e00\u4e2a\u6700\u5927\u6c47\u805a\u5c42\n    #     x = self.pool(x)\n    #     print(\"Output shape after pool1:\", x.shape)  # \u6253\u5370pool1\u5c42\u7684\u8f93\u51fa\u5f62\u72b6\n    #     print('=====\u7b2c\u4e00\u6b21\u5377\u79ef\u4ee5\u53ca\u6c47\u805a\u8fd0\u7b97\u7ed3\u675f========\\n')\n        \n        # ## \u7b2c\u4e8c\u4e2a\u5377\u79ef\u5c42\n        # print('=====\u7b2c\u4e8c\u6b21\u5377\u79ef\u4ee5\u53ca\u6c47\u805a\u8fd0\u7b97\u5f00\u59cb========')\n        # x = self.conv2(x)\n        # print(\"Output shape after conv2:\", x.shape)  # \u6253\u5370conv2\u5c42\u7684\u8f93\u51fa\u5f62\u72b6\n        # x = F.relu(x)\n        # print(\"Output shape after relu2:\", x.shape)  # \u6253\u5370relu2\u5c42\u7684\u8f93\u51fa\u5f62\u72b6\n        # ## \u7b2c\u4e8c\u4e2a\u6700\u5927\u6c47\u805a\u5c42\n        # x = self.pool(x)\n        # print(\"Output shape after pool2:\", x.shape)  # \u6253\u5370pool2\u5c42\u7684\u8f93\u51fa\u5f62\u72b6\n        # print('=====\u7b2c\u4e8c\u6b21\u5377\u79ef\u4ee5\u53ca\u6c47\u805a\u8fd0\u7b97\u7ed3\u675f========\\n')\n                \n        # # \u5377\u79ef\u4e4b\u540e\u8f93\u51fa\n        # x = torch.flatten(x, 1)\n        # print(\"Output shape after flatten:\", x.shape)  # \u6253\u5370flatten\u5c42\u7684\u8f93\u51fa\u5f62\u72b6\n        # x = F.relu(self.fc1(x))\n        # print(\"Output shape after fc1:\", x.shape)  # \u6253\u5370fc1\u5c42\u7684\u8f93\u51fa\u5f62\u72b6\n        # x = F.relu(self.fc2(x))\n        # print(\"Output shape after fc2:\", x.shape)  # \u6253\u5370fc2\u5c42\u7684\u8f93\u51fa\u5f62\u72b6\n        # x = self.fc3(x)\n        # print(\"Final output shape:\", x.shape)  # \u6253\u5370\u6700\u7ec8\u8f93\u51fa\u7684\u5f62\u72b6\n        # return x\n\ncnn = CNN()\ncnn(X_train_batch).shape\n</pre> class CNN(nn.Module):     def __init__(self):         super().__init__()         self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(5, 5), stride=1)  # \u8f93\u5165\u901a\u9053\u4e3a3\uff0c\u8f93\u51fa\u901a\u9053\u4e3a6         self.pool = nn.MaxPool2d(kernel_size=2, stride=2)         self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5), stride=1)  # \u8f93\u5165\u901a\u9053\u4e3a6\uff0c\u8f93\u51fa\u901a\u9053\u4e3a16         self.fc1 = nn.Linear(16 * 5 * 5, 120)         self.fc2 = nn.Linear(120, 84)         self.fc3 = nn.Linear(84, 10)      def forward(self, x):         x = self.pool(F.relu(self.conv1(x)))         x = self.pool(F.relu(self.conv2(x)))         x = torch.flatten(x, 1) # flatten all dimensions except batch         x = F.relu(self.fc1(x))         x = F.relu(self.fc2(x))         x = self.fc3(x)  # \u6700\u7ec8\u7684\u8f93\u51fa\u7684\u5f62\u72b6\uff1a(\u6837\u672c\u6570, 10), 10\u4ee3\u8868\u5206\u7c7b\u95ee\u9898\u7684\u7c7b\u522b\u6570         return x      # def forward(self, x):              #     # \u5377\u79ef\u90e8\u5206     #     ## \u7b2c\u4e00\u4e2a\u5377\u79ef\u5c42     #     print('=====\u7b2c\u4e00\u6b21\u5377\u79ef\u4ee5\u53ca\u6c47\u805a\u8fd0\u7b97\u5f00\u59cb========')     #     x = self.conv1(x)     #     print(\"Output shape after conv1:\", x.shape)  # \u6253\u5370conv1\u5c42\u7684\u8f93\u51fa\u5f62\u72b6     #     x = F.relu(x)     #     print(\"Output shape after relu1:\", x.shape)  # \u6253\u5370relu1\u5c42\u7684\u8f93\u51fa\u5f62\u72b6     #     ## \u7b2c\u4e00\u4e2a\u6700\u5927\u6c47\u805a\u5c42     #     x = self.pool(x)     #     print(\"Output shape after pool1:\", x.shape)  # \u6253\u5370pool1\u5c42\u7684\u8f93\u51fa\u5f62\u72b6     #     print('=====\u7b2c\u4e00\u6b21\u5377\u79ef\u4ee5\u53ca\u6c47\u805a\u8fd0\u7b97\u7ed3\u675f========\\n')                  # ## \u7b2c\u4e8c\u4e2a\u5377\u79ef\u5c42         # print('=====\u7b2c\u4e8c\u6b21\u5377\u79ef\u4ee5\u53ca\u6c47\u805a\u8fd0\u7b97\u5f00\u59cb========')         # x = self.conv2(x)         # print(\"Output shape after conv2:\", x.shape)  # \u6253\u5370conv2\u5c42\u7684\u8f93\u51fa\u5f62\u72b6         # x = F.relu(x)         # print(\"Output shape after relu2:\", x.shape)  # \u6253\u5370relu2\u5c42\u7684\u8f93\u51fa\u5f62\u72b6         # ## \u7b2c\u4e8c\u4e2a\u6700\u5927\u6c47\u805a\u5c42         # x = self.pool(x)         # print(\"Output shape after pool2:\", x.shape)  # \u6253\u5370pool2\u5c42\u7684\u8f93\u51fa\u5f62\u72b6         # print('=====\u7b2c\u4e8c\u6b21\u5377\u79ef\u4ee5\u53ca\u6c47\u805a\u8fd0\u7b97\u7ed3\u675f========\\n')                          # # \u5377\u79ef\u4e4b\u540e\u8f93\u51fa         # x = torch.flatten(x, 1)         # print(\"Output shape after flatten:\", x.shape)  # \u6253\u5370flatten\u5c42\u7684\u8f93\u51fa\u5f62\u72b6         # x = F.relu(self.fc1(x))         # print(\"Output shape after fc1:\", x.shape)  # \u6253\u5370fc1\u5c42\u7684\u8f93\u51fa\u5f62\u72b6         # x = F.relu(self.fc2(x))         # print(\"Output shape after fc2:\", x.shape)  # \u6253\u5370fc2\u5c42\u7684\u8f93\u51fa\u5f62\u72b6         # x = self.fc3(x)         # print(\"Final output shape:\", x.shape)  # \u6253\u5370\u6700\u7ec8\u8f93\u51fa\u7684\u5f62\u72b6         # return x  cnn = CNN() cnn(X_train_batch).shape Out[176]: <pre>torch.Size([4, 10])</pre> In\u00a0[3]: Copied! <pre># \u5b9a\u4e49\u56db\u7ef4\u5f20\u91cf\u8f93\u5165(\u6279\u91cf\u5927\u5c0fbatch_size, \u8f93\u5165\u901a\u9053\u6570Cin, \u9ad8\u5ea6Height, \u5bbd\u5ea6Weight)\ninput = torch.randn(2, 3, 4, 5)\n# \u5b9a\u4e49\u5377\u79ef\u6838\nm = nn.Conv2d(in_channels=3, out_channels=4, kernel_size=(3, 2), stride=1)\nprint(input.shape, '\\n', m)\n</pre> # \u5b9a\u4e49\u56db\u7ef4\u5f20\u91cf\u8f93\u5165(\u6279\u91cf\u5927\u5c0fbatch_size, \u8f93\u5165\u901a\u9053\u6570Cin, \u9ad8\u5ea6Height, \u5bbd\u5ea6Weight) input = torch.randn(2, 3, 4, 5) # \u5b9a\u4e49\u5377\u79ef\u6838 m = nn.Conv2d(in_channels=3, out_channels=4, kernel_size=(3, 2), stride=1) print(input.shape, '\\n', m) <pre>torch.Size([2, 3, 4, 5]) \n Conv2d(3, 4, kernel_size=(3, 2), stride=(1, 1))\n</pre> In\u00a0[158]: Copied! <pre>name, param = next(iter(m.named_parameters()))\nx = param.data\n# \u5377\u79ef\u5c42\u7684\u5f62\u72b6:(out_channels, in_channels, kernel_size[0], kernel_size[1])\nx.shape\n</pre> name, param = next(iter(m.named_parameters())) x = param.data # \u5377\u79ef\u5c42\u7684\u5f62\u72b6:(out_channels, in_channels, kernel_size[0], kernel_size[1]) x.shape Out[158]: <pre>torch.Size([4, 3, 3, 2])</pre> In\u00a0[159]: Copied! <pre># (batch_size, channel, height, width)\noutput = m(input)\noutput.shape\n</pre> # (batch_size, channel, height, width) output = m(input) output.shape Out[159]: <pre>torch.Size([2, 4, 2, 4])</pre> <p>input\uff1a batch_size = 2 channel = 3 length = 4 width = 4 height = 6</p> In\u00a0[163]: Copied! <pre>input = torch.randn(2, 3, 4, 4, 6)\n</pre> input = torch.randn(2, 3, 4, 4, 6) In\u00a0[164]: Copied! <pre>m = nn.Conv3d(in_channels=3, out_channels=4, kernel_size=(3, 3, 2), stride=1)\nm\n</pre> m = nn.Conv3d(in_channels=3, out_channels=4, kernel_size=(3, 3, 2), stride=1) m Out[164]: <pre>Conv3d(3, 4, kernel_size=(3, 3, 2), stride=(1, 1, 1))</pre> <p>\u601d\u8003\u4e00\u4e0b\u4e3a\u4ec0\u4e48output\u7684\u6700\u540e\u4e00\u4e2a\u9636\u7684\u7ef4\u5ea6\u662f5\uff1a\u56e0\u4e3ainput\u6700\u540e\u4e00\u4e2a\u9636\u662f6\uff0c\u5377\u79ef\u6838kernel\u7684\u6700\u540e\u4e00\u4e2a\u9636\u662f2\uff0c\u5c062\u57286\u957f\u5ea6\u4e0a\u5377\u79ef\uff0c\u5219\u7ed3\u679c\u662f5\u7ef4</p> In\u00a0[165]: Copied! <pre>output = m(input)\noutput.shape\n</pre> output = m(input) output.shape Out[165]: <pre>torch.Size([2, 4, 2, 2, 5])</pre> <p>\u5173\u4e8epytorch\u7684\u9ed8\u8ba4\u586b\u8865</p> <p>\u5bf9\u4e8e3D\u5377\u79ef\u6838\uff0c\u5982\u679c\u8f93\u5165\u662f\u56db\u9636\uff08unbatched\uff09\uff0c\u5219pytorch\u4f1a\u5728\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u586b\u8865batch_size = 1\u3002\u6b64\u65f6\u8f93\u5165\u4e2d\uff0cinput\u7684\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u4ee3\u8868channel\uff0c\u5219\u8fd9\u91cc\u7684cahnnel\u540c\u7406\u9700\u8981\u7b49\u4e8eConv3D\u7684\u53c2\u6570in_channels</p> <p>\u5bf9\u4e8e3D\u5377\u79ef\u6838\uff0c\u8f93\u5165\u4e00\u5b9a\u8981\u5927\u4e8e\u7b49\u4e8e4\u9636\uff0c\u5426\u5219\u4f1a\u62a5\u9519\uff1aRuntimeError: Expected 4D (unbatched) or 5D (batched) input to conv3d, but got input of size: [4, 4, 6]</p> In\u00a0[167]: Copied! <pre>input = torch.randn(3, 4, 4, 6)\n</pre> input = torch.randn(3, 4, 4, 6) In\u00a0[168]: Copied! <pre>m = nn.Conv3d(in_channels=3, out_channels=4, kernel_size=(3, 3, 2), stride=1)\nm\n</pre> m = nn.Conv3d(in_channels=3, out_channels=4, kernel_size=(3, 3, 2), stride=1) m Out[168]: <pre>Conv3d(3, 4, kernel_size=(3, 3, 2), stride=(1, 1, 1))</pre> In\u00a0[169]: Copied! <pre># \u6b64\u65f6\u6211\u4eec\u53ef\u4ee5\u7406\u89e3\u4e3a\u6211\u4eec\u53ea\u8f93\u5165\u4e86\u4e00\u4e2a\u6837\u672c\u8fdb\u884c\uff0c\u5219\u8f93\u5165\u548c\u8f93\u51fa\u4e2dbatch\u6240\u5728\u7684\u90a3\u4e2a\u7ef4\u5ea6\u5c31\u6ca1\u6709\u5fc5\u8981\u5b58\u5728\u4e86\u3002\n# \u6b64\u65f6output.shape: (channel, length, width, height)\noutput = m(input)\noutput.shape\n</pre> # \u6b64\u65f6\u6211\u4eec\u53ef\u4ee5\u7406\u89e3\u4e3a\u6211\u4eec\u53ea\u8f93\u5165\u4e86\u4e00\u4e2a\u6837\u672c\u8fdb\u884c\uff0c\u5219\u8f93\u5165\u548c\u8f93\u51fa\u4e2dbatch\u6240\u5728\u7684\u90a3\u4e2a\u7ef4\u5ea6\u5c31\u6ca1\u6709\u5fc5\u8981\u5b58\u5728\u4e86\u3002 # \u6b64\u65f6output.shape: (channel, length, width, height) output = m(input) output.shape Out[169]: <pre>torch.Size([4, 2, 2, 5])</pre> <p>\u7ed3\u8bba</p> <ol> <li>\u75283D\u5377\u79ef\u6838\uff0c\u7406\u8bba\u4e0a\u5e94\u8be5\u8f93\u5165\u4e94\u9636</li> </ol> <ul> <li>\u5982\u679c\u8f93\u5165\u662f\u56db\u9636\uff0c\u90a3\u4e48\u9ed8\u8ba4\u8f93\u5165\u6570\u636e\u662funbatched, \u4f1a\u81ea\u52a8\u586b\u5145batch_size \u8fd9\u4e2a\u9636\u4e3a1</li> <li>\u5982\u679c\u8f93\u5165\u5c0f\u4e8e\u56db\u9636\uff0c\u90a3\u4e48\u4f1a\u62a5\u9519</li> </ul> <ol> <li>\u75282D\u5377\u79ef\u6838\uff0c\u540c\u7406\u7406\u8bba\u4e0a\u5e94\u8be5\u8f93\u5165\u56db\u9636</li> </ol> <ul> <li>\u5982\u679c\u8f93\u5165\u662f\u4e09\u9636\uff0c\u90a3\u4e48\u81ea\u52a8\u586b\u5145batch_size</li> <li>\u5982\u679c\u8f93\u5165\u5c0f\u4e8e\u4e09\u9636\uff0c\u62a5\u9519\u3002</li> </ul> In\u00a0[207]: Copied! <pre>loss = nn.CrossEntropyLoss()\ncnn = CNN()\noptim = torch.optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)\n</pre> loss = nn.CrossEntropyLoss() cnn = CNN() optim = torch.optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9) In\u00a0[208]: Copied! <pre>num_epochs = 2 # \u603b\u5171\u904d\u5386\u4e24\u6b21\u5168\u6837\u672c\n\nfor epoch in range(num_epochs):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optim.zero_grad()\n\n        # forward + backward + optimize\n        outputs = cnn(inputs)\n        l = loss(outputs, labels)\n        l.backward()\n        optim.step()\n\n        # print statistics\n        # 2000\u6b21\u7684\u635f\u5931\u51fd\u6570\u7684\u7d2f\u52a0\uff0c\u6ce8\u610f\u6bcf\u6b21\u7684\u635f\u5931\u90fd\u4f1a\u51cf\u5c11\uff0c\u76f8\u5f53\u4e8e\u5bf9\u4e00\u4e2a\u9012\u51cf\u6570\u5217\u6bcf\u96942000\u9879\u8f93\u51fa\u4e00\u4e2a\u6570\u5217\u548c\n        running_loss += l.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n            running_loss = 0.0\n\nprint('Finished Training')\n</pre> num_epochs = 2 # \u603b\u5171\u904d\u5386\u4e24\u6b21\u5168\u6837\u672c  for epoch in range(num_epochs):  # loop over the dataset multiple times      running_loss = 0.0     for i, data in enumerate(trainloader, 0):         # get the inputs; data is a list of [inputs, labels]         inputs, labels = data          # zero the parameter gradients         optim.zero_grad()          # forward + backward + optimize         outputs = cnn(inputs)         l = loss(outputs, labels)         l.backward()         optim.step()          # print statistics         # 2000\u6b21\u7684\u635f\u5931\u51fd\u6570\u7684\u7d2f\u52a0\uff0c\u6ce8\u610f\u6bcf\u6b21\u7684\u635f\u5931\u90fd\u4f1a\u51cf\u5c11\uff0c\u76f8\u5f53\u4e8e\u5bf9\u4e00\u4e2a\u9012\u51cf\u6570\u5217\u6bcf\u96942000\u9879\u8f93\u51fa\u4e00\u4e2a\u6570\u5217\u548c         running_loss += l.item()         if i % 2000 == 1999:    # print every 2000 mini-batches             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')             running_loss = 0.0  print('Finished Training') <pre>[1,  2000] loss: 2.178\n[1,  4000] loss: 1.815\n[1,  6000] loss: 1.646\n[1,  8000] loss: 1.561\n[1, 10000] loss: 1.492\n[1, 12000] loss: 1.455\n[2,  2000] loss: 1.397\n[2,  4000] loss: 1.351\n[2,  6000] loss: 1.326\n[2,  8000] loss: 1.319\n[2, 10000] loss: 1.311\n[2, 12000] loss: 1.276\nFinished Training\n</pre> In\u00a0[223]: Copied! <pre>loss(outputs, labels)\n</pre> loss(outputs, labels) Out[223]: <pre>tensor(0.7565)</pre> In\u00a0[221]: Copied! <pre>outputs.shape\n</pre> outputs.shape Out[221]: <pre>torch.Size([4, 10])</pre> In\u00a0[222]: Copied! <pre>labels.shape\n</pre> labels.shape Out[222]: <pre>torch.Size([4])</pre> <p>Let's quickly save our trained model:</p> In\u00a0[209]: Copied! <pre>PATH = './data/cifar_net.pth'\ntorch.save(cnn.state_dict(), PATH)\n</pre> PATH = './data/cifar_net.pth' torch.save(cnn.state_dict(), PATH) In\u00a0[210]: Copied! <pre>images, labels = next(iter(testloader))\n\n# print images\nimshow(torchvision.utils.make_grid(images))\nprint('\u771f\u5b9e\u6807\u7b7e: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n</pre> images, labels = next(iter(testloader))  # print images imshow(torchvision.utils.make_grid(images)) print('\u771f\u5b9e\u6807\u7b7e: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4))) <pre>\u771f\u5b9e\u6807\u7b7e:  cat   ship  ship  plane\n</pre> In\u00a0[211]: Copied! <pre>cnn = CNN()\ncnn.load_state_dict(torch.load(PATH))\n</pre> cnn = CNN() cnn.load_state_dict(torch.load(PATH)) Out[211]: <pre>&lt;All keys matched successfully&gt;</pre> In\u00a0[213]: Copied! <pre># output\u4ee3\u8868\u6bcf\u4e2aimage\u5c5e\u4e8e10\u4e2a\u7c7b\u522b\u7684\u5206\u522b\u6982\u7387\uff0c\noutputs = cnn(images)\noutputs\n</pre> # output\u4ee3\u8868\u6bcf\u4e2aimage\u5c5e\u4e8e10\u4e2a\u7c7b\u522b\u7684\u5206\u522b\u6982\u7387\uff0c outputs = cnn(images) outputs Out[213]: <pre>tensor([[-0.6495, -1.1622,  0.3942,  1.3310,  1.1498,  0.8790, -0.6018,  1.1651,\n         -1.0850, -1.0014],\n        [ 3.2479,  5.8777, -1.5823, -2.6425, -2.7502, -3.8079, -2.9400, -3.9557,\n          3.5704,  4.5915],\n        [ 1.7253,  4.1359, -0.7245, -1.1500, -1.9616, -2.3680, -1.4687, -2.2806,\n          2.1279,  2.7783],\n        [ 5.5483,  0.9032,  1.9929, -1.3163,  0.1270, -3.0843, -2.7394, -3.2047,\n          2.2500,  0.0772]], grad_fn=&lt;AddmmBackward0&gt;)</pre> <p>The outputs are energies for the 10 classes. The higher the energy for a class, the more the network thinks that the image is of the particular class. So, let's get the index of the highest energy:</p> In\u00a0[214]: Copied! <pre>_, predicted = torch.max(outputs, dim=1)  # \u6bcf\u884c\u7684\u6700\u5927\u503c\n\nprint('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n                              for j in range(4)))\n</pre> _, predicted = torch.max(outputs, dim=1)  # \u6bcf\u884c\u7684\u6700\u5927\u503c  print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'                               for j in range(4))) <pre>Predicted:  cat   car   car   plane\n</pre> In\u00a0[215]: Copied! <pre>predicted\n</pre> predicted Out[215]: <pre>tensor([3, 1, 1, 0])</pre> <p>The results seem pretty good.</p> <p>Let us look at how the network performs on the whole dataset.</p> In\u00a0[219]: Copied! <pre>labels\n</pre> labels Out[219]: <pre>tensor([3, 5, 1, 7])</pre> In\u00a0[216]: Copied! <pre>correct = 0\ntotal = 0\n# since we're not training, we don't need to calculate the gradients for our outputs\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        # calculate outputs by running images through the network\n        outputs = cnn(images)\n        # the class with the highest energy is what we choose as prediction\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n</pre> correct = 0 total = 0 # since we're not training, we don't need to calculate the gradients for our outputs with torch.no_grad():     for data in testloader:         images, labels = data         # calculate outputs by running images through the network         outputs = cnn(images)         # the class with the highest energy is what we choose as prediction         _, predicted = torch.max(outputs.data, 1)         total += labels.size(0)         correct += (predicted == labels).sum().item()  print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %') <pre>Accuracy of the network on the 10000 test images: 52 %\n</pre> In\u00a0[218]: Copied! <pre># \u5c06\u53ea\u5305\u542b\u4e00\u4e2a\u5143\u7d20\u7684tensor\u8f6c\u6362\u4e3a\u6807\u91cf\uff0c\u65e0\u8bba\u7ef4\u6570\u591a\u5c11\u90fd\u53ef\u4ee5\u8f6c\u6362\nprint(predicted[0].item(), torch.tensor([[1]]).item())\n</pre> # \u5c06\u53ea\u5305\u542b\u4e00\u4e2a\u5143\u7d20\u7684tensor\u8f6c\u6362\u4e3a\u6807\u91cf\uff0c\u65e0\u8bba\u7ef4\u6570\u591a\u5c11\u90fd\u53ef\u4ee5\u8f6c\u6362 print(predicted[0].item(), torch.tensor([[1]]).item()) <pre>3 1\n</pre> <p>That looks way better than chance, which is 10% accuracy (randomly picking a class out of 10 classes). Seems like the network learnt something.</p> <p>Hmmm, what are the classes that performed well, and the classes that did not perform well:</p> In\u00a0[202]: Copied! <pre># prepare to count predictions for each class\ncorrect_pred = {classname: 0 for classname in classes}\ntotal_pred = {classname: 0 for classname in classes}\n\n# again no gradients needed\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = cnn(images)\n        _, predictions = torch.max(outputs, 1)\n        # collect the correct predictions for each class\n        for label, prediction in zip(labels, predictions):\n            if label == prediction:\n                correct_pred[classes[label]] += 1\n            total_pred[classes[label]] += 1\n\n\n# print accuracy for each class\nfor classname, correct_count in correct_pred.items():\n    accuracy = 100 * float(correct_count) / total_pred[classname]\n    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n</pre> # prepare to count predictions for each class correct_pred = {classname: 0 for classname in classes} total_pred = {classname: 0 for classname in classes}  # again no gradients needed with torch.no_grad():     for data in testloader:         images, labels = data         outputs = cnn(images)         _, predictions = torch.max(outputs, 1)         # collect the correct predictions for each class         for label, prediction in zip(labels, predictions):             if label == prediction:                 correct_pred[classes[label]] += 1             total_pred[classes[label]] += 1   # print accuracy for each class for classname, correct_count in correct_pred.items():     accuracy = 100 * float(correct_count) / total_pred[classname]     print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %') <pre>Accuracy for class: plane is 47.9 %\nAccuracy for class: car   is 70.2 %\nAccuracy for class: bird  is 51.3 %\nAccuracy for class: cat   is 38.1 %\nAccuracy for class: deer  is 43.3 %\nAccuracy for class: dog   is 49.4 %\nAccuracy for class: frog  is 63.1 %\nAccuracy for class: horse is 48.8 %\nAccuracy for class: ship  is 71.3 %\nAccuracy for class: truck is 59.3 %\n</pre> <p>Okay, so what next?</p> <p>How do we run these neural networks on the GPU?</p> In\u00a0[203]: Copied! <pre>device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(device)\n</pre> device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')  # Assuming that we are on a CUDA machine, this should print a CUDA device:  print(device) <pre>cpu\n</pre> <p>The rest of this section assumes that <code>device</code> is a CUDA device.</p> <p>Then these methods will recursively go over all modules and convert their parameters and buffers to CUDA tensors:</p> <p>.. code:: python</p> <pre><code>net.to(device)</code></pre> <p>Remember that you will have to send the inputs and targets at every step to the GPU too:</p> <p>.. code:: python</p> <pre><code>    inputs, labels = data[0].to(device), data[1].to(device)</code></pre> <p>Why don't I notice MASSIVE speedup compared to CPU? Because your network is really small.</p> <p>Exercise: Try increasing the width of your network (argument 2 of the first <code>nn.Conv2d</code>, and argument 1 of the second <code>nn.Conv2d</code> \u2013 they need to be the same number), see what kind of speedup you get.</p> <p>Goals achieved:</p> <ul> <li>Understanding PyTorch's Tensor library and neural networks at a high level.</li> <li>Train a small neural network to classify images</li> </ul> <p>torch.nn torch.nn.Conv2d torch.nn.MaxPool2d torch.max</p>"},{"location":"markdown/knowledge/deep_learning_notebook/CNN/#cnn","title":"CNN\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/","title":"\u56fe\u89e3\u539f\u7406\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/#cifar10","title":"\u5bfc\u5165CIFAR10\u6570\u636e\u96c6\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/","title":"\u6570\u636e\u96c6\u4e2d\u7684\u56fe\u7247\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/#shape","title":"\u67e5\u770b\u4e00\u4e0b\u8bad\u7ec3\u96c6\u3001\u6d4b\u8bd5\u96c6\u3001\u5c0f\u6279\u91cf\u7684shape\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/#cnn","title":"\u5b9a\u4e49\u4e00\u4e2aCNN\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/","title":"\u5173\u4e8e\u5377\u79ef\u6838\u7684\u5f62\u72b6\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/#conv2d","title":"Conv2d\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/#conv3d","title":"Conv3d\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/","title":"\u5b9a\u4e49\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/#cnn","title":"\u8bad\u7ec3CNN\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/","title":"\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8fdb\u884c\u9884\u6d4b\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/","title":"\u6253\u5370\u51fa\u4e00\u5f20\u6d4b\u8bd5\u96c6\u4e0a\u7684\u56fe\u7247\u770b\u770b\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/","title":"\u5bfc\u5165\u6211\u4eec\u521a\u521a\u4fdd\u5b58\u7684\u6a21\u578b\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/#cnn","title":"\u4f7f\u7528CNN\u6a21\u578b\u9884\u6d4b\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/","title":"\u5728\u5168\u4f53\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8868\u73b0\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/","title":"\u5728\u4e0d\u540c\u7c7b\u522b\u4e0a\u7684\u8868\u73b0\u5bf9\u6bd4\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/#gpu","title":"\u5728GPU\u4e0a\u8bad\u7ec3\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/CNN/#training-on-gpu","title":"Training on GPU\u00b6","text":"<p>Just like how you transfer a Tensor onto the GPU, you transfer the neural net onto the GPU.</p> <p>Let's first define our device as the first visible cuda device if we have CUDA available:</p>"},{"location":"markdown/knowledge/deep_learning_notebook/CNN/#training-on-multiple-gpus","title":"Training on multiple GPUs\u00b6","text":"<p>If you want to see even more MASSIVE speedup using all of your GPUs, please check out :doc:<code>data_parallel_tutorial</code>.</p>"},{"location":"markdown/knowledge/deep_learning_notebook/CNN/#where-do-i-go-next","title":"Where do I go next?\u00b6","text":"<ul> <li>:doc:<code>Train neural nets to play video games &lt;/intermediate/reinforcement_q_learning&gt;</code></li> <li><code>Train a state-of-the-art ResNet network on imagenet</code>_</li> <li><code>Train a face generator using Generative Adversarial Networks</code>_</li> <li><code>Train a word-level language model using Recurrent LSTM networks</code>_</li> <li><code>More examples</code>_</li> <li><code>More tutorials</code>_</li> <li><code>Discuss PyTorch on the Forums</code>_</li> <li><code>Chat with other users on Slack</code>_</li> </ul>"},{"location":"markdown/knowledge/deep_learning_notebook/CNN/","title":"\u53c2\u8003\u94fe\u63a5\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/LSTM%26GRU/","title":"LSTM &amp; GRU","text":"In\u00a0[1]: Copied! <pre>import torch\nimport torch.nn as nn\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\nfrom IPython.display import Image\n</pre> import torch import torch.nn as nn import numpy as np import matplotlib.pyplot as plt from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split from IPython.display import Image In\u00a0[2]: Copied! <pre># seq_len\u8868\u793a\u65f6\u95f4\u6b65\u6570\uff0cbatch_size\u8868\u793a\u6279\u91cf\u7684\u5927\u5c0f\uff0cinput_size\u8868\u793a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u5165\u7279\u5f81\u7684\u7ef4\u5ea6\u3002\nseq_len = 10\nsample_size = 1000\nfeatures = 15\nBATCH_SIZE = 64\nX = torch.randn(seq_len, sample_size, features)  # (seq_len, batch_size, input_size)\ny = torch.randn(seq_len, sample_size, 1) \nX = X.permute(1, 0, 2)\ny = y.permute(1, 0, 2)\ntorch_dataset = TensorDataset(X, y)\ntrain_size = int(sample_size * 0.8)\ntest_size = sample_size - train_size\ntrainset, testset = random_split(torch_dataset, [train_size, test_size])\ntrainloader = DataLoader(dataset=trainset,      \n                         batch_size=BATCH_SIZE,      \n                         shuffle=True,               \n                         num_workers=2) \n</pre> # seq_len\u8868\u793a\u65f6\u95f4\u6b65\u6570\uff0cbatch_size\u8868\u793a\u6279\u91cf\u7684\u5927\u5c0f\uff0cinput_size\u8868\u793a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u5165\u7279\u5f81\u7684\u7ef4\u5ea6\u3002 seq_len = 10 sample_size = 1000 features = 15 BATCH_SIZE = 64 X = torch.randn(seq_len, sample_size, features)  # (seq_len, batch_size, input_size) y = torch.randn(seq_len, sample_size, 1)  X = X.permute(1, 0, 2) y = y.permute(1, 0, 2) torch_dataset = TensorDataset(X, y) train_size = int(sample_size * 0.8) test_size = sample_size - train_size trainset, testset = random_split(torch_dataset, [train_size, test_size]) trainloader = DataLoader(dataset=trainset,                                batch_size=BATCH_SIZE,                                shuffle=True,                                         num_workers=2)  In\u00a0[3]: Copied! <pre>for x in trainloader:\n    print(x)\n    break\n</pre> for x in trainloader:     print(x)     break <pre>[tensor([[[ 0.4540,  2.0505,  1.8005,  ...,  0.4042, -1.7250,  1.0350],\n         [-0.8664, -1.3743, -0.0184,  ..., -1.0852,  0.1087,  0.7777],\n         [-0.0795,  0.2301, -2.6513,  ...,  0.4672,  1.5841,  1.0589],\n         ...,\n         [ 0.0163,  0.2077, -0.9056,  ..., -0.8597, -1.1141,  0.1540],\n         [ 0.4538,  1.9588,  1.0234,  ..., -0.3064, -0.1393,  2.9072],\n         [-0.0232,  2.0684, -0.3065,  ...,  0.2909,  1.0892,  1.1136]],\n\n        [[ 0.1901,  0.3496,  0.1059,  ...,  2.3296,  1.1058, -1.9532],\n         [-0.6137, -0.1424, -0.8775,  ...,  0.2460,  0.9742, -0.5776],\n         [ 2.4492,  1.1111, -0.1209,  ...,  1.4041,  0.7044,  0.9197],\n         ...,\n         [ 1.1801,  1.4396,  0.1354,  ...,  1.1290,  0.3494,  0.7535],\n         [-0.2014, -0.5187,  0.9556,  ...,  0.2538,  0.5075,  0.3611],\n         [ 1.1014,  0.0194, -1.2717,  ...,  0.9697, -0.0345,  0.2379]],\n\n        [[-0.6724,  1.5309, -0.9318,  ...,  0.8211, -0.0582, -0.6883],\n         [-0.0387,  0.2154, -0.2574,  ..., -0.2483, -0.7780,  0.1357],\n         [ 0.2196, -1.8416,  0.1226,  ..., -2.4800,  1.0984, -0.4491],\n         ...,\n         [-0.7954, -0.3653, -1.4614,  ...,  1.1284, -0.2406, -0.4149],\n         [-0.5738,  0.4865,  0.0638,  ...,  1.8691, -0.8992, -0.4465],\n         [ 0.2563, -0.2688,  0.5947,  ..., -0.9301,  0.2877,  0.0351]],\n\n        ...,\n\n        [[-0.4572,  1.4819,  0.5794,  ..., -1.3377,  0.0698, -0.8983],\n         [-0.5031, -0.8456,  0.2395,  ..., -1.0274,  0.5153, -0.0449],\n         [ 0.7017,  0.4075,  1.2060,  ..., -1.6530, -0.2479, -0.9618],\n         ...,\n         [-0.6460,  0.3897, -1.4528,  ...,  0.9944,  1.0757,  2.3098],\n         [-1.1047, -1.2345,  0.4144,  ..., -1.4963, -1.9488,  0.4453],\n         [-1.0459, -0.0657, -1.2011,  ..., -0.7865, -0.3292, -0.8563]],\n\n        [[ 0.2871, -0.3138,  0.7231,  ..., -0.2983,  0.7018, -0.0636],\n         [ 0.4957,  0.3103, -1.6254,  ..., -1.5479,  0.0831, -1.0979],\n         [-0.1899,  0.5540, -0.1424,  ...,  0.9903, -0.1866,  1.5301],\n         ...,\n         [-0.5276,  0.7333, -0.4807,  ...,  0.3177, -0.8717,  1.5046],\n         [-0.1085, -0.5952,  1.2560,  ..., -0.0697, -0.0551, -0.9879],\n         [-0.5258,  0.6290,  0.2147,  ...,  2.4136, -0.1919, -1.4033]],\n\n        [[ 0.6398, -0.1231,  0.9040,  ...,  0.6298, -0.3919, -0.3392],\n         [ 0.4048,  1.5550, -0.2902,  ..., -0.0494, -0.5509, -0.7130],\n         [ 1.5928,  1.2198, -1.3477,  ..., -0.1728,  0.3132,  1.0235],\n         ...,\n         [-0.4726, -0.3622, -0.3287,  ..., -0.1006,  1.0964,  0.4600],\n         [ 1.5430,  1.6871, -0.8182,  ...,  0.9847, -1.6258, -0.2472],\n         [-1.1018, -0.9390,  1.2753,  ..., -0.2903, -2.0172,  0.1515]]]), tensor([[[-1.5709],\n         [ 0.6907],\n         [-1.6860],\n         [-1.3964],\n         [-0.3577],\n         [ 2.2987],\n         [-1.8072],\n         [ 0.7713],\n         [ 0.4866],\n         [ 1.7622]],\n\n        [[ 0.5684],\n         [-0.1827],\n         [-0.0798],\n         [ 1.5299],\n         [ 0.6218],\n         [-0.0976],\n         [-0.1144],\n         [-0.1398],\n         [-1.1544],\n         [-0.4830]],\n\n        [[ 1.1454],\n         [-0.0628],\n         [-0.7226],\n         [-0.4345],\n         [ 0.0771],\n         [ 0.1056],\n         [ 0.8524],\n         [-0.4551],\n         [ 0.4099],\n         [-0.0734]],\n\n        [[-0.0347],\n         [-1.4483],\n         [-0.5597],\n         [ 0.4482],\n         [ 0.8384],\n         [-0.3172],\n         [ 0.1523],\n         [ 1.9179],\n         [-0.9762],\n         [-0.2537]],\n\n        [[ 0.0734],\n         [-0.1998],\n         [ 1.2260],\n         [ 0.0141],\n         [-0.5588],\n         [ 0.7336],\n         [-0.4237],\n         [-1.9729],\n         [-0.7819],\n         [ 0.8539]],\n\n        [[ 0.3507],\n         [ 2.4681],\n         [-0.6129],\n         [ 0.2836],\n         [-0.3749],\n         [ 0.4448],\n         [ 1.5269],\n         [-1.6124],\n         [-0.6096],\n         [-0.6592]],\n\n        [[-1.0949],\n         [ 0.9060],\n         [ 0.4175],\n         [ 1.0266],\n         [ 2.0856],\n         [-0.9929],\n         [-1.6886],\n         [-1.2776],\n         [-0.5418],\n         [ 0.8046]],\n\n        [[-0.1131],\n         [ 0.8197],\n         [-0.3971],\n         [ 0.0247],\n         [-0.6565],\n         [-0.0853],\n         [ 1.2847],\n         [-1.0787],\n         [-0.7871],\n         [ 0.1985]],\n\n        [[ 0.2310],\n         [-0.6677],\n         [-0.4424],\n         [-0.1500],\n         [-1.7082],\n         [-0.9802],\n         [ 0.2158],\n         [-1.2602],\n         [ 0.1445],\n         [ 0.5894]],\n\n        [[-1.4972],\n         [-0.6308],\n         [ 1.0187],\n         [-0.9368],\n         [ 0.1506],\n         [-0.9020],\n         [ 0.4657],\n         [ 0.4230],\n         [ 0.2151],\n         [-1.7368]],\n\n        [[-0.1018],\n         [-0.9252],\n         [ 0.1418],\n         [-2.0305],\n         [ 1.1622],\n         [ 0.4028],\n         [-1.6947],\n         [ 0.1442],\n         [ 0.3116],\n         [-0.0413]],\n\n        [[-1.8171],\n         [-0.9318],\n         [-0.9737],\n         [-1.0428],\n         [-0.0321],\n         [-2.0666],\n         [-1.9157],\n         [-0.4882],\n         [ 1.8116],\n         [ 0.5419]],\n\n        [[-0.6213],\n         [ 0.3593],\n         [-1.6192],\n         [-1.1549],\n         [-0.7091],\n         [-0.1382],\n         [ 0.7691],\n         [-0.5096],\n         [-1.1488],\n         [ 0.4640]],\n\n        [[ 0.0934],\n         [ 0.7345],\n         [-1.9699],\n         [-0.1501],\n         [-1.4518],\n         [ 0.8438],\n         [-0.9983],\n         [-1.0069],\n         [-0.4270],\n         [-0.3539]],\n\n        [[-0.7299],\n         [-0.8425],\n         [-0.0080],\n         [-0.3593],\n         [ 1.3911],\n         [-2.4460],\n         [-1.1120],\n         [ 0.9920],\n         [-0.4968],\n         [-1.4364]],\n\n        [[-0.1532],\n         [-0.8001],\n         [-0.9527],\n         [ 2.2140],\n         [ 0.8705],\n         [-0.7195],\n         [-0.5074],\n         [ 0.0318],\n         [-1.4823],\n         [ 2.4329]],\n\n        [[ 2.1200],\n         [-0.7386],\n         [-1.1488],\n         [-2.0068],\n         [-0.3175],\n         [-0.6614],\n         [ 1.0267],\n         [ 0.1238],\n         [-1.6986],\n         [-0.2849]],\n\n        [[-0.9482],\n         [ 1.2260],\n         [-1.3401],\n         [-0.5489],\n         [ 1.4622],\n         [ 0.6643],\n         [-0.5707],\n         [ 0.8380],\n         [ 0.3058],\n         [ 0.2090]],\n\n        [[ 1.7450],\n         [-0.2175],\n         [-2.1850],\n         [ 0.2406],\n         [-0.2823],\n         [-0.1151],\n         [ 0.4908],\n         [ 0.6332],\n         [-0.1500],\n         [-1.8751]],\n\n        [[ 0.7139],\n         [ 0.4172],\n         [-2.0881],\n         [ 0.1118],\n         [ 1.3186],\n         [-1.0013],\n         [ 0.1190],\n         [-0.3780],\n         [-0.5342],\n         [ 1.3879]],\n\n        [[-0.8204],\n         [-1.4511],\n         [-0.8640],\n         [-1.5900],\n         [ 1.1896],\n         [ 0.2786],\n         [ 1.8005],\n         [ 0.5636],\n         [ 1.6180],\n         [ 0.6934]],\n\n        [[-0.2423],\n         [-0.4656],\n         [ 0.0649],\n         [ 0.4830],\n         [ 1.0295],\n         [ 0.1270],\n         [ 0.3782],\n         [-2.8454],\n         [-0.2120],\n         [-0.0736]],\n\n        [[ 0.3179],\n         [ 0.7503],\n         [-1.0374],\n         [ 0.9465],\n         [ 0.5352],\n         [ 0.4448],\n         [ 0.4208],\n         [ 0.0478],\n         [-0.7716],\n         [-0.1559]],\n\n        [[-0.0952],\n         [-2.0084],\n         [-0.8770],\n         [-1.4925],\n         [ 1.5185],\n         [ 0.3389],\n         [ 1.9479],\n         [-1.5051],\n         [-0.0909],\n         [ 0.3004]],\n\n        [[ 0.2005],\n         [ 1.5029],\n         [-1.1880],\n         [-0.8149],\n         [-0.4484],\n         [-0.5238],\n         [ 0.8639],\n         [-0.1100],\n         [-1.2331],\n         [ 1.6497]],\n\n        [[-0.6505],\n         [ 0.3652],\n         [ 1.1299],\n         [ 0.5280],\n         [ 1.5002],\n         [-0.3228],\n         [-0.9457],\n         [ 0.6920],\n         [-0.4781],\n         [-0.0550]],\n\n        [[-0.4542],\n         [-1.5607],\n         [ 0.5638],\n         [ 0.9442],\n         [ 1.8492],\n         [ 1.2200],\n         [-2.3016],\n         [ 0.4301],\n         [-0.7828],\n         [-0.2936]],\n\n        [[ 0.1229],\n         [ 0.2418],\n         [-1.1512],\n         [ 0.4611],\n         [-0.8161],\n         [ 0.9149],\n         [ 0.0089],\n         [-0.6489],\n         [ 0.8479],\n         [-0.4264]],\n\n        [[-0.8771],\n         [-1.6645],\n         [-0.5761],\n         [-0.7062],\n         [-0.3473],\n         [ 0.7659],\n         [-1.0553],\n         [-1.0488],\n         [-0.8943],\n         [-0.6548]],\n\n        [[ 1.2723],\n         [-1.6011],\n         [ 0.2794],\n         [ 0.0332],\n         [ 0.9927],\n         [-0.4701],\n         [ 0.8528],\n         [ 1.1369],\n         [-1.1027],\n         [ 0.1231]],\n\n        [[ 0.3783],\n         [-0.2039],\n         [ 0.1211],\n         [-0.1222],\n         [ 0.0259],\n         [ 0.6850],\n         [ 0.2033],\n         [-0.8521],\n         [-1.3138],\n         [-0.5488]],\n\n        [[ 2.6347],\n         [-0.9334],\n         [ 0.0489],\n         [-0.7768],\n         [ 2.5205],\n         [ 1.1248],\n         [ 1.2863],\n         [-1.0040],\n         [-1.0829],\n         [ 0.9272]],\n\n        [[-1.2278],\n         [ 0.8895],\n         [-0.1237],\n         [-1.4893],\n         [ 2.2448],\n         [ 1.5004],\n         [ 0.9575],\n         [ 0.1816],\n         [ 0.3577],\n         [-0.1371]],\n\n        [[-0.9853],\n         [ 1.2098],\n         [-1.4069],\n         [-0.9601],\n         [ 0.5244],\n         [ 1.0759],\n         [ 0.5365],\n         [ 1.6918],\n         [-0.0706],\n         [-0.9400]],\n\n        [[ 0.4468],\n         [-0.0887],\n         [ 0.5069],\n         [-1.2028],\n         [ 0.2851],\n         [-1.9049],\n         [-0.4139],\n         [ 1.3335],\n         [-0.5851],\n         [ 1.3641]],\n\n        [[-0.1526],\n         [ 1.3827],\n         [ 2.5000],\n         [-0.5652],\n         [ 0.4264],\n         [-0.0350],\n         [-0.9127],\n         [-0.6392],\n         [-0.3261],\n         [ 0.1332]],\n\n        [[ 0.6819],\n         [-1.0206],\n         [-0.1230],\n         [-1.6336],\n         [ 1.0668],\n         [-0.9677],\n         [ 1.1188],\n         [-0.7318],\n         [-1.1702],\n         [ 1.0645]],\n\n        [[ 0.2888],\n         [ 1.0870],\n         [-1.0102],\n         [-0.1114],\n         [ 0.4641],\n         [ 0.1511],\n         [-1.5289],\n         [-0.4768],\n         [ 0.1281],\n         [ 0.9391]],\n\n        [[ 0.8516],\n         [-1.1553],\n         [ 0.2368],\n         [ 0.4949],\n         [ 0.3233],\n         [-0.1362],\n         [-0.0573],\n         [-1.1569],\n         [-0.6109],\n         [ 1.3095]],\n\n        [[-0.3924],\n         [-1.1999],\n         [-0.7581],\n         [ 0.1389],\n         [ 0.1853],\n         [-0.1724],\n         [-0.0943],\n         [ 1.5426],\n         [ 0.2150],\n         [-0.8276]],\n\n        [[-1.8525],\n         [-0.3655],\n         [ 0.1520],\n         [ 0.9895],\n         [ 0.2511],\n         [ 1.1828],\n         [ 0.3470],\n         [ 0.7860],\n         [ 0.5649],\n         [-0.6724]],\n\n        [[-1.2869],\n         [ 0.6137],\n         [ 1.1196],\n         [ 1.5099],\n         [ 1.1411],\n         [ 0.6749],\n         [-1.0315],\n         [-1.5448],\n         [ 1.0288],\n         [ 1.7036]],\n\n        [[ 0.4027],\n         [-0.7217],\n         [ 1.9991],\n         [ 1.1133],\n         [-0.6257],\n         [-1.1919],\n         [-0.9954],\n         [-0.2548],\n         [ 0.9436],\n         [-0.6414]],\n\n        [[ 0.5367],\n         [ 0.3248],\n         [ 0.5709],\n         [ 2.6988],\n         [ 0.6149],\n         [-0.0748],\n         [-1.4515],\n         [ 0.0661],\n         [ 0.3674],\n         [ 0.5656]],\n\n        [[ 0.1820],\n         [ 0.9259],\n         [ 0.5967],\n         [ 0.6928],\n         [ 0.3814],\n         [-0.3063],\n         [-0.2378],\n         [ 0.7602],\n         [ 1.2203],\n         [-0.3508]],\n\n        [[ 0.5464],\n         [-1.1729],\n         [ 0.8288],\n         [-1.3005],\n         [-0.8189],\n         [ 0.7396],\n         [ 0.1646],\n         [-2.1795],\n         [ 2.1045],\n         [-0.1535]],\n\n        [[ 1.7980],\n         [ 0.4960],\n         [ 1.1532],\n         [ 2.5535],\n         [-0.6819],\n         [-0.4232],\n         [ 0.9125],\n         [-0.9277],\n         [-0.7095],\n         [ 0.1194]],\n\n        [[ 0.4600],\n         [ 0.7014],\n         [-0.2445],\n         [ 1.0901],\n         [ 0.3241],\n         [-0.5549],\n         [-0.6748],\n         [ 0.8914],\n         [-0.0451],\n         [-0.3045]],\n\n        [[ 1.5078],\n         [-0.4262],\n         [-0.2154],\n         [-2.2366],\n         [-0.3359],\n         [-0.6068],\n         [-0.8079],\n         [ 0.5747],\n         [-1.1080],\n         [ 2.0380]],\n\n        [[-0.4562],\n         [-0.9502],\n         [ 0.2414],\n         [-0.1149],\n         [ 0.3826],\n         [-1.6368],\n         [ 0.1952],\n         [-0.6525],\n         [ 1.0410],\n         [ 0.4080]],\n\n        [[ 0.0213],\n         [ 1.6952],\n         [ 0.6122],\n         [-0.2915],\n         [ 0.8458],\n         [ 0.2689],\n         [ 0.7552],\n         [ 0.2123],\n         [ 0.6404],\n         [-0.7454]],\n\n        [[-0.2145],\n         [-1.3778],\n         [-0.4716],\n         [ 1.3725],\n         [-0.6932],\n         [-0.3569],\n         [ 0.3245],\n         [-1.0493],\n         [ 0.7275],\n         [-1.3761]],\n\n        [[-0.1883],\n         [ 0.6070],\n         [-0.2640],\n         [-0.0570],\n         [ 0.8877],\n         [ 0.7956],\n         [ 0.2761],\n         [ 0.7250],\n         [-0.7508],\n         [ 0.0156]],\n\n        [[-0.8689],\n         [-0.3800],\n         [ 0.3074],\n         [ 0.7342],\n         [ 0.9131],\n         [ 0.2531],\n         [-0.4266],\n         [-2.2457],\n         [ 0.9877],\n         [ 1.4258]],\n\n        [[-0.2649],\n         [-1.3330],\n         [ 2.0015],\n         [-0.3788],\n         [-1.0747],\n         [ 0.1831],\n         [-0.3347],\n         [-1.7849],\n         [-0.1281],\n         [ 0.9245]],\n\n        [[-0.4439],\n         [ 0.2421],\n         [ 0.2592],\n         [-1.1084],\n         [ 0.1238],\n         [ 0.6808],\n         [ 0.4579],\n         [ 0.5432],\n         [-0.4756],\n         [-1.2161]],\n\n        [[ 1.9364],\n         [ 0.5351],\n         [ 0.1978],\n         [ 0.8171],\n         [-1.2738],\n         [-1.9240],\n         [-0.3814],\n         [-0.7230],\n         [-0.8296],\n         [-0.3990]],\n\n        [[ 0.0366],\n         [ 0.5989],\n         [ 0.6553],\n         [ 1.3627],\n         [ 2.7729],\n         [-1.1558],\n         [ 1.2091],\n         [ 0.3231],\n         [ 0.1199],\n         [-0.6324]],\n\n        [[-0.8138],\n         [-1.6674],\n         [ 0.0269],\n         [-0.2478],\n         [ 0.0819],\n         [-1.7926],\n         [-0.1844],\n         [ 0.6594],\n         [-0.6274],\n         [-0.3338]],\n\n        [[-0.2131],\n         [-0.6385],\n         [ 0.8359],\n         [ 1.0082],\n         [ 1.4671],\n         [ 0.1550],\n         [-1.6600],\n         [-0.1142],\n         [ 0.4333],\n         [ 1.6088]],\n\n        [[-1.0346],\n         [-0.4436],\n         [-0.1512],\n         [-1.2718],\n         [-0.0598],\n         [-1.8043],\n         [-0.6428],\n         [-0.5077],\n         [-0.1200],\n         [-0.8708]],\n\n        [[-0.1190],\n         [-0.6906],\n         [-1.4925],\n         [-0.5035],\n         [-0.4851],\n         [-0.5124],\n         [ 1.1289],\n         [-0.8942],\n         [-0.4142],\n         [ 1.0863]],\n\n        [[-0.3967],\n         [ 1.1904],\n         [-1.5017],\n         [ 0.8212],\n         [-1.0112],\n         [ 0.5949],\n         [-2.4454],\n         [ 1.2159],\n         [-1.2109],\n         [-0.1800]],\n\n        [[-1.1689],\n         [-0.3799],\n         [ 1.4444],\n         [-0.9269],\n         [-0.2881],\n         [ 0.2412],\n         [ 1.7357],\n         [-1.4642],\n         [-1.9955],\n         [-0.4879]]])]\n</pre> In\u00a0[4]: Copied! <pre>x[0].shape, x[1].shape\n</pre> x[0].shape, x[1].shape Out[4]: <pre>(torch.Size([64, 10, 15]), torch.Size([64, 10, 1]))</pre> <p>tensor.detach()\u65b9\u6cd5\u7528\u4e8e\u8fd4\u56de\u4e00\u4e2a\u65b0\u7684Tensor\uff0c\u8fd9\u4e2aTensor\u548c\u539f\u6765\u7684Tensor\u5171\u4eab\u76f8\u540c\u7684\u5185\u5b58\u7a7a\u95f4\uff0c\u4f46\u662f\u4e0d\u4f1a\u88ab\u8ba1\u7b97\u56fe\u6240\u8ffd\u8e2a\uff0c\u4e5f\u5c31\u662f\u8bf4\u5b83\u4e0d\u4f1a\u53c2\u4e0e\u53cd\u5411\u4f20\u64ad\uff0c\u4e0d\u4f1a\u5f71\u54cd\u5230\u539f\u6709\u7684\u8ba1\u7b97\u56fe</p> In\u00a0[2]: Copied! <pre>Image(filename='./data/LSTM_1.png')\n</pre> Image(filename='./data/LSTM_1.png') Out[2]: In\u00a0[3]: Copied! <pre>Image(filename='./data/LSTM_2.png')\n</pre> Image(filename='./data/LSTM_2.png') Out[3]: In\u00a0[6]: Copied! <pre>Image(filename='./data/LSTM_3.png')\n</pre> Image(filename='./data/LSTM_3.png') Out[6]: In\u00a0[8]: Copied! <pre>Image(filename='./data/LSTM_4.png')\n</pre> Image(filename='./data/LSTM_4.png') Out[8]: In\u00a0[27]: Copied! <pre>class LSTM(nn.Module):\n    def __init__(self, \n                 input_size, \n                 hidden_size, \n                 output_size, \n                 num_layers: int=1, \n                 bias: bool=True, \n                 batch_first: bool=False, \n                 dropout: float=0,\n                 bidirectional: bool=False,\n                 proj_size: int=0):\n        super(LSTM, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(input_size=input_size, \n                            hidden_size=hidden_size, \n                            num_layers=num_layers, \n                            bias=bias, \n                            batch_first=batch_first,\n                            dropout=dropout,\n                            bidirectional=bidirectional,\n                            proj_size=proj_size)\n        # \u4f7f\u7528\u8fd9\u4e00\u6b65\uff0c\u6211\u4eec\u53ef\u4ee5\u81ea\u5b9a\u4e49\u8f93\u51fa\u5f62\u72b6output_size\n        self.fc = nn.Linear(hidden_size, output_size)\n        \n    def forward(self, x):\n        # \u8fd9\u91cc\u5982\u679c\u4e0d\u63d0\u4f9bh0\uff0c\u90a3\u4e48\u4f1a\u9ed8\u8ba4\u4f7f\u7528zero tensor\u4f5c\u4e3ah0\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()\n        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()\n        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n        out = self.fc(out)\n        return out, (hn, cn)\n</pre> class LSTM(nn.Module):     def __init__(self,                   input_size,                   hidden_size,                   output_size,                   num_layers: int=1,                   bias: bool=True,                   batch_first: bool=False,                   dropout: float=0,                  bidirectional: bool=False,                  proj_size: int=0):         super(LSTM, self).__init__()         self.hidden_size = hidden_size         self.num_layers = num_layers         self.lstm = nn.LSTM(input_size=input_size,                              hidden_size=hidden_size,                              num_layers=num_layers,                              bias=bias,                              batch_first=batch_first,                             dropout=dropout,                             bidirectional=bidirectional,                             proj_size=proj_size)         # \u4f7f\u7528\u8fd9\u4e00\u6b65\uff0c\u6211\u4eec\u53ef\u4ee5\u81ea\u5b9a\u4e49\u8f93\u51fa\u5f62\u72b6output_size         self.fc = nn.Linear(hidden_size, output_size)              def forward(self, x):         # \u8fd9\u91cc\u5982\u679c\u4e0d\u63d0\u4f9bh0\uff0c\u90a3\u4e48\u4f1a\u9ed8\u8ba4\u4f7f\u7528zero tensor\u4f5c\u4e3ah0         h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()         c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()         out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))         out = self.fc(out)         return out, (hn, cn) In\u00a0[25]: Copied! <pre>BATCH_SIZE = 64\nseq_len = 30\nfeatures = 40\nsample_size = 1000\nlearning_rate = 0.01\nnum_epochs = 100\nloss = nn.MSELoss()\nlstm = LSTM(input_size=features, hidden_size=128, output_size=1, batch_first=True)\noptim = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n</pre> BATCH_SIZE = 64 seq_len = 30 features = 40 sample_size = 1000 learning_rate = 0.01 num_epochs = 100 loss = nn.MSELoss() lstm = LSTM(input_size=features, hidden_size=128, output_size=1, batch_first=True) optim = torch.optim.Adam(lstm.parameters(), lr=learning_rate) In\u00a0[26]: Copied! <pre># \u8bad\u7ec3\u6a21\u578b\nidx = 0\nloss_list = []\nfor epoch in range(num_epochs):\n    for step, (inputs, targets) in enumerate(trainloader):  # \u6bcf\u4e00\u6b65 loader \u91ca\u653e\u4e00\u5c0f\u6279\u6570\u636e\u7528\u6765\u5b66\u4e60\n        optim.zero_grad()\n        \n        output_tensor, _ = lstm(inputs)\n        l = loss(output_tensor, targets)\n        \n        l.backward()\n        optim.step()\n        \n    if (epoch + 1) % 10 == 0:\n        idx += 1\n        loss_list.append(l)\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {l.item():.4f}\")\n\nwith torch.no_grad():\n# plot the train loss    \n    plt.plot(np.arange(idx), np.array(loss_list))\n    plt.xlabel('train epochs')\n    plt.ylabel('train loss')\n    plt.show()\n</pre> # \u8bad\u7ec3\u6a21\u578b idx = 0 loss_list = [] for epoch in range(num_epochs):     for step, (inputs, targets) in enumerate(trainloader):  # \u6bcf\u4e00\u6b65 loader \u91ca\u653e\u4e00\u5c0f\u6279\u6570\u636e\u7528\u6765\u5b66\u4e60         optim.zero_grad()                  output_tensor, _ = lstm(inputs)         l = loss(output_tensor, targets)                  l.backward()         optim.step()              if (epoch + 1) % 10 == 0:         idx += 1         loss_list.append(l)         print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {l.item():.4f}\")  with torch.no_grad(): # plot the train loss         plt.plot(np.arange(idx), np.array(loss_list))     plt.xlabel('train epochs')     plt.ylabel('train loss')     plt.show() <pre>Epoch [10/100], Loss: 0.2422\nEpoch [20/100], Loss: 0.0581\nEpoch [30/100], Loss: 0.0343\nEpoch [40/100], Loss: 0.0318\nEpoch [50/100], Loss: 0.0218\nEpoch [60/100], Loss: 0.0228\nEpoch [70/100], Loss: 0.0220\nEpoch [80/100], Loss: 0.0191\nEpoch [90/100], Loss: 0.0177\nEpoch [100/100], Loss: 0.0169\n</pre> In\u00a0[\u00a0]: Copied! <pre># \u5148\u5c06test_dataset\u9006\u8f6c\u6362\u4e3atensor\u7684\u683c\u5f0f\nwith torch.no_grad():\n    test_data_x = [x[0] for x in testset]\n    test_data_y = [x[1] for x in testset]\n    test_data_x = torch.stack(test_data_x, dim=0)\n    test_data_y = torch.stack(test_data_y, dim=0)\n</pre> # \u5148\u5c06test_dataset\u9006\u8f6c\u6362\u4e3atensor\u7684\u683c\u5f0f with torch.no_grad():     test_data_x = [x[0] for x in testset]     test_data_y = [x[1] for x in testset]     test_data_x = torch.stack(test_data_x, dim=0)     test_data_y = torch.stack(test_data_y, dim=0) In\u00a0[\u00a0]: Copied! <pre>with torch.no_grad():\n    lstm_output = lstm(test_data_x)[0]\n    l = loss(lstm_output, test_data_y)\n    print(f'Test loss is {l}')\n</pre> with torch.no_grad():     lstm_output = lstm(test_data_x)[0]     l = loss(lstm_output, test_data_y)     print(f'Test loss is {l}') <pre>Test loss is 1.6294636726379395\n</pre> <p>\u5728pytorch\u4e2d\uff0cGRU\u7684\u5b9e\u73b0\u65b9\u5f0f\u548cLSTM\u51e0\u4e4e\u4e00\u81f4\uff0c\u6700\u5927\u7684\u533a\u522b\u5728\u4e8eGRU\u4e2d\u4e0d\u5305\u542b\u5019\u9009\u72b6\u6001ct</p> In\u00a0[10]: Copied! <pre>Image(filename='./data/GRU_1.png')\n</pre> Image(filename='./data/GRU_1.png') Out[10]: In\u00a0[11]: Copied! <pre>Image(filename='./data/GRU_2.png')\n</pre> Image(filename='./data/GRU_2.png') Out[11]: In\u00a0[13]: Copied! <pre>Image(filename='./data/GRU_3.png')\n</pre> Image(filename='./data/GRU_3.png') Out[13]: In\u00a0[14]: Copied! <pre>Image(filename='./data/GRU_4.png')\n</pre> Image(filename='./data/GRU_4.png') Out[14]: In\u00a0[46]: Copied! <pre>class GRU(nn.Module):\n    def __init__(self, \n                 input_size, \n                 hidden_size, \n                 output_size, \n                 num_layers: int=1, \n                 bias: bool=True, \n                 batch_first: bool=False, \n                 dropout: float=0,\n                 bidirectional: bool=False):\n        super(GRU, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.gru = nn.GRU(input_size=input_size, \n                          hidden_size=hidden_size, \n                          num_layers=num_layers, \n                          bias=bias, \n                          batch_first=batch_first,\n                          dropout=dropout,\n                          bidirectional=bidirectional)\n        # \u4f7f\u7528\u8fd9\u4e00\u6b65\uff0c\u6211\u4eec\u53ef\u4ee5\u81ea\u5b9a\u4e49\u8f93\u51fa\u5f62\u72b6output_size\n        self.fc = nn.Linear(hidden_size, output_size)\n        \n    def forward(self, x):\n        # \u8fd9\u91cc\u5982\u679c\u4e0d\u63d0\u4f9bh0\uff0c\u90a3\u4e48\u4f1a\u9ed8\u8ba4\u4f7f\u7528zero tensor\u4f5c\u4e3ah0\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()\n        out, hn = self.gru(x, h0.detach())\n        out = self.fc(out)\n        return out, hn\n</pre> class GRU(nn.Module):     def __init__(self,                   input_size,                   hidden_size,                   output_size,                   num_layers: int=1,                   bias: bool=True,                   batch_first: bool=False,                   dropout: float=0,                  bidirectional: bool=False):         super(GRU, self).__init__()         self.hidden_size = hidden_size         self.num_layers = num_layers         self.gru = nn.GRU(input_size=input_size,                            hidden_size=hidden_size,                            num_layers=num_layers,                            bias=bias,                            batch_first=batch_first,                           dropout=dropout,                           bidirectional=bidirectional)         # \u4f7f\u7528\u8fd9\u4e00\u6b65\uff0c\u6211\u4eec\u53ef\u4ee5\u81ea\u5b9a\u4e49\u8f93\u51fa\u5f62\u72b6output_size         self.fc = nn.Linear(hidden_size, output_size)              def forward(self, x):         # \u8fd9\u91cc\u5982\u679c\u4e0d\u63d0\u4f9bh0\uff0c\u90a3\u4e48\u4f1a\u9ed8\u8ba4\u4f7f\u7528zero tensor\u4f5c\u4e3ah0         h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).requires_grad_()         out, hn = self.gru(x, h0.detach())         out = self.fc(out)         return out, hn In\u00a0[41]: Copied! <pre>inputs.shape\n</pre> inputs.shape Out[41]: <pre>torch.Size([64, 30, 40])</pre> In\u00a0[48]: Copied! <pre>BATCH_SIZE = 64\nseq_len = 30\nfeatures = 40\nsample_size = 1000\nlearning_rate = 0.01\nnum_epochs = 100\nloss = nn.MSELoss()\ngru = GRU(input_size=features, hidden_size=128, output_size=1, batch_first=True)\noptim = torch.optim.Adam(gru.parameters(), lr=learning_rate)\n</pre> BATCH_SIZE = 64 seq_len = 30 features = 40 sample_size = 1000 learning_rate = 0.01 num_epochs = 100 loss = nn.MSELoss() gru = GRU(input_size=features, hidden_size=128, output_size=1, batch_first=True) optim = torch.optim.Adam(gru.parameters(), lr=learning_rate) In\u00a0[49]: Copied! <pre># \u8bad\u7ec3\u6a21\u578b\nidx = 0\nloss_list = []\nfor epoch in range(num_epochs):  \n    for step, (inputs, targets) in enumerate(trainloader):  # \u6bcf\u4e00\u6b65 loader \u91ca\u653e\u4e00\u5c0f\u6279\u6570\u636e\u7528\u6765\u5b66\u4e60\n        optim.zero_grad()\n        \n        output_tensor, _ = gru(inputs)\n        l = loss(output_tensor, targets)\n        \n        l.backward()\n        optim.step()\n        \n    if (epoch + 1) % 10 == 0:\n        idx += 1\n        loss_list.append(l)\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {l.item():.4f}\")\n\nwith torch.no_grad():\n# plot the train loss    \n    plt.plot(np.arange(idx), np.array(loss_list))\n    plt.xlabel('train epochs')\n    plt.ylabel('train loss')\n    plt.show()\n</pre> # \u8bad\u7ec3\u6a21\u578b idx = 0 loss_list = [] for epoch in range(num_epochs):       for step, (inputs, targets) in enumerate(trainloader):  # \u6bcf\u4e00\u6b65 loader \u91ca\u653e\u4e00\u5c0f\u6279\u6570\u636e\u7528\u6765\u5b66\u4e60         optim.zero_grad()                  output_tensor, _ = gru(inputs)         l = loss(output_tensor, targets)                  l.backward()         optim.step()              if (epoch + 1) % 10 == 0:         idx += 1         loss_list.append(l)         print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {l.item():.4f}\")  with torch.no_grad(): # plot the train loss         plt.plot(np.arange(idx), np.array(loss_list))     plt.xlabel('train epochs')     plt.ylabel('train loss')     plt.show() <pre>Epoch [10/100], Loss: 0.3580\nEpoch [20/100], Loss: 0.1204\nEpoch [30/100], Loss: 0.0780\nEpoch [40/100], Loss: 0.0581\nEpoch [50/100], Loss: 0.0602\nEpoch [60/100], Loss: 0.0508\nEpoch [70/100], Loss: 0.0483\nEpoch [80/100], Loss: 0.0553\nEpoch [90/100], Loss: 0.0513\nEpoch [100/100], Loss: 0.0651\n</pre> In\u00a0[50]: Copied! <pre># \u5148\u5c06test_dataset\u9006\u8f6c\u6362\u4e3atensor\u7684\u683c\u5f0f\nwith torch.no_grad():\n    test_data_x = [x[0] for x in testset]\n    test_data_y = [x[1] for x in testset]\n    test_data_x = torch.stack(test_data_x, dim=0)\n    test_data_y = torch.stack(test_data_y, dim=0)\n</pre> # \u5148\u5c06test_dataset\u9006\u8f6c\u6362\u4e3atensor\u7684\u683c\u5f0f with torch.no_grad():     test_data_x = [x[0] for x in testset]     test_data_y = [x[1] for x in testset]     test_data_x = torch.stack(test_data_x, dim=0)     test_data_y = torch.stack(test_data_y, dim=0) In\u00a0[51]: Copied! <pre>with torch.no_grad():\n    lstm_output = lstm(test_data_x)[0]\n    l = loss(lstm_output, test_data_y)\n    print(f'Test loss is {l}')\n</pre> with torch.no_grad():     lstm_output = lstm(test_data_x)[0]     l = loss(lstm_output, test_data_y)     print(f'Test loss is {l}') <pre>Test loss is 1.5890101194381714\n</pre> <p>nn.LSTM nn.GRU LSTM\u8f93\u5165\u5f62\u72b6 LSTM\u4e0d\u4e00\u5b9a\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\u90fd\u9700\u8981\u8ba1\u7b97\u4e00\u4e2a\u635f\u5931\u3002\u6839\u636e\u5177\u4f53\u95ee\u9898\uff0c\u5982\u679c\u6bcf\u7ec4\u65f6\u95f4\u6b65\u53ea\u6709\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u5177\u6709\u6807\u7b7e\uff0c\u90a3\u4e48\u53ef\u4ee5\u53ea\u8ba1\u7b97\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u51fa\uff0c\u5e76\u4e14\u548c\u6807\u7b7e\u6bd4\u5bf9\uff0c\u8f93\u51fa\u4e00\u4e2a\u635f\u5931\u3002\u4f8b\u5982\uff0c\u8f93\u5165\u6837\u672c\u5f62\u72b6\u4e3a(batch, seq_len, feature)\uff0c\u5219LSTM\u7684\u6bcf\u4e2a\u65f6\u95f4\u6b65\u90fd\u8f93\u5165\u4e00\u4e2a\u5927\u5c0f\u4e3a(batch, feature)\u7684\u6837\u672c\u3002\u8fd9\u70b9\u5176\u5b9e\u662fRNN\u4e0d\u540c\u6a21\u5f0f\u7684\u533a\u522b\uff0c\u5177\u4f53\u89c1\u6df1\u5ea6\u5b66\u4e60\u8bfe\u4ef6\u3002</p>"},{"location":"markdown/knowledge/deep_learning_notebook/LSTM%26GRU/#lstm-gru","title":"LSTM &amp; GRU\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/LSTM%26GRU/","title":"\u5b9a\u4e49\u8f93\u5165\u6570\u636e\u00b6","text":"<p>\u5047\u8bbe\u8f93\u5165\u6837\u672c\u6570\u91cf\u4e3a1000\uff0c\u6bcf\u4e2a\u6837\u672c\u7684\u7279\u5f81\u6570\u91cf\u4e3a15\uff0c\u6bcf\u4e2a\u5c0f\u6279\u91cf\u4e2d\u65f6\u95f4\u6b65\u6570\u4e3a10\uff0c\u6279\u91cf\u5927\u5c0f\u4e3a64\uff0c\u540c\u65f6\uff0c\u6bcf\u4e2a\u6837\u672c\u90fd\u5bf9\u5e94\u4e00\u4e2a\u6807\u91cf\u6807\u7b7e\u3002 \u8f93\u5165\u7684\u5f62\u72b6\uff1a\u5982\u679cbatch_first\u4e3aFalse\uff0c\u90a3\u4e48\u8f93\u5165\u5f62\u72b6\u4e3a(seq_len, batch_size, input_size)\uff0cTrue\u5219\u4e3a(batch_size, seq_len, input_size\uff09</p>"},{"location":"markdown/knowledge/deep_learning_notebook/LSTM%26GRU/#nnlstm","title":"\u4f7f\u7528nn.LSTM\u6784\u9020\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/LSTM%26GRU/#lstm","title":"\u5b9a\u4e49LSTM\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/LSTM%26GRU/","title":"\u5b9a\u4e49\u4e00\u4e9b\u53c2\u6570\u5e76\u521d\u59cb\u5316\u6a21\u578b\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/LSTM%26GRU/","title":"\u8bad\u7ec3\u6a21\u578b\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/LSTM%26GRU/","title":"\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8868\u73b0\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/LSTM%26GRU/#gru","title":"\u4f7f\u7528GRU(\u95e8\u63a7\u795e\u7ecf\u5355\u5143)\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/LSTM%26GRU/#gru","title":"\u5b9a\u4e49GRU\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/LSTM%26GRU/","title":"\u5b9a\u4e49\u4e00\u4e9b\u53c2\u6570\u5e76\u521d\u59cb\u5316\u6a21\u578b\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/LSTM%26GRU/","title":"\u8bad\u7ec3\u6a21\u578b\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/LSTM%26GRU/","title":"\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8868\u73b0\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/LSTM%26GRU/","title":"\u53c2\u8003\u94fe\u63a5\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/RNN/","title":"RNN","text":"In\u00a0[1]: Copied! <pre>import torch\nimport torch.nn as nn\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\nfrom IPython.display import Image\n</pre> import torch import torch.nn as nn import numpy as np import matplotlib.pyplot as plt from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split from IPython.display import Image <p>\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u53d1\u660e\u5c31\u662f\u9488\u5bf9\u6df7\u5408\u9762\u677f\u6570\u636e\uff0c\u4e5f\u5c31\u662f\u8bf4\uff0c\u8f93\u5165RNN\u7684\u6570\u636e\u7ed3\u6784\u4e3a\u65f6\u95f4\u5e8f\u5217\u6570\u636e\uff0c\u4e14\u5728\u6bcf\u4e2a\u65f6\u95f4\u70b9\u90fd\u5177\u6709n\u4e2a\u6837\u672c\u3002nn.RNN\u6a21\u5757\u9ed8\u8ba4\u5c06\u8f93\u5165\u5f20\u91cf\u7684\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u89c6\u4e3a\u65f6\u95f4\u6b65\u6570\u3002</p> <p>\u6211\u4eec\u7684\u6837\u672c\u6570\u636e\u4e00\u822c\u662f\u6df7\u5408\u9762\u677f\u6570\u636e\uff0c\u521d\u59cb\u7ed3\u6784\u4e00\u822c\u4e3a\u4e00\u4e2a\u8868\u683c\uff0c\u5176\u4e2d\u5305\u542b\u4e00\u5217\u65f6\u95f4\uff0c\u6bcf\u4e2a\u65f6\u95f4\u90fd\u5305\u542b\u4e00\u4e9b\u6837\u672c\u3002\u5047\u8bbe\u6df7\u5408\u9762\u677f\u6570\u636e\u662f\u5e73\u8861\u7684\uff0c\u4e5f\u5c31\u662f\u6bcf\u4e2a\u65f6\u95f4\u70b9\u7684\u6837\u672c\u662f\u76f8\u540c\u7684\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u53ef\u4ee5\u5c06\u521d\u59cb\u6570\u636e\u8f6c\u6362\u4e3a(seq_len, sample_size, input_size)\u683c\u5f0f\u3002</p> <p><code>\u8f93\u5165:</code> \u9ed8\u8ba4\u7684\u8f93\u5165\u5f62\u72b6\u4e3a<code>(seq_len, batch_size, input_size)</code>\uff0c\u4ee3\u8868(\u65f6\u95f4\u6b65\u6570, \u6279\u91cf\u5927\u5c0f, \u6bcf\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u5165\u7279\u5f81\u7684\u7ef4\u5ea6)</p> <p><code>h_0: </code> \u9690\u85cf\u5c42\u521d\u59cb\u8f93\u5165\u5f62\u72b6\u4e3a<code>(num_layers * num_directions, batch_size, hidden_size)</code>\uff0c\u5176\u4e2dhidden_size\u4ee3\u8868\u9690\u85cf\u5c42\u7684\u795e\u7ecf\u5143\u6570\u91cf\uff0c\u4e5f\u5c31\u662f\u9690\u85cf\u5c42\u7684\u7279\u5f81\u6570\u91cf\u3002</p> <p><code>\u8f93\u51fa:</code> nn.RNN\u6a21\u5757\u7684\u8f93\u51fa\u662f\u4e00\u4e2a\u5143\u7ec4\uff0c\u5176\u4e2d\u5305\u542b\u4e24\u4e2a\u5f20\u91cf\uff1aoutput\u548ch_n\u3002output\u5f20\u91cf\u7684\u5f62\u72b6\u4e3a<code>(seq_len, batch, num_directions * hidden_size)</code>\uff0c\u5176\u4e2dseq_len\u8868\u793a\u5e8f\u5217\u7684\u957f\u5ea6\uff0cbatch\u8868\u793a\u6279\u6b21\u5927\u5c0f\uff0cnum_directions\u8868\u793a\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u5411\u6570\uff08\u5355\u5411\u6216\u53cc\u5411\uff09\uff0chidden_size\u8868\u793a\u9690\u85cf\u72b6\u6001\u7684\u7279\u5f81\u7ef4\u5ea6\u3002\u5728\u6bcf\u4e2a\u65f6\u95f4\u6b65\uff0coutput\u5f20\u91cf\u90fd\u5305\u542b\u5f53\u524d\u65f6\u95f4\u6b65\u7684\u8f93\u51fa\u3002h_n\u5f20\u91cf\u7684\u5f62\u72b6\u4e3a<code>(num_layers * num_directions, batch, hidden_size)</code>\uff0c\u5176\u4e2dnum_layers\u8868\u793a\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u5c42\u6570\uff0cnum_directions\u8868\u793a\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u5411\u6570\uff08\u5355\u5411\u6216\u53cc\u5411\uff09\uff0chidden_size\u8868\u793a\u9690\u85cf\u72b6\u6001\u7684\u7279\u5f81\u7ef4\u5ea6\u3002h_n\u5f20\u91cf\u5305\u542b\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u9690\u85cf\u72b6\u6001\u3002\u5982\u679c\u60a8\u7684\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\u662f\u5355\u5411\u7684\uff0c\u5219num_directions\u4e3a1\uff0c\u5426\u5219\u4e3a2\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0cnn.RNN\u5305\u62ecLSTM\u4ee5\u53caGRU\u7684\u8f93\u51fa\u5f62\u72b6\u9ed8\u8ba4\u7684\u90fd\u662f<code>\u540c\u6b65\u7684\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u5f0f</code>\u3002</p> <p><code>\u5c0f\u6279\u91cf:</code> \u6211\u4eec\u5bf9RNN\u7684\u8bad\u7ec3\u4e00\u822c\u662f\u5c06\u6837\u672c\u5206\u6210\u5c0f\u6279\u91cf\uff0c\u4e5f\u5c31\u662f\u6211\u4eec\u4f1a\u6309\u7167\u521d\u59cb\u6570\u636e\u4e2d\u7684 sample_size \u5c06\u603b\u4f53\u6837\u672c\u5206\u4e3a\u591a\u4e2a\u5c0f\u6279\u91cf\uff0c\u6bcf\u4e2a\u5c0f\u6279\u91cf\u7684\u5f62\u72b6\u4e3a<code>(seq_len, batch_size, input_size)</code>\uff0c\u7136\u540e\u6211\u4eec\u904d\u5386\u6240\u6709\u6279\u91cf\uff0c\u6bcf\u6b21\u8bad\u7ec3\u7684\u65f6\u5019\u8f93\u5165\u4e00\u4e2a\u5c0f\u6279\u91cf\uff0c\u8ba1\u7b97loss\uff0c\u8fdb\u884c\u4e00\u6b21\u68af\u5ea6\u4e0b\u964d\u3002\u904d\u5386\u5b8c\u6240\u6709\u6279\u91cf\u540e\uff0c\u6211\u4eec\u5c31\u5b8c\u6210\u4e86\u4e00\u4e2aepoch\u3002\u4e00\u822c\u6765\u8bf4\u6a21\u578b\u9700\u8981\u8bad\u7ec3\u591a\u4e2aepoch\u3002</p> In\u00a0[6]: Copied! <pre>Image(filename='./data/RNN_inout.png')\n</pre> Image(filename='./data/RNN_inout.png') Out[6]: In\u00a0[7]: Copied! <pre>Image(filename='./data/RNN_principle4.png')\n</pre> Image(filename='./data/RNN_principle4.png') Out[7]: In\u00a0[9]: Copied! <pre>Image(filename='./data/RNN_principle3.png')\n</pre> Image(filename='./data/RNN_principle3.png') Out[9]: In\u00a0[12]: Copied! <pre>Image(filename='./data/RNN_principle1.png')\n</pre> Image(filename='./data/RNN_principle1.png') Out[12]: <p>\u6ce8\u610f\u5230nn.RNN\u4e2d\uff0c8.4.6\u5f0f\u7684\u8ba1\u7b97\u662f\u9ed8\u8ba4\u4e0d\u8fdb\u884c\u7684</p> In\u00a0[11]: Copied! <pre>Image(filename='./data/RNN_principle2.png')\n</pre> Image(filename='./data/RNN_principle2.png') Out[11]: In\u00a0[215]: Copied! <pre>BATCH_SIZE = 64    # \u6bcf\u4e2a\u6279\u6b21\u7684\u5927\u5c0f\uff0c\u4e5f\u5c31\u662f\u6bcf\u4e2a\u6279\u6b21\u4e2d\u5305\u542b\u7684\u6837\u672c\u6570\u91cf\nnum_sample = 1000  # \u603b\u4f53\u6837\u672c\u6570\u91cf\nnum_epochs = 100\ninput_size = 40  # \u6837\u672c\u7279\u5f81\u6570d\nseq_len = 30  # \u6bcf\u4e2a\u6837\u672c\u7684\u65f6\u95f4\u6b65\u6570\nhidden_size = 128  # \u9690\u85cf\u5c42\u7684\u7279\u5f81\u6570h\noutput_size = 1  # \u8f93\u51fa\u7279\u5f81\u6570\n\n# \u751f\u6210\u968f\u673a\u6570\uff0c\u4ee3\u8868\u6570\u636e\nraw_data = torch.randn(seq_len, num_sample, input_size)  # \u6700\u539f\u59cb\u7684\u6837\u672c\uff0c\u5f62\u72b6\u4e3a(\u65f6\u95f4\u6b65\u6570, \u6837\u672c\u6570\u91cf, \u6837\u672c\u7279\u5f81\u6570)\n\n# \u901a\u8fc7\u5c06\u6837\u672c\u5411\u524d\u5e73\u79fb\u4e00\u4e2a\u65f6\u95f4\u6b65shift(-1)\uff0c\u751f\u6210\u6807\u7b7etarget\uff0ce.g. \u4ee3\u8868\u6bcf\u652f\u80a1\u7968\u5728\u6bcf\u4e2a\u65f6\u95f4\u8282\u70b9\u7684\u6536\u76ca\u7387\ntarget = torch.randn(seq_len, num_sample, 1)\n\n# \u8c03\u6574\u6570\u636e\u683c\u5f0f\uff0c\u5c06\u6837\u672c\u6570\u91cf\u8c03\u6574\u5230\u7b2c\u4e00\u4e2a\u8f74\uff0c\u65b9\u4fbf\u540e\u7eed\u64cd\u4f5c\u3002\u9700\u8981\u8f93\u5165\u5230DataLoader\u4e2d\u7684\u6837\u672c\uff0c\u5f62\u72b6\u4e3a(\u6837\u672c\u6570\u91cf, \u65f6\u95f4\u6b65\u6570, \u6837\u672c\u7279\u5f81\u6570)\ndata = raw_data.permute(1, 0, 2)\ntarget = target.permute(1, 0, 2)\n\n# \u5148\u8f6c\u6362\u6210 torch \u80fd\u8bc6\u522b\u7684 Dataset\ntorch_dataset = TensorDataset(data, target)\n\n# \u5c06\u6570\u636e\u5207\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\ntrain_size = int(0.8 * data.shape[0])\ntest_size = data.shape[0] - train_size\n# random_split\u51fd\u6570\u7684\u8f93\u5165\u662f\u4e00\u4e2aTensorDataset\u7c7b\u578b\u7684\u5bf9\u8c61\n# \u5176\u4e2d\u5305\u542b\u8f93\u5165\u5f20\u91cf\u548c\u5bf9\u5e94\u7684\u6807\u7b7e\u5f20\u91cf\u3002\u8f93\u5165\u5f20\u91cf\u7684\u5f62\u72b6\u662f(num_samples, input_size)\n# \u5176\u4e2dnum_samples\u662f\u6837\u672c\u6570\u91cf\uff0cinput_size\u662f\u8f93\u5165\u7279\u5f81\u7684\u7ef4\u5ea6\ntrainset, testset = random_split(torch_dataset, [train_size, test_size])\n\n\n# \u628a\u8bad\u7ec3\u96c6\u653e\u5165DataLoader\n# \u6ce8\u610f\u9700\u8981\u6307\u5b9a\u8f93\u5165\u5f20\u91cf\u7684\u54ea\u4e2a\u7ef4\u5ea6\u4ee3\u8868\u6837\u672c\uff0c\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cDataLoader\u5047\u5b9a\u8f93\u5165\u5f20\u91cf\u7684\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u4ee3\u8868\u6837\u672c\u3002\n# \u81ea\u884c\u6307\u5b9a\u54ea\u4e2a\u7ef4\u5ea6\u662f\u6837\u672c\u5f88\u9ebb\u70e6\uff01\u6240\u4ee5\u6211\u4eec\u5c31\u6309\u7167\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u4e3a\u6837\u672c\u8c03\u6574\u6570\u636e\u683c\u5f0f\n# \u4e0a\u9762\u7684data\u5c31\u662f\u5df2\u7ecf\u8c03\u6574\u597d\u7684\u6837\u672c\n# DataLoader\u4e2d\u6bcf\u4e2abatch\u7684\u5f62\u72b6\u4e3a(batch_size, seq_len, feature_nums)\uff0c\u5373(\u6279\u91cf\u5927\u5c0f\uff0c\u65f6\u95f4\u6b65\u6570\uff0c\u6bcf\u4e2a\u6837\u672c\u7684\u7279\u5f81\u6570\u91cf)\n# \u6ce8\u610f\u6d4b\u8bd5\u96c6\u65e0\u9700\u653e\u5165loader\u4e2d\n\ntrainloader = DataLoader(\n    dataset=trainset,      # torch TensorDataset format\n    batch_size=BATCH_SIZE,      # mini batch size\n    shuffle=True,               # \u8981\u4e0d\u8981\u6253\u4e71\u6570\u636e (\u6253\u4e71\u6bd4\u8f83\u597d)\n    num_workers=2)              # \u591a\u7ebf\u7a0b\u6765\u8bfb\u6570\u636e\n\nfor x in trainloader:\n    x_batch = x[0]\n    y_batch = x[1]\n    train_data_shape_of_one_batch = x[0].shape\n    label_shape_of_one_batch = x[1].shape\n    break\n\n# \u67e5\u770b\u6570\u636e\u7ed3\u6784\nprint(f'random_split\u751f\u6210\u7684\u8bad\u7ec3\u96c6\u7684\u957f\u5ea6\u4e3a{len(trainset)}\uff0c\u6d4b\u8bd5\u96c6\u7684\u957f\u5ea6\u4e3a{len(testset)}')\nprint(f'random_split\u751f\u6210\u7684\u8bad\u7ec3\u96c6\u7684\u7b2c\u4e00\u4e2a\u6837\u672c\u7684\u5f62\u72b6\u4e3a{trainset[0][0].shape}')\nprint(f'random_split\u751f\u6210\u7684\u8bad\u7ec3\u96c6\u7684\u7b2c\u4e00\u4e2a\u6807\u7b7e\u7684\u5f62\u72b6\u4e3a{trainset[0][1].shape}')\nprint(f'\u8bad\u7ec3\u96c6\u4e2d\u603b\u5171\u751f\u6210{len(trainloader)}\u4e2a\u6279\u91cf\u7684\u6570\u636e\uff0c\u6bcf\u4e2a\u6279\u91cf\u90fd\u5305\u542b{BATCH_SIZE}\u4e2a\u6837\u672c(\u9664\u4e86\u6700\u540e\u4e00\u4e2abatch)')\nprint(f'\u6bcf\u4e2a\u8bad\u7ec3\u96c6\u7684\u5c0f\u6279\u91cf\u4e2d\uff0c\u81ea\u53d8\u91cf\u7684\u5f62\u72b6\u4e3a{train_data_shape_of_one_batch}')\nprint(f'\u6bcf\u4e2a\u8bad\u7ec3\u96c6\u7684\u5c0f\u6279\u91cf\u4e2d\uff0c\u6807\u7b7e\u7684\u5f62\u72b6\u4e3a{label_shape_of_one_batch}')\n</pre> BATCH_SIZE = 64    # \u6bcf\u4e2a\u6279\u6b21\u7684\u5927\u5c0f\uff0c\u4e5f\u5c31\u662f\u6bcf\u4e2a\u6279\u6b21\u4e2d\u5305\u542b\u7684\u6837\u672c\u6570\u91cf num_sample = 1000  # \u603b\u4f53\u6837\u672c\u6570\u91cf num_epochs = 100 input_size = 40  # \u6837\u672c\u7279\u5f81\u6570d seq_len = 30  # \u6bcf\u4e2a\u6837\u672c\u7684\u65f6\u95f4\u6b65\u6570 hidden_size = 128  # \u9690\u85cf\u5c42\u7684\u7279\u5f81\u6570h output_size = 1  # \u8f93\u51fa\u7279\u5f81\u6570  # \u751f\u6210\u968f\u673a\u6570\uff0c\u4ee3\u8868\u6570\u636e raw_data = torch.randn(seq_len, num_sample, input_size)  # \u6700\u539f\u59cb\u7684\u6837\u672c\uff0c\u5f62\u72b6\u4e3a(\u65f6\u95f4\u6b65\u6570, \u6837\u672c\u6570\u91cf, \u6837\u672c\u7279\u5f81\u6570)  # \u901a\u8fc7\u5c06\u6837\u672c\u5411\u524d\u5e73\u79fb\u4e00\u4e2a\u65f6\u95f4\u6b65shift(-1)\uff0c\u751f\u6210\u6807\u7b7etarget\uff0ce.g. \u4ee3\u8868\u6bcf\u652f\u80a1\u7968\u5728\u6bcf\u4e2a\u65f6\u95f4\u8282\u70b9\u7684\u6536\u76ca\u7387 target = torch.randn(seq_len, num_sample, 1)  # \u8c03\u6574\u6570\u636e\u683c\u5f0f\uff0c\u5c06\u6837\u672c\u6570\u91cf\u8c03\u6574\u5230\u7b2c\u4e00\u4e2a\u8f74\uff0c\u65b9\u4fbf\u540e\u7eed\u64cd\u4f5c\u3002\u9700\u8981\u8f93\u5165\u5230DataLoader\u4e2d\u7684\u6837\u672c\uff0c\u5f62\u72b6\u4e3a(\u6837\u672c\u6570\u91cf, \u65f6\u95f4\u6b65\u6570, \u6837\u672c\u7279\u5f81\u6570) data = raw_data.permute(1, 0, 2) target = target.permute(1, 0, 2)  # \u5148\u8f6c\u6362\u6210 torch \u80fd\u8bc6\u522b\u7684 Dataset torch_dataset = TensorDataset(data, target)  # \u5c06\u6570\u636e\u5207\u5206\u4e3a\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6 train_size = int(0.8 * data.shape[0]) test_size = data.shape[0] - train_size # random_split\u51fd\u6570\u7684\u8f93\u5165\u662f\u4e00\u4e2aTensorDataset\u7c7b\u578b\u7684\u5bf9\u8c61 # \u5176\u4e2d\u5305\u542b\u8f93\u5165\u5f20\u91cf\u548c\u5bf9\u5e94\u7684\u6807\u7b7e\u5f20\u91cf\u3002\u8f93\u5165\u5f20\u91cf\u7684\u5f62\u72b6\u662f(num_samples, input_size) # \u5176\u4e2dnum_samples\u662f\u6837\u672c\u6570\u91cf\uff0cinput_size\u662f\u8f93\u5165\u7279\u5f81\u7684\u7ef4\u5ea6 trainset, testset = random_split(torch_dataset, [train_size, test_size])   # \u628a\u8bad\u7ec3\u96c6\u653e\u5165DataLoader # \u6ce8\u610f\u9700\u8981\u6307\u5b9a\u8f93\u5165\u5f20\u91cf\u7684\u54ea\u4e2a\u7ef4\u5ea6\u4ee3\u8868\u6837\u672c\uff0c\u9ed8\u8ba4\u60c5\u51b5\u4e0b\uff0cDataLoader\u5047\u5b9a\u8f93\u5165\u5f20\u91cf\u7684\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u4ee3\u8868\u6837\u672c\u3002 # \u81ea\u884c\u6307\u5b9a\u54ea\u4e2a\u7ef4\u5ea6\u662f\u6837\u672c\u5f88\u9ebb\u70e6\uff01\u6240\u4ee5\u6211\u4eec\u5c31\u6309\u7167\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u4e3a\u6837\u672c\u8c03\u6574\u6570\u636e\u683c\u5f0f # \u4e0a\u9762\u7684data\u5c31\u662f\u5df2\u7ecf\u8c03\u6574\u597d\u7684\u6837\u672c # DataLoader\u4e2d\u6bcf\u4e2abatch\u7684\u5f62\u72b6\u4e3a(batch_size, seq_len, feature_nums)\uff0c\u5373(\u6279\u91cf\u5927\u5c0f\uff0c\u65f6\u95f4\u6b65\u6570\uff0c\u6bcf\u4e2a\u6837\u672c\u7684\u7279\u5f81\u6570\u91cf) # \u6ce8\u610f\u6d4b\u8bd5\u96c6\u65e0\u9700\u653e\u5165loader\u4e2d  trainloader = DataLoader(     dataset=trainset,      # torch TensorDataset format     batch_size=BATCH_SIZE,      # mini batch size     shuffle=True,               # \u8981\u4e0d\u8981\u6253\u4e71\u6570\u636e (\u6253\u4e71\u6bd4\u8f83\u597d)     num_workers=2)              # \u591a\u7ebf\u7a0b\u6765\u8bfb\u6570\u636e  for x in trainloader:     x_batch = x[0]     y_batch = x[1]     train_data_shape_of_one_batch = x[0].shape     label_shape_of_one_batch = x[1].shape     break  # \u67e5\u770b\u6570\u636e\u7ed3\u6784 print(f'random_split\u751f\u6210\u7684\u8bad\u7ec3\u96c6\u7684\u957f\u5ea6\u4e3a{len(trainset)}\uff0c\u6d4b\u8bd5\u96c6\u7684\u957f\u5ea6\u4e3a{len(testset)}') print(f'random_split\u751f\u6210\u7684\u8bad\u7ec3\u96c6\u7684\u7b2c\u4e00\u4e2a\u6837\u672c\u7684\u5f62\u72b6\u4e3a{trainset[0][0].shape}') print(f'random_split\u751f\u6210\u7684\u8bad\u7ec3\u96c6\u7684\u7b2c\u4e00\u4e2a\u6807\u7b7e\u7684\u5f62\u72b6\u4e3a{trainset[0][1].shape}') print(f'\u8bad\u7ec3\u96c6\u4e2d\u603b\u5171\u751f\u6210{len(trainloader)}\u4e2a\u6279\u91cf\u7684\u6570\u636e\uff0c\u6bcf\u4e2a\u6279\u91cf\u90fd\u5305\u542b{BATCH_SIZE}\u4e2a\u6837\u672c(\u9664\u4e86\u6700\u540e\u4e00\u4e2abatch)') print(f'\u6bcf\u4e2a\u8bad\u7ec3\u96c6\u7684\u5c0f\u6279\u91cf\u4e2d\uff0c\u81ea\u53d8\u91cf\u7684\u5f62\u72b6\u4e3a{train_data_shape_of_one_batch}') print(f'\u6bcf\u4e2a\u8bad\u7ec3\u96c6\u7684\u5c0f\u6279\u91cf\u4e2d\uff0c\u6807\u7b7e\u7684\u5f62\u72b6\u4e3a{label_shape_of_one_batch}') <pre>random_split\u751f\u6210\u7684\u8bad\u7ec3\u96c6\u7684\u957f\u5ea6\u4e3a800\uff0c\u6d4b\u8bd5\u96c6\u7684\u957f\u5ea6\u4e3a200\nrandom_split\u751f\u6210\u7684\u8bad\u7ec3\u96c6\u7684\u7b2c\u4e00\u4e2a\u6837\u672c\u7684\u5f62\u72b6\u4e3atorch.Size([30, 40])\nrandom_split\u751f\u6210\u7684\u8bad\u7ec3\u96c6\u7684\u7b2c\u4e00\u4e2a\u6807\u7b7e\u7684\u5f62\u72b6\u4e3atorch.Size([30, 1])\n\u8bad\u7ec3\u96c6\u4e2d\u603b\u5171\u751f\u621013\u4e2a\u6279\u91cf\u7684\u6570\u636e\uff0c\u6bcf\u4e2a\u6279\u91cf\u90fd\u5305\u542b64\u4e2a\u6837\u672c(\u9664\u4e86\u6700\u540e\u4e00\u4e2abatch)\n\u6bcf\u4e2a\u8bad\u7ec3\u96c6\u7684\u5c0f\u6279\u91cf\u4e2d\uff0c\u81ea\u53d8\u91cf\u7684\u5f62\u72b6\u4e3atorch.Size([64, 30, 40])\n\u6bcf\u4e2a\u8bad\u7ec3\u96c6\u7684\u5c0f\u6279\u91cf\u4e2d\uff0c\u6807\u7b7e\u7684\u5f62\u72b6\u4e3atorch.Size([64, 30, 1])\n</pre> In\u00a0[59]: Copied! <pre>X_train_batch, y_train_batch = next(iter(trainloader))\n# (batch_size, seq_len, input_size)\nX_train_batch.shape, y_train_batch.shape\n</pre> X_train_batch, y_train_batch = next(iter(trainloader)) # (batch_size, seq_len, input_size) X_train_batch.shape, y_train_batch.shape Out[59]: <pre>(torch.Size([64, 30, 40]), torch.Size([64, 30, 40]))</pre> In\u00a0[54]: Copied! <pre># \u8bf4\u660e\u4e00\u4e0btorch.cat\u7684\u7528\u6cd5\na = torch.arange(6).reshape(2, 3)\nb = torch.arange(8).reshape(2, 4)\n# \u6a2a\u5411\u62fc\u63a5\na, b, torch.cat((a, b), 1)\n</pre> # \u8bf4\u660e\u4e00\u4e0btorch.cat\u7684\u7528\u6cd5 a = torch.arange(6).reshape(2, 3) b = torch.arange(8).reshape(2, 4) # \u6a2a\u5411\u62fc\u63a5 a, b, torch.cat((a, b), 1) Out[54]: <pre>(tensor([[0, 1, 2],\n         [3, 4, 5]]),\n tensor([[0, 1, 2, 3],\n         [4, 5, 6, 7]]),\n tensor([[0, 1, 2, 0, 1, 2, 3],\n         [3, 4, 5, 4, 5, 6, 7]]))</pre> In\u00a0[256]: Copied! <pre>class RNN(nn.Module):\n    # \u8fd9\u4e2a\u6a21\u578b\u6a21\u62df\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u51fa\n    def __init__(self, input_size, hidden_size, output_size):\n        super(RNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n\n    def forward(self, input_tensor, hidden_tensor=None):\n        # \u5bf9\u4e00\u4e2a\u65f6\u95f4\u6b65input_tensor: (batch_size, input_size)\uff0c\u5373(batch_size, feature_size)\n        # hidden_tensor: (batch_size, hideen_size)\n        if hidden_tensor is None:\n            hidden_tensor = torch.zeros(input_tensor.size(0), self.hidden_size)\n        combined = torch.cat((input_tensor, hidden_tensor), 1)\n        hidden = self.i2h(combined)  # (batch_size, hidden_size)\n        output = self.i2o(combined)  # (batch_size, output_size)\n        # \u8868\u793a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u8fd4\u56de\u7684\u7ed3\u679c\uff0c\u5206\u522b\u4e3a\u8f93\u51faoutput\u548c\u9690\u72b6\u6001hidden\n        return output, hidden\nrnn = RNN(input_size, hidden_size, output_size).to(device)\n</pre> class RNN(nn.Module):     # \u8fd9\u4e2a\u6a21\u578b\u6a21\u62df\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u51fa     def __init__(self, input_size, hidden_size, output_size):         super(RNN, self).__init__()         self.hidden_size = hidden_size         self.i2h = nn.Linear(input_size + hidden_size, hidden_size)         self.i2o = nn.Linear(input_size + hidden_size, output_size)      def forward(self, input_tensor, hidden_tensor=None):         # \u5bf9\u4e00\u4e2a\u65f6\u95f4\u6b65input_tensor: (batch_size, input_size)\uff0c\u5373(batch_size, feature_size)         # hidden_tensor: (batch_size, hideen_size)         if hidden_tensor is None:             hidden_tensor = torch.zeros(input_tensor.size(0), self.hidden_size)         combined = torch.cat((input_tensor, hidden_tensor), 1)         hidden = self.i2h(combined)  # (batch_size, hidden_size)         output = self.i2o(combined)  # (batch_size, output_size)         # \u8868\u793a\u6bcf\u4e2a\u65f6\u95f4\u6b65\u8fd4\u56de\u7684\u7ed3\u679c\uff0c\u5206\u522b\u4e3a\u8f93\u51faoutput\u548c\u9690\u72b6\u6001hidden         return output, hidden rnn = RNN(input_size, hidden_size, output_size).to(device) In\u00a0[310]: Copied! <pre>device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nloss = nn.MSELoss()\noptim = torch.optim.Adam(rnn.parameters(), lr=0.01)\n</pre> device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') loss = nn.MSELoss() optim = torch.optim.Adam(rnn.parameters(), lr=0.01) In\u00a0[271]: Copied! <pre># \u8bad\u7ec3num_epochs=100\u4e2a\u5468\u671f\uff0c\u6bcf\u6b21\u8bad\u7ec3\u5468\u671f\u90fd\u904d\u5386\u4e86\u4e00\u904d\u5168\u6837\u672c\uff0c\u76f8\u5f53\u4e8e\u904d\u5386\u4e86100\u6b21\u5168\u6837\u672c\nfor epoch in range(num_epochs):  \n    # \u6bcf\u4e2a\u8bad\u7ec3\u5468\u671f\u90fd\u5bf9\u6bcf\u4e2a\u6279\u91cf\u8fdb\u884c\u904d\u5386\uff0c\u603b\u5171\u670916\u4e2a\u6279\u91cf\uff0c\u6bcf\u4e2a\u6279\u91cf\u7684\u5927\u5c0f\u4e3a64\uff0c\u5219\u904d\u538616\u6b21\n    for inputs, targets in trainloader:  \n        # (batch_size, seq_len, input_size)\n        # \u8fd9\u91cc\u4ee3\u8868\u6bcf\u4e2a(batch_size, hidden_size)\n        hidden = torch.zeros(inputs.size(0), hidden_size).to(device)\n        optimizer.zero_grad()\n        # \u8fd9\u6b65\u901a\u8fc7\u4e0d\u65ad\u66f4\u65b0\u9690\u72b6\u6001hidden\u5b9e\u73b0RNN\u7684\u6838\u5fc3\uff1a\u5faa\u73af\uff0c\u5faa\u73af\u6b21\u6570\u4e3a\u65f6\u95f4\u6b65\u6570seq_len\uff0c\u5728\u521d\u59cb\u5316\u6837\u672c\u7684\u65f6\u5019\u7ed9\u5b9a\n        for i in range(inputs.size(1)):\n            # inputs[:, i, :]\u4ee3\u8868\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u5165\n            output, hidden = rnn(inputs[:, i, :], hidden)\n\n        # targets\u672c\u8eab\u662f\u5c06inputs\u6309\u7167\u65f6\u95f4\u6b65\u5e73\u79fb\u4e00\u4e2a\u5355\u4f4d\uff0ctargets[:, -1, :]\u4ee3\u8868\u6211\u4eec\u7528\u5f53\u524d\u7684\u65f6\u95f4\u6b65\u6700\u540e\u8f93\u51fa\u7684Ot\uff0c\u9884\u6d4b\u4e0b\u4e00\u4e2a\u6570\u636e\u3002\n        # \u5bf9\u4e8e\u6bcf\u4e2a\u5c0f\u6279\u91cf\uff0c\u90fd\u4f1a\u8ba1\u7b97\u51fa\u4e00\u4e2aloss\uff0c\u8fdb\u884c\u4e00\u6b21\u68af\u5ea6\u4e0b\u964d\n        # targets[:, -1, :]\u5e26\u4ee3\u8868\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u6807\u7b7e\n        l = loss(output, targets[:, -1, :])\n        l.backward()\n        optim.step()\n    \n    # \u6bcf10\u4e2a\u8bad\u7ec3\u5468\u671f\u8f93\u51fa\u4e00\u6b21\u7ed3\u679c\n    if (epoch+1) % 10 == 0:\n        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {l.item():.4f}')\n\n# \u6d4b\u8bd5\u6a21\u578b\n# \u5e8f\u5217\u5230\u7c7b\u522b\u6a21\u5f0f\uff0c\u5e76\u4e14\u5047\u8bbe\u6d4b\u8bd5\u96c6\u5df2\u6309\u7167\u65f6\u95f4\u987a\u5e8f\uff0c\u800c\u4e14\u521d\u59cb\u9690\u72b6\u6001\u4e3a0\u3002\n# \u53ef\u4ee5\u5efa\u6a21\u4f7f\u7528\u80a1\u7968\u4e00\u6bb5\u65f6\u95f4\u7684\u5386\u53f2\u6570\u636e\u9884\u6d4b\u4eca\u5929\u80a1\u7968\u7684\u6536\u76ca\u7387\nwith torch.no_grad():\n    test_loss = 0\n    for input, target in testset:\n        # input: \u4ee3\u8868\u5355\u4e2a\u6837\u672c(seq_len, input_size)\n        \n        for i in range(input.unsqueeze(0).size(1)):  # \u904d\u5386\u65f6\u95f4\u6b65\n            # input.unsqueeze(0)[:, i, :]: (batch_size, seq_len)\n            hidden = torch.zeros(input.unsqueeze(0).size(0), hidden_size)\n            output, hidden = rnn(input.unsqueeze(0)[:, i, :], hidden)\n            # print(output)\n        # \u6d4b\u8bd5\u96c6\u4e0a\u7684\u8bef\u5dee\n        # target[-1]\u4ee3\u8868\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u7ed3\u679c\n        test_loss += loss(output, target[-1])\n        \n    print(f'Test Loss: {test_loss.item():.4f}')\n</pre> # \u8bad\u7ec3num_epochs=100\u4e2a\u5468\u671f\uff0c\u6bcf\u6b21\u8bad\u7ec3\u5468\u671f\u90fd\u904d\u5386\u4e86\u4e00\u904d\u5168\u6837\u672c\uff0c\u76f8\u5f53\u4e8e\u904d\u5386\u4e86100\u6b21\u5168\u6837\u672c for epoch in range(num_epochs):       # \u6bcf\u4e2a\u8bad\u7ec3\u5468\u671f\u90fd\u5bf9\u6bcf\u4e2a\u6279\u91cf\u8fdb\u884c\u904d\u5386\uff0c\u603b\u5171\u670916\u4e2a\u6279\u91cf\uff0c\u6bcf\u4e2a\u6279\u91cf\u7684\u5927\u5c0f\u4e3a64\uff0c\u5219\u904d\u538616\u6b21     for inputs, targets in trainloader:           # (batch_size, seq_len, input_size)         # \u8fd9\u91cc\u4ee3\u8868\u6bcf\u4e2a(batch_size, hidden_size)         hidden = torch.zeros(inputs.size(0), hidden_size).to(device)         optimizer.zero_grad()         # \u8fd9\u6b65\u901a\u8fc7\u4e0d\u65ad\u66f4\u65b0\u9690\u72b6\u6001hidden\u5b9e\u73b0RNN\u7684\u6838\u5fc3\uff1a\u5faa\u73af\uff0c\u5faa\u73af\u6b21\u6570\u4e3a\u65f6\u95f4\u6b65\u6570seq_len\uff0c\u5728\u521d\u59cb\u5316\u6837\u672c\u7684\u65f6\u5019\u7ed9\u5b9a         for i in range(inputs.size(1)):             # inputs[:, i, :]\u4ee3\u8868\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u8f93\u5165             output, hidden = rnn(inputs[:, i, :], hidden)          # targets\u672c\u8eab\u662f\u5c06inputs\u6309\u7167\u65f6\u95f4\u6b65\u5e73\u79fb\u4e00\u4e2a\u5355\u4f4d\uff0ctargets[:, -1, :]\u4ee3\u8868\u6211\u4eec\u7528\u5f53\u524d\u7684\u65f6\u95f4\u6b65\u6700\u540e\u8f93\u51fa\u7684Ot\uff0c\u9884\u6d4b\u4e0b\u4e00\u4e2a\u6570\u636e\u3002         # \u5bf9\u4e8e\u6bcf\u4e2a\u5c0f\u6279\u91cf\uff0c\u90fd\u4f1a\u8ba1\u7b97\u51fa\u4e00\u4e2aloss\uff0c\u8fdb\u884c\u4e00\u6b21\u68af\u5ea6\u4e0b\u964d         # targets[:, -1, :]\u5e26\u4ee3\u8868\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u6807\u7b7e         l = loss(output, targets[:, -1, :])         l.backward()         optim.step()          # \u6bcf10\u4e2a\u8bad\u7ec3\u5468\u671f\u8f93\u51fa\u4e00\u6b21\u7ed3\u679c     if (epoch+1) % 10 == 0:         print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {l.item():.4f}')  # \u6d4b\u8bd5\u6a21\u578b # \u5e8f\u5217\u5230\u7c7b\u522b\u6a21\u5f0f\uff0c\u5e76\u4e14\u5047\u8bbe\u6d4b\u8bd5\u96c6\u5df2\u6309\u7167\u65f6\u95f4\u987a\u5e8f\uff0c\u800c\u4e14\u521d\u59cb\u9690\u72b6\u6001\u4e3a0\u3002 # \u53ef\u4ee5\u5efa\u6a21\u4f7f\u7528\u80a1\u7968\u4e00\u6bb5\u65f6\u95f4\u7684\u5386\u53f2\u6570\u636e\u9884\u6d4b\u4eca\u5929\u80a1\u7968\u7684\u6536\u76ca\u7387 with torch.no_grad():     test_loss = 0     for input, target in testset:         # input: \u4ee3\u8868\u5355\u4e2a\u6837\u672c(seq_len, input_size)                  for i in range(input.unsqueeze(0).size(1)):  # \u904d\u5386\u65f6\u95f4\u6b65             # input.unsqueeze(0)[:, i, :]: (batch_size, seq_len)             hidden = torch.zeros(input.unsqueeze(0).size(0), hidden_size)             output, hidden = rnn(input.unsqueeze(0)[:, i, :], hidden)             # print(output)         # \u6d4b\u8bd5\u96c6\u4e0a\u7684\u8bef\u5dee         # target[-1]\u4ee3\u8868\u6700\u540e\u4e00\u4e2a\u65f6\u95f4\u6b65\u7684\u7ed3\u679c         test_loss += loss(output, target[-1])              print(f'Test Loss: {test_loss.item():.4f}')   <pre>Epoch [10/100], Loss: 1.1373\nEpoch [20/100], Loss: 0.8575\nEpoch [30/100], Loss: 0.8799\nEpoch [40/100], Loss: 1.0073\nEpoch [50/100], Loss: 0.9231\nEpoch [60/100], Loss: 0.9187\nEpoch [70/100], Loss: 1.3394\nEpoch [80/100], Loss: 0.8703\nEpoch [90/100], Loss: 1.2427\nEpoch [100/100], Loss: 1.1696\nTest Loss: 220.9221\n</pre> In\u00a0[301]: Copied! <pre>import torch\nimport torch.nn as nn\n\n# \u5b9a\u4e49RNN\u6a21\u578b\nclass RNN(nn.Module):\n    def __init__(self, \n                 input_size, \n                 hidden_size, \n                 output_size,\n                 num_layers: int=1,\n                 nonlinearity: str='tanh',\n                 bias: bool=True,\n                 batch_first: bool=False,\n                 dropout: float=0,\n                 bidirectional: bool=False):\n        super(RNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.rnn = nn.RNN(input_size=input_size, \n                          hidden_size=hidden_size,\n                          num_layers=num_layers,\n                          nonlinearity=nonlinearity,\n                          bias=bias,\n                          batch_first=batch_first,\n                          dropout=dropout,\n                          bidirectional=bidirectional)\n        # \u5982\u679c\u4f7f\u7528\u8fd9\u6b65\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u81ea\u5df1\u6307\u5b9a\u8f93\u51fa\u7684\u5f62\u72b6\uff0c\u5b9e\u73b0d2l(8.4.6)\u5f0f\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, input_tensor, hidden_tensor: torch.tensor=None):\n        # \u4e0d\u63d0\u4f9bhidden_tensor\uff0c\u5219\u9ed8\u8ba4\u4e3ahidden_tensor\u4e3azero tensor\n        out, hidden_tensor = self.rnn(input_tensor, hidden_tensor)\n        out = self.fc(out)\n        return out, hidden_tensor\n    \nrnn = RNN(input_size=input_size, hidden_size=hidden_size, output_size=1)\n</pre> import torch import torch.nn as nn  # \u5b9a\u4e49RNN\u6a21\u578b class RNN(nn.Module):     def __init__(self,                   input_size,                   hidden_size,                   output_size,                  num_layers: int=1,                  nonlinearity: str='tanh',                  bias: bool=True,                  batch_first: bool=False,                  dropout: float=0,                  bidirectional: bool=False):         super(RNN, self).__init__()         self.hidden_size = hidden_size         self.rnn = nn.RNN(input_size=input_size,                            hidden_size=hidden_size,                           num_layers=num_layers,                           nonlinearity=nonlinearity,                           bias=bias,                           batch_first=batch_first,                           dropout=dropout,                           bidirectional=bidirectional)         # \u5982\u679c\u4f7f\u7528\u8fd9\u6b65\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u81ea\u5df1\u6307\u5b9a\u8f93\u51fa\u7684\u5f62\u72b6\uff0c\u5b9e\u73b0d2l(8.4.6)\u5f0f         self.fc = nn.Linear(hidden_size, output_size)      def forward(self, input_tensor, hidden_tensor: torch.tensor=None):         # \u4e0d\u63d0\u4f9bhidden_tensor\uff0c\u5219\u9ed8\u8ba4\u4e3ahidden_tensor\u4e3azero tensor         out, hidden_tensor = self.rnn(input_tensor, hidden_tensor)         out = self.fc(out)         return out, hidden_tensor      rnn = RNN(input_size=input_size, hidden_size=hidden_size, output_size=1) In\u00a0[291]: Copied! <pre>inputs, targets  = next(iter(trainloader))\n</pre> inputs, targets  = next(iter(trainloader)) In\u00a0[292]: Copied! <pre>inputs = inputs.permute(1, 0, 2)  # (seq_len, batch_size, input_size)\ntargets = targets.permute(1, 0, 2)\ninputs.shape, targets.shape\n</pre> inputs = inputs.permute(1, 0, 2)  # (seq_len, batch_size, input_size) targets = targets.permute(1, 0, 2) inputs.shape, targets.shape Out[292]: <pre>(torch.Size([30, 64, 40]), torch.Size([30, 64, 1]))</pre> In\u00a0[325]: Copied! <pre># RNN\u6a21\u578b\u7684\u9ed8\u8ba4\u8f93\u51fa\u5f62\u72b6\u4e3a(\u65f6\u95f4\u6b65\u6570, \u6279\u91cf\u5927\u5c0f\uff0c\u9690\u85cf\u5c42\u5355\u5143\u6570)\nnn.RNN(input_size=40, hidden_size=128)(inputs)[0].shape, \\\nnn.RNN(input_size=40, hidden_size=128)(inputs)[1].shape\n</pre> # RNN\u6a21\u578b\u7684\u9ed8\u8ba4\u8f93\u51fa\u5f62\u72b6\u4e3a(\u65f6\u95f4\u6b65\u6570, \u6279\u91cf\u5927\u5c0f\uff0c\u9690\u85cf\u5c42\u5355\u5143\u6570) nn.RNN(input_size=40, hidden_size=128)(inputs)[0].shape, \\ nn.RNN(input_size=40, hidden_size=128)(inputs)[1].shape Out[325]: <pre>(torch.Size([30, 32, 128]), torch.Size([1, 32, 128]))</pre> In\u00a0[300]: Copied! <pre>rnn = RNN(input_size=40, hidden_size=128, output_size=1)\noutput_shape = rnn(inputs)[0].shape\nprint(f'\u5728\u6211\u4eec\u7684RNN\u6a21\u578b\u4e2d\u7684\u6bcf\u4e00\u4e2abatch\u8bad\u7ec3\u65f6\uff0c\u8f93\u5165RNN\u7684x_batch\u5f62\u72b6\u4e3a{batch_x.shape}\uff0c\u4ee3\u8868(\u65f6\u95f4\u6b65\u6570, \u6279\u91cf\u5927\u5c0f, \u6837\u672c\u7279\u5f81\u6570)\\n'\n      f'\u56e0\u4e3a\u672c\u793a\u4f8b\u6570\u636e\u4e2d\uff0c\u6807\u7b7e\u5f62\u72b6\u4e3a{batch_y.shape}\uff0c\u4ee3\u8868\u6bcf\u4e2a\u65f6\u95f4\u70b9\u7684\u6bcf\u4e2a\u6837\u672c\u90fd\u5bf9\u5e94\u4e00\u4e2a\u6807\u91cf\u7684\u6807\u7b7e\uff0c\\n'\n      f'\u5219\u6211\u4eec\u60f3\u8981RNN\u6a21\u578b\u7684\u8f93\u51fa\u5f62\u72b6\u7b49\u4e8e\u6807\u7b7e\u5f62\u72b6\uff0c'\n      f'\u8fd9\u6837\u5c31\u76f8\u5f53\u4e8e\u5bf9\u6807\u7b7e\u8fdb\u884c\u4e86\u9884\u6d4b\u3002\u6211\u4eec\u8bbe\u5b9a\u4e3aoutput_size={output_size}\uff0c\\n\u6b64\u65f6RNN\u6a21\u578b\u8f93\u51fa\u5f62\u72b6\u4e3a{output_shape}\u3002')\n</pre> rnn = RNN(input_size=40, hidden_size=128, output_size=1) output_shape = rnn(inputs)[0].shape print(f'\u5728\u6211\u4eec\u7684RNN\u6a21\u578b\u4e2d\u7684\u6bcf\u4e00\u4e2abatch\u8bad\u7ec3\u65f6\uff0c\u8f93\u5165RNN\u7684x_batch\u5f62\u72b6\u4e3a{batch_x.shape}\uff0c\u4ee3\u8868(\u65f6\u95f4\u6b65\u6570, \u6279\u91cf\u5927\u5c0f, \u6837\u672c\u7279\u5f81\u6570)\\n'       f'\u56e0\u4e3a\u672c\u793a\u4f8b\u6570\u636e\u4e2d\uff0c\u6807\u7b7e\u5f62\u72b6\u4e3a{batch_y.shape}\uff0c\u4ee3\u8868\u6bcf\u4e2a\u65f6\u95f4\u70b9\u7684\u6bcf\u4e2a\u6837\u672c\u90fd\u5bf9\u5e94\u4e00\u4e2a\u6807\u91cf\u7684\u6807\u7b7e\uff0c\\n'       f'\u5219\u6211\u4eec\u60f3\u8981RNN\u6a21\u578b\u7684\u8f93\u51fa\u5f62\u72b6\u7b49\u4e8e\u6807\u7b7e\u5f62\u72b6\uff0c'       f'\u8fd9\u6837\u5c31\u76f8\u5f53\u4e8e\u5bf9\u6807\u7b7e\u8fdb\u884c\u4e86\u9884\u6d4b\u3002\u6211\u4eec\u8bbe\u5b9a\u4e3aoutput_size={output_size}\uff0c\\n\u6b64\u65f6RNN\u6a21\u578b\u8f93\u51fa\u5f62\u72b6\u4e3a{output_shape}\u3002') <pre>\u5728\u6211\u4eec\u7684RNN\u6a21\u578b\u4e2d\u7684\u6bcf\u4e00\u4e2abatch\u8bad\u7ec3\u65f6\uff0c\u8f93\u5165RNN\u7684x_batch\u5f62\u72b6\u4e3atorch.Size([30, 64, 40])\uff0c\u4ee3\u8868(\u65f6\u95f4\u6b65\u6570, \u6279\u91cf\u5927\u5c0f, \u6837\u672c\u7279\u5f81\u6570)\n\u56e0\u4e3a\u672c\u793a\u4f8b\u6570\u636e\u4e2d\uff0c\u6807\u7b7e\u5f62\u72b6\u4e3atorch.Size([30, 64, 1])\uff0c\u4ee3\u8868\u6bcf\u4e2a\u65f6\u95f4\u70b9\u7684\u6bcf\u4e2a\u6837\u672c\u90fd\u5bf9\u5e94\u4e00\u4e2a\u6807\u91cf\u7684\u6807\u7b7e\uff0c\n\u5219\u6211\u4eec\u60f3\u8981RNN\u6a21\u578b\u7684\u8f93\u51fa\u5f62\u72b6\u7b49\u4e8e\u6807\u7b7e\u5f62\u72b6\uff0c\u8fd9\u6837\u5c31\u76f8\u5f53\u4e8e\u5bf9\u6807\u7b7e\u8fdb\u884c\u4e86\u9884\u6d4b\u3002\u6211\u4eec\u8bbe\u5b9a\u4e3aoutput_size=1\uff0c\n\u6b64\u65f6RNN\u6a21\u578b\u8f93\u51fa\u5f62\u72b6\u4e3atorch.Size([30, 64, 1])\u3002\n</pre> In\u00a0[320]: Copied! <pre>optim = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\nloss = nn.MSELoss()\n</pre> optim = torch.optim.Adam(rnn.parameters(), lr=learning_rate) loss = nn.MSELoss() In\u00a0[322]: Copied! <pre># \u5b9a\u4e49\u8d85\u53c2\u6570\nlearning_rate = 0.01\nnum_epochs = 300\n\n# \u8bad\u7ec3\u6a21\u578b\nidx = 0\nloss_list = []\nfor epoch in range(num_epochs):  \n    for inputs, targets in trainloader:  # \u6bcf\u4e00\u6b65 loader \u91ca\u653e\u4e00\u5c0f\u6279\u6570\u636e\u7528\u6765\u5b66\u4e60\n        # \u6bcf\u6b21\u8f93\u5165RNN\u7684\u53c2\u6570\u5f62\u72b6\u9700\u8981\u4e3a(seq_len, batch, input_size)\n        inputs = inputs.permute(1, 0, 2)\n        targets = targets.permute(1, 0, 2)\n        # optimizer.zero_grad()\u7684\u4f5c\u7528\u662f\u5c06\u6a21\u578b\u7684\u6240\u6709\u53c2\u6570\u7684\u68af\u5ea6\u503c\u6e05\u96f6\u3002\n        # \u8fd9\u4e2a\u64cd\u4f5c\u901a\u5e38\u5728\u6bcf\u4e2abatch\u7684\u8bad\u7ec3\u4e4b\u524d\u8c03\u7528\uff0c\u4ee5\u786e\u4fdd\u6bcf\u4e2abatch\u7684\u68af\u5ea6\u8ba1\u7b97\u662f\u72ec\u7acb\u7684\u3002\n        # \u5177\u4f53\u6765\u8bf4\uff0coptimizer.zero_grad()\u4f1a\u904d\u5386\u6a21\u578b\u7684\u6240\u6709\u53c2\u6570\uff0c\u5e76\u5c06\u5b83\u4eec\u7684\u68af\u5ea6\u503c\u8bbe\u4e3a0\u3002\n        # \u8fd9\u6837\u505a\u662f\u56e0\u4e3a\u5728PyTorch\u4e2d\uff0c\u68af\u5ea6\u662f\u9ed8\u8ba4\u4f1a\u7d2f\u52a0\u7684\uff0c\u800c\u4e0d\u662f\u88ab\u66ff\u6362\u6389\u3002\n        # \u56e0\u6b64\uff0c\u5728\u6bcf\u4e2abatch\u7684\u8bad\u7ec3\u4e4b\u524d\uff0c\u9700\u8981\u5c06\u68af\u5ea6\u6e05\u96f6\uff0c\u4ee5\u786e\u4fdd\u6bcf\u4e2abatch\u7684\u68af\u5ea6\u8ba1\u7b97\u662f\u72ec\u7acb\u7684\u3002\n        optim.zero_grad()\n        \n        output_tensor, hidden_tensor = rnn(inputs)\n        l = loss(output_tensor, targets)\n        l.backward()\n        optim.step()\n        \n    if (epoch + 1) % 10 == 0:\n        idx += 1\n        loss_list.append(l)\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {l.item():.4f}\")\n\n# with torch.no_grad()\u662f\u4e00\u4e2a\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\uff0c\u7528\u4e8e\u7981\u7528\u68af\u5ea6\u8ba1\u7b97\u3002\n# \u5728PyTorch\u4e2d\uff0c\u5982\u679c\u4e00\u4e2a\u5f20\u91cf\u7684requires_grad\u5c5e\u6027\u88ab\u8bbe\u7f6e\u4e3aTrue\uff0c\u5219\u53cd\u5411\u4f20\u64ad\u65f6\uff0c\u8be5\u5f20\u91cf\u5c31\u4f1a\u81ea\u52a8\u6c42\u5bfc\u3002\n# \u4f46\u662f\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u4e0d\u9700\u8981\u8ba1\u7b97\u68af\u5ea6\uff0c\u4f8b\u5982\u5728\u6a21\u578b\u6d4b\u8bd5\u65f6\u3002\u8fd9\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528with torch.no_grad()\u6765\u7981\u7528\u68af\u5ea6\u8ba1\u7b97\uff0c\n# \u4ee5\u51cf\u5c11\u5185\u5b58\u7684\u4f7f\u7528\u5e76\u52a0\u5feb\u4ee3\u7801\u7684\u8fd0\u884c\u901f\u5ea6\u3002\n# \u5728with torch.no_grad()\u4ee3\u7801\u5757\u4e2d\u8ba1\u7b97\u5f97\u5230\u7684\u5f20\u91cf\u7684requires_grad\u5c5e\u6027\u90fd\u4f1a\u88ab\u81ea\u52a8\u8bbe\u7f6e\u4e3aFalse\uff0c\n# \u4ee5\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u5185\u5b58\u6d88\u8017\u548c\u8ba1\u7b97\u5f00\u9500\u3002\u901a\u5e38\u60c5\u51b5\u4e0b\uff0cwith torch.no_grad()\u4f1a\u5728\u6d4b\u8bd5\u6a21\u578b\u65f6\u4f7f\u7528\u3002\nwith torch.no_grad():\n# plot the train loss     \n    plt.plot(np.arange(idx), np.array(loss_list))\n    plt.xlabel('train epochs')\n    plt.ylabel('train loss')\n    plt.show()\n</pre> # \u5b9a\u4e49\u8d85\u53c2\u6570 learning_rate = 0.01 num_epochs = 300  # \u8bad\u7ec3\u6a21\u578b idx = 0 loss_list = [] for epoch in range(num_epochs):       for inputs, targets in trainloader:  # \u6bcf\u4e00\u6b65 loader \u91ca\u653e\u4e00\u5c0f\u6279\u6570\u636e\u7528\u6765\u5b66\u4e60         # \u6bcf\u6b21\u8f93\u5165RNN\u7684\u53c2\u6570\u5f62\u72b6\u9700\u8981\u4e3a(seq_len, batch, input_size)         inputs = inputs.permute(1, 0, 2)         targets = targets.permute(1, 0, 2)         # optimizer.zero_grad()\u7684\u4f5c\u7528\u662f\u5c06\u6a21\u578b\u7684\u6240\u6709\u53c2\u6570\u7684\u68af\u5ea6\u503c\u6e05\u96f6\u3002         # \u8fd9\u4e2a\u64cd\u4f5c\u901a\u5e38\u5728\u6bcf\u4e2abatch\u7684\u8bad\u7ec3\u4e4b\u524d\u8c03\u7528\uff0c\u4ee5\u786e\u4fdd\u6bcf\u4e2abatch\u7684\u68af\u5ea6\u8ba1\u7b97\u662f\u72ec\u7acb\u7684\u3002         # \u5177\u4f53\u6765\u8bf4\uff0coptimizer.zero_grad()\u4f1a\u904d\u5386\u6a21\u578b\u7684\u6240\u6709\u53c2\u6570\uff0c\u5e76\u5c06\u5b83\u4eec\u7684\u68af\u5ea6\u503c\u8bbe\u4e3a0\u3002         # \u8fd9\u6837\u505a\u662f\u56e0\u4e3a\u5728PyTorch\u4e2d\uff0c\u68af\u5ea6\u662f\u9ed8\u8ba4\u4f1a\u7d2f\u52a0\u7684\uff0c\u800c\u4e0d\u662f\u88ab\u66ff\u6362\u6389\u3002         # \u56e0\u6b64\uff0c\u5728\u6bcf\u4e2abatch\u7684\u8bad\u7ec3\u4e4b\u524d\uff0c\u9700\u8981\u5c06\u68af\u5ea6\u6e05\u96f6\uff0c\u4ee5\u786e\u4fdd\u6bcf\u4e2abatch\u7684\u68af\u5ea6\u8ba1\u7b97\u662f\u72ec\u7acb\u7684\u3002         optim.zero_grad()                  output_tensor, hidden_tensor = rnn(inputs)         l = loss(output_tensor, targets)         l.backward()         optim.step()              if (epoch + 1) % 10 == 0:         idx += 1         loss_list.append(l)         print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {l.item():.4f}\")  # with torch.no_grad()\u662f\u4e00\u4e2a\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\uff0c\u7528\u4e8e\u7981\u7528\u68af\u5ea6\u8ba1\u7b97\u3002 # \u5728PyTorch\u4e2d\uff0c\u5982\u679c\u4e00\u4e2a\u5f20\u91cf\u7684requires_grad\u5c5e\u6027\u88ab\u8bbe\u7f6e\u4e3aTrue\uff0c\u5219\u53cd\u5411\u4f20\u64ad\u65f6\uff0c\u8be5\u5f20\u91cf\u5c31\u4f1a\u81ea\u52a8\u6c42\u5bfc\u3002 # \u4f46\u662f\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u4e0d\u9700\u8981\u8ba1\u7b97\u68af\u5ea6\uff0c\u4f8b\u5982\u5728\u6a21\u578b\u6d4b\u8bd5\u65f6\u3002\u8fd9\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528with torch.no_grad()\u6765\u7981\u7528\u68af\u5ea6\u8ba1\u7b97\uff0c # \u4ee5\u51cf\u5c11\u5185\u5b58\u7684\u4f7f\u7528\u5e76\u52a0\u5feb\u4ee3\u7801\u7684\u8fd0\u884c\u901f\u5ea6\u3002 # \u5728with torch.no_grad()\u4ee3\u7801\u5757\u4e2d\u8ba1\u7b97\u5f97\u5230\u7684\u5f20\u91cf\u7684requires_grad\u5c5e\u6027\u90fd\u4f1a\u88ab\u81ea\u52a8\u8bbe\u7f6e\u4e3aFalse\uff0c # \u4ee5\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u5185\u5b58\u6d88\u8017\u548c\u8ba1\u7b97\u5f00\u9500\u3002\u901a\u5e38\u60c5\u51b5\u4e0b\uff0cwith torch.no_grad()\u4f1a\u5728\u6d4b\u8bd5\u6a21\u578b\u65f6\u4f7f\u7528\u3002 with torch.no_grad(): # plot the train loss          plt.plot(np.arange(idx), np.array(loss_list))     plt.xlabel('train epochs')     plt.ylabel('train loss')     plt.show() <pre>Epoch [10/300], Loss: 0.8741\nEpoch [20/300], Loss: 0.8971\nEpoch [30/300], Loss: 0.9560\nEpoch [40/300], Loss: 1.0280\nEpoch [50/300], Loss: 1.0422\nEpoch [60/300], Loss: 0.9863\nEpoch [70/300], Loss: 0.9971\nEpoch [80/300], Loss: 0.8785\nEpoch [90/300], Loss: 1.0862\nEpoch [100/300], Loss: 1.0048\nEpoch [110/300], Loss: 1.0082\nEpoch [120/300], Loss: 0.9713\nEpoch [130/300], Loss: 0.9859\nEpoch [140/300], Loss: 0.9465\nEpoch [150/300], Loss: 1.0283\nEpoch [160/300], Loss: 1.0209\nEpoch [170/300], Loss: 1.0305\nEpoch [180/300], Loss: 0.9262\nEpoch [190/300], Loss: 0.8996\nEpoch [200/300], Loss: 0.9678\nEpoch [210/300], Loss: 1.0906\nEpoch [220/300], Loss: 0.9513\nEpoch [230/300], Loss: 0.9987\nEpoch [240/300], Loss: 1.0000\nEpoch [250/300], Loss: 1.0177\nEpoch [260/300], Loss: 1.0527\nEpoch [270/300], Loss: 1.0290\nEpoch [280/300], Loss: 0.9537\nEpoch [290/300], Loss: 1.1618\nEpoch [300/300], Loss: 1.0905\n</pre> In\u00a0[321]: Copied! <pre># \u6bcf\u4e2a\u6837\u672c\u7684\u5f62\u72b6\u4e3a(\u65f6\u95f4\u6b65\u6570\uff0c\u6837\u672c\u7279\u5f81\u6570)\n# \u6bcf\u4e2a\u6807\u7b7e\u7684\u5f62\u72b6\u4e5f\u4e3a(\u65f6\u95f4\u6b65\u6570\uff0c\u6837\u672c\u7279\u5f81\u6570)\nprint(testset[100][0].shape, testset[100][1].shape)\n</pre> # \u6bcf\u4e2a\u6837\u672c\u7684\u5f62\u72b6\u4e3a(\u65f6\u95f4\u6b65\u6570\uff0c\u6837\u672c\u7279\u5f81\u6570) # \u6bcf\u4e2a\u6807\u7b7e\u7684\u5f62\u72b6\u4e5f\u4e3a(\u65f6\u95f4\u6b65\u6570\uff0c\u6837\u672c\u7279\u5f81\u6570) print(testset[100][0].shape, testset[100][1].shape) <pre>torch.Size([30, 40]) torch.Size([30, 1])\n</pre> In\u00a0[317]: Copied! <pre># RNN\u6a21\u578b\u7684\u9ed8\u8ba4\u8f93\u51fa\u5f62\u72b6\u4e3a(\u65f6\u95f4\u6b65\u6570, \u6279\u91cf\u5927\u5c0f\uff0c\u6837\u672c\u7279\u5f81\u6570)\uff0c\u4f46\u662f\u5982\u679c\u8f93\u5165\u53ea\u6709\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u90a3\u4e48\u9ed8\u8ba4\u8f93\u5165\u4e3a(\u65f6\u95f4\u6b65\u6570\uff0c\u6837\u672c\u7279\u5f81\u6570)\uff0c\n# \u8f93\u51fa\u4e2dbatch_size\u8fd9\u4e00\u7ef4\u5ea6\u81ea\u52a8\u6d88\u5931\ns = testset[100][0]\ns.shape, rnn(s)[0].shape\n</pre> # RNN\u6a21\u578b\u7684\u9ed8\u8ba4\u8f93\u51fa\u5f62\u72b6\u4e3a(\u65f6\u95f4\u6b65\u6570, \u6279\u91cf\u5927\u5c0f\uff0c\u6837\u672c\u7279\u5f81\u6570)\uff0c\u4f46\u662f\u5982\u679c\u8f93\u5165\u53ea\u6709\u4e24\u4e2a\u7ef4\u5ea6\uff0c\u90a3\u4e48\u9ed8\u8ba4\u8f93\u5165\u4e3a(\u65f6\u95f4\u6b65\u6570\uff0c\u6837\u672c\u7279\u5f81\u6570)\uff0c # \u8f93\u51fa\u4e2dbatch_size\u8fd9\u4e00\u7ef4\u5ea6\u81ea\u52a8\u6d88\u5931 s = testset[100][0] s.shape, rnn(s)[0].shape Out[317]: <pre>(torch.Size([30, 40]), torch.Size([30, 1]))</pre> In\u00a0[312]: Copied! <pre># \u5bf9\u4e8e\u6bcf\u4e2a\u6837\u672c\uff0c\u8f93\u51fa\u90fd\u662f\u4e00\u4e2a\u6807\u91cf\uff0c\u90a3\u4e48\u5bf9\u5168\u4f53\u6837\u672c\u7684MSEloss\u7684\u8ba1\u7b97\u65b9\u5f0f\u4e3a\uff1a\u5c06\u6bcf\u4e2a\u6837\u672c\u7684MSEloss\u76f8\u52a0\uff0c\u7136\u540e\u9664\u4ee5\u6837\u672c\u6570\u91cf\u3002\nwith torch.no_grad():\n    l = 0\n    for sample, label in testset:\n        output, _ = rnn(sample)\n        l += loss(output, label)\n    l = l / len(testset)\n    print(f'Test loss is {l}')\n</pre> # \u5bf9\u4e8e\u6bcf\u4e2a\u6837\u672c\uff0c\u8f93\u51fa\u90fd\u662f\u4e00\u4e2a\u6807\u91cf\uff0c\u90a3\u4e48\u5bf9\u5168\u4f53\u6837\u672c\u7684MSEloss\u7684\u8ba1\u7b97\u65b9\u5f0f\u4e3a\uff1a\u5c06\u6bcf\u4e2a\u6837\u672c\u7684MSEloss\u76f8\u52a0\uff0c\u7136\u540e\u9664\u4ee5\u6837\u672c\u6570\u91cf\u3002 with torch.no_grad():     l = 0     for sample, label in testset:         output, _ = rnn(sample)         l += loss(output, label)     l = l / len(testset)     print(f'Test loss is {l}') <pre>Test loss is 1.118180751800537\n</pre> <p>nn.RNN</p>"},{"location":"markdown/knowledge/deep_learning_notebook/RNN/#rnn","title":"RNN\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/RNN/#rnn","title":"\u6570\u636e\u96c6\u548cRNN\u57fa\u672c\u539f\u7406\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/RNN/#rnn","title":"\u8be6\u7ec6\u7684\u4ece\u96f6\u5f00\u59cb\u7684RNN\u7f51\u7edc\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/RNN/#rnn","title":"\u5b9a\u4e49RNN\u6a21\u578b\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/RNN/","title":"\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/RNN/","title":"\u6a21\u578b\u8bad\u7ec3\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/RNN/#nnrnn","title":"\u4f7f\u7528nn.RNN\u7b80\u6d01\u5b9e\u73b0\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/RNN/#rnn","title":"\u5b9a\u4e49RNN\u6a21\u578b\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/RNN/#shape","title":"\u67e5\u770b\u4e00\u4e0bshape\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/RNN/","title":"\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/RNN/","title":"\u8bad\u7ec3\u6a21\u578b\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/RNN/","title":"\u8f93\u51fa\u5728\u6d4b\u8bd5\u96c6\u4e0a\u7684\u7ed3\u679c\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/RNN/","title":"\u53c2\u8003\u94fe\u63a5\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/chapter-transformer/","title":"Torch Notes for Transformer and Related Materials","text":"In\u00a0[2]: Copied! <pre># As before, we need to include some libraries\nimport torch\nfrom torch import nn\nimport math\nimport myutils\nimport pandas as pd\n</pre> # As before, we need to include some libraries import torch from torch import nn import math import myutils import pandas as pd In\u00a0[3]: Copied! <pre>import os\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n</pre> import os os.environ['KMP_DUPLICATE_LIB_OK'] = 'True' In\u00a0[\u00a0]: Copied! <pre>#  A colab link for attention visualization\n#  https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb#scrollTo=OJKU36QAfqOC\n</pre> #  A colab link for attention visualization #  https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb#scrollTo=OJKU36QAfqOC In\u00a0[4]: Copied! <pre># Some visualizations of attention\n# Identity weight\n\nattention_weights = torch.eye(10).reshape((1, 1, 10, 10))\nmyutils.show_heatmaps(attention_weights, xlabel='Keys', ylabel='Queries')\n</pre> # Some visualizations of attention # Identity weight  attention_weights = torch.eye(10).reshape((1, 1, 10, 10)) myutils.show_heatmaps(attention_weights, xlabel='Keys', ylabel='Queries') In\u00a0[5]: Copied! <pre># functionality of masked softmax\n# Check what masked softmax do?\nmyutils.masked_softmax(torch.rand(2, 2, 4), torch.tensor([2, 3]))\n</pre> # functionality of masked softmax # Check what masked softmax do? myutils.masked_softmax(torch.rand(2, 2, 4), torch.tensor([2, 3])) Out[5]: <pre>tensor([[[0.4538, 0.5462, 0.0000, 0.0000],\n         [0.4829, 0.5171, 0.0000, 0.0000]],\n\n        [[0.3702, 0.3026, 0.3272, 0.0000],\n         [0.2644, 0.4502, 0.2854, 0.0000]]])</pre> In\u00a0[17]: Copied! <pre># ---------------------------------\n# additive attention\n# ---------------------------------\n# a(q,k) = w_v tanh(W_q q + W_k k)\n# pay attention to tensor operation.\n\nclass AdditiveAttention(nn.Module):\n    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):\n        super(AdditiveAttention, self).__init__(**kwargs)\n        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)\n        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)\n        self.w_v = nn.Linear(num_hiddens, 1, bias=False)\n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, queries, keys, values, valid_lens):\n        # \u7ebf\u6027\u5c42\u9ed8\u8ba4\u90fd\u662f\u5bf9\u8f93\u5165\u6837\u672c\u7684\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u64cd\u4f5c\n        queries, keys = self.W_q(queries), self.W_k(keys)\n        # \u5728\u7ef4\u5ea6\u6269\u5c55\u540e\uff0c\n        # queries\u7684\u5f62\u72b6\uff1a(batch_size\uff0c\u67e5\u8be2\u7684\u4e2a\u6570\uff0c1\uff0cnum_hidden)\n        # key\u7684\u5f62\u72b6\uff1a(batch_size\uff0c1\uff0c\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570\uff0cnum_hiddens)\n        # \u4f7f\u2f64\u2f34\u64ad\u2f45\u5f0f\u8fdb\u2f8f\u6c42\u548c\n        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n        # print(features.shape)\n        features = torch.tanh(features)\n        # self.w_v\u4ec5\u6709\u2f00\u4e2a\u8f93\u51fa\uff0c\u56e0\u6b64\u4ece\u5f62\u72b6\u4e2d\u79fb\u9664\u6700\u540e\u90a3\u4e2a\u7ef4\u5ea6\u3002\n        # scores\u7684\u5f62\u72b6\uff1a(batch_size\uff0c\u67e5\u8be2\u7684\u4e2a\u6570\uff0c\u201c\u952e-\u503c\u201d\u5bf9\u7684\u4e2a\u6570)\n        scores = self.w_v(features).squeeze(-1)\n        self.attention_weights = myutils.masked_softmax(scores, valid_lens)\n        # values\u7684\u5f62\u72b6\uff1a(batch_size\uff0c\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570\uff0c\u503c\u7684\u7ef4\u5ea6)\n        # torch.bmm: https://blog.csdn.net/qq_43391414/article/details/110442229\n        return torch.bmm(self.dropout(self.attention_weights), values)\n</pre> # --------------------------------- # additive attention # --------------------------------- # a(q,k) = w_v tanh(W_q q + W_k k) # pay attention to tensor operation.  class AdditiveAttention(nn.Module):     def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):         super(AdditiveAttention, self).__init__(**kwargs)         self.W_q = nn.Linear(query_size, num_hiddens, bias=False)         self.W_k = nn.Linear(key_size, num_hiddens, bias=False)         self.w_v = nn.Linear(num_hiddens, 1, bias=False)         self.dropout = nn.Dropout(dropout)          def forward(self, queries, keys, values, valid_lens):         # \u7ebf\u6027\u5c42\u9ed8\u8ba4\u90fd\u662f\u5bf9\u8f93\u5165\u6837\u672c\u7684\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\u64cd\u4f5c         queries, keys = self.W_q(queries), self.W_k(keys)         # \u5728\u7ef4\u5ea6\u6269\u5c55\u540e\uff0c         # queries\u7684\u5f62\u72b6\uff1a(batch_size\uff0c\u67e5\u8be2\u7684\u4e2a\u6570\uff0c1\uff0cnum_hidden)         # key\u7684\u5f62\u72b6\uff1a(batch_size\uff0c1\uff0c\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570\uff0cnum_hiddens)         # \u4f7f\u2f64\u2f34\u64ad\u2f45\u5f0f\u8fdb\u2f8f\u6c42\u548c         features = queries.unsqueeze(2) + keys.unsqueeze(1)         # print(features.shape)         features = torch.tanh(features)         # self.w_v\u4ec5\u6709\u2f00\u4e2a\u8f93\u51fa\uff0c\u56e0\u6b64\u4ece\u5f62\u72b6\u4e2d\u79fb\u9664\u6700\u540e\u90a3\u4e2a\u7ef4\u5ea6\u3002         # scores\u7684\u5f62\u72b6\uff1a(batch_size\uff0c\u67e5\u8be2\u7684\u4e2a\u6570\uff0c\u201c\u952e-\u503c\u201d\u5bf9\u7684\u4e2a\u6570)         scores = self.w_v(features).squeeze(-1)         self.attention_weights = myutils.masked_softmax(scores, valid_lens)         # values\u7684\u5f62\u72b6\uff1a(batch_size\uff0c\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570\uff0c\u503c\u7684\u7ef4\u5ea6)         # torch.bmm: https://blog.csdn.net/qq_43391414/article/details/110442229         return torch.bmm(self.dropout(self.attention_weights), values) In\u00a0[151]: Copied! <pre># In the following cells, we test additive attention\n\n# check the sizes of your query and key \nqueries, keys = torch.normal(0, 1, (2, 1, 20)), torch.ones((2, 10, 2))\n# batch size\u662f2\uff0c\u6709\u4e00\u4e2a\u67e5\u8be2\uff0c\u67e5\u8be2\u7684\u7ef4\u5ea6\u662f20\uff1b\n# \u670910\u4e2a\u539f\u672c\u7684key\uff08\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570\u4e3a10\uff09\uff0c\u6bcf\u4e2akey\u7684\u7ef4\u5ea6\u662f2\nqueries.shape, keys.shape\n</pre> # In the following cells, we test additive attention  # check the sizes of your query and key  queries, keys = torch.normal(0, 1, (2, 1, 20)), torch.ones((2, 10, 2)) # batch size\u662f2\uff0c\u6709\u4e00\u4e2a\u67e5\u8be2\uff0c\u67e5\u8be2\u7684\u7ef4\u5ea6\u662f20\uff1b # \u670910\u4e2a\u539f\u672c\u7684key\uff08\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570\u4e3a10\uff09\uff0c\u6bcf\u4e2akey\u7684\u7ef4\u5ea6\u662f2 queries.shape, keys.shape Out[151]: <pre>(torch.Size([2, 1, 20]), torch.Size([2, 10, 2]))</pre> In\u00a0[152]: Copied! <pre># check the size of value\nvalues = torch.arange(40, dtype=torch.float32).reshape(1, 10, 4).repeat(2, 1, 1)\nvalid_lens = torch.tensor([2, 6])\nvalues.shape\n</pre> # check the size of value values = torch.arange(40, dtype=torch.float32).reshape(1, 10, 4).repeat(2, 1, 1) valid_lens = torch.tensor([2, 6]) values.shape Out[152]: <pre>torch.Size([2, 10, 4])</pre> In\u00a0[20]: Copied! <pre># \u9690\u85cf\u5c42\u795e\u7ecf\u5143\u6570\u91cf\u4e3a8\nattention = AdditiveAttention(key_size=2, query_size=20, num_hiddens=8, dropout=0.1)\nattention.eval()\nattention(queries, keys, values, valid_lens)\n</pre> # \u9690\u85cf\u5c42\u795e\u7ecf\u5143\u6570\u91cf\u4e3a8 attention = AdditiveAttention(key_size=2, query_size=20, num_hiddens=8, dropout=0.1) attention.eval() attention(queries, keys, values, valid_lens) Out[20]: <pre>tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],\n\n        [[10.0000, 11.0000, 12.0000, 13.0000]]], grad_fn=&lt;BmmBackward0&gt;)</pre> In\u00a0[22]: Copied! <pre>attention.W_q(queries).shape, attention.W_q(queries).unsqueeze(2).shape\n</pre> attention.W_q(queries).shape, attention.W_q(queries).unsqueeze(2).shape Out[22]: <pre>(torch.Size([2, 1, 8]), torch.Size([2, 1, 1, 8]))</pre> In\u00a0[27]: Copied! <pre># heat map of attention values\nmyutils.show_heatmaps(attention.attention_weights.reshape((1, 1, 2, 10)), xlabel='Keys', ylabel='Queries')\n</pre> # heat map of attention values myutils.show_heatmaps(attention.attention_weights.reshape((1, 1, 2, 10)), xlabel='Keys', ylabel='Queries') In\u00a0[160]: Copied! <pre># ---------------------\n# dot attention\n# ---------------------\n\nclass DotProductAttention(nn.Module):\n    \"\"\"\u7f29\u653e\u70b9\u79ef\u6ce8\u610f\u2f12\"\"\"\n    def __init__(self, dropout, **kwargs):\n        super(DotProductAttention, self).__init__(**kwargs)\n        self.dropout = nn.Dropout(dropout)\n        self.softmax = nn.Softmax(dim=-1)\n    # DotProductAttention\u8981\u6c42\u6bcf\u4e2aqueries\u548ckeys\u7684\u957f\u5ea6\u76f8\u540c\n    # queries\u7684\u5f62\u72b6\uff1a(batch_size\uff0c\u67e5\u8be2\u7684\u4e2a\u6570\uff0cd)\n    # keys\u7684\u5f62\u72b6\uff1a(batch_size\uff0c\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570\uff0cd)\n    # values\u7684\u5f62\u72b6\uff1a(batch_size\uff0c\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570\uff0c\u503c\u7684\u7ef4\u5ea6)\n    # valid_lens\u7684\u5f62\u72b6:(batch_size\uff0c)\u6216\u8005(batch_size\uff0c\u67e5\u8be2\u7684\u4e2a\u6570)\n\n    def forward(self, queries, keys, values, valid_lens=None):\n        d = queries.shape[-1]\n        # \u8bbe\u7f6etranspose_b=True\u4e3a\u4e86\u4ea4\u6362keys\u7684\u6700\u540e\u4e24\u4e2a\u7ef4\u5ea6\n        # torch.bmm\u5c06\u6bcf\u4e2a\u8f93\u5165\u7684\u6700\u540e\u4e24\u4e2a\u7ef4\u5ea6\u5bf9\u5e94\u7684\u77e9\u9635\u5bf9\u5e94\u76f8\u4e58\uff0c\u5f97\u5230\u6570\u91cf\u7b49\u4e8e\u7b2c\u4e00\u7ef4\u5927\u5c0f\u7684\u7ed3\u679c\uff0c\u7136\u540e\u5c06\u7ed3\u679c\u62fc\u63a5\u8d77\u6765\n        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\n        # \u5982\u679c\u4e0d\u4f7f\u7528masked_softmax\uff0c\u4f7f\u7528\u7b80\u5355\u7684softmax\uff0c\u5219\u548c\u7ecf\u5178\u7684\u70b9\u79ef\u6ce8\u610f\u529b\u76f8\u540c\n        self.attention_weights = myutils.masked_softmax(scores, valid_lens)\n        # \u66ff\u6362\u4e3a\u8fd9\u4e2a\u4e5f\u53ef\u4ee5\uff0c\u5bf9\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\uff08\u5373\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570\u8fd9\u4e2a\u7ef4\u5ea6\u505asoftmax\uff09\n        # self.attention_weights = self.softmax(scores)  \n        return torch.bmm(self.dropout(self.attention_weights), values)\n</pre> # --------------------- # dot attention # ---------------------  class DotProductAttention(nn.Module):     \"\"\"\u7f29\u653e\u70b9\u79ef\u6ce8\u610f\u2f12\"\"\"     def __init__(self, dropout, **kwargs):         super(DotProductAttention, self).__init__(**kwargs)         self.dropout = nn.Dropout(dropout)         self.softmax = nn.Softmax(dim=-1)     # DotProductAttention\u8981\u6c42\u6bcf\u4e2aqueries\u548ckeys\u7684\u957f\u5ea6\u76f8\u540c     # queries\u7684\u5f62\u72b6\uff1a(batch_size\uff0c\u67e5\u8be2\u7684\u4e2a\u6570\uff0cd)     # keys\u7684\u5f62\u72b6\uff1a(batch_size\uff0c\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570\uff0cd)     # values\u7684\u5f62\u72b6\uff1a(batch_size\uff0c\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570\uff0c\u503c\u7684\u7ef4\u5ea6)     # valid_lens\u7684\u5f62\u72b6:(batch_size\uff0c)\u6216\u8005(batch_size\uff0c\u67e5\u8be2\u7684\u4e2a\u6570)      def forward(self, queries, keys, values, valid_lens=None):         d = queries.shape[-1]         # \u8bbe\u7f6etranspose_b=True\u4e3a\u4e86\u4ea4\u6362keys\u7684\u6700\u540e\u4e24\u4e2a\u7ef4\u5ea6         # torch.bmm\u5c06\u6bcf\u4e2a\u8f93\u5165\u7684\u6700\u540e\u4e24\u4e2a\u7ef4\u5ea6\u5bf9\u5e94\u7684\u77e9\u9635\u5bf9\u5e94\u76f8\u4e58\uff0c\u5f97\u5230\u6570\u91cf\u7b49\u4e8e\u7b2c\u4e00\u7ef4\u5927\u5c0f\u7684\u7ed3\u679c\uff0c\u7136\u540e\u5c06\u7ed3\u679c\u62fc\u63a5\u8d77\u6765         scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)         # \u5982\u679c\u4e0d\u4f7f\u7528masked_softmax\uff0c\u4f7f\u7528\u7b80\u5355\u7684softmax\uff0c\u5219\u548c\u7ecf\u5178\u7684\u70b9\u79ef\u6ce8\u610f\u529b\u76f8\u540c         self.attention_weights = myutils.masked_softmax(scores, valid_lens)         # \u66ff\u6362\u4e3a\u8fd9\u4e2a\u4e5f\u53ef\u4ee5\uff0c\u5bf9\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6\uff08\u5373\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570\u8fd9\u4e2a\u7ef4\u5ea6\u505asoftmax\uff09         # self.attention_weights = self.softmax(scores)           return torch.bmm(self.dropout(self.attention_weights), values) In\u00a0[161]: Copied! <pre># In the following cells, we test dot attention\n\nqueries = torch.normal(0, 1, (2, 1, 2))\nattention = DotProductAttention(dropout=0.5)\nattention.eval()\nattention(queries, keys, values, valid_lens)\n</pre> # In the following cells, we test dot attention  queries = torch.normal(0, 1, (2, 1, 2)) attention = DotProductAttention(dropout=0.5) attention.eval() attention(queries, keys, values, valid_lens) Out[161]: <pre>tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],\n\n        [[10.0000, 11.0000, 12.0000, 13.0000]]])</pre> In\u00a0[73]: Copied! <pre>self = attention\nprint(queries.shape, keys.shape, keys.transpose(1,2).shape, values.shape)\nprint('-' * 100)\nd = queries.shape[-1]\nscores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)\nprint(scores, scores.shape)\nprint('-' * 100)\nself.attention_weights = myutils.masked_softmax(scores, valid_lens)\nprint(self.attention_weights, self.attention_weights.shape)\nprint('-' * 100)\nprint(self.dropout(self.attention_weights).shape, values.shape)\nprint(torch.bmm(self.dropout(self.attention_weights), values), \n      torch.bmm(self.dropout(self.attention_weights), values).shape)\n</pre> self = attention print(queries.shape, keys.shape, keys.transpose(1,2).shape, values.shape) print('-' * 100) d = queries.shape[-1] scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d) print(scores, scores.shape) print('-' * 100) self.attention_weights = myutils.masked_softmax(scores, valid_lens) print(self.attention_weights, self.attention_weights.shape) print('-' * 100) print(self.dropout(self.attention_weights).shape, values.shape) print(torch.bmm(self.dropout(self.attention_weights), values),        torch.bmm(self.dropout(self.attention_weights), values).shape) <pre>torch.Size([2, 1, 2]) torch.Size([2, 10, 2]) torch.Size([2, 2, 10]) torch.Size([2, 10, 4])\n----------------------------------------------------------------------------------------------------\ntensor([[[2.2507, 2.2507, 2.2507, 2.2507, 2.2507, 2.2507, 2.2507, 2.2507,\n          2.2507, 2.2507]],\n\n        [[0.1801, 0.1801, 0.1801, 0.1801, 0.1801, 0.1801, 0.1801, 0.1801,\n          0.1801, 0.1801]]]) torch.Size([2, 1, 10])\n----------------------------------------------------------------------------------------------------\ntensor([[[0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n          0.0000, 0.0000]],\n\n        [[0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000,\n          0.0000, 0.0000]]]) torch.Size([2, 1, 10])\n----------------------------------------------------------------------------------------------------\ntorch.Size([2, 1, 10]) torch.Size([2, 10, 4])\ntensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],\n\n        [[10.0000, 11.0000, 12.0000, 13.0000]]]) torch.Size([2, 1, 4])\n</pre> In\u00a0[14]: Copied! <pre>myutils.show_heatmaps(attention.attention_weights.reshape((1, 1, 2, 10)),\n        xlabel='Keys', ylabel='Queries')\n</pre> myutils.show_heatmaps(attention.attention_weights.reshape((1, 1, 2, 10)),         xlabel='Keys', ylabel='Queries') In\u00a0[89]: Copied! <pre># ----------------------\n# position encoding\n# ----------------------\n# write the encoding function from scratch\n\nclass PositionalEncoding(nn.Module):\n    \"\"\"\u4f4d\u7f6e\u7f16\u7801\"\"\"\n    def __init__(self, num_hiddens, dropout, max_len=1000):\n        super(PositionalEncoding, self).__init__()\n        self.dropout = nn.Dropout(dropout)\n        # \u521b\u5efa\u2f00\u4e2a\u2f9c\u591f\u2ed3\u7684P\n        self.P = torch.zeros((1, max_len, num_hiddens))\n        X = torch.arange(max_len, dtype=torch.float32).reshape(\n            -1, 1) / torch.pow(10000, torch.arange(\n            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n        self.P[:, :, 0::2] = torch.sin(X)  # \u5076\u6570\u5217\u4e3asin\n        self.P[:, :, 1::2] = torch.cos(X)  # \u5947\u6570\u5217\u4e3acos\n        \n    def forward(self, X):\n        # \u8fd9\u91cc\u76f8\u52a0\u8fd0\u7528\u4e86\u5e7f\u64ad\u673a\u5236\uff0c\u5bf9\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\uff08\u4ee3\u8868batch\uff09\u8fdb\u884c\u5e7f\u64ad\u76f8\u52a0\n        X = X + self.P[:, :X.shape[1], :].to(X.device)\n        return self.dropout(X)\n</pre> # ---------------------- # position encoding # ---------------------- # write the encoding function from scratch  class PositionalEncoding(nn.Module):     \"\"\"\u4f4d\u7f6e\u7f16\u7801\"\"\"     def __init__(self, num_hiddens, dropout, max_len=1000):         super(PositionalEncoding, self).__init__()         self.dropout = nn.Dropout(dropout)         # \u521b\u5efa\u2f00\u4e2a\u2f9c\u591f\u2ed3\u7684P         self.P = torch.zeros((1, max_len, num_hiddens))         X = torch.arange(max_len, dtype=torch.float32).reshape(             -1, 1) / torch.pow(10000, torch.arange(             0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)         self.P[:, :, 0::2] = torch.sin(X)  # \u5076\u6570\u5217\u4e3asin         self.P[:, :, 1::2] = torch.cos(X)  # \u5947\u6570\u5217\u4e3acos              def forward(self, X):         # \u8fd9\u91cc\u76f8\u52a0\u8fd0\u7528\u4e86\u5e7f\u64ad\u673a\u5236\uff0c\u5bf9\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\uff08\u4ee3\u8868batch\uff09\u8fdb\u884c\u5e7f\u64ad\u76f8\u52a0         X = X + self.P[:, :X.shape[1], :].to(X.device)         return self.dropout(X) In\u00a0[76]: Copied! <pre># Curve plot of position encoding values\nencoding_dim, num_steps = 32, 60\npos_encoding = PositionalEncoding(encoding_dim, 0)\n# model.eval() \u65b9\u6cd5\u7528\u4e8e\u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f\uff08evaluation mode\uff09\u3002\n# \u8fd9\u5728\u8fdb\u884c\u6a21\u578b\u9a8c\u8bc1\u6216\u6d4b\u8bd5\u65f6\u975e\u5e38\u91cd\u8981\uff0c\u56e0\u4e3a\u5b83\u4f1a\u5f71\u54cd\u6a21\u578b\u4e2d\u67d0\u4e9b\u5c42\uff08\u5982 Batch Normalization \u548c Dropout\uff09\u7684\u884c\u4e3a\uff1a\n# 1. Batch Normalization\uff1a\u5728\u8bad\u7ec3\u6a21\u5f0f\u4e0b\uff0cBatch Normalization \u5c42\u4f1a\u4f7f\u7528\u5f53\u524d\u6279\u6b21\u7684\u5747\u503c\u548c\u65b9\u5dee\u8fdb\u884c\u5f52\u4e00\u5316\uff1b\n# \u800c\u5728\u8bc4\u4f30\u6a21\u5f0f\u4e0b\uff0c\u5b83\u4f1a\u4f7f\u7528\u6574\u4e2a\u8bad\u7ec3\u96c6\u7684\u5747\u503c\u548c\u65b9\u5dee\u3002\n# 2. Dropout\uff1a\u5728\u8bad\u7ec3\u6a21\u5f0f\u4e0b\uff0cDropout \u5c42\u4f1a\u968f\u673a\u4e22\u5f03\u4e00\u90e8\u5206\u795e\u7ecf\u5143\u4ee5\u9632\u6b62\u8fc7\u62df\u5408\uff1b\n# \u800c\u5728\u8bc4\u4f30\u6a21\u5f0f\u4e0b\uff0cDropout \u5c42\u4f1a\u4fdd\u6301\u6240\u6709\u795e\u7ecf\u5143\u7684\u6fc0\u6d3b\u72b6\u6001\uff0c\u4e0d\u8fdb\u884c\u4e22\u5f03\u64cd\u4f5c\u3002\npos_encoding.eval()\nX = pos_encoding(torch.zeros((1, num_steps, encoding_dim)))\nP = pos_encoding.P[:, :X.shape[1], :]\nmyutils.plot(torch.arange(num_steps), P[0, :, 6:10].T, xlabel='Row (position)',\n        figsize=(6, 2.5), legend=[\"Col %d\" % d for d in torch.arange(6, 10)])\n</pre> # Curve plot of position encoding values encoding_dim, num_steps = 32, 60 pos_encoding = PositionalEncoding(encoding_dim, 0) # model.eval() \u65b9\u6cd5\u7528\u4e8e\u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f\uff08evaluation mode\uff09\u3002 # \u8fd9\u5728\u8fdb\u884c\u6a21\u578b\u9a8c\u8bc1\u6216\u6d4b\u8bd5\u65f6\u975e\u5e38\u91cd\u8981\uff0c\u56e0\u4e3a\u5b83\u4f1a\u5f71\u54cd\u6a21\u578b\u4e2d\u67d0\u4e9b\u5c42\uff08\u5982 Batch Normalization \u548c Dropout\uff09\u7684\u884c\u4e3a\uff1a # 1. Batch Normalization\uff1a\u5728\u8bad\u7ec3\u6a21\u5f0f\u4e0b\uff0cBatch Normalization \u5c42\u4f1a\u4f7f\u7528\u5f53\u524d\u6279\u6b21\u7684\u5747\u503c\u548c\u65b9\u5dee\u8fdb\u884c\u5f52\u4e00\u5316\uff1b # \u800c\u5728\u8bc4\u4f30\u6a21\u5f0f\u4e0b\uff0c\u5b83\u4f1a\u4f7f\u7528\u6574\u4e2a\u8bad\u7ec3\u96c6\u7684\u5747\u503c\u548c\u65b9\u5dee\u3002 # 2. Dropout\uff1a\u5728\u8bad\u7ec3\u6a21\u5f0f\u4e0b\uff0cDropout \u5c42\u4f1a\u968f\u673a\u4e22\u5f03\u4e00\u90e8\u5206\u795e\u7ecf\u5143\u4ee5\u9632\u6b62\u8fc7\u62df\u5408\uff1b # \u800c\u5728\u8bc4\u4f30\u6a21\u5f0f\u4e0b\uff0cDropout \u5c42\u4f1a\u4fdd\u6301\u6240\u6709\u795e\u7ecf\u5143\u7684\u6fc0\u6d3b\u72b6\u6001\uff0c\u4e0d\u8fdb\u884c\u4e22\u5f03\u64cd\u4f5c\u3002 pos_encoding.eval() X = pos_encoding(torch.zeros((1, num_steps, encoding_dim))) P = pos_encoding.P[:, :X.shape[1], :] myutils.plot(torch.arange(num_steps), P[0, :, 6:10].T, xlabel='Row (position)',         figsize=(6, 2.5), legend=[\"Col %d\" % d for d in torch.arange(6, 10)]) In\u00a0[81]: Copied! <pre># X\u8868\u793a\u4e00\u4e2a\u6837\u672c\uff0c\u5176\u4e2d\u5305\u542b60\u4e2a\u8bcd\u5143\uff08\u65f6\u95f4\u6b65\u957fT=60\uff09\uff0c\u6bcf\u4e2a\u8bcd\u5143\u7684\u5d4c\u5165\u8868\u793a\u90fd\u662f32\u7ef4\u7684\nprint('\u8f93\u5165X\u7684\u5f62\u72b6\uff1a', torch.zeros((1, num_steps, encoding_dim)).shape)\nprint('P\u7684\u5f62\u72b6\uff1a', P.shape)  # P\u7684\u5f62\u72b6\u548cX\u76f8\u540c\uff0c\u6700\u7ec8\u4f4d\u7f6e\u7f16\u7801\u5d4c\u5165\u540e\u7684\u7ed3\u679c\u5c31\u662fX + P\n</pre> # X\u8868\u793a\u4e00\u4e2a\u6837\u672c\uff0c\u5176\u4e2d\u5305\u542b60\u4e2a\u8bcd\u5143\uff08\u65f6\u95f4\u6b65\u957fT=60\uff09\uff0c\u6bcf\u4e2a\u8bcd\u5143\u7684\u5d4c\u5165\u8868\u793a\u90fd\u662f32\u7ef4\u7684 print('\u8f93\u5165X\u7684\u5f62\u72b6\uff1a', torch.zeros((1, num_steps, encoding_dim)).shape) print('P\u7684\u5f62\u72b6\uff1a', P.shape)  # P\u7684\u5f62\u72b6\u548cX\u76f8\u540c\uff0c\u6700\u7ec8\u4f4d\u7f6e\u7f16\u7801\u5d4c\u5165\u540e\u7684\u7ed3\u679c\u5c31\u662fX + P <pre>\u8f93\u5165X\u7684\u5f62\u72b6\uff1a torch.Size([1, 60, 32])\nP\u7684\u5f62\u72b6\uff1a torch.Size([1, 60, 32])\n</pre> In\u00a0[88]: Copied! <pre>self = pos_encoding\nmax_len = 1000\nnum_hiddens = encoding_dim\nX = torch.arange(max_len, dtype=torch.float32).reshape(\n    -1, 1) / torch.pow(10000, torch.arange(\n    0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\nprint(X.shape, self.P.shape)\n</pre> self = pos_encoding max_len = 1000 num_hiddens = encoding_dim X = torch.arange(max_len, dtype=torch.float32).reshape(     -1, 1) / torch.pow(10000, torch.arange(     0, num_hiddens, 2, dtype=torch.float32) / num_hiddens) print(X.shape, self.P.shape) <pre>torch.Size([1000, 16]) torch.Size([1, 1000, 32])\n</pre> In\u00a0[90]: Copied! <pre># Heatmap of position encoding values\nP = P[0, :, :].unsqueeze(0).unsqueeze(0)\nmyutils.show_heatmaps(P, xlabel='Column (encoding dimension)',\n    ylabel='Row (position)', figsize=(3.5, 4), cmap='Blues')\n</pre> # Heatmap of position encoding values P = P[0, :, :].unsqueeze(0).unsqueeze(0) myutils.show_heatmaps(P, xlabel='Column (encoding dimension)',     ylabel='Row (position)', figsize=(3.5, 4), cmap='Blues') In\u00a0[96]: Copied! <pre># --------------------------\n# multi-head attention\n# --------------------------\n\ndef transpose_qkv(X, num_heads):\n    \"\"\"\u4e3a\u4e86\u591a\u6ce8\u610f\u2f12\u5934\u7684\u5e76\u2f8f\u8ba1\u7b97\u2f7d\u53d8\u6362\u5f62\u72b6\"\"\"\n    # \u8f93\u2f0aX\u7684\u5f62\u72b6:(batch_size\uff0c\u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570, num_hiddens)\n    # \u8f93\u51faX\u7684\u5f62\u72b6:(batch_size\uff0c\u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570, num_heads\uff0cnum_hiddens/num_heads)\n    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n    # \u8f93\u51faX\u7684\u5f62\u72b6:(batch_size\uff0cnum_heads, \u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570, num_hiddens/num_heads)\n    X = X.permute(0, 2, 1, 3)\n    # \u6700\u7ec8\u8f93\u51fa\u7684\u5f62\u72b6:(batch_size*num_heads, \u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570, num_hiddens/num_heads)\n    return X.reshape(-1, X.shape[2], X.shape[3])\n\ndef transpose_output(X, num_heads):\n    \"\"\"\u9006\u8f6ctranspose_qkv\u51fd\u6570\u7684\u64cd\u4f5c\"\"\"\n    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n    X = X.permute(0, 2, 1, 3)\n    return X.reshape(X.shape[0], X.shape[1], -1)\n\n\nclass MultiHeadAttention(nn.Module):\n    \"\"\"\u591a\u5934\u6ce8\u610f\u2f12\"\"\"\n    def __init__(self, key_size, query_size, value_size, num_hiddens,\n            num_heads, dropout, bias=False, **kwargs):\n        # query_size\u4ee3\u8868\u6bcf\u4e2aquery\u7684\u957f\u5ea6\uff0c\u5bf9\u5e94T * C\u4e2d\u7684C\n        # key_size\u548cvalue_size\u5206\u522b\u4ee3\u8868key\u548cvalue\u7684\u957f\u5ea6\n        super(MultiHeadAttention, self).__init__(**kwargs)\n        self.num_heads = num_heads\n        self.attention = myutils.DotProductAttention(dropout)\n        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)\n        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)\n        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)\n            \n    def forward(self, queries, keys, values, valid_lens):\n        # \u539f\u59cb\u7684queries\uff0ckeys\uff0cvalues\u7684\u5f62\u72b6:\n        # (batch_size, \u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570, query_size/key_size/value_size)\n        \n        # queries\uff0ckeys\uff0cvalues\u7ecf\u8fc7\u7ebf\u6027\u5c42W_q/W_k/W_v\u540e\u7684\u5f62\u72b6:\n        # (batch_size, \u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570, num_hiddens)\n        \n        # valid_lens \u7684\u5f62\u72b6:\n        # (batch_size\uff0c)\u6216(batch_size\uff0c\u67e5\u8be2\u7684\u4e2a\u6570)\n        # \u7ecf\u8fc7\u53d8\u6362\u540e\uff0c\u8f93\u51fa\u7684queries\uff0ckeys\uff0cvalues \u7684\u5f62\u72b6:\n        # (batch_size*num_heads\uff0c\u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570\uff0cnum_hiddens/num_heads)\n        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n        values = transpose_qkv(self.W_v(values), self.num_heads)\n        if valid_lens is not None:\n            # \u5728\u8f740\uff0c\u5c06\u7b2c\u2f00\u9879\uff08\u6807\u91cf\u6216\u8005\u2f6e\u91cf\uff09\u590d\u5236num_heads\u6b21\uff0c\n            # \u7136\u540e\u5982\u6b64\u590d\u5236\u7b2c\u2f06\u9879\uff0c\u7136\u540e\u8bf8\u5982\u6b64\u7c7b\u3002\n            valid_lens = torch.repeat_interleave(\n                valid_lens, repeats=self.num_heads, dim=0)\n        \n        # output\u7684\u5f62\u72b6:(batch_size*num_heads\uff0c\u67e5\u8be2\u7684\u4e2a\u6570\uff0cnum_hiddens/num_heads)\n        output = self.attention(queries, keys, values, valid_lens)\n        \n        # output_concat\u7684\u5f62\u72b6:(batch_size\uff0c\u67e5\u8be2\u7684\u4e2a\u6570\uff0cnum_hiddens)\n        output_concat = transpose_output(output, self.num_heads)\n        return self.W_o(output_concat)\n</pre> # -------------------------- # multi-head attention # --------------------------  def transpose_qkv(X, num_heads):     \"\"\"\u4e3a\u4e86\u591a\u6ce8\u610f\u2f12\u5934\u7684\u5e76\u2f8f\u8ba1\u7b97\u2f7d\u53d8\u6362\u5f62\u72b6\"\"\"     # \u8f93\u2f0aX\u7684\u5f62\u72b6:(batch_size\uff0c\u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570, num_hiddens)     # \u8f93\u51faX\u7684\u5f62\u72b6:(batch_size\uff0c\u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570, num_heads\uff0cnum_hiddens/num_heads)     X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)     # \u8f93\u51faX\u7684\u5f62\u72b6:(batch_size\uff0cnum_heads, \u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570, num_hiddens/num_heads)     X = X.permute(0, 2, 1, 3)     # \u6700\u7ec8\u8f93\u51fa\u7684\u5f62\u72b6:(batch_size*num_heads, \u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570, num_hiddens/num_heads)     return X.reshape(-1, X.shape[2], X.shape[3])  def transpose_output(X, num_heads):     \"\"\"\u9006\u8f6ctranspose_qkv\u51fd\u6570\u7684\u64cd\u4f5c\"\"\"     X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])     X = X.permute(0, 2, 1, 3)     return X.reshape(X.shape[0], X.shape[1], -1)   class MultiHeadAttention(nn.Module):     \"\"\"\u591a\u5934\u6ce8\u610f\u2f12\"\"\"     def __init__(self, key_size, query_size, value_size, num_hiddens,             num_heads, dropout, bias=False, **kwargs):         # query_size\u4ee3\u8868\u6bcf\u4e2aquery\u7684\u957f\u5ea6\uff0c\u5bf9\u5e94T * C\u4e2d\u7684C         # key_size\u548cvalue_size\u5206\u522b\u4ee3\u8868key\u548cvalue\u7684\u957f\u5ea6         super(MultiHeadAttention, self).__init__(**kwargs)         self.num_heads = num_heads         self.attention = myutils.DotProductAttention(dropout)         self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)         self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)         self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)         self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)                  def forward(self, queries, keys, values, valid_lens):         # \u539f\u59cb\u7684queries\uff0ckeys\uff0cvalues\u7684\u5f62\u72b6:         # (batch_size, \u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570, query_size/key_size/value_size)                  # queries\uff0ckeys\uff0cvalues\u7ecf\u8fc7\u7ebf\u6027\u5c42W_q/W_k/W_v\u540e\u7684\u5f62\u72b6:         # (batch_size, \u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570, num_hiddens)                  # valid_lens \u7684\u5f62\u72b6:         # (batch_size\uff0c)\u6216(batch_size\uff0c\u67e5\u8be2\u7684\u4e2a\u6570)         # \u7ecf\u8fc7\u53d8\u6362\u540e\uff0c\u8f93\u51fa\u7684queries\uff0ckeys\uff0cvalues \u7684\u5f62\u72b6:         # (batch_size*num_heads\uff0c\u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570\uff0cnum_hiddens/num_heads)         queries = transpose_qkv(self.W_q(queries), self.num_heads)         keys = transpose_qkv(self.W_k(keys), self.num_heads)         values = transpose_qkv(self.W_v(values), self.num_heads)         if valid_lens is not None:             # \u5728\u8f740\uff0c\u5c06\u7b2c\u2f00\u9879\uff08\u6807\u91cf\u6216\u8005\u2f6e\u91cf\uff09\u590d\u5236num_heads\u6b21\uff0c             # \u7136\u540e\u5982\u6b64\u590d\u5236\u7b2c\u2f06\u9879\uff0c\u7136\u540e\u8bf8\u5982\u6b64\u7c7b\u3002             valid_lens = torch.repeat_interleave(                 valid_lens, repeats=self.num_heads, dim=0)                  # output\u7684\u5f62\u72b6:(batch_size*num_heads\uff0c\u67e5\u8be2\u7684\u4e2a\u6570\uff0cnum_hiddens/num_heads)         output = self.attention(queries, keys, values, valid_lens)                  # output_concat\u7684\u5f62\u72b6:(batch_size\uff0c\u67e5\u8be2\u7684\u4e2a\u6570\uff0cnum_hiddens)         output_concat = transpose_output(output, self.num_heads)         return self.W_o(output_concat) In\u00a0[109]: Copied! <pre># Create and attention instance\nnum_hiddens, num_heads = 100, 5\nattention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens, num_hiddens, num_heads, 0.5)\nattention.eval()\n</pre> # Create and attention instance num_hiddens, num_heads = 100, 5 attention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens, num_hiddens, num_heads, 0.5) attention.eval() Out[109]: <pre>MultiHeadAttention(\n  (attention): DotProductAttention(\n    (dropout): Dropout(p=0.5, inplace=False)\n  )\n  (W_q): Linear(in_features=100, out_features=100, bias=False)\n  (W_k): Linear(in_features=100, out_features=100, bias=False)\n  (W_v): Linear(in_features=100, out_features=100, bias=False)\n  (W_o): Linear(in_features=100, out_features=100, bias=False)\n)</pre> In\u00a0[110]: Copied! <pre># Check the output size \nbatch_size, num_queries = 2, 4\nnum_kvpairs, valid_lens = 8, torch.tensor([3, 2])\nX = torch.ones((batch_size, num_queries, num_hiddens))\nY = torch.ones((batch_size, num_kvpairs, num_hiddens))\nattention(X, Y, Y, None).shape\n</pre> # Check the output size  batch_size, num_queries = 2, 4 num_kvpairs, valid_lens = 8, torch.tensor([3, 2]) X = torch.ones((batch_size, num_queries, num_hiddens)) Y = torch.ones((batch_size, num_kvpairs, num_hiddens)) attention(X, Y, Y, None).shape Out[110]: <pre>torch.Size([2, 4, 100])</pre> In\u00a0[112]: Copied! <pre>queries = X\nkeys = Y\nvalues = Y\nvalid_lens = None\nself = attention\n# \u539f\u59cb\u8f93\u5165\u7684\u5f62\u72b6\nprint(queries.shape, self.W_q(queries).shape)\nprint(keys.shape, self.W_k(keys).shape)\nprint(values.shape, self.W_v(values).shape)\n\nprint('-' * 100)\n\nqueries = transpose_qkv(self.W_q(queries), self.num_heads)\nkeys = transpose_qkv(self.W_k(keys), self.num_heads)\nvalues = transpose_qkv(self.W_v(values), self.num_heads)\nprint(queries.shape, keys.shape, values.shape)\nprint('-' * 100)\noutput = self.attention(queries, keys, values, valid_lens)\nprint(output.shape)\n</pre> queries = X keys = Y values = Y valid_lens = None self = attention # \u539f\u59cb\u8f93\u5165\u7684\u5f62\u72b6 print(queries.shape, self.W_q(queries).shape) print(keys.shape, self.W_k(keys).shape) print(values.shape, self.W_v(values).shape)  print('-' * 100)  queries = transpose_qkv(self.W_q(queries), self.num_heads) keys = transpose_qkv(self.W_k(keys), self.num_heads) values = transpose_qkv(self.W_v(values), self.num_heads) print(queries.shape, keys.shape, values.shape) print('-' * 100) output = self.attention(queries, keys, values, valid_lens) print(output.shape) <pre>torch.Size([2, 4, 100]) torch.Size([2, 4, 100])\ntorch.Size([2, 8, 100]) torch.Size([2, 8, 100])\ntorch.Size([2, 8, 100]) torch.Size([2, 8, 100])\n----------------------------------------------------------------------------------------------------\ntorch.Size([10, 4, 20]) torch.Size([10, 8, 20]) torch.Size([10, 8, 20])\n----------------------------------------------------------------------------------------------------\ntorch.Size([10, 4, 20])\n</pre> In\u00a0[134]: Copied! <pre># (batch_size\uff0c\u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570, num_hiddens)\n# batch_size = 2, \u67e5\u8be2\u4e2a\u6570 = 4\uff0cnum_hidden = 10\n# num_heads = 5\nX1 = torch.normal(0, 1, (2, 4, 10))\nprint(X1)\nprint('-' * 100)\nX2 = transpose_qkv(X1, num_heads)\n# (batch_size*num_heads\uff0c\u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570\uff0cnum_hiddens/num_heads)\nprint(X2.shape, X2)\nprint('-' * 100)\nX3 = transpose_output(X2, num_heads)\nprint(X3.shape, X3)\n</pre> # (batch_size\uff0c\u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570, num_hiddens) # batch_size = 2, \u67e5\u8be2\u4e2a\u6570 = 4\uff0cnum_hidden = 10 # num_heads = 5 X1 = torch.normal(0, 1, (2, 4, 10)) print(X1) print('-' * 100) X2 = transpose_qkv(X1, num_heads) # (batch_size*num_heads\uff0c\u67e5\u8be2\u6216\u8005\u201c\u952e\uff0d\u503c\u201d\u5bf9\u7684\u4e2a\u6570\uff0cnum_hiddens/num_heads) print(X2.shape, X2) print('-' * 100) X3 = transpose_output(X2, num_heads) print(X3.shape, X3) <pre>tensor([[[ 0.5539,  1.0705, -0.2467, -0.5468, -1.7312, -2.0616,  0.3531,\n          -0.4130,  1.0877, -0.5055],\n         [-0.5932, -1.7048, -1.2851,  2.2417,  0.1598,  1.7439,  0.2931,\n           0.5772, -0.9581,  0.0934],\n         [-2.5355,  0.7530,  0.1360,  1.8002,  0.1014,  1.0509,  0.1189,\n           0.1370,  2.0581,  0.5469],\n         [-0.9428, -0.5843,  0.3410,  0.3342, -0.4662,  0.3798,  0.4280,\n           0.1393,  0.8714,  0.8208]],\n\n        [[-0.5270,  1.1127, -0.8002,  0.2327,  0.0092,  2.0392,  0.1956,\n           0.4724,  0.5946,  0.7278],\n         [ 0.8295,  0.6407,  0.8582,  0.0355,  0.8866,  0.4612, -0.6274,\n          -0.7547, -2.3391, -0.6268],\n         [ 0.6303, -0.8556, -0.5170,  0.2306,  2.2069,  1.0255, -1.3400,\n          -1.7307,  1.8668, -0.6481],\n         [ 0.6687,  0.5716, -0.0222,  0.2900,  0.4844,  0.8148, -0.4691,\n           0.3035,  0.2025, -0.0987]]])\n----------------------------------------------------------------------------------------------------\ntorch.Size([10, 4, 2]) tensor([[[ 0.5539,  1.0705],\n         [-0.5932, -1.7048],\n         [-2.5355,  0.7530],\n         [-0.9428, -0.5843]],\n\n        [[-0.2467, -0.5468],\n         [-1.2851,  2.2417],\n         [ 0.1360,  1.8002],\n         [ 0.3410,  0.3342]],\n\n        [[-1.7312, -2.0616],\n         [ 0.1598,  1.7439],\n         [ 0.1014,  1.0509],\n         [-0.4662,  0.3798]],\n\n        [[ 0.3531, -0.4130],\n         [ 0.2931,  0.5772],\n         [ 0.1189,  0.1370],\n         [ 0.4280,  0.1393]],\n\n        [[ 1.0877, -0.5055],\n         [-0.9581,  0.0934],\n         [ 2.0581,  0.5469],\n         [ 0.8714,  0.8208]],\n\n        [[-0.5270,  1.1127],\n         [ 0.8295,  0.6407],\n         [ 0.6303, -0.8556],\n         [ 0.6687,  0.5716]],\n\n        [[-0.8002,  0.2327],\n         [ 0.8582,  0.0355],\n         [-0.5170,  0.2306],\n         [-0.0222,  0.2900]],\n\n        [[ 0.0092,  2.0392],\n         [ 0.8866,  0.4612],\n         [ 2.2069,  1.0255],\n         [ 0.4844,  0.8148]],\n\n        [[ 0.1956,  0.4724],\n         [-0.6274, -0.7547],\n         [-1.3400, -1.7307],\n         [-0.4691,  0.3035]],\n\n        [[ 0.5946,  0.7278],\n         [-2.3391, -0.6268],\n         [ 1.8668, -0.6481],\n         [ 0.2025, -0.0987]]])\n----------------------------------------------------------------------------------------------------\ntorch.Size([2, 4, 10]) tensor([[[ 0.5539,  1.0705, -0.2467, -0.5468, -1.7312, -2.0616,  0.3531,\n          -0.4130,  1.0877, -0.5055],\n         [-0.5932, -1.7048, -1.2851,  2.2417,  0.1598,  1.7439,  0.2931,\n           0.5772, -0.9581,  0.0934],\n         [-2.5355,  0.7530,  0.1360,  1.8002,  0.1014,  1.0509,  0.1189,\n           0.1370,  2.0581,  0.5469],\n         [-0.9428, -0.5843,  0.3410,  0.3342, -0.4662,  0.3798,  0.4280,\n           0.1393,  0.8714,  0.8208]],\n\n        [[-0.5270,  1.1127, -0.8002,  0.2327,  0.0092,  2.0392,  0.1956,\n           0.4724,  0.5946,  0.7278],\n         [ 0.8295,  0.6407,  0.8582,  0.0355,  0.8866,  0.4612, -0.6274,\n          -0.7547, -2.3391, -0.6268],\n         [ 0.6303, -0.8556, -0.5170,  0.2306,  2.2069,  1.0255, -1.3400,\n          -1.7307,  1.8668, -0.6481],\n         [ 0.6687,  0.5716, -0.0222,  0.2900,  0.4844,  0.8148, -0.4691,\n           0.3035,  0.2025, -0.0987]]])\n</pre> In\u00a0[141]: Copied! <pre># X2\u7684\u6bcf\u4e2a\u7b2c\u4e00\u7ef4\u5ea6\u5bf9\u5e94\u77e9\u9635\uff0c\u90fd\u662f\u67e5\u8be2\u4e2a\u6570 * (\u67e5\u8be2\u957f\u5ea6 / num_head)\u5f62\u72b6\u7684\uff0c\u4ee3\u8868\u4e86\u672c\u8eabX1\u9700\u8981\u5e76\u884c\u7684\u90e8\u5206\n# \u5bf9\u4e8e\u7b2c\u4e00\u4e2abatch\u7ef4\u5ea6\uff0c\u672c\u8eabDotProductAttention\u7684\u8ba1\u7b97\u5c31\u662f\u5bf9\u7b2c\u4e00\u4e2abatch\u7ef4\u5ea6\u5e76\u884c\u7684\uff08\u56e0\u4e3atorch.bmm\u64cd\u4f5c\uff09\uff0c\n# \u6240\u4ee5\u5c06\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6C\u63d0\u524d\u5230\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u5b9e\u73b0\u5e76\u884c\u3002\nX2[0, :, :]\n</pre> # X2\u7684\u6bcf\u4e2a\u7b2c\u4e00\u7ef4\u5ea6\u5bf9\u5e94\u77e9\u9635\uff0c\u90fd\u662f\u67e5\u8be2\u4e2a\u6570 * (\u67e5\u8be2\u957f\u5ea6 / num_head)\u5f62\u72b6\u7684\uff0c\u4ee3\u8868\u4e86\u672c\u8eabX1\u9700\u8981\u5e76\u884c\u7684\u90e8\u5206 # \u5bf9\u4e8e\u7b2c\u4e00\u4e2abatch\u7ef4\u5ea6\uff0c\u672c\u8eabDotProductAttention\u7684\u8ba1\u7b97\u5c31\u662f\u5bf9\u7b2c\u4e00\u4e2abatch\u7ef4\u5ea6\u5e76\u884c\u7684\uff08\u56e0\u4e3atorch.bmm\u64cd\u4f5c\uff09\uff0c # \u6240\u4ee5\u5c06\u6700\u540e\u4e00\u4e2a\u7ef4\u5ea6C\u63d0\u524d\u5230\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\uff0c\u6211\u4eec\u5c31\u53ef\u4ee5\u5b9e\u73b0\u5e76\u884c\u3002 X2[0, :, :] Out[141]: <pre>tensor([[ 0.5539,  1.0705],\n        [-0.5932, -1.7048],\n        [-2.5355,  0.7530],\n        [-0.9428, -0.5843]])</pre> In\u00a0[143]: Copied! <pre>X1[:, :, :2]\n</pre> X1[:, :, :2] Out[143]: <pre>tensor([[[ 0.5539,  1.0705],\n         [-0.5932, -1.7048],\n         [-2.5355,  0.7530],\n         [-0.9428, -0.5843]],\n\n        [[-0.5270,  1.1127],\n         [ 0.8295,  0.6407],\n         [ 0.6303, -0.8556],\n         [ 0.6687,  0.5716]]])</pre> In\u00a0[142]: Copied! <pre>X2\n</pre> X2 Out[142]: <pre>tensor([[[ 0.5539,  1.0705],\n         [-0.5932, -1.7048],\n         [-2.5355,  0.7530],\n         [-0.9428, -0.5843]],\n\n        [[-0.2467, -0.5468],\n         [-1.2851,  2.2417],\n         [ 0.1360,  1.8002],\n         [ 0.3410,  0.3342]],\n\n        [[-1.7312, -2.0616],\n         [ 0.1598,  1.7439],\n         [ 0.1014,  1.0509],\n         [-0.4662,  0.3798]],\n\n        [[ 0.3531, -0.4130],\n         [ 0.2931,  0.5772],\n         [ 0.1189,  0.1370],\n         [ 0.4280,  0.1393]],\n\n        [[ 1.0877, -0.5055],\n         [-0.9581,  0.0934],\n         [ 2.0581,  0.5469],\n         [ 0.8714,  0.8208]],\n\n        [[-0.5270,  1.1127],\n         [ 0.8295,  0.6407],\n         [ 0.6303, -0.8556],\n         [ 0.6687,  0.5716]],\n\n        [[-0.8002,  0.2327],\n         [ 0.8582,  0.0355],\n         [-0.5170,  0.2306],\n         [-0.0222,  0.2900]],\n\n        [[ 0.0092,  2.0392],\n         [ 0.8866,  0.4612],\n         [ 2.2069,  1.0255],\n         [ 0.4844,  0.8148]],\n\n        [[ 0.1956,  0.4724],\n         [-0.6274, -0.7547],\n         [-1.3400, -1.7307],\n         [-0.4691,  0.3035]],\n\n        [[ 0.5946,  0.7278],\n         [-2.3391, -0.6268],\n         [ 1.8668, -0.6481],\n         [ 0.2025, -0.0987]]])</pre> In\u00a0[135]: Copied! <pre>X2[:, :, 0]\n</pre> X2[:, :, 0] Out[135]: <pre>tensor([[ 0.5539, -0.5932, -2.5355, -0.9428],\n        [-0.2467, -1.2851,  0.1360,  0.3410],\n        [-1.7312,  0.1598,  0.1014, -0.4662],\n        [ 0.3531,  0.2931,  0.1189,  0.4280],\n        [ 1.0877, -0.9581,  2.0581,  0.8714],\n        [-0.5270,  0.8295,  0.6303,  0.6687],\n        [-0.8002,  0.8582, -0.5170, -0.0222],\n        [ 0.0092,  0.8866,  2.2069,  0.4844],\n        [ 0.1956, -0.6274, -1.3400, -0.4691],\n        [ 0.5946, -2.3391,  1.8668,  0.2025]])</pre> In\u00a0[21]: Copied! <pre># Position-Wise Feed Forward Network Layer\nclass PositionWiseFFN(nn.Module):\n    \"\"\"\u57fa\u4e8e\u4f4d\u7f6e\u7684\u524d\u9988\u2f79\u7edc\"\"\"\n    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs, **kwargs):\n        super(PositionWiseFFN, self).__init__(**kwargs)\n        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)\n        self.relu = nn.ReLU()\n        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)\n\n    def forward(self, X):\n        return self.dense2(self.relu(self.dense1(X)))\n</pre> # Position-Wise Feed Forward Network Layer class PositionWiseFFN(nn.Module):     \"\"\"\u57fa\u4e8e\u4f4d\u7f6e\u7684\u524d\u9988\u2f79\u7edc\"\"\"     def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs, **kwargs):         super(PositionWiseFFN, self).__init__(**kwargs)         self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)         self.relu = nn.ReLU()         self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)      def forward(self, X):         return self.dense2(self.relu(self.dense1(X))) In\u00a0[22]: Copied! <pre># Put attention, PositionWiseFFN, and addnorm together\n\nclass EncoderBlock(nn.Module):\n    \"\"\"Transformer\u7f16\u7801\u5668\u5757\"\"\"\n    def __init__(self, key_size, query_size, value_size, num_hiddens,\n            norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n            dropout, use_bias=False, **kwargs):\n        super(EncoderBlock, self).__init__(**kwargs)\n        self.attention = MultiHeadAttention(\n            key_size, query_size, value_size, num_hiddens, num_heads, dropout,\n            use_bias)\n        self.addnorm1 = myutils.AddNorm(norm_shape, dropout)\n        self.ffn = PositionWiseFFN(\n            ffn_num_input, ffn_num_hiddens, num_hiddens)\n        self.addnorm2 = myutils.AddNorm(norm_shape, dropout)\n\n    def forward(self, X, valid_lens):\n        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))  # mode 1\n        return self.addnorm2(Y, self.ffn(Y))\n</pre> # Put attention, PositionWiseFFN, and addnorm together  class EncoderBlock(nn.Module):     \"\"\"Transformer\u7f16\u7801\u5668\u5757\"\"\"     def __init__(self, key_size, query_size, value_size, num_hiddens,             norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,             dropout, use_bias=False, **kwargs):         super(EncoderBlock, self).__init__(**kwargs)         self.attention = MultiHeadAttention(             key_size, query_size, value_size, num_hiddens, num_heads, dropout,             use_bias)         self.addnorm1 = myutils.AddNorm(norm_shape, dropout)         self.ffn = PositionWiseFFN(             ffn_num_input, ffn_num_hiddens, num_hiddens)         self.addnorm2 = myutils.AddNorm(norm_shape, dropout)      def forward(self, X, valid_lens):         Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))  # mode 1         return self.addnorm2(Y, self.ffn(Y)) In\u00a0[23]: Copied! <pre># \u67e5\u770bencoder-block\u7684\u8f93\u51fa\u5f62\u72b6\nX = torch.ones((2, 100, 24))\nvalid_lens = torch.tensor([3, 2])\nencoder_blk = EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5)\nencoder_blk.eval()\nencoder_blk(X, valid_lens).shape\n</pre> # \u67e5\u770bencoder-block\u7684\u8f93\u51fa\u5f62\u72b6 X = torch.ones((2, 100, 24)) valid_lens = torch.tensor([3, 2]) encoder_blk = EncoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5) encoder_blk.eval() encoder_blk(X, valid_lens).shape Out[23]: <pre>torch.Size([2, 100, 24])</pre> In\u00a0[24]: Copied! <pre># Concatenate Encoder Block Together\n\nclass TransformerEncoder(myutils.Encoder):\n    \"\"\"Transformer\u7f16\u7801\u5668\"\"\"\n    def __init__(self, vocab_size, key_size, query_size, value_size,\n            num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n            num_heads, num_layers, dropout, use_bias=False, **kwargs):\n        super(TransformerEncoder, self).__init__(**kwargs)\n        self.num_hiddens = num_hiddens\n        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n        self.pos_encoding = myutils.PositionalEncoding(num_hiddens, dropout)\n        self.blks = nn.Sequential()\n        for i in range(num_layers):\n            self.blks.add_module(\"block\"+str(i),\n                EncoderBlock(key_size, query_size, value_size, num_hiddens,\n                    norm_shape, ffn_num_input, ffn_num_hiddens,\n                    num_heads, dropout, use_bias))\n\n    \n    def forward(self, X, valid_lens, *args):\n        # \u56e0\u4e3a\u4f4d\u7f6e\u7f16\u7801\u503c\u5728-1\u548c1\u4e4b\u95f4\uff0c\n        # \u56e0\u6b64\u5d4c\u2f0a\u503c\u4e58\u4ee5\u5d4c\u2f0a\u7ef4\u5ea6\u7684\u5e73\u2f45\u6839\u8fdb\u2f8f\u7f29\u653e\uff0c\n        # \u7136\u540e\u518d\u4e0e\u4f4d\u7f6e\u7f16\u7801\u76f8\u52a0\u3002\n        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n        self.attention_weights = [None] * len(self.blks)\n        for i, blk in enumerate(self.blks):\n            X = blk(X, valid_lens) \n            self.attention_weights[i] = blk.attention.attention.attention_weights\n        return X\n</pre> # Concatenate Encoder Block Together  class TransformerEncoder(myutils.Encoder):     \"\"\"Transformer\u7f16\u7801\u5668\"\"\"     def __init__(self, vocab_size, key_size, query_size, value_size,             num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,             num_heads, num_layers, dropout, use_bias=False, **kwargs):         super(TransformerEncoder, self).__init__(**kwargs)         self.num_hiddens = num_hiddens         self.embedding = nn.Embedding(vocab_size, num_hiddens)         self.pos_encoding = myutils.PositionalEncoding(num_hiddens, dropout)         self.blks = nn.Sequential()         for i in range(num_layers):             self.blks.add_module(\"block\"+str(i),                 EncoderBlock(key_size, query_size, value_size, num_hiddens,                     norm_shape, ffn_num_input, ffn_num_hiddens,                     num_heads, dropout, use_bias))           def forward(self, X, valid_lens, *args):         # \u56e0\u4e3a\u4f4d\u7f6e\u7f16\u7801\u503c\u5728-1\u548c1\u4e4b\u95f4\uff0c         # \u56e0\u6b64\u5d4c\u2f0a\u503c\u4e58\u4ee5\u5d4c\u2f0a\u7ef4\u5ea6\u7684\u5e73\u2f45\u6839\u8fdb\u2f8f\u7f29\u653e\uff0c         # \u7136\u540e\u518d\u4e0e\u4f4d\u7f6e\u7f16\u7801\u76f8\u52a0\u3002         X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))         self.attention_weights = [None] * len(self.blks)         for i, blk in enumerate(self.blks):             X = blk(X, valid_lens)              self.attention_weights[i] = blk.attention.attention.attention_weights         return X In\u00a0[25]: Copied! <pre># \u67e5\u770b\u7f16\u7801\u5668\u7684\u8f93\u51fa\u5f62\u72b6\nencoder = TransformerEncoder(\n        200, 24, 24, 24, 24, [15, 24], 24, 48, 8, 2, 0.5)\nencoder.eval()\nencoder(torch.ones((2, 15), dtype=torch.long), valid_lens).shape\n</pre> # \u67e5\u770b\u7f16\u7801\u5668\u7684\u8f93\u51fa\u5f62\u72b6 encoder = TransformerEncoder(         200, 24, 24, 24, 24, [15, 24], 24, 48, 8, 2, 0.5) encoder.eval() encoder(torch.ones((2, 15), dtype=torch.long), valid_lens).shape Out[25]: <pre>torch.Size([2, 15, 24])</pre> In\u00a0[26]: Copied! <pre># Construct the decoder block\n# two attentions and position wise FFN, together with addnorm layers\nclass DecoderBlock(nn.Module):\n    \"\"\"\u89e3\u7801\u5668\u4e2d\u7b2ci\u4e2a\u5757\"\"\"\n    def __init__(self, key_size, query_size, value_size, num_hiddens,\n            norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n            dropout, i, **kwargs):\n        super(DecoderBlock, self).__init__(**kwargs)\n        self.i = i\n        self.attention1 = MultiHeadAttention(\n            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n        self.addnorm1 = myutils.AddNorm(norm_shape, dropout)\n        self.attention2 = MultiHeadAttention(\n            key_size, query_size, value_size, num_hiddens, num_heads, dropout)\n        self.addnorm2 = myutils.AddNorm(norm_shape, dropout)\n        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)\n        self.addnorm3 = myutils.AddNorm(norm_shape, dropout)\n\n    def forward(self, X, state):\n        enc_outputs, enc_valid_lens = state[0], state[1]\n        # \u8bad\u7ec3\u9636\u6bb5\uff0c\u8f93\u51fa\u5e8f\u5217\u7684\u6240\u6709\u8bcd\u5143\u90fd\u5728\u540c\u2f00\u65f6\u95f4\u5904\u7406\uff0c\n        # \u56e0\u6b64state[2][self.i]\u521d\u59cb\u5316\u4e3aNone\u3002\n        # \u9884\u6d4b\u9636\u6bb5\uff0c\u8f93\u51fa\u5e8f\u5217\u662f\u901a\u8fc7\u8bcd\u5143\u2f00\u4e2a\u63a5\u7740\u2f00\u4e2a\u89e3\u7801\u7684\uff0c\n        # \u56e0\u6b64state[2][self.i]\u5305\u542b\u7740\u76f4\u5230\u5f53\u524d\u65f6\u95f4\u6b65\u7b2ci\u4e2a\u5757\u89e3\u7801\u7684\u8f93\u51fa\u8868\u2f70\n        if state[2][self.i] is None:\n            key_values = X    # mode 2\n        else:\n            key_values = torch.cat((state[2][self.i], X), axis=1)   # mode 3\n        state[2][self.i] = key_values\n        \n        if self.training:\n            batch_size, num_steps, _ = X.shape\n            # dec_valid_lens\u7684\u5f00\u5934:(batch_size,num_steps),\n            # \u5176\u4e2d\u6bcf\u2f00\u2f8f\u662f[1,2,...,num_steps]\n            dec_valid_lens = torch.arange(1, num_steps + 1, device=X.device).repeat(batch_size, 1)  # mode 2\n        else:\n            dec_valid_lens = None   # mode 3\n        \n        \n        # \u2f83\u6ce8\u610f\u2f12\n        # print(key_values.shape)\n        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)\n        # print(X2.shape)\n        Y = self.addnorm1(X, X2)\n        # \u7f16\u7801\u5668\uff0d\u89e3\u7801\u5668\u6ce8\u610f\u2f12\u3002\n        # enc_outputs\u7684\u5f00\u5934:(batch_size,num_steps,num_hiddens)\n        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)\n        Z = self.addnorm2(Y, Y2)\n        return self.addnorm3(Z, self.ffn(Z)), state\n</pre> # Construct the decoder block # two attentions and position wise FFN, together with addnorm layers class DecoderBlock(nn.Module):     \"\"\"\u89e3\u7801\u5668\u4e2d\u7b2ci\u4e2a\u5757\"\"\"     def __init__(self, key_size, query_size, value_size, num_hiddens,             norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,             dropout, i, **kwargs):         super(DecoderBlock, self).__init__(**kwargs)         self.i = i         self.attention1 = MultiHeadAttention(             key_size, query_size, value_size, num_hiddens, num_heads, dropout)         self.addnorm1 = myutils.AddNorm(norm_shape, dropout)         self.attention2 = MultiHeadAttention(             key_size, query_size, value_size, num_hiddens, num_heads, dropout)         self.addnorm2 = myutils.AddNorm(norm_shape, dropout)         self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)         self.addnorm3 = myutils.AddNorm(norm_shape, dropout)      def forward(self, X, state):         enc_outputs, enc_valid_lens = state[0], state[1]         # \u8bad\u7ec3\u9636\u6bb5\uff0c\u8f93\u51fa\u5e8f\u5217\u7684\u6240\u6709\u8bcd\u5143\u90fd\u5728\u540c\u2f00\u65f6\u95f4\u5904\u7406\uff0c         # \u56e0\u6b64state[2][self.i]\u521d\u59cb\u5316\u4e3aNone\u3002         # \u9884\u6d4b\u9636\u6bb5\uff0c\u8f93\u51fa\u5e8f\u5217\u662f\u901a\u8fc7\u8bcd\u5143\u2f00\u4e2a\u63a5\u7740\u2f00\u4e2a\u89e3\u7801\u7684\uff0c         # \u56e0\u6b64state[2][self.i]\u5305\u542b\u7740\u76f4\u5230\u5f53\u524d\u65f6\u95f4\u6b65\u7b2ci\u4e2a\u5757\u89e3\u7801\u7684\u8f93\u51fa\u8868\u2f70         if state[2][self.i] is None:             key_values = X    # mode 2         else:             key_values = torch.cat((state[2][self.i], X), axis=1)   # mode 3         state[2][self.i] = key_values                  if self.training:             batch_size, num_steps, _ = X.shape             # dec_valid_lens\u7684\u5f00\u5934:(batch_size,num_steps),             # \u5176\u4e2d\u6bcf\u2f00\u2f8f\u662f[1,2,...,num_steps]             dec_valid_lens = torch.arange(1, num_steps + 1, device=X.device).repeat(batch_size, 1)  # mode 2         else:             dec_valid_lens = None   # mode 3                           # \u2f83\u6ce8\u610f\u2f12         # print(key_values.shape)         X2 = self.attention1(X, key_values, key_values, dec_valid_lens)         # print(X2.shape)         Y = self.addnorm1(X, X2)         # \u7f16\u7801\u5668\uff0d\u89e3\u7801\u5668\u6ce8\u610f\u2f12\u3002         # enc_outputs\u7684\u5f00\u5934:(batch_size,num_steps,num_hiddens)         Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)         Z = self.addnorm2(Y, Y2)         return self.addnorm3(Z, self.ffn(Z)), state In\u00a0[27]: Copied! <pre># \u67e5\u770bdecoder-block\u7684\u8f93\u51fa\u5f62\u72b6\ndecoder_blk = DecoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5, 0)\ndecoder_blk.eval()\nX = torch.ones((2, 100, 24))\nstate = [encoder_blk(X, valid_lens), valid_lens, [None]]\ndecoder_blk(X, state)[1][0].shape\n</pre> # \u67e5\u770bdecoder-block\u7684\u8f93\u51fa\u5f62\u72b6 decoder_blk = DecoderBlock(24, 24, 24, 24, [100, 24], 24, 48, 8, 0.5, 0) decoder_blk.eval() X = torch.ones((2, 100, 24)) state = [encoder_blk(X, valid_lens), valid_lens, [None]] decoder_blk(X, state)[1][0].shape Out[27]: <pre>torch.Size([2, 100, 24])</pre> In\u00a0[28]: Copied! <pre># Concatenate Decoder Block Together\n\nclass TransformerDecoder(myutils.AttentionDecoder):\n    def __init__(self, vocab_size, key_size, query_size, value_size,\n            num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,\n            num_heads, num_layers, dropout, **kwargs):\n        super(TransformerDecoder, self).__init__(**kwargs)\n        self.num_hiddens = num_hiddens\n        self.num_layers = num_layers\n        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n        self.pos_encoding = myutils.PositionalEncoding(num_hiddens, dropout)\n        self.blks = nn.Sequential()\n        for i in range(num_layers):\n            self.blks.add_module(\"block\"+str(i),\n                DecoderBlock(key_size, query_size, value_size, num_hiddens,\n                    norm_shape, ffn_num_input, ffn_num_hiddens,\n                    num_heads, dropout, i))\n        self.dense = nn.Linear(num_hiddens, vocab_size)\n        \n    def init_state(self, enc_outputs, enc_valid_lens, *args):\n        return [enc_outputs, enc_valid_lens, [None] * self.num_layers]\n    \n    def forward(self, X, state):\n        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]\n        for i, blk in enumerate(self.blks):\n            X, state = blk(X, state)\n            # \u89e3\u7801\u5668\u2f83\u6ce8\u610f\u2f12\u6743\u91cd\n            self._attention_weights[0][i] = blk.attention1.attention.attention_weights\n            # \u201c\u7f16\u7801\u5668\uff0d\u89e3\u7801\u5668\u201d\u2f83\u6ce8\u610f\u2f12\u6743\u91cd\n            self._attention_weights[1][i] = blk.attention2.attention.attention_weights\n        return self.dense(X), state\n    \n    @property\n    def attention_weights(self):\n        return self._attention_weights\n</pre> # Concatenate Decoder Block Together  class TransformerDecoder(myutils.AttentionDecoder):     def __init__(self, vocab_size, key_size, query_size, value_size,             num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,             num_heads, num_layers, dropout, **kwargs):         super(TransformerDecoder, self).__init__(**kwargs)         self.num_hiddens = num_hiddens         self.num_layers = num_layers         self.embedding = nn.Embedding(vocab_size, num_hiddens)         self.pos_encoding = myutils.PositionalEncoding(num_hiddens, dropout)         self.blks = nn.Sequential()         for i in range(num_layers):             self.blks.add_module(\"block\"+str(i),                 DecoderBlock(key_size, query_size, value_size, num_hiddens,                     norm_shape, ffn_num_input, ffn_num_hiddens,                     num_heads, dropout, i))         self.dense = nn.Linear(num_hiddens, vocab_size)              def init_state(self, enc_outputs, enc_valid_lens, *args):         return [enc_outputs, enc_valid_lens, [None] * self.num_layers]          def forward(self, X, state):         X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))         self._attention_weights = [[None] * len(self.blks) for _ in range (2)]         for i, blk in enumerate(self.blks):             X, state = blk(X, state)             # \u89e3\u7801\u5668\u2f83\u6ce8\u610f\u2f12\u6743\u91cd             self._attention_weights[0][i] = blk.attention1.attention.attention_weights             # \u201c\u7f16\u7801\u5668\uff0d\u89e3\u7801\u5668\u201d\u2f83\u6ce8\u610f\u2f12\u6743\u91cd             self._attention_weights[1][i] = blk.attention2.attention.attention_weights         return self.dense(X), state          @property     def attention_weights(self):         return self._attention_weights In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[29]: Copied! <pre># Do Translation Task\n# Set up of Tuning Parameter\nnum_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10\nlr, num_epochs, device = 0.005, 200, None\nffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4\nkey_size, query_size, value_size = 32, 32, 32\nnorm_shape = [32]\n</pre> # Do Translation Task # Set up of Tuning Parameter num_hiddens, num_layers, dropout, batch_size, num_steps = 32, 2, 0.1, 64, 10 lr, num_epochs, device = 0.005, 200, None ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4 key_size, query_size, value_size = 32, 32, 32 norm_shape = [32] In\u00a0[30]: Copied! <pre># \u8bfb\u53d6\u7ffb\u8bd1\u4efb\u52a1\u6570\u636e\ntrain_iter, src_vocab, tgt_vocab = myutils.load_data_nmt(batch_size, num_steps)\n</pre> # \u8bfb\u53d6\u7ffb\u8bd1\u4efb\u52a1\u6570\u636e train_iter, src_vocab, tgt_vocab = myutils.load_data_nmt(batch_size, num_steps) In\u00a0[31]: Copied! <pre># \u6cd5\u8bed\u7684\u8bcd\u6c47\u8868\ntgt_vocab.idx_to_token[:10]\n</pre> # \u6cd5\u8bed\u7684\u8bcd\u6c47\u8868 tgt_vocab.idx_to_token[:10] Out[31]: <pre>['&lt;unk&gt;', '&lt;pad&gt;', '&lt;bos&gt;', '&lt;eos&gt;', '.', '!', 'je', 'suis', 'tom', '?']</pre> In\u00a0[32]: Copied! <pre># \u82f1\u6587\u7684\u8bcd\u6c47\u8868\nsrc_vocab.idx_to_token[:10]\n</pre> # \u82f1\u6587\u7684\u8bcd\u6c47\u8868 src_vocab.idx_to_token[:10] Out[32]: <pre>['&lt;unk&gt;', '&lt;pad&gt;', '&lt;bos&gt;', '&lt;eos&gt;', '.', '!', 'i', \"i'm\", 'it', 'go']</pre> In\u00a0[33]: Copied! <pre># \u67e5\u770b\u4e00\u4e2abatch\u7684\u8bad\u7ec3\u6837\u672c\u7684\u5177\u4f53\u5185\u5bb9\u548c\u5f62\u72b6\nfor batch in train_iter:\n    print(batch)\n    break\n</pre> # \u67e5\u770b\u4e00\u4e2abatch\u7684\u8bad\u7ec3\u6837\u672c\u7684\u5177\u4f53\u5185\u5bb9\u548c\u5f62\u72b6 for batch in train_iter:     print(batch)     break <pre>[tensor([[118,  55,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 39,  19,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 86,   8,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  7,  56,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 63,  21,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  7, 155,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  7,   0,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 39,  91,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  0,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [113,   4,   3,   1,   1,   1,   1,   1,   1,   1],\n        [ 16,  21,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 66,  15,   5,   3,   1,   1,   1,   1,   1,   1],\n        [ 16,  60,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  6,  18,  64,   4,   3,   1,   1,   1,   1,   1],\n        [  6, 146,   8,   4,   3,   1,   1,   1,   1,   1],\n        [130,  23,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 17,  20,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 62,  38,   5,   3,   1,   1,   1,   1,   1,   1],\n        [ 53,   8,   5,   3,   1,   1,   1,   1,   1,   1],\n        [  0,  12,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 52, 176,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  6, 146,   8,   4,   3,   1,   1,   1,   1,   1],\n        [ 79,  34,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  6,  73,   4,   3,   1,   1,   1,   1,   1,   1],\n        [106, 122,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 78,   9,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 88,  23,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 47,  48,   5,   3,   1,   1,   1,   1,   1,   1],\n        [ 54,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [ 30,  38,   5,   3,   1,   1,   1,   1,   1,   1],\n        [ 10, 120,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  6, 147,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 17,  22,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 31,   0,   4,   3,   1,   1,   1,   1,   1,   1],\n        [164,  12,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 14,  33,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 29,  20,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 49,   6, 110,  11,   3,   1,   1,   1,   1,   1],\n        [  7, 150,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 14,  43,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  6, 124,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  9,  28,   4,   3,   1,   1,   1,   1,   1,   1],\n        [140,  10,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  6, 126,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 61,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [ 66,  15,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  6,   0,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 10,   0,   4,   3,   1,   1,   1,   1,   1,   1],\n        [136,  15,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  9,  28,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  0,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [165,  10,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 26,  32,   5,   3,   1,   1,   1,   1,   1,   1],\n        [ 90,  19,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  0,   4,   3,   1,   1,   1,   1,   1,   1,   1],\n        [  6,  97,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 41,  85,  11,   3,   1,   1,   1,   1,   1,   1],\n        [ 30,  38,   4,   3,   1,   1,   1,   1,   1,   1],\n        [113, 131,   0,   4,   3,   1,   1,   1,   1,   1],\n        [  0,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [  6, 143,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  8, 159,   4,   3,   1,   1,   1,   1,   1,   1],\n        [158,  22,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 76,   8,   5,   3,   1,   1,   1,   1,   1,   1]]), tensor([4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 4, 5, 5, 4, 4, 4, 4, 4, 4, 5, 4, 4,\n        4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4,\n        4, 4, 3, 4, 4, 4, 3, 4, 4, 4, 5, 3, 4, 4, 4, 4]), tensor([[  0,   4,   3,   1,   1,   1,   1,   1,   1,   1],\n        [ 91,  12,   5,   3,   1,   1,   1,   1,   1,   1],\n        [  0,   4,   3,   1,   1,   1,   1,   1,   1,   1],\n        [  6,   7,  37,  44,   4,   3,   1,   1,   1,   1],\n        [  0,  15, 152,   5,   3,   1,   1,   1,   1,   1],\n        [  6,   7,   0,   4,   3,   1,   1,   1,   1,   1],\n        [  6,   7,   0,   4,   3,   1,   1,   1,   1,   1],\n        [ 92,  12,   5,   3,   1,   1,   1,   1,   1,   1],\n        [  0,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [ 65,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [ 49,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [142,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [ 41,  53,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  6,   7, 135,   4,   3,   1,   1,   1,   1,   1],\n        [  6,  46, 157,   4,   3,   1,   1,   1,   1,   1],\n        [139,   4,   3,   1,   1,   1,   1,   1,   1,   1],\n        [ 11,  39,  62, 143,   4,   3,   1,   1,   1,   1],\n        [  0,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [  0,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [  0,   4,   3,   1,   1,   1,   1,   1,   1,   1],\n        [ 30,   0,  22,   5,   3,   1,   1,   1,   1,   1],\n        [  6,   0, 157,   4,   3,   1,   1,   1,   1,   1],\n        [  0,  22,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  6,   7, 108,   4,   3,   1,   1,   1,   1,   1],\n        [ 63, 130,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  0,   4,   3,   1,   1,   1,   1,   1,   1,   1],\n        [  0,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [  0,   0,   5,   3,   1,   1,   1,   1,   1,   1],\n        [ 93,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [149,   4,   3,   1,   1,   1,   1,   1,   1,   1],\n        [  8,  43, 109,   4,   3,   1,   1,   1,   1,   1],\n        [  6,   7,   0,   4,   3,   1,   1,   1,   1,   1],\n        [ 11,   0,  47,   4,   3,   1,   1,   1,   1,   1],\n        [ 77,  23,   0,   4,   3,   1,   1,   1,   1,   1],\n        [  0,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [ 20, 117,   5,   3,   1,   1,   1,   1,   1,   1],\n        [ 42,   0,  48,   4,   3,   1,   1,   1,   1,   1],\n        [  0,  47,   9,   3,   1,   1,   1,   1,   1,   1],\n        [  6,   7,   0,   5,   3,   1,   1,   1,   1,   1],\n        [ 20, 115,   5,   3,   1,   1,   1,   1,   1,   1],\n        [  6,  27,   7,   0,   4,   3,   1,   1,   1,   1],\n        [ 73,   0,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 81,   8,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 21,   0,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 12,   0,   5,   3,   1,   1,   1,   1,   1,   1],\n        [142,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [ 21,   0,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  8,   0,   4,   3,   1,   1,   1,   1,   1,   1],\n        [  0,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [  0,  36,   0,   5,   3,   1,   1,   1,   1,   1],\n        [114,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [  0,   8,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 19,   0,   0,   4,   3,   1,   1,   1,   1,   1],\n        [  0,  12,   5,   3,   1,   1,   1,   1,   1,   1],\n        [ 99,   5,   3,   1,   1,   1,   1,   1,   1,   1],\n        [ 10,   0,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 24,  14, 180,   9,   3,   1,   1,   1,   1,   1],\n        [  0,   4,   3,   1,   1,   1,   1,   1,   1,   1],\n        [ 65, 100,  83,   0,   5,   3,   1,   1,   1,   1],\n        [ 15,  29,   0,   4,   3,   1,   1,   1,   1,   1],\n        [  6,   0,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 12,   0,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 10,  25,   4,   3,   1,   1,   1,   1,   1,   1],\n        [ 71,  28,   5,   3,   1,   1,   1,   1,   1,   1]]), tensor([3, 4, 3, 6, 5, 5, 5, 4, 3, 3, 3, 3, 4, 5, 5, 3, 6, 3, 3, 3, 5, 5, 4, 5,\n        4, 3, 3, 4, 3, 3, 5, 5, 5, 5, 3, 4, 5, 4, 5, 4, 6, 4, 4, 4, 4, 3, 4, 4,\n        3, 5, 3, 4, 5, 4, 3, 4, 5, 3, 6, 5, 4, 4, 4, 4])]\n</pre> In\u00a0[34]: Copied! <pre># \u8c03\u7528 TransformerEncoder\uff0cTransformerDecoder\nencoder = TransformerEncoder(\n    len(src_vocab), key_size, query_size, value_size, num_hiddens,\n    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n    num_layers, dropout)\n\ndecoder = TransformerDecoder(\n    len(tgt_vocab), key_size, query_size, value_size, num_hiddens,\n    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n    num_layers, dropout)\n\nnet = myutils.EncoderDecoder(encoder, decoder)\n</pre> # \u8c03\u7528 TransformerEncoder\uff0cTransformerDecoder encoder = TransformerEncoder(     len(src_vocab), key_size, query_size, value_size, num_hiddens,     norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,     num_layers, dropout)  decoder = TransformerDecoder(     len(tgt_vocab), key_size, query_size, value_size, num_hiddens,     norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,     num_layers, dropout)  net = myutils.EncoderDecoder(encoder, decoder) In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[35]: Copied! <pre># \u8bad\u7ec3\nmyutils.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)\n</pre> # \u8bad\u7ec3 myutils.train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device) <pre>loss 0.031, 6046.3 tokens/sec on None\n</pre> In\u00a0[36]: Copied! <pre>engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .']\nfras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']\n\nfor eng, fra in zip(engs, fras):\n    translation, dec_attention_weight_seq = myutils.predict_seq2seq(\n        net, eng, src_vocab, tgt_vocab, num_steps, device, True)\n    print(f'{eng} =&gt; {translation}, ', f'bleu {myutils.bleu(translation, fra, k=2):.3f}')\n</pre> engs = ['go .', \"i lost .\", 'he\\'s calm .', 'i\\'m home .'] fras = ['va !', 'j\\'ai perdu .', 'il est calme .', 'je suis chez moi .']  for eng, fra in zip(engs, fras):     translation, dec_attention_weight_seq = myutils.predict_seq2seq(         net, eng, src_vocab, tgt_vocab, num_steps, device, True)     print(f'{eng} =&gt; {translation}, ', f'bleu {myutils.bleu(translation, fra, k=2):.3f}') <pre>go . =&gt; va !,  bleu 1.000\ni lost . =&gt; je suis &lt;unk&gt; .,  bleu 0.000\nhe's calm . =&gt; il est bon .,  bleu 0.658\ni'm home . =&gt; je suis chez moi .,  bleu 1.000\n</pre> In\u00a0[37]: Copied! <pre># encoder \u90e8\u5206\u7684\u6ce8\u610f\u529b\u6743\u91cd\nenc_attention_weights = torch.cat(net.encoder.attention_weights, 0).reshape((num_layers, num_heads,\n-1, num_steps))\n\nmyutils.show_heatmaps(\nenc_attention_weights.cpu(), xlabel='Key positions',\nylabel='Query positions', titles=['Head %d' % i for i in range(1, 5)],\nfigsize=(7, 3.5))\n</pre> # encoder \u90e8\u5206\u7684\u6ce8\u610f\u529b\u6743\u91cd enc_attention_weights = torch.cat(net.encoder.attention_weights, 0).reshape((num_layers, num_heads, -1, num_steps))  myutils.show_heatmaps( enc_attention_weights.cpu(), xlabel='Key positions', ylabel='Query positions', titles=['Head %d' % i for i in range(1, 5)], figsize=(7, 3.5)) In\u00a0[38]: Copied! <pre># decoder \u90e8\u5206\u7684\u6ce8\u610f\u529b\u6743\u91cd\ndec_attention_weights_2d = [head[0].tolist() for step in dec_attention_weight_seq for attn in step for blk in attn for head in blk]\n\ndec_attention_weights_filled = torch.tensor(\n        pd.DataFrame(dec_attention_weights_2d).fillna(0.0).values)\ndec_attention_weights = dec_attention_weights_filled.reshape((-1, 2, num_layers, num_heads, num_steps))\ndec_self_attention_weights, dec_inter_attention_weights = dec_attention_weights.permute(1, 2, 3, 0, 4)\ndec_self_attention_weights.shape, dec_inter_attention_weights.shape\n</pre> # decoder \u90e8\u5206\u7684\u6ce8\u610f\u529b\u6743\u91cd dec_attention_weights_2d = [head[0].tolist() for step in dec_attention_weight_seq for attn in step for blk in attn for head in blk]  dec_attention_weights_filled = torch.tensor(         pd.DataFrame(dec_attention_weights_2d).fillna(0.0).values) dec_attention_weights = dec_attention_weights_filled.reshape((-1, 2, num_layers, num_heads, num_steps)) dec_self_attention_weights, dec_inter_attention_weights = dec_attention_weights.permute(1, 2, 3, 0, 4) dec_self_attention_weights.shape, dec_inter_attention_weights.shape Out[38]: <pre>(torch.Size([2, 4, 6, 10]), torch.Size([2, 4, 6, 10]))</pre> In\u00a0[39]: Copied! <pre># decoder \u7684\u81ea\u6ce8\u610f\u529b\u6743\u91cd\nmyutils.show_heatmaps(\n    dec_self_attention_weights[:, :, :, :len(translation.split()) + 1],\n    xlabel='Key positions', ylabel='Query positions',\n    titles=['Head %d' % i for i in range(1, 5)], figsize=(7, 3.5))\n</pre> # decoder \u7684\u81ea\u6ce8\u610f\u529b\u6743\u91cd myutils.show_heatmaps(     dec_self_attention_weights[:, :, :, :len(translation.split()) + 1],     xlabel='Key positions', ylabel='Query positions',     titles=['Head %d' % i for i in range(1, 5)], figsize=(7, 3.5)) In\u00a0[40]: Copied! <pre># decoder \u4e0e encoder \u90e8\u5206\u7684\u6ce8\u610f\u529b\u6743\u91cd\nmyutils.show_heatmaps(\n    dec_inter_attention_weights, xlabel='Key positions',\n    ylabel='Query positions', titles=['Head %d' % i for i in range(1, 5)],\n    figsize=(7, 3.5))\n</pre> # decoder \u4e0e encoder \u90e8\u5206\u7684\u6ce8\u610f\u529b\u6743\u91cd myutils.show_heatmaps(     dec_inter_attention_weights, xlabel='Key positions',     ylabel='Query positions', titles=['Head %d' % i for i in range(1, 5)],     figsize=(7, 3.5)) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/knowledge/deep_learning_notebook/chapter-transformer/#torch-notes-for-transformer-and-related-materials","title":"Torch Notes for Transformer and Related Materials\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/chapter-transformer/#visualization-of-attention-weights","title":"Visualization of Attention Weights\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/chapter-transformer/","title":"\u53ef\u89c6\u5316\u6700\u540e\u4e00\u4e2a\u53e5\u5b50\u7684\u6ce8\u610f\u529b\u6743\u91cd\u77e9\u9635\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/","title":"Training a Classifier","text":"In\u00a0[\u00a0]: Copied! <pre>%matplotlib inline\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\n</pre> %matplotlib inline import torch import torchvision import torchvision.transforms as transforms import torch.nn as nn In\u00a0[1]: Copied! <pre>\n</pre> <p>The output of torchvision datasets are PILImage images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1].</p> Note<p>If running on Windows and you get a BrokenPipeError, try setting     the num_worker of torch.utils.data.DataLoader() to 0.</p> In\u00a0[261]: Copied! <pre>transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\nbatch_size = 4\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n                                          shuffle=True, num_workers=2)\n\ntestset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n                                         shuffle=False, num_workers=2)\n\nclasses = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n</pre> transform = transforms.Compose(     [transforms.ToTensor(),      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])  batch_size = 4  trainset = torchvision.datasets.CIFAR10(root='./data', train=True,                                         download=True, transform=transform) trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,                                           shuffle=True, num_workers=2)  testset = torchvision.datasets.CIFAR10(root='./data', train=False,                                        download=True, transform=transform) testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,                                          shuffle=False, num_workers=2)  classes = ('plane', 'car', 'bird', 'cat',            'deer', 'dog', 'frog', 'horse', 'ship', 'truck') <pre>Files already downloaded and verified\nFiles already downloaded and verified\n</pre> <p>Let us show some of the training images, for fun.</p> In\u00a0[262]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# functions to show an image\n\n\ndef imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = next(dataiter)\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))\n</pre> import matplotlib.pyplot as plt import numpy as np  # functions to show an image   def imshow(img):     img = img / 2 + 0.5     # unnormalize     npimg = img.numpy()     plt.imshow(np.transpose(npimg, (1, 2, 0)))     plt.show()   # get some random training images dataiter = iter(trainloader) images, labels = next(dataiter)  # show images imshow(torchvision.utils.make_grid(images)) # print labels print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size))) <pre>frog  cat   car   ship \n</pre> In\u00a0[263]: Copied! <pre># \u603b\u5171\u7684\u5c0f\u6279\u91cf\u4e2a\u6570\uff0c\u6bcf\u4e2a\u5c0f\u6279\u91cf\u5305\u542b\u56db\u4e2a\u6837\u672c\nlen(dataiter)\n</pre> # \u603b\u5171\u7684\u5c0f\u6279\u91cf\u4e2a\u6570\uff0c\u6bcf\u4e2a\u5c0f\u6279\u91cf\u5305\u542b\u56db\u4e2a\u6837\u672c len(dataiter) Out[263]: <pre>12500</pre> In\u00a0[110]: Copied! <pre>for i in dataiter:\n    x = i\n    print(x)\n    break\n    \n</pre> for i in dataiter:     x = i     print(x)     break      <pre>[tensor([[[[ 1.0000,  0.8039,  0.5294,  ...,  0.4196,  0.6314,  0.9686],\n          [ 0.7882,  0.5922,  0.2706,  ...,  0.0431,  0.4431,  0.7255],\n          [ 0.5529,  0.3490,  0.0745,  ..., -0.1216,  0.1529,  0.3804],\n          ...,\n          [ 0.7961,  0.5843,  0.4275,  ...,  0.2078,  0.3882,  0.6000],\n          [ 0.8667,  0.7255,  0.5686,  ...,  0.4353,  0.6235,  0.7804],\n          [ 0.9922,  0.8510,  0.6863,  ...,  0.6471,  0.7725,  0.9451]],\n\n         [[ 1.0000,  0.8431,  0.5922,  ...,  0.4902,  0.6784,  1.0000],\n          [ 0.8275,  0.6706,  0.3804,  ...,  0.1608,  0.5294,  0.7804],\n          [ 0.6157,  0.4588,  0.2392,  ...,  0.0588,  0.2863,  0.4588],\n          ...,\n          [ 0.8745,  0.7412,  0.6784,  ...,  0.5137,  0.6078,  0.7333],\n          [ 0.9216,  0.8431,  0.7490,  ...,  0.6549,  0.7882,  0.8745],\n          [ 1.0000,  0.9137,  0.7961,  ...,  0.7804,  0.8667,  0.9765]],\n\n         [[ 1.0000,  0.7961,  0.5137,  ...,  0.4275,  0.6392,  0.9765],\n          [ 0.7804,  0.5843,  0.2549,  ...,  0.0353,  0.4431,  0.7333],\n          [ 0.5451,  0.3333,  0.0431,  ..., -0.1373,  0.1529,  0.3882],\n          ...,\n          [ 0.6627,  0.3882,  0.1686,  ..., -0.0667,  0.1922,  0.4902],\n          [ 0.7804,  0.5922,  0.3804,  ...,  0.2471,  0.4824,  0.7020],\n          [ 0.9686,  0.7882,  0.5843,  ...,  0.5608,  0.7098,  0.8980]]],\n\n\n        [[[-0.7412, -0.5451, -0.2784,  ..., -0.6941, -0.8667, -0.9294],\n          [-0.8745, -0.7176, -0.5216,  ..., -0.9137, -0.9451, -0.9843],\n          [-0.8196, -0.8039, -0.6627,  ..., -0.8353, -0.9529, -1.0000],\n          ...,\n          [-0.3333, -0.3725, -0.3490,  ..., -0.3020, -0.3098, -0.3098],\n          [-0.4431, -0.4510, -0.3961,  ..., -0.2941, -0.3176, -0.3098],\n          [-0.5451, -0.5451, -0.4039,  ..., -0.0902, -0.1922, -0.2863]],\n\n         [[-0.7255, -0.5843, -0.3725,  ..., -0.7255, -0.8980, -0.9373],\n          [-0.8980, -0.7804, -0.6157,  ..., -0.9451, -0.9765, -0.9922],\n          [-0.8510, -0.8510, -0.7333,  ..., -0.8667, -0.9843, -1.0000],\n          ...,\n          [-0.2549, -0.2863, -0.2627,  ..., -0.2157, -0.2314, -0.2235],\n          [-0.4196, -0.4118, -0.3412,  ..., -0.2392, -0.2627, -0.2392],\n          [-0.5294, -0.5216, -0.3647,  ..., -0.1765, -0.2314, -0.2784]],\n\n         [[-0.7412, -0.6706, -0.5216,  ..., -0.7725, -0.9137, -0.9294],\n          [-0.9373, -0.9059, -0.8275,  ..., -0.9843, -0.9843, -0.9843],\n          [-0.9137, -0.9686, -0.9137,  ..., -0.9137, -0.9922, -1.0000],\n          ...,\n          [-0.6078, -0.6784, -0.6863,  ..., -0.7098, -0.7176, -0.7255],\n          [-0.6941, -0.7176, -0.7098,  ..., -0.7020, -0.7255, -0.7255],\n          [-0.7412, -0.7961, -0.6706,  ..., -0.5843, -0.6784, -0.6941]]],\n\n\n        [[[-0.8510, -0.8588, -0.9137,  ..., -0.6627, -0.6314, -0.6863],\n          [-0.9137, -0.8588, -0.8431,  ..., -0.5137, -0.6157, -0.5451],\n          [-0.9451, -0.7804, -0.7176,  ..., -0.3725, -0.5059, -0.4118],\n          ...,\n          [ 0.3882,  0.3882,  0.3882,  ...,  0.0824,  0.0667,  0.0431],\n          [ 0.3725,  0.3725,  0.3804,  ...,  0.3333,  0.3020,  0.2627],\n          [ 0.3490,  0.3490,  0.3412,  ...,  0.3569,  0.3412,  0.3412]],\n\n         [[-0.8510, -0.8588, -0.9059,  ..., -0.6784, -0.6235, -0.6784],\n          [-0.9216, -0.8745, -0.8588,  ..., -0.5843, -0.6627, -0.5843],\n          [-0.9686, -0.8196, -0.7725,  ..., -0.5059, -0.6078, -0.5059],\n          ...,\n          [ 0.3176,  0.3176,  0.3176,  ..., -0.4196, -0.4667, -0.4980],\n          [ 0.3098,  0.3098,  0.3176,  ...,  0.0510, -0.0039, -0.0510],\n          [ 0.2863,  0.2863,  0.2863,  ...,  0.2549,  0.2392,  0.2157]],\n\n         [[-0.8510, -0.8588, -0.9059,  ..., -0.7176, -0.6627, -0.7098],\n          [-0.9216, -0.8745, -0.8588,  ..., -0.6314, -0.7176, -0.6314],\n          [-0.9765, -0.8275, -0.7725,  ..., -0.5686, -0.6941, -0.5843],\n          ...,\n          [ 0.0353,  0.0353,  0.0431,  ..., -0.4824, -0.5059, -0.5294],\n          [ 0.0196,  0.0118,  0.0118,  ..., -0.1608, -0.1765, -0.2157],\n          [ 0.0039, -0.0118, -0.0353,  ..., -0.0667, -0.0431, -0.0353]]],\n\n\n        [[[-0.2078, -0.2627, -0.3255,  ..., -0.2549, -0.2706, -0.2157],\n          [-0.1608, -0.2000, -0.2941,  ..., -0.1608, -0.2235, -0.2314],\n          [-0.1843, -0.2157, -0.2314,  ...,  0.0039, -0.0353, -0.1922],\n          ...,\n          [-0.3490, -0.3333, -0.4667,  ..., -0.3804, -0.4196, -0.5137],\n          [-0.4275, -0.4588, -0.4902,  ..., -0.4353, -0.4431, -0.5059],\n          [-0.5059, -0.5216, -0.5686,  ..., -0.4510, -0.4039, -0.4588]],\n\n         [[-0.3961, -0.3882, -0.4039,  ..., -0.2863, -0.2863, -0.2392],\n          [-0.2784, -0.2784, -0.3412,  ..., -0.1451, -0.2078, -0.2157],\n          [-0.2549, -0.2627, -0.2706,  ..., -0.0431, -0.0902, -0.2549],\n          ...,\n          [-0.4275, -0.4275, -0.4510,  ..., -0.4353, -0.4902, -0.5843],\n          [-0.4980, -0.5294, -0.4588,  ..., -0.4902, -0.5059, -0.5529],\n          [-0.5451, -0.5216, -0.5137,  ..., -0.5059, -0.4510, -0.4745]],\n\n         [[-0.4196, -0.4588, -0.5137,  ..., -0.4118, -0.4275, -0.3882],\n          [-0.3804, -0.4039, -0.4824,  ..., -0.3490, -0.3882, -0.3725],\n          [-0.4118, -0.4196, -0.4275,  ..., -0.2235, -0.2392, -0.3569],\n          ...,\n          [-0.5059, -0.4980, -0.5608,  ..., -0.4588, -0.4824, -0.5451],\n          [-0.5765, -0.6078, -0.5765,  ..., -0.5294, -0.5294, -0.5686],\n          [-0.6157, -0.6235, -0.6471,  ..., -0.5608, -0.5137, -0.5608]]]]), tensor([7, 7, 7, 5])]\n</pre> In\u00a0[264]: Copied! <pre>x[0].shape, x[1].shape\n</pre> x[0].shape, x[1].shape Out[264]: <pre>(torch.Size([4, 3, 32, 32]), torch.Size([4]))</pre> In\u00a0[265]: Copied! <pre>x[1]\n</pre> x[1] Out[265]: <pre>tensor([7, 7, 7, 5])</pre> In\u00a0[266]: Copied! <pre># images\u662f\u56db\u7ef4\u5f20\u91cf\uff0c\u8fd9\u4e5f\u662f\u56fe\u50cf\u6570\u636e\u7684\u4e00\u822c\u5f62\u5f0f\uff0c\u8868\u793a(\u6279\u91cf\u5927\u5c0f\uff0c\u901a\u9053\u6570\uff0c\u9ad8\u5ea6\uff0c\u5bbd\u5ea6)\u3002\n# \u901a\u9053\u6570\u4e3a3\u4ee3\u8868\u4e86RGB\u4e09\u539f\u8272\uff0c\u9ad8\u5ea6\u5bbd\u5ea6\u5747\u4e3a32\u4ee3\u8868\u4e86\u6bcf\u4e2a\u56fe\u50cf\u662f\u753132*32\u4e2a\u50cf\u7d20\u70b9\u6784\u6210\u7684\nimages.shape, labels.shape\n</pre> # images\u662f\u56db\u7ef4\u5f20\u91cf\uff0c\u8fd9\u4e5f\u662f\u56fe\u50cf\u6570\u636e\u7684\u4e00\u822c\u5f62\u5f0f\uff0c\u8868\u793a(\u6279\u91cf\u5927\u5c0f\uff0c\u901a\u9053\u6570\uff0c\u9ad8\u5ea6\uff0c\u5bbd\u5ea6)\u3002 # \u901a\u9053\u6570\u4e3a3\u4ee3\u8868\u4e86RGB\u4e09\u539f\u8272\uff0c\u9ad8\u5ea6\u5bbd\u5ea6\u5747\u4e3a32\u4ee3\u8868\u4e86\u6bcf\u4e2a\u56fe\u50cf\u662f\u753132*32\u4e2a\u50cf\u7d20\u70b9\u6784\u6210\u7684 images.shape, labels.shape Out[266]: <pre>(torch.Size([4, 3, 32, 32]), torch.Size([4]))</pre> In\u00a0[267]: Copied! <pre>images[0].shape\n</pre> images[0].shape Out[267]: <pre>torch.Size([3, 32, 32])</pre> In\u00a0[268]: Copied! <pre># labels\u4ee3\u8868classes\u4e2d\u5bf9\u5e94\u7d22\u5f15\u7684\u7c7b\u522b\nlabels\n</pre> # labels\u4ee3\u8868classes\u4e2d\u5bf9\u5e94\u7d22\u5f15\u7684\u7c7b\u522b labels Out[268]: <pre>tensor([6, 3, 1, 8])</pre> In\u00a0[269]: Copied! <pre>classes\n</pre> classes Out[269]: <pre>('plane',\n 'car',\n 'bird',\n 'cat',\n 'deer',\n 'dog',\n 'frog',\n 'horse',\n 'ship',\n 'truck')</pre> In\u00a0[184]: Copied! <pre>import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # \u8f93\u5165\u901a\u9053\u4e3a3\uff0c\u8f93\u51fa\u901a\u9053\u4e3a6\uff0c\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = torch.flatten(x, 1) # flatten all dimensions except batch\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)  # \u6700\u7ec8\u7684\u8f93\u51fa\u7684\u5f62\u72b6\uff1a(\u6837\u672c\u6570, 10)\n        return x\n\n\nnet = Net()\n</pre> import torch.nn as nn import torch.nn.functional as F   class Net(nn.Module):     def __init__(self):         super().__init__()         # \u8f93\u5165\u901a\u9053\u4e3a3\uff0c\u8f93\u51fa\u901a\u9053\u4e3a6\uff0c         self.conv1 = nn.Conv2d(3, 6, 5)         self.pool = nn.MaxPool2d(2, 2)         self.conv2 = nn.Conv2d(6, 16, 5)         self.fc1 = nn.Linear(16 * 5 * 5, 120)         self.fc2 = nn.Linear(120, 84)         self.fc3 = nn.Linear(84, 10)      def forward(self, x):         x = self.pool(F.relu(self.conv1(x)))         x = self.pool(F.relu(self.conv2(x)))         x = torch.flatten(x, 1) # flatten all dimensions except batch         x = F.relu(self.fc1(x))         x = F.relu(self.fc2(x))         x = self.fc3(x)  # \u6700\u7ec8\u7684\u8f93\u51fa\u7684\u5f62\u72b6\uff1a(\u6837\u672c\u6570, 10)         return x   net = Net() In\u00a0[183]: Copied! <pre>input = torch.randn(2, 3, 4, 5)\ninput\n</pre> input = torch.randn(2, 3, 4, 5) input Out[183]: <pre>tensor([[[[ 0.6225, -0.8113, -1.8838, -0.2240,  0.2866],\n          [-0.0669, -1.4303, -2.9979, -1.2393, -1.6159],\n          [-1.2844, -0.4319,  0.9939, -0.2550,  0.1937],\n          [-3.0341, -0.6222,  0.3282,  2.5938,  0.0217]],\n\n         [[-1.0176,  1.6110, -0.2397, -0.9023,  1.4768],\n          [-0.6748,  0.0756, -0.6852,  0.6152, -0.1683],\n          [-0.2232, -0.7124, -0.5200, -1.3011, -0.7381],\n          [ 0.6417, -0.2909, -0.4589, -0.6818, -1.8558]],\n\n         [[ 0.4817, -0.6089, -1.0552,  1.6166, -0.7537],\n          [-0.3851, -1.6183,  0.4431, -0.1010,  2.1800],\n          [-0.0835,  1.1149,  0.4344,  0.9962, -1.9566],\n          [ 1.6456,  0.0948,  0.0496, -0.6095, -0.6063]]],\n\n\n        [[[ 0.2601,  1.8444, -1.4860,  2.1580,  0.0430],\n          [ 0.5619, -0.7727,  1.4346,  0.5709,  1.8412],\n          [-0.4810, -2.0775, -1.0071,  0.9915,  0.2114],\n          [-0.7517, -1.1980, -2.1478, -0.0142,  0.1597]],\n\n         [[-0.2679,  0.1812,  0.6679, -1.1643, -0.1946],\n          [-0.2755,  0.3408, -0.9709,  0.0666,  0.7944],\n          [ 1.3179,  0.0302,  0.1058, -0.6762, -0.1141],\n          [ 0.3910,  0.2609,  0.6954, -0.6243, -1.0048]],\n\n         [[ 0.0591, -0.7116, -1.2806, -0.5320, -0.5194],\n          [-0.7971,  1.1928, -0.3057,  0.0704, -1.5506],\n          [ 0.0448, -1.1057, -1.1935,  1.4112, -0.7906],\n          [ 1.1410, -0.1199, -0.2434,  0.2573,  0.7855]]]])</pre> In\u00a0[184]: Copied! <pre>input.shape\n</pre> input.shape Out[184]: <pre>torch.Size([2, 3, 4, 5])</pre> <p>tutorial</p> <ol> <li>\u5bf9\u4e8e\u56db\u7ef4\u5f20\u91cf\u7684\u8f93\u5165\uff0cin_channels\u4ee3\u8868\u8f93\u5165\u7684\u901a\u9053\u6570\uff0c\u5728\u6b64\u4f8b\u4e2d\u8f93\u5165\u7684\u901a\u9053\u6570\u4e3a3\uff0c\u5219in_channel\u53c2\u6570\u5fc5\u987b\u7531\u8f93\u5165\u7684\u5f62\u72b6\u786e\u5b9a\uff0c\u5426\u5219\u4f1a\u62a5\u9519\u3002\u5373\uff1a\u6211\u4eec\u9700\u8981\u4fdd\u8bc1 in_channels = input.shape[1]</li> </ol> <ol> <li>out_channels\u4ee3\u8868\u8f93\u51fa\u7684\u901a\u9053\u6570\uff0c\u5bf9\u4e8e\u56db\u7ef4\u5f20\u91cf\uff0c\u6838\u51fd\u6570\u6709\u51e0\u4e2a\u77e9\u9635\u7ec4\uff0c\u5c31\u6709\u51e0\u4e2a\u8f93\u51fa\u901a\u9053\uff0c\u5219\u8f93\u51fa\u901a\u9053\u6570\u91cf\u53ef\u4ee5\u6307\u5b9a</li> </ol> <ol> <li>\u5982\u679c\u8f93\u5165\u6837\u672c\u7684\u6279\u91cf\u5927\u5c0f\u5927\u4e8e1\uff0c\u5219\u5bf9\u4e8e\u6bcf\u4e00\u4e2a\u8f93\u5165\u7684\u6837\u672c\uff0c\u90fd\u4f1a\u8fdb\u884c\u4e00\u6b21\u5377\u79ef\u3002\u5373\u8f93\u51fa\u7684\u6279\u91cf\u6570 = \u8f93\u5165\u7684\u6279\u91cf\u6570 output.shape[0] = input.shape[0]</li> </ol> <ol> <li>\u53ef\u4ee5\u770b\u51fa\uff0cConv2d\u5b9a\u4e49\u7684\u6838\u51fd\u6570\u6700\u591a\u5c31\u662f\u4e00\u4e2a\u56db\u7ef4\u5f20\u91cf\uff0c\u5f62\u72b6\u4e3a(\u8f93\u51fa\u901a\u9053\u6570, \u8f93\u5165\u901a\u9053\u6570\uff0c\u5377\u79ef\u6838\u9ad8\u5ea6\uff0c\u5377\u79ef\u6838\u8de8\u5ea6)</li> </ol> In\u00a0[185]: Copied! <pre>m = nn.Conv2d(in_channels=3, out_channels=4, kernel_size=(3, 5), stride=1)\nm\n</pre> m = nn.Conv2d(in_channels=3, out_channels=4, kernel_size=(3, 5), stride=1) m Out[185]: <pre>Conv2d(3, 4, kernel_size=(3, 5), stride=(1, 1))</pre> In\u00a0[186]: Copied! <pre>for name, param in m.named_parameters():\n    x = param.data\n    break\n    print(name, param.data)\n</pre> for name, param in m.named_parameters():     x = param.data     break     print(name, param.data) <p>\u5377\u79ef\u5c42\u7684\u5f62\u72b6:(out_channels, in_channels, kernel_size[0], kernel_size[1])</p> In\u00a0[187]: Copied! <pre>x.shape\n</pre> x.shape Out[187]: <pre>torch.Size([4, 3, 3, 5])</pre> In\u00a0[188]: Copied! <pre># (batch_size, channel, height, width)\noutput = m(input)\noutput.shape\n</pre> # (batch_size, channel, height, width) output = m(input) output.shape Out[188]: <pre>torch.Size([2, 4, 2, 1])</pre> In\u00a0[141]: Copied! <pre>output\n</pre> output Out[141]: <pre>tensor([[[[ 8.9423e-01,  1.5068e+00],\n          [ 2.5219e-01, -1.1022e+00]],\n\n         [[ 7.8779e-01, -9.8146e-01],\n          [-1.8985e-01, -6.0783e-01]],\n\n         [[ 6.5202e-02, -3.3441e-01],\n          [-7.2188e-01,  1.1952e-02]],\n\n         [[ 2.9757e-01, -1.4567e+00],\n          [-4.0437e-01,  1.5513e-01]]],\n\n\n        [[[-6.5894e-01,  6.8088e-01],\n          [ 3.3791e-01, -4.1992e-01]],\n\n         [[ 2.3165e-04,  3.3204e-02],\n          [ 4.3622e-01, -9.0894e-01]],\n\n         [[ 6.0523e-01, -9.0314e-01],\n          [-1.1732e+00,  3.2243e-01]],\n\n         [[ 7.8821e-01, -1.0278e-01],\n          [ 6.2431e-01, -2.5323e-01]]]], grad_fn=&lt;ConvolutionBackward0&gt;)</pre> In\u00a0[142]: Copied! <pre>x.shape\n</pre> x.shape Out[142]: <pre>torch.Size([4, 3, 3, 3])</pre> <p>input\uff1a batch_size = 2 channel = 3 length = 4 width = 4 height = 6</p> In\u00a0[143]: Copied! <pre>input = torch.randn(2, 3, 4, 4, 6)\n</pre> input = torch.randn(2, 3, 4, 4, 6) In\u00a0[144]: Copied! <pre>m = nn.Conv3d(in_channels=3, out_channels=4, kernel_size=(3, 3, 2), stride=1)\nm\n</pre> m = nn.Conv3d(in_channels=3, out_channels=4, kernel_size=(3, 3, 2), stride=1) m Out[144]: <pre>Conv3d(3, 4, kernel_size=(3, 3, 2), stride=(1, 1, 1))</pre> In\u00a0[145]: Copied! <pre>output = m(input)\noutput.shape\n</pre> output = m(input) output.shape Out[145]: <pre>torch.Size([2, 4, 2, 2, 5])</pre> <p>\u601d\u8003\u4e00\u4e0b\u4e3a\u4ec0\u4e48output\u7684\u6700\u540e\u4e00\u4e2a\u9636\u7684\u7ef4\u5ea6\u662f5\uff1a\u56e0\u4e3ainput\u6700\u540e\u4e00\u4e2a\u9636\u662f6\uff0c\u5377\u79ef\u6838kernel\u7684\u6700\u540e\u4e00\u4e2a\u9636\u662f2\uff0c\u5c062\u57286\u957f\u5ea6\u4e0a\u5377\u79ef\uff0c\u5219\u7ed3\u679c\u662f5\u7ef4</p> In\u00a0[146]: Copied! <pre>output\n</pre> output Out[146]: <pre>tensor([[[[[ 0.2995, -0.2516,  0.0781, -0.5229, -0.6305],\n           [ 0.5272,  1.0944,  0.6250, -0.3257,  0.5574]],\n\n          [[-0.0381,  0.0107, -0.3247, -0.3197, -0.2873],\n           [ 1.1302,  1.1678, -0.4066,  0.9155,  1.3612]]],\n\n\n         [[[-0.6991, -0.3981, -0.8287,  0.3560, -0.7797],\n           [ 1.0538,  1.2710,  1.0157, -0.4563, -1.0284]],\n\n          [[-1.2038,  0.4122, -0.4734,  0.2056, -0.3488],\n           [ 0.1822, -0.2392,  0.6679, -0.0028, -0.2663]]],\n\n\n         [[[-0.3069, -0.2013,  0.6086, -0.8995, -0.4334],\n           [-1.0282,  0.3515,  0.1661, -0.5898, -0.0159]],\n\n          [[-0.0258, -0.8679,  0.3484, -1.2534,  0.3699],\n           [ 0.9861, -1.8515,  0.9079, -0.5061,  0.0106]]],\n\n\n         [[[-0.3252, -0.6444, -0.1278, -0.0578, -1.1351],\n           [-0.1810,  0.5004, -0.5404,  1.1136, -0.0860]],\n\n          [[ 0.0237,  0.0198, -0.7980, -0.8286,  0.1473],\n           [ 0.1368, -0.8457, -0.4680, -0.1043, -0.4395]]]],\n\n\n\n        [[[[ 1.4744, -0.5146,  0.6787,  0.6548, -0.1079],\n           [-0.3460, -0.3200, -0.2586, -0.7955, -0.6110]],\n\n          [[ 0.6880, -0.6771, -0.1918, -0.3200,  0.0926],\n           [ 0.3409, -1.3889, -0.3480,  0.6266, -0.4243]]],\n\n\n         [[[ 0.0470, -0.3401, -0.2308,  0.0931, -0.0423],\n           [-0.1369, -1.3137,  0.6834, -0.7008, -0.3649]],\n\n          [[ 0.9235,  0.9452,  0.7471, -0.5918, -0.2309],\n           [ 0.5110, -0.7049,  1.2927, -0.1430, -0.4591]]],\n\n\n         [[[ 0.0571,  0.4529,  0.0979, -1.0744, -0.1449],\n           [ 0.6290,  0.2879,  0.2546, -0.5385, -0.7998]],\n\n          [[-0.6644,  0.0671, -1.2095,  0.2371,  0.0020],\n           [ 0.1292, -0.3297, -0.1390, -0.5129,  0.0350]]],\n\n\n         [[[-0.8882,  0.6642,  0.0890, -0.2276, -1.0358],\n           [-0.1055,  1.0595,  0.5567,  0.0592,  0.0972]],\n\n          [[-0.8411, -0.0732, -0.5441,  0.6652, -1.1740],\n           [-0.1027,  0.3413, -0.6674,  0.3260, -0.7745]]]]],\n       grad_fn=&lt;ConvolutionBackward0&gt;)</pre> <p>\u5173\u4e8epytorch\u7684\u9ed8\u8ba4\u586b\u8865</p> <p>\u5bf9\u4e8e3D\u5377\u79ef\u6838\uff0c\u5982\u679c\u8f93\u5165\u662f\u56db\u9636\uff08unbatched\uff09\uff0c\u5219pytorch\u4f1a\u5728\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u586b\u8865batch_size = 1\u3002\u6b64\u65f6\u8f93\u5165\u4e2d\uff0cinput\u7684\u7b2c\u4e00\u4e2a\u7ef4\u5ea6\u4ee3\u8868channel\uff0c\u5219\u8fd9\u91cc\u7684cahnnel\u540c\u7406\u9700\u8981\u7b49\u4e8eConv3D\u7684\u53c2\u6570in_channels</p> <p>\u5bf9\u4e8e3D\u5377\u79ef\u6838\uff0c\u8f93\u5165\u4e00\u5b9a\u8981\u5927\u4e8e\u7b49\u4e8e4\u9636\uff0c\u5426\u5219\u4f1a\u62a5\u9519\uff1aRuntimeError: Expected 4D (unbatched) or 5D (batched) input to conv3d, but got input of size: [4, 4, 6]</p> In\u00a0[147]: Copied! <pre>input = torch.randn(3, 4, 4, 6)\n</pre> input = torch.randn(3, 4, 4, 6) In\u00a0[148]: Copied! <pre>m = nn.Conv3d(in_channels=3, out_channels=4, kernel_size=(3, 3, 2), stride=1)\nm\n</pre> m = nn.Conv3d(in_channels=3, out_channels=4, kernel_size=(3, 3, 2), stride=1) m Out[148]: <pre>Conv3d(3, 4, kernel_size=(3, 3, 2), stride=(1, 1, 1))</pre> In\u00a0[149]: Copied! <pre># \u6b64\u65f6\u6211\u4eec\u53ef\u4ee5\u7406\u89e3\u4e3a\u6211\u4eec\u53ea\u8f93\u5165\u4e86\u4e00\u4e2a\u6837\u672c\u8fdb\u884c\uff0c\u5219\u8f93\u5165\u548c\u8f93\u51fa\u4e2dbatch\u6240\u5728\u7684\u90a3\u4e2a\u7ef4\u5ea6\u5c31\u6ca1\u6709\u5fc5\u8981\u5b58\u5728\u4e86\u3002\n# \u6b64\u65f6output.shape: (channel, length, width, height)\noutput = m(input)\noutput.shape\n</pre> # \u6b64\u65f6\u6211\u4eec\u53ef\u4ee5\u7406\u89e3\u4e3a\u6211\u4eec\u53ea\u8f93\u5165\u4e86\u4e00\u4e2a\u6837\u672c\u8fdb\u884c\uff0c\u5219\u8f93\u5165\u548c\u8f93\u51fa\u4e2dbatch\u6240\u5728\u7684\u90a3\u4e2a\u7ef4\u5ea6\u5c31\u6ca1\u6709\u5fc5\u8981\u5b58\u5728\u4e86\u3002 # \u6b64\u65f6output.shape: (channel, length, width, height) output = m(input) output.shape Out[149]: <pre>torch.Size([4, 2, 2, 5])</pre> <p>\u7ed3\u8bba</p> <ol> <li>\u75283D\u5377\u79ef\u6838\uff0c\u7406\u8bba\u4e0a\u5e94\u8be5\u8f93\u5165\u4e94\u9636</li> </ol> <ul> <li>\u5982\u679c\u8f93\u5165\u662f\u56db\u9636\uff0c\u90a3\u4e48\u9ed8\u8ba4\u8f93\u5165\u6570\u636e\u662funbatched, \u4f1a\u81ea\u52a8\u586b\u5145batch_size \u8fd9\u4e2a\u9636\u4e3a1</li> <li>\u5982\u679c\u8f93\u5165\u5c0f\u4e8e\u56db\u9636\uff0c\u90a3\u4e48\u4f1a\u62a5\u9519</li> </ul> <ol> <li>\u75282D\u5377\u79ef\u6838\uff0c\u540c\u7406\u7406\u8bba\u4e0a\u5e94\u8be5\u8f93\u5165\u56db\u9636</li> </ol> <ul> <li>\u5982\u679c\u8f93\u5165\u662f\u4e09\u9636\uff0c\u90a3\u4e48\u81ea\u52a8\u586b\u5145batch_size</li> <li>\u5982\u679c\u8f93\u5165\u5c0f\u4e8e\u4e09\u9636\uff0c\u62a5\u9519\u3002</li> </ul> In\u00a0[158]: Copied! <pre>import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n</pre> import torch.optim as optim  criterion = nn.CrossEntropyLoss() optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) In\u00a0[170]: Copied! <pre>for iter_times, iter_element in enumerate([3, 2, 7], 0):\n    print(iter_element, iter_times)\n</pre> for iter_times, iter_element in enumerate([3, 2, 7], 0):     print(iter_element, iter_times) <pre>3 0\n2 1\n7 2\n</pre> In\u00a0[171]: Copied! <pre>for epoch in range(2):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(trainloader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        # 2000\u6b21\u7684\u635f\u5931\u51fd\u6570\u7684\u7d2f\u52a0\uff0c\u6ce8\u610f\u6bcf\u6b21\u7684\u635f\u5931\u90fd\u4f1a\u51cf\u5c11\uff0c\u76f8\u5f53\u4e8e\u5bf9\u4e00\u4e2a\u9012\u51cf\u6570\u5217\u6bcf\u96942000\u9879\u8f93\u51fa\u4e00\u4e2a\u6570\u5217\u548c\n        running_loss += loss.item()\n        if i % 2000 == 1999:    # print every 2000 mini-batches\n            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n            running_loss = 0.0\n\nprint('Finished Training')\n</pre> for epoch in range(2):  # loop over the dataset multiple times      running_loss = 0.0     for i, data in enumerate(trainloader, 0):         # get the inputs; data is a list of [inputs, labels]         inputs, labels = data          # zero the parameter gradients         optimizer.zero_grad()          # forward + backward + optimize         outputs = net(inputs)         loss = criterion(outputs, labels)         loss.backward()         optimizer.step()          # print statistics         # 2000\u6b21\u7684\u635f\u5931\u51fd\u6570\u7684\u7d2f\u52a0\uff0c\u6ce8\u610f\u6bcf\u6b21\u7684\u635f\u5931\u90fd\u4f1a\u51cf\u5c11\uff0c\u76f8\u5f53\u4e8e\u5bf9\u4e00\u4e2a\u9012\u51cf\u6570\u5217\u6bcf\u96942000\u9879\u8f93\u51fa\u4e00\u4e2a\u6570\u5217\u548c         running_loss += loss.item()         if i % 2000 == 1999:    # print every 2000 mini-batches             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')             running_loss = 0.0  print('Finished Training') <pre>[1,  2000] loss: 2.235\n[1,  4000] loss: 1.917\n[1,  6000] loss: 1.718\n[1,  8000] loss: 1.615\n[1, 10000] loss: 1.539\n[1, 12000] loss: 1.471\n[2,  2000] loss: 1.419\n[2,  4000] loss: 1.387\n[2,  6000] loss: 1.372\n[2,  8000] loss: 1.328\n[2, 10000] loss: 1.303\n[2, 12000] loss: 1.312\nFinished Training\n</pre> In\u00a0[270]: Copied! <pre>inputs.shape, labels\n</pre> inputs.shape, labels Out[270]: <pre>(torch.Size([4, 3, 32, 32]), tensor([6, 3, 1, 8]))</pre> In\u00a0[271]: Copied! <pre>outputs = net(inputs)\noutputs, outputs.shape\n</pre> outputs = net(inputs) outputs, outputs.shape Out[271]: <pre>(tensor([[-2.1512,  0.1529,  1.6479,  1.5444,  1.5035,  0.9052,  6.7240, -2.6738,\n          -4.6282, -1.3235],\n         [-1.7226, -3.4159,  1.3129,  2.7902,  1.6486,  2.6387,  1.1697,  0.7477,\n          -2.6952, -3.3751],\n         [ 2.3464,  0.8334, -0.8974, -0.6976, -0.9966, -1.8850, -1.0086, -2.1002,\n           2.9898,  2.0452],\n         [ 0.0157,  1.2160,  0.1687, -0.1456, -0.2955, -0.8466, -0.7482, -0.7036,\n          -0.0135,  0.4391]], grad_fn=&lt;AddmmBackward0&gt;),\n torch.Size([4, 10]))</pre> In\u00a0[272]: Copied! <pre>outputs.sum(axis=1)\n</pre> outputs.sum(axis=1) Out[272]: <pre>tensor([ 1.7013, -0.9010,  0.6294, -0.9134], grad_fn=&lt;SumBackward1&gt;)</pre> <p>Let's quickly save our trained model:</p> In\u00a0[172]: Copied! <pre>PATH = './cifar_net.pth'\ntorch.save(net.state_dict(), PATH)\n</pre> PATH = './cifar_net.pth' torch.save(net.state_dict(), PATH) <p>See here for more details on saving PyTorch models.</p> In\u00a0[204]: Copied! <pre>dataiter = iter(testloader)\nimages, labels = next(dataiter)\n\n# print images\nimshow(torchvision.utils.make_grid(images))\nprint('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n</pre> dataiter = iter(testloader) images, labels = next(dataiter)  # print images imshow(torchvision.utils.make_grid(images)) print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4))) <pre>GroundTruth:  cat   ship  ship  plane\n</pre> <p>Next, let's load back in our saved model (note: saving and re-loading the model wasn't necessary here, we only did it to illustrate how to do so):</p> In\u00a0[205]: Copied! <pre>net = Net()\nnet.load_state_dict(torch.load(PATH))\n</pre> net = Net() net.load_state_dict(torch.load(PATH)) Out[205]: <pre>&lt;All keys matched successfully&gt;</pre> <p>Okay, now let us see what the neural network thinks these examples above are:</p> In\u00a0[206]: Copied! <pre>outputs = net(images)\noutputs\n</pre> outputs = net(images) outputs Out[206]: <pre>tensor([[-0.8840, -1.9322,  0.7545,  2.3560, -0.2670,  0.7243,  1.7412, -1.6958,\n          0.4516, -2.0219],\n        [ 4.3044,  5.7241, -2.2412, -2.3598, -3.0835, -4.0123, -4.4979, -3.6283,\n          7.0589,  3.9774],\n        [ 1.8818,  2.6752, -0.7233, -0.9703, -1.5518, -2.3249, -3.1088, -1.6351,\n          3.2967,  2.4530],\n        [ 4.4465, -0.6558,  0.4437, -0.9582,  0.0508, -2.8245, -2.4236, -1.9248,\n          3.2848, -0.1935]], grad_fn=&lt;AddmmBackward0&gt;)</pre> <p>The outputs are energies for the 10 classes. The higher the energy for a class, the more the network thinks that the image is of the particular class. So, let's get the index of the highest energy:</p> <p>torch.max</p> In\u00a0[230]: Copied! <pre>_, predicted = torch.max(outputs, 1)\n\nprint('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n                              for j in range(4)))\n</pre> _, predicted = torch.max(outputs, 1)  print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'                               for j in range(4))) <pre>Predicted:  cat   ship  ship  plane\n</pre> In\u00a0[231]: Copied! <pre>predicted\n</pre> predicted Out[231]: <pre>tensor([3, 8, 8, 0])</pre> In\u00a0[232]: Copied! <pre>_\n</pre> _ Out[232]: <pre>tensor([2.3560, 7.0589, 3.2967, 4.4465], grad_fn=&lt;MaxBackward0&gt;)</pre> In\u00a0[235]: Copied! <pre>torch.max(outputs, 1)[0], torch.max(outputs, 1)[1]\n</pre> torch.max(outputs, 1)[0], torch.max(outputs, 1)[1] Out[235]: <pre>(tensor([2.3560, 7.0589, 3.2967, 4.4465], grad_fn=&lt;MaxBackward0&gt;),\n tensor([3, 8, 8, 0]))</pre> <p>The results seem pretty good.</p> <p>Let us look at how the network performs on the whole dataset.</p> In\u00a0[195]: Copied! <pre>correct = 0\ntotal = 0\n# since we're not training, we don't need to calculate the gradients for our outputs\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        # calculate outputs by running images through the network\n        outputs = net(images)\n        # the class with the highest energy is what we choose as prediction\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n</pre> correct = 0 total = 0 # since we're not training, we don't need to calculate the gradients for our outputs with torch.no_grad():     for data in testloader:         images, labels = data         # calculate outputs by running images through the network         outputs = net(images)         # the class with the highest energy is what we choose as prediction         _, predicted = torch.max(outputs.data, 1)         total += labels.size(0)         correct += (predicted == labels).sum().item()  print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %') <pre>Accuracy of the network on the 10000 test images: 55 %\n</pre> In\u00a0[241]: Copied! <pre>(predicted == predicted).sum().item()\n</pre> (predicted == predicted).sum().item() Out[241]: <pre>4</pre> In\u00a0[256]: Copied! <pre>predicted[0].item()\n</pre> predicted[0].item() Out[256]: <pre>3</pre> In\u00a0[257]: Copied! <pre>torch.tensor([[1]]).item()\n</pre> torch.tensor([[1]]).item() Out[257]: <pre>1</pre> <p>That looks way better than chance, which is 10% accuracy (randomly picking a class out of 10 classes). Seems like the network learnt something.</p> <p>Hmmm, what are the classes that performed well, and the classes that did not perform well:</p> In\u00a0[\u00a0]: Copied! <pre># prepare to count predictions for each class\ncorrect_pred = {classname: 0 for classname in classes}\ntotal_pred = {classname: 0 for classname in classes}\n\n# again no gradients needed\nwith torch.no_grad():\n    for data in testloader:\n        images, labels = data\n        outputs = net(images)\n        _, predictions = torch.max(outputs, 1)\n        # collect the correct predictions for each class\n        for label, prediction in zip(labels, predictions):\n            if label == prediction:\n                correct_pred[classes[label]] += 1\n            total_pred[classes[label]] += 1\n\n\n# print accuracy for each class\nfor classname, correct_count in correct_pred.items():\n    accuracy = 100 * float(correct_count) / total_pred[classname]\n    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n</pre> # prepare to count predictions for each class correct_pred = {classname: 0 for classname in classes} total_pred = {classname: 0 for classname in classes}  # again no gradients needed with torch.no_grad():     for data in testloader:         images, labels = data         outputs = net(images)         _, predictions = torch.max(outputs, 1)         # collect the correct predictions for each class         for label, prediction in zip(labels, predictions):             if label == prediction:                 correct_pred[classes[label]] += 1             total_pred[classes[label]] += 1   # print accuracy for each class for classname, correct_count in correct_pred.items():     accuracy = 100 * float(correct_count) / total_pred[classname]     print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %') <p>Okay, so what next?</p> <p>How do we run these neural networks on the GPU?</p> In\u00a0[\u00a0]: Copied! <pre>device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(device)\n</pre> device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')  # Assuming that we are on a CUDA machine, this should print a CUDA device:  print(device) <p>The rest of this section assumes that <code>device</code> is a CUDA device.</p> <p>Then these methods will recursively go over all modules and convert their parameters and buffers to CUDA tensors:</p> <p>.. code:: python</p> <pre><code>net.to(device)</code></pre> <p>Remember that you will have to send the inputs and targets at every step to the GPU too:</p> <p>.. code:: python</p> <pre><code>    inputs, labels = data[0].to(device), data[1].to(device)</code></pre> <p>Why don't I notice MASSIVE speedup compared to CPU? Because your network is really small.</p> <p>Exercise: Try increasing the width of your network (argument 2 of the first <code>nn.Conv2d</code>, and argument 1 of the second <code>nn.Conv2d</code> \u2013 they need to be the same number), see what kind of speedup you get.</p> <p>Goals achieved:</p> <ul> <li>Understanding PyTorch's Tensor library and neural networks at a high level.</li> <li>Train a small neural network to classify images</li> </ul> In\u00a0[\u00a0]: Copied! <pre>del dataiter\n</pre> del dataiter"},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/#training-a-classifier","title":"Training a Classifier\u00b6","text":"<p>This is it. You have seen how to define neural networks, compute loss and make updates to the weights of the network.</p> <p>Now you might be thinking,</p>"},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/#what-about-data","title":"What about data?\u00b6","text":"<p>Generally, when you have to deal with image, text, audio or video data, you can use standard python packages that load data into a numpy array. Then you can convert this array into a <code>torch.*Tensor</code>.</p> <ul> <li>For images, packages such as Pillow, OpenCV are useful</li> <li>For audio, packages such as scipy and librosa</li> <li>For text, either raw Python or Cython based loading, or NLTK and SpaCy are useful</li> </ul> <p>Specifically for vision, we have created a package called <code>torchvision</code>, that has data loaders for common datasets such as ImageNet, CIFAR10, MNIST, etc. and data transformers for images, viz., <code>torchvision.datasets</code> and <code>torch.utils.data.DataLoader</code>.</p> <p>This provides a huge convenience and avoids writing boilerplate code.</p> <p>For this tutorial, we will use the CIFAR10 dataset. It has the classes: \u2018airplane\u2019, \u2018automobile\u2019, \u2018bird\u2019, \u2018cat\u2019, \u2018deer\u2019, \u2018dog\u2019, \u2018frog\u2019, \u2018horse\u2019, \u2018ship\u2019, \u2018truck\u2019. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.</p> <p>.. figure:: /_static/img/cifar10.png :alt: cifar10</p> <p>cifar10</p>"},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/#training-an-image-classifier","title":"Training an image classifier\u00b6","text":"<p>We will do the following steps in order:</p> <ol> <li>Load and normalize the CIFAR10 training and test datasets using <code>torchvision</code></li> <li>Define a Convolutional Neural Network</li> <li>Define a loss function</li> <li>Train the network on the training data</li> <li>Test the network on the test data</li> </ol>"},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/#1-load-and-normalize-cifar10","title":"1. Load and normalize CIFAR10\u00b6","text":"<p>Using <code>torchvision</code>, it\u2019s extremely easy to load CIFAR10.</p>"},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/#2-define-a-convolutional-neural-network","title":"2. Define a Convolutional Neural Network\u00b6","text":"<p>Copy the neural network from the Neural Networks section before and modify it to take 3-channel images (instead of 1-channel images as it was defined).</p>"},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/","title":"\u6d4b\u8bd5\u4e00\u4e0b\u5377\u79ef\u6838\u7684\u5f62\u72b6\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/#3d","title":"\u770b\u4e00\u770b3D\u5377\u79ef\u6838\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/#3-define-a-loss-function-and-optimizer","title":"3. Define a Loss function and optimizer\u00b6","text":"<p>Let's use a Classification Cross-Entropy loss and SGD with momentum.</p>"},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/#4-train-the-network","title":"4. Train the network\u00b6","text":"<p>This is when things start to get interesting. We simply have to loop over our data iterator, and feed the inputs to the network and optimize.</p>"},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/","title":"\u770b\u4e00\u770b\u7ec6\u8282\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/#5-test-the-network-on-the-test-data","title":"5. Test the network on the test data\u00b6","text":"<p>We have trained the network for 2 passes over the training dataset. But we need to check if the network has learnt anything at all.</p> <p>We will check this by predicting the class label that the neural network outputs, and checking it against the ground-truth. If the prediction is correct, we add the sample to the list of correct predictions.</p> <p>Okay, first step. Let us display an image from the test set to get familiar.</p>"},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/","title":"\u8fd9\u6b65\u5c06\u4e4b\u524d\u8bad\u7ec3\u597d\u7684\u53c2\u6570\u5bfc\u5165\u6a21\u578b\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/#tensor","title":"\u5c06\u53ea\u5305\u542b\u4e00\u4e2a\u5143\u7d20\u7684tensor\u8f6c\u6362\u4e3a\u6807\u91cf\uff0c\u65e0\u8bba\u7ef4\u6570\u591a\u5c11\u90fd\u53ef\u4ee5\u8f6c\u6362\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/#training-on-gpu","title":"Training on GPU\u00b6","text":"<p>Just like how you transfer a Tensor onto the GPU, you transfer the neural net onto the GPU.</p> <p>Let's first define our device as the first visible cuda device if we have CUDA available:</p>"},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/#training-on-multiple-gpus","title":"Training on multiple GPUs\u00b6","text":"<p>If you want to see even more MASSIVE speedup using all of your GPUs, please check out :doc:<code>data_parallel_tutorial</code>.</p>"},{"location":"markdown/knowledge/deep_learning_notebook/cifar10_tutorial/#where-do-i-go-next","title":"Where do I go next?\u00b6","text":"<ul> <li>:doc:<code>Train neural nets to play video games &lt;/intermediate/reinforcement_q_learning&gt;</code></li> <li><code>Train a state-of-the-art ResNet network on imagenet</code>_</li> <li><code>Train a face generator using Generative Adversarial Networks</code>_</li> <li><code>Train a word-level language model using Recurrent LSTM networks</code>_</li> <li><code>More examples</code>_</li> <li><code>More tutorials</code>_</li> <li><code>Discuss PyTorch on the Forums</code>_</li> <li><code>Chat with other users on Slack</code>_</li> </ul>"},{"location":"markdown/knowledge/deep_learning_notebook/linear_models/","title":"Dataset\u683c\u5f0f","text":"In\u00a0[121]: Copied! <pre>import numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, TensorDataset\n</pre> import numpy as np import torch from torch import nn from torch.utils.data import DataLoader, TensorDataset <p>\u5728PyTorch\u7684torch.nn\u4e2d\uff0c\u6a21\u578b\u7c7b\u7684\u53c2\u6570\u8bbe\u7f6e\u7684\u90fd\u662f\u8f93\u5165\u3001\u8f93\u51fa\u7684<code>\u7279\u5f81</code>\uff0c\u800c\u8f93\u5165\u8f93\u51fa\u7684\u6837\u672c\u5927\u5c0f\uff08\u6279\u91cf\u5927\u5c0f\uff09\uff0c\u5219\u76f4\u63a5\u7531\u6570\u636e\u51b3\u5b9a\uff0c\u4e0d\u9700\u8981\u5728\u6a21\u578b\u4e2d\u8fdb\u884c\u53c2\u6570\u8bbe\u7f6e\u3002</p> In\u00a0[98]: Copied! <pre># \u4e00\u822c\u6765\u8bf4\u6211\u4eec\u7528DataLoader, TensorDataset\u8fd9\u4e24\u4e2a\u5305\uff0c\n# \u5176\u4e2d\u5148\u4f7f\u7528TensorDataset\u8f6c\u6362\u6570\u636e\u4e2a\u6570\uff0c\u518d\u653e\u5165DataLoader\u4e2d\u4f5c\u4e3a\u4e00\u4e2a\u751f\u6210\u5668\nx = torch.randn(32, 4)  # x data (torch tensor)\ny = torch.randn(32, 1)      # y data (torch tensor)\n \n# \u5148\u8f6c\u6362\u6210 torch \u80fd\u8bc6\u522b\u7684 Dataset\ntorch_dataset = TensorDataset(x, y)\n \n# \u628a dataset \u653e\u5165 DataLoader\ndata_iter = DataLoader(\n    dataset=torch_dataset,      # torch TensorDataset format\n    batch_size=3,               # batch size\n    shuffle=True,               # \u8981\u4e0d\u8981\u6253\u4e71\u6570\u636e (\u6253\u4e71\u6bd4\u8f83\u597d)\n    num_workers=2)              # \u591a\u7ebf\u7a0b\u6765\u8bfb\u6570\u636e\n</pre> # \u4e00\u822c\u6765\u8bf4\u6211\u4eec\u7528DataLoader, TensorDataset\u8fd9\u4e24\u4e2a\u5305\uff0c # \u5176\u4e2d\u5148\u4f7f\u7528TensorDataset\u8f6c\u6362\u6570\u636e\u4e2a\u6570\uff0c\u518d\u653e\u5165DataLoader\u4e2d\u4f5c\u4e3a\u4e00\u4e2a\u751f\u6210\u5668 x = torch.randn(32, 4)  # x data (torch tensor) y = torch.randn(32, 1)      # y data (torch tensor)   # \u5148\u8f6c\u6362\u6210 torch \u80fd\u8bc6\u522b\u7684 Dataset torch_dataset = TensorDataset(x, y)   # \u628a dataset \u653e\u5165 DataLoader data_iter = DataLoader(     dataset=torch_dataset,      # torch TensorDataset format     batch_size=3,               # batch size     shuffle=True,               # \u8981\u4e0d\u8981\u6253\u4e71\u6570\u636e (\u6253\u4e71\u6bd4\u8f83\u597d)     num_workers=2)              # \u591a\u7ebf\u7a0b\u6765\u8bfb\u6570\u636e In\u00a0[20]: Copied! <pre># check how data_iter works\ncount = 0 \nfor X, y in data_iter:\n    if count == 0:\n        print(\"feature:\", X, \"\\n\", \"target:\", y)\n    count += 1\n    continue\nprint(f'data_iter\u4e2d\u603b\u5171\u6709{count}\u4e2abatch\u7684\u6570\u636e\u3002')\n</pre> # check how data_iter works count = 0  for X, y in data_iter:     if count == 0:         print(\"feature:\", X, \"\\n\", \"target:\", y)     count += 1     continue print(f'data_iter\u4e2d\u603b\u5171\u6709{count}\u4e2abatch\u7684\u6570\u636e\u3002') <pre>feature: tensor([[-1.0117, -0.8266, -0.6284, -2.5816],\n        [-0.0178, -0.9856, -1.4027, -0.3659],\n        [ 0.5260,  0.1485,  0.3743,  0.1258]]) \n target: tensor([0.2598, 1.8055, 1.7201])\ndata_iter\u4e2d\u603b\u5171\u670911\u4e2abatch\u7684\u6570\u636e\u3002\n</pre> In\u00a0[191]: Copied! <pre>class LinearModel(nn.Module):\n    def __init__(self):\n        super(LinearModel, self).__init__()\n        linear = nn.Linear(in_features=4, out_features=1)\n        linear.weight.data.normal_(0, 0.01)\n        linear.bias.data.fill_(0)\n        self.layer = linear\n    def forward(self, x):\n        x = self.layer(x)\n        # x = x.sum(axis=0)\n        return x\n</pre> class LinearModel(nn.Module):     def __init__(self):         super(LinearModel, self).__init__()         linear = nn.Linear(in_features=4, out_features=1)         linear.weight.data.normal_(0, 0.01)         linear.bias.data.fill_(0)         self.layer = linear     def forward(self, x):         x = self.layer(x)         # x = x.sum(axis=0)         return x In\u00a0[107]: Copied! <pre># \u4f7f\u7528\u4e0a\u4f8b\u4e00\u6837\u7684\u6570\u636e\nx = torch.randn(32, 4)  # x data (torch tensor)\ny = torch.randn(32, 1)      # y data (torch tensor)\n# \u5148\u8f6c\u6362\u6210 torch \u80fd\u8bc6\u522b\u7684 Dataset\ntorch_dataset = TensorDataset(x, y)\ndata_iter = DataLoader(\n    dataset=torch_dataset,      # torch TensorDataset format\n    batch_size=3,               # batch size\n    shuffle=True,               # \u8981\u4e0d\u8981\u6253\u4e71\u6570\u636e (\u6253\u4e71\u6bd4\u8f83\u597d)\n    num_workers=2)              # \u591a\u7ebf\u7a0b\u6765\u8bfb\u6570\u636e\n</pre> # \u4f7f\u7528\u4e0a\u4f8b\u4e00\u6837\u7684\u6570\u636e x = torch.randn(32, 4)  # x data (torch tensor) y = torch.randn(32, 1)      # y data (torch tensor) # \u5148\u8f6c\u6362\u6210 torch \u80fd\u8bc6\u522b\u7684 Dataset torch_dataset = TensorDataset(x, y) data_iter = DataLoader(     dataset=torch_dataset,      # torch TensorDataset format     batch_size=3,               # batch size     shuffle=True,               # \u8981\u4e0d\u8981\u6253\u4e71\u6570\u636e (\u6253\u4e71\u6bd4\u8f83\u597d)     num_workers=2)              # \u591a\u7ebf\u7a0b\u6765\u8bfb\u6570\u636e In\u00a0[72]: Copied! <pre>lm = LinearModel()\n# \u6b64\u65f6\u4ee3\u886832 * 4\u7684\u81ea\u53d8\u91cfx\u548c4 * 1\u7684\u7cfb\u6570\u77e9\u9635\u76f8\u4e58\uff0c\u4fdd\u8bc1\u4e86\u76f8\u5bb9\nprint(f'\u8f93\u51fa\u5f62\u72b6: {lm(x).shape}')\n</pre> lm = LinearModel() # \u6b64\u65f6\u4ee3\u886832 * 4\u7684\u81ea\u53d8\u91cfx\u548c4 * 1\u7684\u7cfb\u6570\u77e9\u9635\u76f8\u4e58\uff0c\u4fdd\u8bc1\u4e86\u76f8\u5bb9 print(f'\u8f93\u51fa\u5f62\u72b6: {lm(x).shape}') <pre>\u8f93\u51fa\u5f62\u72b6: torch.Size([32, 1])\n</pre> In\u00a0[73]: Copied! <pre># construct a linear neural net\nnet = nn.Sequential(nn.Linear(4, 1))\n\n# initialization of parameters\nnet[0].weight.data.normal_(0, 0.01)\nnet[0].bias.data.fill_(0)\nprint(f'\u8f93\u51fa\u5f62\u72b6: {net(x).shape}')\n</pre> # construct a linear neural net net = nn.Sequential(nn.Linear(4, 1))  # initialization of parameters net[0].weight.data.normal_(0, 0.01) net[0].bias.data.fill_(0) print(f'\u8f93\u51fa\u5f62\u72b6: {net(x).shape}') <pre>\u8f93\u51fa\u5f62\u72b6: torch.Size([32, 1])\n</pre> In\u00a0[74]: Copied! <pre># let us check the detailed values of parameters\nfor paras in net.parameters():\n    print(paras)\n</pre> # let us check the detailed values of parameters for paras in net.parameters():     print(paras) <pre>Parameter containing:\ntensor([[ 0.0113,  0.0072, -0.0092, -0.0127]], requires_grad=True)\nParameter containing:\ntensor([0.], requires_grad=True)\n</pre> In\u00a0[111]: Copied! <pre># specification of loss function\n# specification of optimizer\nloss = nn.MSELoss()\noptim = torch.optim.SGD(lm.parameters(), lr=0.03)\n</pre> # specification of loss function # specification of optimizer loss = nn.MSELoss() optim = torch.optim.SGD(lm.parameters(), lr=0.03) In\u00a0[112]: Copied! <pre>y_hat = lm(x)\nloss(y_hat, y)\n</pre> y_hat = lm(x) loss(y_hat, y) Out[112]: <pre>tensor(1.3066, grad_fn=&lt;MseLossBackward0&gt;)</pre> In\u00a0[113]: Copied! <pre># \u67e5\u770bloss\u7684\u7b97\u6cd5\uff1aMSE\u5c31\u662f\u8bef\u5dee\u7684\u5e73\u65b9\u7684\u5e73\u5747\u503c\nprint((sum((y - y_hat) ** 2) / len(y)).item())\nprint(round((sum((y - y_hat) ** 2) / len(y)).item(), 5) == round(loss(y_hat, y).item(), 5))\n</pre> # \u67e5\u770bloss\u7684\u7b97\u6cd5\uff1aMSE\u5c31\u662f\u8bef\u5dee\u7684\u5e73\u65b9\u7684\u5e73\u5747\u503c print((sum((y - y_hat) ** 2) / len(y)).item()) print(round((sum((y - y_hat) ** 2) / len(y)).item(), 5) == round(loss(y_hat, y).item(), 5)) <pre>1.3066014051437378\nTrue\n</pre> In\u00a0[115]: Copied! <pre># \u9996\u5148\u660e\u786e\u7684\u662f\uff0c\u5728\u53cd\u5411\u4f20\u64ad\u4e4b\u524d\uff0c\u5404\u4e2a\u53c2\u6570\u7684\u68af\u5ea6\u4e3a\u7a7a\nfor p in lm.parameters():\n    print(p, p.grad)\n</pre> # \u9996\u5148\u660e\u786e\u7684\u662f\uff0c\u5728\u53cd\u5411\u4f20\u64ad\u4e4b\u524d\uff0c\u5404\u4e2a\u53c2\u6570\u7684\u68af\u5ea6\u4e3a\u7a7a for p in lm.parameters():     print(p, p.grad) <pre>Parameter containing:\ntensor([[-0.0095,  0.0007,  0.0019, -0.0010]], requires_grad=True) tensor([[-19.5573, -32.4925,   1.5564, -22.6102]])\nParameter containing:\ntensor([0.], requires_grad=True) tensor([1.1328])\n</pre> In\u00a0[116]: Copied! <pre># start training \n# loss backward + opt step\nnum_epochs = 3  # \u603b\u5171\u904d\u5386\u4e09\u6b21\u5168\u6837\u672c\nfor epoch in range(num_epochs):\n    for X_train, y_train in data_iter:\n        l = loss(lm(X_train), y_train)\n        # \u5bf9optimizer\u8fdb\u884czero_grad\u64cd\u4f5c\u53ef\u4ee5\u5c06\u5b9a\u4e49\u7684\u7ebf\u6027\u6a21\u578b\u7684\u53c2\u6570\u7684\u68af\u5ea6\u5316\u4e3a0\n        # \u6bcf\u6b65\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u7684\u65f6\u5019\uff0c\u6211\u4eec\u90fd\u9700\u8981\u5c06\u4f18\u5316\u5668\u4e2d\u4fdd\u5b58\u7684\u53c2\u6570\u91cd\u7f6e\u4e3a0\uff0c\u5426\u5219\u8fd9\u6b21\u8ba1\u7b97\u7684\u68af\u5ea6\u5c31\u4f1a\u7d2f\u52a0\u5230\u4e0a\u6b21\u7684\u68af\u5ea6\u4e2d\n        optim.zero_grad()\n        l.backward()\n        # \u4f18\u5316\u5668\u8d70\u4e00\u6b65\uff0c\u5c31\u662f\u6839\u636e\u76ee\u524d\u7684\u68af\u5ea6\u8fdb\u884c\u4e00\u6b21\u68af\u5ea6\u4e0b\u964d\n        optim.step()\n    l = loss(lm(x), y)\n    print(f'epoch {epoch + 1}, loss {l:f}')\n</pre> # start training  # loss backward + opt step num_epochs = 3  # \u603b\u5171\u904d\u5386\u4e09\u6b21\u5168\u6837\u672c for epoch in range(num_epochs):     for X_train, y_train in data_iter:         l = loss(lm(X_train), y_train)         # \u5bf9optimizer\u8fdb\u884czero_grad\u64cd\u4f5c\u53ef\u4ee5\u5c06\u5b9a\u4e49\u7684\u7ebf\u6027\u6a21\u578b\u7684\u53c2\u6570\u7684\u68af\u5ea6\u5316\u4e3a0         # \u6bcf\u6b65\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u7684\u65f6\u5019\uff0c\u6211\u4eec\u90fd\u9700\u8981\u5c06\u4f18\u5316\u5668\u4e2d\u4fdd\u5b58\u7684\u53c2\u6570\u91cd\u7f6e\u4e3a0\uff0c\u5426\u5219\u8fd9\u6b21\u8ba1\u7b97\u7684\u68af\u5ea6\u5c31\u4f1a\u7d2f\u52a0\u5230\u4e0a\u6b21\u7684\u68af\u5ea6\u4e2d         optim.zero_grad()         l.backward()         # \u4f18\u5316\u5668\u8d70\u4e00\u6b65\uff0c\u5c31\u662f\u6839\u636e\u76ee\u524d\u7684\u68af\u5ea6\u8fdb\u884c\u4e00\u6b21\u68af\u5ea6\u4e0b\u964d         optim.step()     l = loss(lm(x), y)     print(f'epoch {epoch + 1}, loss {l:f}') <pre>epoch 1, loss 1.289197\nepoch 2, loss 1.278411\nepoch 3, loss 1.361941\n</pre> In\u00a0[180]: Copied! <pre># generating the synthetic data following a logit model\n\"\"\"\u2f63\u6210logit(p = 1) = XW + b\u566a\u58f0\"\"\"\n# \u771f\u5b9e\u53c2\u6570\nw = torch.tensor([2, -3.4])\nb = 1.2\nnum_examples = 30\n\n# \u6839\u636e\u771f\u5b9e\u53c2\u6570\uff0c\u6a21\u62df\u6570\u636e\nX = torch.normal(0, 1, (num_examples, len(w)))\nprob = torch.matmul(X, w) + b\nprob = torch.exp(prob) / (1 + torch.exp(prob))\n\n# prob\u662f\u957f\u5ea630\u7684\u5411\u91cf\uff0c\u8fd9\u91cc\u6839\u636e\u6bcf\u4e2a\u5206\u91cf\u5bf9\u5e94\u751f\u6210y\u2208{0, 1}\ny = np.random.binomial(np.ones(num_examples, dtype = \"int\"), prob)\ny = torch.tensor(y).reshape((-1, 1))\n\n#  \u6784\u9020\u6570\u636e\u751f\u6210\u5668\ntorch_dataset = TensorDataset(X, y)\ndata_iter = DataLoader(\n    dataset=torch_dataset,      # torch TensorDataset format\n    batch_size=3,               # batch size\n    shuffle=True,               # \u8981\u4e0d\u8981\u6253\u4e71\u6570\u636e (\u6253\u4e71\u6bd4\u8f83\u597d)\n    num_workers=2)              # \u591a\u7ebf\u7a0b\u6765\u8bfb\u6570\u636e\n</pre> # generating the synthetic data following a logit model \"\"\"\u2f63\u6210logit(p = 1) = XW + b\u566a\u58f0\"\"\" # \u771f\u5b9e\u53c2\u6570 w = torch.tensor([2, -3.4]) b = 1.2 num_examples = 30  # \u6839\u636e\u771f\u5b9e\u53c2\u6570\uff0c\u6a21\u62df\u6570\u636e X = torch.normal(0, 1, (num_examples, len(w))) prob = torch.matmul(X, w) + b prob = torch.exp(prob) / (1 + torch.exp(prob))  # prob\u662f\u957f\u5ea630\u7684\u5411\u91cf\uff0c\u8fd9\u91cc\u6839\u636e\u6bcf\u4e2a\u5206\u91cf\u5bf9\u5e94\u751f\u6210y\u2208{0, 1} y = np.random.binomial(np.ones(num_examples, dtype = \"int\"), prob) y = torch.tensor(y).reshape((-1, 1))  #  \u6784\u9020\u6570\u636e\u751f\u6210\u5668 torch_dataset = TensorDataset(X, y) data_iter = DataLoader(     dataset=torch_dataset,      # torch TensorDataset format     batch_size=3,               # batch size     shuffle=True,               # \u8981\u4e0d\u8981\u6253\u4e71\u6570\u636e (\u6253\u4e71\u6bd4\u8f83\u597d)     num_workers=2)              # \u591a\u7ebf\u7a0b\u6765\u8bfb\u6570\u636e In\u00a0[181]: Copied! <pre>X.shape, y.shape, prob.shape\n</pre> X.shape, y.shape, prob.shape Out[181]: <pre>(torch.Size([30, 2]), torch.Size([30, 1]), torch.Size([30]))</pre> In\u00a0[189]: Copied! <pre># logistic loss function, i.e., the negative log-likelihood\ndef logit_loss(y_hat, y): \n    \"\"\"logit loss function\"\"\"\n    # \u8fd9\u4e2a\u516c\u5f0f\u7684\u8be6\u7ec6\u63a8\u5bfc\u89c1Logistic Regression \u7b14\u8bb0\n    return (- y.reshape(y_hat.shape) * y_hat + torch.log(1 + torch.exp(y_hat))).sum()\n</pre> # logistic loss function, i.e., the negative log-likelihood def logit_loss(y_hat, y):      \"\"\"logit loss function\"\"\"     # \u8fd9\u4e2a\u516c\u5f0f\u7684\u8be6\u7ec6\u63a8\u5bfc\u89c1Logistic Regression \u7b14\u8bb0     return (- y.reshape(y_hat.shape) * y_hat + torch.log(1 + torch.exp(y_hat))).sum()  In\u00a0[190]: Copied! <pre># training procedure\nloss = logit_loss\nlm = nn.Sequential(nn.Linear(2, 1))\noptim = torch.optim.SGD(lm.parameters(), lr=0.03)\n\n# tuning parameters\nlr = 0.1\nnum_epochs = 10\n\n# initialization\n# initialization of parameters\nlm[0].weight.data.normal_(0, 0.01)\nlm[0].bias.data.fill_(1)\n\n# start training \nfor epoch in range(num_epochs):\n    for X_train, y_train in data_iter:\n        y_train = y_train.to(torch.float)\n        l = loss(lm(X_train), y_train)\n        # \u5bf9optimizer\u8fdb\u884czero_grad\u64cd\u4f5c\u53ef\u4ee5\u5c06\u5b9a\u4e49\u7684\u7ebf\u6027\u6a21\u578b\u7684\u53c2\u6570\u7684\u68af\u5ea6\u5316\u4e3a0\n        # \u6bcf\u6b65\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u7684\u65f6\u5019\uff0c\u6211\u4eec\u90fd\u9700\u8981\u5c06\u4f18\u5316\u5668\u4e2d\u4fdd\u5b58\u7684\u53c2\u6570\u91cd\u7f6e\u4e3a0\uff0c\u5426\u5219\u8fd9\u6b21\u8ba1\u7b97\u7684\u68af\u5ea6\u5c31\u4f1a\u7d2f\u52a0\u5230\u4e0a\u6b21\u7684\u68af\u5ea6\u4e2d\n        optim.zero_grad()\n        l.backward()\n        # \u4f18\u5316\u5668\u8d70\u4e00\u6b65\uff0c\u5c31\u662f\u6839\u636e\u76ee\u524d\u7684\u68af\u5ea6\u8fdb\u884c\u4e00\u6b21\u68af\u5ea6\u4e0b\u964d\n        optim.step()\n    l = loss(lm(X), y)\n    print(f'epoch {epoch + 1}, loss {l:f}')\n</pre> # training procedure loss = logit_loss lm = nn.Sequential(nn.Linear(2, 1)) optim = torch.optim.SGD(lm.parameters(), lr=0.03)  # tuning parameters lr = 0.1 num_epochs = 10  # initialization # initialization of parameters lm[0].weight.data.normal_(0, 0.01) lm[0].bias.data.fill_(1)  # start training  for epoch in range(num_epochs):     for X_train, y_train in data_iter:         y_train = y_train.to(torch.float)         l = loss(lm(X_train), y_train)         # \u5bf9optimizer\u8fdb\u884czero_grad\u64cd\u4f5c\u53ef\u4ee5\u5c06\u5b9a\u4e49\u7684\u7ebf\u6027\u6a21\u578b\u7684\u53c2\u6570\u7684\u68af\u5ea6\u5316\u4e3a0         # \u6bcf\u6b65\u8fdb\u884c\u68af\u5ea6\u4e0b\u964d\u7684\u65f6\u5019\uff0c\u6211\u4eec\u90fd\u9700\u8981\u5c06\u4f18\u5316\u5668\u4e2d\u4fdd\u5b58\u7684\u53c2\u6570\u91cd\u7f6e\u4e3a0\uff0c\u5426\u5219\u8fd9\u6b21\u8ba1\u7b97\u7684\u68af\u5ea6\u5c31\u4f1a\u7d2f\u52a0\u5230\u4e0a\u6b21\u7684\u68af\u5ea6\u4e2d         optim.zero_grad()         l.backward()         # \u4f18\u5316\u5668\u8d70\u4e00\u6b65\uff0c\u5c31\u662f\u6839\u636e\u76ee\u524d\u7684\u68af\u5ea6\u8fdb\u884c\u4e00\u6b21\u68af\u5ea6\u4e0b\u964d         optim.step()     l = loss(lm(X), y)     print(f'epoch {epoch + 1}, loss {l:f}') <pre>epoch 1, loss 17.202641\nepoch 2, loss 14.917555\nepoch 3, loss 13.360222\nepoch 4, loss 12.256972\nepoch 5, loss 11.437306\nepoch 6, loss 10.835018\nepoch 7, loss 10.369900\nepoch 8, loss 9.999341\nepoch 9, loss 9.704663\nepoch 10, loss 9.456801\n</pre> In\u00a0[5]: Copied! <pre>mat = [[0] * 3 for _ in range(3)]\nmat\n</pre> mat = [[0] * 3 for _ in range(3)] mat Out[5]: <pre>[[0, 0, 0], [0, 0, 0], [0, 0, 0]]</pre> In\u00a0[6]: Copied! <pre>mat[0][1] = 1\n</pre> mat[0][1] = 1 In\u00a0[7]: Copied! <pre>mat\n</pre> mat Out[7]: <pre>[[0, 1, 0], [0, 0, 0], [0, 0, 0]]</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"markdown/knowledge/deep_learning_notebook/linear_models/#pytorch","title":"Pytorch\u57fa\u7840: \u6a21\u578b\u53c2\u6570\u8bbe\u7f6e\u548c\u8f93\u5165\u3001\u8f93\u51fa\u5f62\u72b6\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/linear_models/#dataset","title":"Dataset\u683c\u5f0f\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/linear_models/#linear-regression","title":"Linear Regression\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/linear_models/","title":"\u9996\u5148\u4f7f\u7528\u7c7b\u7684\u683c\u5f0f\u5199\u4e00\u4e2a\u5355\u5c42\u7ebf\u6027\u795e\u7ecf\u7f51\u7edc\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/linear_models/#nnsequential","title":"\u6211\u4eec\u8fd8\u53ef\u4ee5\u4f7f\u7528nn.Sequential\u7b80\u6d01\u5b9e\u73b0\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/linear_models/","title":"\u635f\u5931\u51fd\u6570\u548c\u4f18\u5316\u5668\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/linear_models/","title":"\u53cd\u5411\u4f20\u64ad\u8bad\u7ec3\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/linear_models/#logistic-regression","title":"Logistic Regression\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/linear_models/","title":"\u751f\u6210\u6a21\u62df\u6570\u636e\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/linear_models/#logistic","title":"Logistic \u635f\u5931\u51fd\u6570\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/linear_models/#logistic-regression","title":"\u8bad\u7ec3Logistic Regression\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/loss_funcs/","title":"pytorch\u5e38\u89c1\u635f\u5931\u51fd\u6570","text":"In\u00a0[1]: Copied! <pre>import torch\nimport torch.nn as nn\n</pre> import torch import torch.nn as nn <p>$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$</p> In\u00a0[\u00a0]: Copied! <pre># \u5b9a\u4e49\u8f93\u5165\u5f20\u91cf\ninput_tensor = torch.randn(3, 5)\ntarget_tensor = torch.randn(3, 5)\n</pre> # \u5b9a\u4e49\u8f93\u5165\u5f20\u91cf input_tensor = torch.randn(3, 5) target_tensor = torch.randn(3, 5) In\u00a0[\u00a0]: Copied! <pre>delta = input_tensor - target_tensor\nloss_check = (delta **2).sum() / (delta.shape[0] * delta.shape[1])\nloss_check\n</pre> delta = input_tensor - target_tensor loss_check = (delta **2).sum() / (delta.shape[0] * delta.shape[1]) loss_check <pre>tensor(0.9925)</pre> In\u00a0[\u00a0]: Copied! <pre># \u5b9a\u4e49\u635f\u5931\u51fd\u6570\nmse = nn.MSELoss()\n\n# \u8ba1\u7b97\u635f\u5931\nloss = mse(input_tensor, target_tensor)\nloss, loss == loss_check\n</pre> # \u5b9a\u4e49\u635f\u5931\u51fd\u6570 mse = nn.MSELoss()  # \u8ba1\u7b97\u635f\u5931 loss = mse(input_tensor, target_tensor) loss, loss == loss_check <pre>(tensor(0.9925), tensor(True))</pre> <p>$$\\text{MAE} = \\frac{1}{n}\\sum_{i=1}^{n}\\left|y_i - \\hat{y}_i\\right|$$</p> In\u00a0[\u00a0]: Copied! <pre># \u5b9a\u4e49\u8f93\u5165\u5f20\u91cf\ninput_tensor = torch.randn(3, 5)\ntarget_tensor = torch.randn(3, 5)\n</pre> # \u5b9a\u4e49\u8f93\u5165\u5f20\u91cf input_tensor = torch.randn(3, 5) target_tensor = torch.randn(3, 5) In\u00a0[\u00a0]: Copied! <pre>delta = input_tensor - target_tensor\nloss_check = abs(delta).sum() / (delta.shape[0] * delta.shape[1])\nloss_check\n</pre> delta = input_tensor - target_tensor loss_check = abs(delta).sum() / (delta.shape[0] * delta.shape[1]) loss_check <pre>tensor(1.1050)</pre> In\u00a0[\u00a0]: Copied! <pre># \u5b9a\u4e49\u635f\u5931\u51fd\u6570\nmae = nn.L1Loss()\n\n# \u8ba1\u7b97\u635f\u5931\nloss = mae(input_tensor, target_tensor)\nloss, loss == loss_check\n</pre> # \u5b9a\u4e49\u635f\u5931\u51fd\u6570 mae = nn.L1Loss()  # \u8ba1\u7b97\u635f\u5931 loss = mae(input_tensor, target_tensor) loss, loss == loss_check <pre>(tensor(1.1050), tensor(True))</pre> <p>$$\\text{CrossEntropyLoss}(\\mathbf{p}, \\mathbf{y}) = -\\sum_i y_i \\log(p_i)$$ \u5176\u4e2d\uff0cyi\u200b \u662f\u771f\u5b9e\u6807\u7b7e\u4e2d\u7b2c i \u7c7b\u7684\u6982\u7387\uff08\u901a\u5e38\u4e3a 0 \u6216 1\uff09\uff0cpi\u200b \u662f\u6a21\u578b\u8f93\u51fa\u7684\u6982\u7387\u3002 nn.CrossEntropyLoss\u6ce8\u610f\u70b9</p> <ul> <li>\u5982\u679c\u4e0d\u540c\u7c7b\u522b\u5bf9\u5e94\u7684\u6743\u91cd\u4e0d\u540c\uff0c\u4f20\u5165\u7684\u6743\u91cd\u53c2\u6570\u5e94\u8be5\u662f\u4e00\u4e2a1\u7ef4\u7684tensor\u3002</li> <li>\u8f93\u5165\u7684\u6bcf\u4e00\u7c7b\u7684\u7f6e\u4fe1\u5ea6\u5f97\u5206\uff08input\uff09\u5e94\u8be5\u662f\u539f\u59cb\u7684\uff0c\u672a\u7ecf\u8fc7softmax\u6216\u8005normalized\u3002\u539f\u56e0\u662f\u8fd9\u4e2a\u51fd\u6570\u4f1a\u9996\u5148\u5bf9\u8f93\u5165\u7684\u539f\u59cb\u5f97\u5206\u8fdb\u884csoftmax\uff0c\u6240\u4ee5\u5fc5\u987b\u4fdd\u8bc1\u8f93\u5165\u7684\u662f\u6bcf\u4e00\u7c7b\u7684\u539f\u59cb\u5f97\u5206\u3002\u4e0d\u80fd\u5199\u6210[0.2, 0.36, 0.44]\u8fd9\u79cdsoftmax\u4e4b\u540e\u7684\u6216\u8005[0, 1, 0]\u8fd9\u79cdone-hot\u7f16\u7801\u3002</li> <li>\u8f93\u5165\u7684target\u4e5f\u4e0d\u80fd\u662fone-hot\u6807\u7b7e\uff0c\u76f4\u63a5\u8f93\u5165\u6bcf\u4e2a\u4f8b\u5b50\u5bf9\u5e94\u7684\u7c7b\u522b\u7f16\u53f7\u5c31\u884c\u4e86\uff080 &lt; target_value &lt; C-1\uff09\uff0c\u6bd4\u5982\u4ea7\u751f\u7684\u7ed3\u679c\u6570\u4e3aN*C\uff08N\u4e3a\u4e2a\u6570\uff0cC\u4e3a\u7c7b\u522b\u6570\uff09\uff0c\u90a3\u4e48\u8f93\u5165\u7684target\u5fc5\u987b\u8f93\u5165\u4e00\u4e2a\u957f\u5ea6\u4e3aN\u7684\u4e00\u7ef4tensor\uff08\u6307\u660e\u6bcf\u4e2a\u7ed3\u679c\u5c5e\u4e8e\u54ea\u4e00\u7c7b\uff0c\u5982[1, 3, 0],\u51fd\u6570\u5185\u90e8\u4f1a\u81ea\u52a8\u8f6c\u5316\u4e3aone-hot\u6807\u7b7e\uff09\u3002 nn.CrossEntropyLoss</li> </ul> <p>nn.loss</p>"},{"location":"markdown/knowledge/deep_learning_notebook/loss_funcs/#pytorch","title":"pytorch\u5e38\u89c1\u635f\u5931\u51fd\u6570\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/loss_funcs/#nnmseloss","title":"nn.MSELoss\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/loss_funcs/#nnl1loss-mae-loss","title":"nn.L1Loss (MAE Loss)\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/loss_funcs/#nncrossentropyloss","title":"nn.CrossEntropyLoss\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/loss_funcs/","title":"\u53c2\u8003\u94fe\u63a5\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/myutils/","title":"Myutils","text":"In\u00a0[\u00a0]: Copied! <pre>DATA_HUB = dict()\nDATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'\n</pre> DATA_HUB = dict() DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/' <p>credit to d2l module with little modification</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport torch\nimport torchvision\nfrom PIL import Image\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils import data\nfrom torchvision import transforms\n</pre> import numpy as np import torch import torchvision from PIL import Image from torch import nn from torch.nn import functional as F from torch.utils import data from torchvision import transforms In\u00a0[\u00a0]: Copied! <pre>nn_Module = nn.Module\n</pre> nn_Module = nn.Module <p>################   WARNING   ################ The below part is generated automatically through: d2lbook build lib Don't edit it directly</p> In\u00a0[\u00a0]: Copied! <pre>import collections\nimport hashlib\nimport inspect\nimport math\nimport os\nimport random\nimport re\nimport shutil\nimport sys\nimport tarfile\nimport time\nimport zipfile\nfrom collections import defaultdict\nimport gym\nimport pandas as pd\nimport requests\nfrom IPython import display\nfrom matplotlib import pyplot as plt\nfrom matplotlib_inline import backend_inline\nfrom scipy.spatial import distance_matrix\n</pre> import collections import hashlib import inspect import math import os import random import re import shutil import sys import tarfile import time import zipfile from collections import defaultdict import gym import pandas as pd import requests from IPython import display from matplotlib import pyplot as plt from matplotlib_inline import backend_inline from scipy.spatial import distance_matrix In\u00a0[\u00a0]: Copied! <pre>myutils = sys.modules[__name__]\n</pre> myutils = sys.modules[__name__] In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport torch\nimport torchvision\nfrom PIL import Image\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torchvision import transforms\n</pre> import numpy as np import torch import torchvision from PIL import Image from torch import nn from torch.nn import functional as F from torchvision import transforms In\u00a0[\u00a0]: Copied! <pre>def use_svg_display():\n    \"\"\"Use the svg format to display a plot in Jupyter.\n    Defined in :numref:`sec_calculus`\"\"\"\n    backend_inline.set_matplotlib_formats('svg')\n</pre> def use_svg_display():     \"\"\"Use the svg format to display a plot in Jupyter.     Defined in :numref:`sec_calculus`\"\"\"     backend_inline.set_matplotlib_formats('svg') In\u00a0[\u00a0]: Copied! <pre>def set_figsize(figsize=(3.5, 2.5)):\n    \"\"\"Set the figure size for matplotlib.\n    Defined in :numref:`sec_calculus`\"\"\"\n    use_svg_display()\n    myutils.plt.rcParams['figure.figsize'] = figsize\n</pre> def set_figsize(figsize=(3.5, 2.5)):     \"\"\"Set the figure size for matplotlib.     Defined in :numref:`sec_calculus`\"\"\"     use_svg_display()     myutils.plt.rcParams['figure.figsize'] = figsize In\u00a0[\u00a0]: Copied! <pre>def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n    \"\"\"Set the axes for matplotlib.\n    Defined in :numref:`sec_calculus`\"\"\"\n    axes.set_xlabel(xlabel), axes.set_ylabel(ylabel)\n    axes.set_xscale(xscale), axes.set_yscale(yscale)\n    axes.set_xlim(xlim), axes.set_ylim(ylim)\n    if legend:\n        axes.legend(legend)\n    axes.grid()\n</pre> def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):     \"\"\"Set the axes for matplotlib.     Defined in :numref:`sec_calculus`\"\"\"     axes.set_xlabel(xlabel), axes.set_ylabel(ylabel)     axes.set_xscale(xscale), axes.set_yscale(yscale)     axes.set_xlim(xlim), axes.set_ylim(ylim)     if legend:         axes.legend(legend)     axes.grid() In\u00a0[\u00a0]: Copied! <pre>def plot(X, Y=None, xlabel=None, ylabel=None, legend=[], xlim=None,\n         ylim=None, xscale='linear', yscale='linear',\n         fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):\n    \"\"\"Plot data points.\n    Defined in :numref:`sec_calculus`\"\"\"\n\n    def has_one_axis(X):  # True if X (tensor or list) has 1 axis\n        return (hasattr(X, \"ndim\") and X.ndim == 1 or isinstance(X, list)\n                and not hasattr(X[0], \"__len__\"))\n\n    if has_one_axis(X): X = [X]\n    if Y is None:\n        X, Y = [[]] * len(X), X\n    elif has_one_axis(Y):\n        Y = [Y]\n    if len(X) != len(Y):\n        X = X * len(Y)\n\n    set_figsize(figsize)\n    if axes is None:\n        axes = myutils.plt.gca()\n    axes.cla()\n    for x, y, fmt in zip(X, Y, fmts):\n        axes.plot(x, y, fmt) if len(x) else axes.plot(y, fmt)\n    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n</pre> def plot(X, Y=None, xlabel=None, ylabel=None, legend=[], xlim=None,          ylim=None, xscale='linear', yscale='linear',          fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):     \"\"\"Plot data points.     Defined in :numref:`sec_calculus`\"\"\"      def has_one_axis(X):  # True if X (tensor or list) has 1 axis         return (hasattr(X, \"ndim\") and X.ndim == 1 or isinstance(X, list)                 and not hasattr(X[0], \"__len__\"))      if has_one_axis(X): X = [X]     if Y is None:         X, Y = [[]] * len(X), X     elif has_one_axis(Y):         Y = [Y]     if len(X) != len(Y):         X = X * len(Y)      set_figsize(figsize)     if axes is None:         axes = myutils.plt.gca()     axes.cla()     for x, y, fmt in zip(X, Y, fmts):         axes.plot(x, y, fmt) if len(x) else axes.plot(y, fmt)     set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend) In\u00a0[\u00a0]: Copied! <pre>def add_to_class(Class):\n    \"\"\"Register functions as methods in created class.\n    Defined in :numref:`sec_oo-design`\"\"\"\n\n    def wrapper(obj):\n        setattr(Class, obj.__name__, obj)\n\n    return wrapper\n</pre> def add_to_class(Class):     \"\"\"Register functions as methods in created class.     Defined in :numref:`sec_oo-design`\"\"\"      def wrapper(obj):         setattr(Class, obj.__name__, obj)      return wrapper In\u00a0[\u00a0]: Copied! <pre>class HyperParameters:\n    \"\"\"The base class of hyperparameters.\"\"\"\n\n    def save_hyperparameters(self, ignore=[]):\n        \"\"\"Defined in :numref:`sec_oo-design`\"\"\"\n        raise NotImplemented\n\n    def save_hyperparameters(self, ignore=[]):\n        \"\"\"Save function arguments into class attributes.\n    \n        Defined in :numref:`sec_utils`\"\"\"\n        frame = inspect.currentframe().f_back\n        _, _, _, local_vars = inspect.getargvalues(frame)\n        self.hparams = {k: v for k, v in local_vars.items()\n                        if k not in set(ignore + ['self']) and not k.startswith('_')}\n        for k, v in self.hparams.items():\n            setattr(self, k, v)\n</pre> class HyperParameters:     \"\"\"The base class of hyperparameters.\"\"\"      def save_hyperparameters(self, ignore=[]):         \"\"\"Defined in :numref:`sec_oo-design`\"\"\"         raise NotImplemented      def save_hyperparameters(self, ignore=[]):         \"\"\"Save function arguments into class attributes.              Defined in :numref:`sec_utils`\"\"\"         frame = inspect.currentframe().f_back         _, _, _, local_vars = inspect.getargvalues(frame)         self.hparams = {k: v for k, v in local_vars.items()                         if k not in set(ignore + ['self']) and not k.startswith('_')}         for k, v in self.hparams.items():             setattr(self, k, v) In\u00a0[\u00a0]: Copied! <pre>class ProgressBoard(myutils.HyperParameters):\n    \"\"\"The board that plots data points in animation.\n    Defined in :numref:`sec_oo-design`\"\"\"\n\n    def __init__(self, xlabel=None, ylabel=None, xlim=None,\n                 ylim=None, xscale='linear', yscale='linear',\n                 ls=['-', '--', '-.', ':'], colors=['C0', 'C1', 'C2', 'C3'],\n                 fig=None, axes=None, figsize=(3.5, 2.5), display=True):\n        self.save_hyperparameters()\n\n    def draw(self, x, y, label, every_n=1):\n        raise NotImplemented\n\n    def draw(self, x, y, label, every_n=1):\n        \"\"\"Defined in :numref:`sec_utils`\"\"\"\n        Point = collections.namedtuple('Point', ['x', 'y'])\n        if not hasattr(self, 'raw_points'):\n            self.raw_points = collections.OrderedDict()\n            self.data = collections.OrderedDict()\n        if label not in self.raw_points:\n            self.raw_points[label] = []\n            self.data[label] = []\n        points = self.raw_points[label]\n        line = self.data[label]\n        points.append(Point(x, y))\n        if len(points) != every_n:\n            return\n        mean = lambda x: sum(x) / len(x)\n        line.append(Point(mean([p.x for p in points]),\n                          mean([p.y for p in points])))\n        points.clear()\n        if not self.display:\n            return\n        myutils.use_svg_display()\n        if self.fig is None:\n            self.fig = myutils.plt.figure(figsize=self.figsize)\n        plt_lines, labels = [], []\n        for (k, v), ls, color in zip(self.data.items(), self.ls, self.colors):\n            plt_lines.append(myutils.plt.plot([p.x for p in v], [p.y for p in v],\n                                              linestyle=ls, color=color)[0])\n            labels.append(k)\n        axes = self.axes if self.axes else myutils.plt.gca()\n        if self.xlim: axes.set_xlim(self.xlim)\n        if self.ylim: axes.set_ylim(self.ylim)\n        if not self.xlabel: self.xlabel = self.x\n        axes.set_xlabel(self.xlabel)\n        axes.set_ylabel(self.ylabel)\n        axes.set_xscale(self.xscale)\n        axes.set_yscale(self.yscale)\n        axes.legend(plt_lines, labels)\n        display.display(self.fig)\n        display.clear_output(wait=True)\n</pre> class ProgressBoard(myutils.HyperParameters):     \"\"\"The board that plots data points in animation.     Defined in :numref:`sec_oo-design`\"\"\"      def __init__(self, xlabel=None, ylabel=None, xlim=None,                  ylim=None, xscale='linear', yscale='linear',                  ls=['-', '--', '-.', ':'], colors=['C0', 'C1', 'C2', 'C3'],                  fig=None, axes=None, figsize=(3.5, 2.5), display=True):         self.save_hyperparameters()      def draw(self, x, y, label, every_n=1):         raise NotImplemented      def draw(self, x, y, label, every_n=1):         \"\"\"Defined in :numref:`sec_utils`\"\"\"         Point = collections.namedtuple('Point', ['x', 'y'])         if not hasattr(self, 'raw_points'):             self.raw_points = collections.OrderedDict()             self.data = collections.OrderedDict()         if label not in self.raw_points:             self.raw_points[label] = []             self.data[label] = []         points = self.raw_points[label]         line = self.data[label]         points.append(Point(x, y))         if len(points) != every_n:             return         mean = lambda x: sum(x) / len(x)         line.append(Point(mean([p.x for p in points]),                           mean([p.y for p in points])))         points.clear()         if not self.display:             return         myutils.use_svg_display()         if self.fig is None:             self.fig = myutils.plt.figure(figsize=self.figsize)         plt_lines, labels = [], []         for (k, v), ls, color in zip(self.data.items(), self.ls, self.colors):             plt_lines.append(myutils.plt.plot([p.x for p in v], [p.y for p in v],                                               linestyle=ls, color=color)[0])             labels.append(k)         axes = self.axes if self.axes else myutils.plt.gca()         if self.xlim: axes.set_xlim(self.xlim)         if self.ylim: axes.set_ylim(self.ylim)         if not self.xlabel: self.xlabel = self.x         axes.set_xlabel(self.xlabel)         axes.set_ylabel(self.ylabel)         axes.set_xscale(self.xscale)         axes.set_yscale(self.yscale)         axes.legend(plt_lines, labels)         display.display(self.fig)         display.clear_output(wait=True) In\u00a0[\u00a0]: Copied! <pre>class Module(myutils.nn_Module, myutils.HyperParameters):\n    \"\"\"The base class of models.\n    Defined in :numref:`sec_oo-design`\"\"\"\n\n    def __init__(self, plot_train_per_epoch=2, plot_valid_per_epoch=1):\n        super().__init__()\n        self.save_hyperparameters()\n        self.board = ProgressBoard()\n\n    def loss(self, y_hat, y):\n        raise NotImplementedError\n\n    def forward(self, X):\n        assert hasattr(self, 'net'), 'Neural network is defined'\n        return self.net(X)\n\n    def plot(self, key, value, train):\n        \"\"\"Plot a point in animation.\"\"\"\n        assert hasattr(self, 'trainer'), 'Trainer is not inited'\n        self.board.xlabel = 'epoch'\n        if train:\n            x = self.trainer.train_batch_idx / \\\n                self.trainer.num_train_batches\n            n = self.trainer.num_train_batches / \\\n                self.plot_train_per_epoch\n        else:\n            x = self.trainer.epoch + 1\n            n = self.trainer.num_val_batches / \\\n                self.plot_valid_per_epoch\n        self.board.draw(x, myutils.numpy(myutils.to(value, myutils.cpu())),\n                        ('train_' if train else 'val_') + key,\n                        every_n=int(n))\n\n    def training_step(self, batch):\n        l = self.loss(self(*batch[:-1]), batch[-1])\n        self.plot('loss', l, train=True)\n        return l\n\n    def validation_step(self, batch):\n        l = self.loss(self(*batch[:-1]), batch[-1])\n        self.plot('loss', l, train=False)\n\n    def configure_optimizers(self):\n        raise NotImplementedError\n\n    def configure_optimizers(self):\n        \"\"\"Defined in :numref:`sec_classification`\"\"\"\n        return torch.optim.SGD(self.parameters(), lr=self.lr)\n\n    def apply_init(self, inputs, init=None):\n        \"\"\"Defined in :numref:`sec_lazy_init`\"\"\"\n        self.forward(*inputs)\n        if init is not None:\n            self.net.apply(init)\n</pre> class Module(myutils.nn_Module, myutils.HyperParameters):     \"\"\"The base class of models.     Defined in :numref:`sec_oo-design`\"\"\"      def __init__(self, plot_train_per_epoch=2, plot_valid_per_epoch=1):         super().__init__()         self.save_hyperparameters()         self.board = ProgressBoard()      def loss(self, y_hat, y):         raise NotImplementedError      def forward(self, X):         assert hasattr(self, 'net'), 'Neural network is defined'         return self.net(X)      def plot(self, key, value, train):         \"\"\"Plot a point in animation.\"\"\"         assert hasattr(self, 'trainer'), 'Trainer is not inited'         self.board.xlabel = 'epoch'         if train:             x = self.trainer.train_batch_idx / \\                 self.trainer.num_train_batches             n = self.trainer.num_train_batches / \\                 self.plot_train_per_epoch         else:             x = self.trainer.epoch + 1             n = self.trainer.num_val_batches / \\                 self.plot_valid_per_epoch         self.board.draw(x, myutils.numpy(myutils.to(value, myutils.cpu())),                         ('train_' if train else 'val_') + key,                         every_n=int(n))      def training_step(self, batch):         l = self.loss(self(*batch[:-1]), batch[-1])         self.plot('loss', l, train=True)         return l      def validation_step(self, batch):         l = self.loss(self(*batch[:-1]), batch[-1])         self.plot('loss', l, train=False)      def configure_optimizers(self):         raise NotImplementedError      def configure_optimizers(self):         \"\"\"Defined in :numref:`sec_classification`\"\"\"         return torch.optim.SGD(self.parameters(), lr=self.lr)      def apply_init(self, inputs, init=None):         \"\"\"Defined in :numref:`sec_lazy_init`\"\"\"         self.forward(*inputs)         if init is not None:             self.net.apply(init) In\u00a0[\u00a0]: Copied! <pre>class DataModule(myutils.HyperParameters):\n    \"\"\"The base class of data.\n    Defined in :numref:`subsec_oo-design-models`\"\"\"\n\n    def __init__(self, root='./chpdata/data', num_workers=4):\n        self.save_hyperparameters()\n\n    def get_dataloader(self, train):\n        raise NotImplementedError\n\n    def train_dataloader(self):\n        return self.get_dataloader(train=True)\n\n    def val_dataloader(self):\n        return self.get_dataloader(train=False)\n\n    def get_tensorloader(self, tensors, train, indices=slice(0, None)):\n        \"\"\"Defined in :numref:`sec_synthetic-regression-data`\"\"\"\n        tensors = tuple(a[indices] for a in tensors)\n        dataset = torch.utils.data.TensorDataset(*tensors)\n        return torch.utils.data.DataLoader(dataset, self.batch_size,\n                                           shuffle=train)\n</pre> class DataModule(myutils.HyperParameters):     \"\"\"The base class of data.     Defined in :numref:`subsec_oo-design-models`\"\"\"      def __init__(self, root='./chpdata/data', num_workers=4):         self.save_hyperparameters()      def get_dataloader(self, train):         raise NotImplementedError      def train_dataloader(self):         return self.get_dataloader(train=True)      def val_dataloader(self):         return self.get_dataloader(train=False)      def get_tensorloader(self, tensors, train, indices=slice(0, None)):         \"\"\"Defined in :numref:`sec_synthetic-regression-data`\"\"\"         tensors = tuple(a[indices] for a in tensors)         dataset = torch.utils.data.TensorDataset(*tensors)         return torch.utils.data.DataLoader(dataset, self.batch_size,                                            shuffle=train) In\u00a0[\u00a0]: Copied! <pre>class Trainer(myutils.HyperParameters):\n    \"\"\"The base class for training models with data.\n    Defined in :numref:`subsec_oo-design-models`\"\"\"\n\n    def __init__(self, max_epochs, num_gpus=0, gradient_clip_val=0):\n        self.save_hyperparameters()\n        assert num_gpus == 0, 'No GPU support yet'\n\n    def prepare_data(self, data):\n        self.train_dataloader = data.train_dataloader()\n        self.val_dataloader = data.val_dataloader()\n        self.num_train_batches = len(self.train_dataloader)\n        self.num_val_batches = (len(self.val_dataloader)\n                                if self.val_dataloader is not None else 0)\n\n    def prepare_model(self, model):\n        model.trainer = self\n        model.board.xlim = [0, self.max_epochs]\n        self.model = model\n\n    def fit(self, model, data):\n        self.prepare_data(data)\n        self.prepare_model(model)\n        self.optim = model.configure_optimizers()\n        self.epoch = 0\n        self.train_batch_idx = 0\n        self.val_batch_idx = 0\n        for self.epoch in range(self.max_epochs):\n            self.fit_epoch()\n\n    def fit_epoch(self):\n        raise NotImplementedError\n\n    def prepare_batch(self, batch):\n        \"\"\"Defined in :numref:`sec_linear_scratch`\"\"\"\n        return batch\n\n    def fit_epoch(self):\n        \"\"\"Defined in :numref:`sec_linear_scratch`\"\"\"\n        self.model.train()\n        for batch in self.train_dataloader:\n            loss = self.model.training_step(self.prepare_batch(batch))\n            self.optim.zero_grad()\n            with torch.no_grad():\n                loss.backward()\n                if self.gradient_clip_val &gt; 0:  # To be discussed later\n                    self.clip_gradients(self.gradient_clip_val, self.model)\n                self.optim.step()\n            self.train_batch_idx += 1\n        if self.val_dataloader is None:\n            return\n        self.model.eval()\n        for batch in self.val_dataloader:\n            with torch.no_grad():\n                self.model.validation_step(self.prepare_batch(batch))\n            self.val_batch_idx += 1\n\n    def __init__(self, max_epochs, num_gpus=0, gradient_clip_val=0):\n        \"\"\"Defined in :numref:`sec_use_gpu`\"\"\"\n        self.save_hyperparameters()\n        self.gpus = [myutils.gpu(i) for i in range(min(num_gpus, myutils.num_gpus()))]\n\n    def prepare_batch(self, batch):\n        \"\"\"Defined in :numref:`sec_use_gpu`\"\"\"\n        if self.gpus:\n            batch = [myutils.to(a, self.gpus[0]) for a in batch]\n        return batch\n\n    def prepare_model(self, model):\n        \"\"\"Defined in :numref:`sec_use_gpu`\"\"\"\n        model.trainer = self\n        model.board.xlim = [0, self.max_epochs]\n        if self.gpus:\n            model.to(self.gpus[0])\n        self.model = model\n\n    def clip_gradients(self, grad_clip_val, model):\n        \"\"\"Defined in :numref:`sec_rnn-scratch`\"\"\"\n        params = [p for p in model.parameters() if p.requires_grad]\n        norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n        if norm &gt; grad_clip_val:\n            for param in params:\n                param.grad[:] *= grad_clip_val / norm\n</pre> class Trainer(myutils.HyperParameters):     \"\"\"The base class for training models with data.     Defined in :numref:`subsec_oo-design-models`\"\"\"      def __init__(self, max_epochs, num_gpus=0, gradient_clip_val=0):         self.save_hyperparameters()         assert num_gpus == 0, 'No GPU support yet'      def prepare_data(self, data):         self.train_dataloader = data.train_dataloader()         self.val_dataloader = data.val_dataloader()         self.num_train_batches = len(self.train_dataloader)         self.num_val_batches = (len(self.val_dataloader)                                 if self.val_dataloader is not None else 0)      def prepare_model(self, model):         model.trainer = self         model.board.xlim = [0, self.max_epochs]         self.model = model      def fit(self, model, data):         self.prepare_data(data)         self.prepare_model(model)         self.optim = model.configure_optimizers()         self.epoch = 0         self.train_batch_idx = 0         self.val_batch_idx = 0         for self.epoch in range(self.max_epochs):             self.fit_epoch()      def fit_epoch(self):         raise NotImplementedError      def prepare_batch(self, batch):         \"\"\"Defined in :numref:`sec_linear_scratch`\"\"\"         return batch      def fit_epoch(self):         \"\"\"Defined in :numref:`sec_linear_scratch`\"\"\"         self.model.train()         for batch in self.train_dataloader:             loss = self.model.training_step(self.prepare_batch(batch))             self.optim.zero_grad()             with torch.no_grad():                 loss.backward()                 if self.gradient_clip_val &gt; 0:  # To be discussed later                     self.clip_gradients(self.gradient_clip_val, self.model)                 self.optim.step()             self.train_batch_idx += 1         if self.val_dataloader is None:             return         self.model.eval()         for batch in self.val_dataloader:             with torch.no_grad():                 self.model.validation_step(self.prepare_batch(batch))             self.val_batch_idx += 1      def __init__(self, max_epochs, num_gpus=0, gradient_clip_val=0):         \"\"\"Defined in :numref:`sec_use_gpu`\"\"\"         self.save_hyperparameters()         self.gpus = [myutils.gpu(i) for i in range(min(num_gpus, myutils.num_gpus()))]      def prepare_batch(self, batch):         \"\"\"Defined in :numref:`sec_use_gpu`\"\"\"         if self.gpus:             batch = [myutils.to(a, self.gpus[0]) for a in batch]         return batch      def prepare_model(self, model):         \"\"\"Defined in :numref:`sec_use_gpu`\"\"\"         model.trainer = self         model.board.xlim = [0, self.max_epochs]         if self.gpus:             model.to(self.gpus[0])         self.model = model      def clip_gradients(self, grad_clip_val, model):         \"\"\"Defined in :numref:`sec_rnn-scratch`\"\"\"         params = [p for p in model.parameters() if p.requires_grad]         norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))         if norm &gt; grad_clip_val:             for param in params:                 param.grad[:] *= grad_clip_val / norm In\u00a0[\u00a0]: Copied! <pre>class SyntheticRegressionData(myutils.DataModule):\n    \"\"\"Synthetic data for linear regression.\n    Defined in :numref:`sec_synthetic-regression-data`\"\"\"\n\n    def __init__(self, w, b, noise=0.01, num_train=1000, num_val=1000,\n                 batch_size=32):\n        super().__init__()\n        self.save_hyperparameters()\n        n = num_train + num_val\n        self.X = myutils.randn(n, len(w))\n        noise = myutils.randn(n, 1) * noise\n        self.y = myutils.matmul(self.X, myutils.reshape(w, (-1, 1))) + b + noise\n\n    def get_dataloader(self, train):\n        \"\"\"Defined in :numref:`sec_synthetic-regression-data`\"\"\"\n        i = slice(0, self.num_train) if train else slice(self.num_train, None)\n        return self.get_tensorloader((self.X, self.y), train, i)\n</pre> class SyntheticRegressionData(myutils.DataModule):     \"\"\"Synthetic data for linear regression.     Defined in :numref:`sec_synthetic-regression-data`\"\"\"      def __init__(self, w, b, noise=0.01, num_train=1000, num_val=1000,                  batch_size=32):         super().__init__()         self.save_hyperparameters()         n = num_train + num_val         self.X = myutils.randn(n, len(w))         noise = myutils.randn(n, 1) * noise         self.y = myutils.matmul(self.X, myutils.reshape(w, (-1, 1))) + b + noise      def get_dataloader(self, train):         \"\"\"Defined in :numref:`sec_synthetic-regression-data`\"\"\"         i = slice(0, self.num_train) if train else slice(self.num_train, None)         return self.get_tensorloader((self.X, self.y), train, i) In\u00a0[\u00a0]: Copied! <pre>class LinearRegressionScratch(myutils.Module):\n    \"\"\"The linear regression model implemented from scratch.\n    Defined in :numref:`sec_linear_scratch`\"\"\"\n\n    def __init__(self, num_inputs, lr, sigma=0.01):\n        super().__init__()\n        self.save_hyperparameters()\n        self.w = myutils.normal(0, sigma, (num_inputs, 1), requires_grad=True)\n        self.b = myutils.zeros(1, requires_grad=True)\n\n    def forward(self, X):\n        \"\"\"Defined in :numref:`sec_linear_scratch`\"\"\"\n        return myutils.matmul(X, self.w) + self.b\n\n    def loss(self, y_hat, y):\n        \"\"\"Defined in :numref:`sec_linear_scratch`\"\"\"\n        l = (y_hat - y) ** 2 / 2\n        return myutils.reduce_mean(l)\n\n    def configure_optimizers(self):\n        \"\"\"Defined in :numref:`sec_linear_scratch`\"\"\"\n        return SGD([self.w, self.b], self.lr)\n</pre> class LinearRegressionScratch(myutils.Module):     \"\"\"The linear regression model implemented from scratch.     Defined in :numref:`sec_linear_scratch`\"\"\"      def __init__(self, num_inputs, lr, sigma=0.01):         super().__init__()         self.save_hyperparameters()         self.w = myutils.normal(0, sigma, (num_inputs, 1), requires_grad=True)         self.b = myutils.zeros(1, requires_grad=True)      def forward(self, X):         \"\"\"Defined in :numref:`sec_linear_scratch`\"\"\"         return myutils.matmul(X, self.w) + self.b      def loss(self, y_hat, y):         \"\"\"Defined in :numref:`sec_linear_scratch`\"\"\"         l = (y_hat - y) ** 2 / 2         return myutils.reduce_mean(l)      def configure_optimizers(self):         \"\"\"Defined in :numref:`sec_linear_scratch`\"\"\"         return SGD([self.w, self.b], self.lr) In\u00a0[\u00a0]: Copied! <pre>class SGD(myutils.HyperParameters):\n    \"\"\"Minibatch stochastic gradient descent.\n    Defined in :numref:`sec_linear_scratch`\"\"\"\n\n    def __init__(self, params, lr):\n        self.save_hyperparameters()\n\n    def step(self):\n        for param in self.params:\n            param -= self.lr * param.grad\n\n    def zero_grad(self):\n        for param in self.params:\n            if param.grad is not None:\n                param.grad.zero_()\n</pre> class SGD(myutils.HyperParameters):     \"\"\"Minibatch stochastic gradient descent.     Defined in :numref:`sec_linear_scratch`\"\"\"      def __init__(self, params, lr):         self.save_hyperparameters()      def step(self):         for param in self.params:             param -= self.lr * param.grad      def zero_grad(self):         for param in self.params:             if param.grad is not None:                 param.grad.zero_() In\u00a0[\u00a0]: Copied! <pre>class LinearRegression(myutils.Module):\n    \"\"\"The linear regression model implemented with high-level APIs.\n    Defined in :numref:`sec_linear_concise`\"\"\"\n\n    def __init__(self, lr):\n        super().__init__()\n        self.save_hyperparameters()\n        self.net = nn.LazyLinear(1)\n        self.net.weight.data.normal_(0, 0.01)\n        self.net.bias.data.fill_(0)\n\n    def forward(self, X):\n        \"\"\"Defined in :numref:`sec_linear_concise`\"\"\"\n        return self.net(X)\n\n    def loss(self, y_hat, y):\n        \"\"\"Defined in :numref:`sec_linear_concise`\"\"\"\n        fn = nn.MSELoss()\n        return fn(y_hat, y)\n\n    def configure_optimizers(self):\n        \"\"\"Defined in :numref:`sec_linear_concise`\"\"\"\n        return torch.optim.SGD(self.parameters(), self.lr)\n\n    def get_w_b(self):\n        \"\"\"Defined in :numref:`sec_linear_concise`\"\"\"\n        return (self.net.weight.data, self.net.bias.data)\n</pre> class LinearRegression(myutils.Module):     \"\"\"The linear regression model implemented with high-level APIs.     Defined in :numref:`sec_linear_concise`\"\"\"      def __init__(self, lr):         super().__init__()         self.save_hyperparameters()         self.net = nn.LazyLinear(1)         self.net.weight.data.normal_(0, 0.01)         self.net.bias.data.fill_(0)      def forward(self, X):         \"\"\"Defined in :numref:`sec_linear_concise`\"\"\"         return self.net(X)      def loss(self, y_hat, y):         \"\"\"Defined in :numref:`sec_linear_concise`\"\"\"         fn = nn.MSELoss()         return fn(y_hat, y)      def configure_optimizers(self):         \"\"\"Defined in :numref:`sec_linear_concise`\"\"\"         return torch.optim.SGD(self.parameters(), self.lr)      def get_w_b(self):         \"\"\"Defined in :numref:`sec_linear_concise`\"\"\"         return (self.net.weight.data, self.net.bias.data) In\u00a0[\u00a0]: Copied! <pre>class FashionMNIST(myutils.DataModule):\n    \"\"\"The Fashion-MNIST dataset.\n    Defined in :numref:`sec_fashion_mnist`\"\"\"\n\n    def __init__(self, batch_size=64, resize=(28, 28)):\n        super().__init__()\n        self.save_hyperparameters()\n        trans = transforms.Compose([transforms.Resize(resize),\n                                    transforms.ToTensor()])\n        self.train = torchvision.datasets.FashionMNIST(\n            root=self.root, train=True, transform=trans, download=True)\n        self.val = torchvision.datasets.FashionMNIST(\n            root=self.root, train=False, transform=trans, download=True)\n\n    def text_labels(self, indices):\n        \"\"\"Return text labels.\n    \n        Defined in :numref:`sec_fashion_mnist`\"\"\"\n        labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n                  'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n        return [labels[int(i)] for i in indices]\n\n    def get_dataloader(self, train):\n        \"\"\"Defined in :numref:`sec_fashion_mnist`\"\"\"\n        data = self.train if train else self.val\n        return torch.utils.data.DataLoader(data, self.batch_size, shuffle=train,\n                                           num_workers=self.num_workers)\n\n    def visualize(self, batch, nrows=1, ncols=8, labels=[]):\n        \"\"\"Defined in :numref:`sec_fashion_mnist`\"\"\"\n        X, y = batch\n        if not labels:\n            labels = self.text_labels(y)\n        myutils.show_images(X.squeeze(1), nrows, ncols, titles=labels)\n</pre> class FashionMNIST(myutils.DataModule):     \"\"\"The Fashion-MNIST dataset.     Defined in :numref:`sec_fashion_mnist`\"\"\"      def __init__(self, batch_size=64, resize=(28, 28)):         super().__init__()         self.save_hyperparameters()         trans = transforms.Compose([transforms.Resize(resize),                                     transforms.ToTensor()])         self.train = torchvision.datasets.FashionMNIST(             root=self.root, train=True, transform=trans, download=True)         self.val = torchvision.datasets.FashionMNIST(             root=self.root, train=False, transform=trans, download=True)      def text_labels(self, indices):         \"\"\"Return text labels.              Defined in :numref:`sec_fashion_mnist`\"\"\"         labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']         return [labels[int(i)] for i in indices]      def get_dataloader(self, train):         \"\"\"Defined in :numref:`sec_fashion_mnist`\"\"\"         data = self.train if train else self.val         return torch.utils.data.DataLoader(data, self.batch_size, shuffle=train,                                            num_workers=self.num_workers)      def visualize(self, batch, nrows=1, ncols=8, labels=[]):         \"\"\"Defined in :numref:`sec_fashion_mnist`\"\"\"         X, y = batch         if not labels:             labels = self.text_labels(y)         myutils.show_images(X.squeeze(1), nrows, ncols, titles=labels) In\u00a0[\u00a0]: Copied! <pre>def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n    \"\"\"Plot a list of images.\n    Defined in :numref:`sec_fashion_mnist`\"\"\"\n    raise NotImplementedError\n</pre> def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):     \"\"\"Plot a list of images.     Defined in :numref:`sec_fashion_mnist`\"\"\"     raise NotImplementedError In\u00a0[\u00a0]: Copied! <pre>class Classifier(myutils.Module):\n    \"\"\"The base class of classification models.\n    Defined in :numref:`sec_classification`\"\"\"\n\n    def validation_step(self, batch):\n        Y_hat = self(*batch[:-1])\n        self.plot('loss', self.loss(Y_hat, batch[-1]), train=False)\n        self.plot('acc', self.accuracy(Y_hat, batch[-1]), train=False)\n\n    def accuracy(self, Y_hat, Y, averaged=True):\n        \"\"\"Compute the number of correct predictions.\n    \n        Defined in :numref:`sec_classification`\"\"\"\n        Y_hat = myutils.reshape(Y_hat, (-1, Y_hat.shape[-1]))\n        preds = myutils.astype(myutils.argmax(Y_hat, axis=1), Y.dtype)\n        compare = myutils.astype(preds == myutils.reshape(Y, -1), myutils.float32)\n        return myutils.reduce_mean(compare) if averaged else compare\n\n    def loss(self, Y_hat, Y, averaged=True):\n        \"\"\"Defined in :numref:`sec_softmax_concise`\"\"\"\n        Y_hat = myutils.reshape(Y_hat, (-1, Y_hat.shape[-1]))\n        Y = myutils.reshape(Y, (-1,))\n        return F.cross_entropy(\n            Y_hat, Y, reduction='mean' if averaged else 'none')\n\n    def layer_summary(self, X_shape):\n        \"\"\"Defined in :numref:`sec_lenet`\"\"\"\n        X = myutils.randn(*X_shape)\n        for layer in self.net:\n            X = layer(X)\n            print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n</pre> class Classifier(myutils.Module):     \"\"\"The base class of classification models.     Defined in :numref:`sec_classification`\"\"\"      def validation_step(self, batch):         Y_hat = self(*batch[:-1])         self.plot('loss', self.loss(Y_hat, batch[-1]), train=False)         self.plot('acc', self.accuracy(Y_hat, batch[-1]), train=False)      def accuracy(self, Y_hat, Y, averaged=True):         \"\"\"Compute the number of correct predictions.              Defined in :numref:`sec_classification`\"\"\"         Y_hat = myutils.reshape(Y_hat, (-1, Y_hat.shape[-1]))         preds = myutils.astype(myutils.argmax(Y_hat, axis=1), Y.dtype)         compare = myutils.astype(preds == myutils.reshape(Y, -1), myutils.float32)         return myutils.reduce_mean(compare) if averaged else compare      def loss(self, Y_hat, Y, averaged=True):         \"\"\"Defined in :numref:`sec_softmax_concise`\"\"\"         Y_hat = myutils.reshape(Y_hat, (-1, Y_hat.shape[-1]))         Y = myutils.reshape(Y, (-1,))         return F.cross_entropy(             Y_hat, Y, reduction='mean' if averaged else 'none')      def layer_summary(self, X_shape):         \"\"\"Defined in :numref:`sec_lenet`\"\"\"         X = myutils.randn(*X_shape)         for layer in self.net:             X = layer(X)             print(layer.__class__.__name__, 'output shape:\\t', X.shape) In\u00a0[\u00a0]: Copied! <pre>class SoftmaxRegression(myutils.Classifier):\n    \"\"\"The softmax regression model.\n    Defined in :numref:`sec_softmax_concise`\"\"\"\n\n    def __init__(self, num_outputs, lr):\n        super().__init__()\n        self.save_hyperparameters()\n        self.net = nn.Sequential(nn.Flatten(),\n                                 nn.LazyLinear(num_outputs))\n\n    def forward(self, X):\n        return self.net(X)\n</pre> class SoftmaxRegression(myutils.Classifier):     \"\"\"The softmax regression model.     Defined in :numref:`sec_softmax_concise`\"\"\"      def __init__(self, num_outputs, lr):         super().__init__()         self.save_hyperparameters()         self.net = nn.Sequential(nn.Flatten(),                                  nn.LazyLinear(num_outputs))      def forward(self, X):         return self.net(X) In\u00a0[\u00a0]: Copied! <pre>def cpu():\n    \"\"\"Get the CPU device.\n    Defined in :numref:`sec_use_gpu`\"\"\"\n    return torch.device('cpu')\n</pre> def cpu():     \"\"\"Get the CPU device.     Defined in :numref:`sec_use_gpu`\"\"\"     return torch.device('cpu') In\u00a0[\u00a0]: Copied! <pre>def gpu(i=0):\n    \"\"\"Get a GPU device.\n    Defined in :numref:`sec_use_gpu`\"\"\"\n    return torch.device(f'cuda:{i}')\n</pre> def gpu(i=0):     \"\"\"Get a GPU device.     Defined in :numref:`sec_use_gpu`\"\"\"     return torch.device(f'cuda:{i}') In\u00a0[\u00a0]: Copied! <pre>def num_gpus():\n    \"\"\"Get the number of available GPUs.\n    Defined in :numref:`sec_use_gpu`\"\"\"\n    return torch.cuda.device_count()\n</pre> def num_gpus():     \"\"\"Get the number of available GPUs.     Defined in :numref:`sec_use_gpu`\"\"\"     return torch.cuda.device_count() In\u00a0[\u00a0]: Copied! <pre>def try_gpu(i=0):\n    \"\"\"Return gpu(i) if exists, otherwise return cpu().\n    Defined in :numref:`sec_use_gpu`\"\"\"\n    if num_gpus() &gt;= i + 1:\n        return gpu(i)\n    return cpu()\n</pre> def try_gpu(i=0):     \"\"\"Return gpu(i) if exists, otherwise return cpu().     Defined in :numref:`sec_use_gpu`\"\"\"     if num_gpus() &gt;= i + 1:         return gpu(i)     return cpu() In\u00a0[\u00a0]: Copied! <pre>def try_all_gpus():\n    \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.\n    Defined in :numref:`sec_use_gpu`\"\"\"\n    return [gpu(i) for i in range(num_gpus())]\n</pre> def try_all_gpus():     \"\"\"Return all available GPUs, or [cpu(),] if no GPU exists.     Defined in :numref:`sec_use_gpu`\"\"\"     return [gpu(i) for i in range(num_gpus())] In\u00a0[\u00a0]: Copied! <pre>def corr2d(X, K):\n    \"\"\"Compute 2D cross-correlation.\n    Defined in :numref:`sec_conv_layer`\"\"\"\n    h, w = K.shape\n    Y = myutils.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n    for i in range(Y.shape[0]):\n        for j in range(Y.shape[1]):\n            Y[i, j] = myutils.reduce_sum((X[i: i + h, j: j + w] * K))\n    return Y\n</pre> def corr2d(X, K):     \"\"\"Compute 2D cross-correlation.     Defined in :numref:`sec_conv_layer`\"\"\"     h, w = K.shape     Y = myutils.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))     for i in range(Y.shape[0]):         for j in range(Y.shape[1]):             Y[i, j] = myutils.reduce_sum((X[i: i + h, j: j + w] * K))     return Y In\u00a0[\u00a0]: Copied! <pre>def init_cnn(module):\n    \"\"\"Initialize weights for CNNs.\n    Defined in :numref:`sec_lenet`\"\"\"\n    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n        nn.init.xavier_uniform_(module.weight)\n</pre> def init_cnn(module):     \"\"\"Initialize weights for CNNs.     Defined in :numref:`sec_lenet`\"\"\"     if type(module) == nn.Linear or type(module) == nn.Conv2d:         nn.init.xavier_uniform_(module.weight) In\u00a0[\u00a0]: Copied! <pre>class LeNet(myutils.Classifier):\n    \"\"\"The LeNet-5 model.\n    Defined in :numref:`sec_lenet`\"\"\"\n\n    def __init__(self, lr=0.1, num_classes=10):\n        super().__init__()\n        self.save_hyperparameters()\n        self.net = nn.Sequential(\n            nn.LazyConv2d(6, kernel_size=5, padding=2), nn.Sigmoid(),\n            nn.AvgPool2d(kernel_size=2, stride=2),\n            nn.LazyConv2d(16, kernel_size=5), nn.Sigmoid(),\n            nn.AvgPool2d(kernel_size=2, stride=2),\n            nn.Flatten(),\n            nn.LazyLinear(120), nn.Sigmoid(),\n            nn.LazyLinear(84), nn.Sigmoid(),\n            nn.LazyLinear(num_classes))\n</pre> class LeNet(myutils.Classifier):     \"\"\"The LeNet-5 model.     Defined in :numref:`sec_lenet`\"\"\"      def __init__(self, lr=0.1, num_classes=10):         super().__init__()         self.save_hyperparameters()         self.net = nn.Sequential(             nn.LazyConv2d(6, kernel_size=5, padding=2), nn.Sigmoid(),             nn.AvgPool2d(kernel_size=2, stride=2),             nn.LazyConv2d(16, kernel_size=5), nn.Sigmoid(),             nn.AvgPool2d(kernel_size=2, stride=2),             nn.Flatten(),             nn.LazyLinear(120), nn.Sigmoid(),             nn.LazyLinear(84), nn.Sigmoid(),             nn.LazyLinear(num_classes)) In\u00a0[\u00a0]: Copied! <pre>class Residual(nn.Module):\n    \"\"\"The Residual block of ResNet models.\n    Defined in :numref:`sec_resnet`\"\"\"\n\n    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n        super().__init__()\n        self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,\n                                   stride=strides)\n        self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)\n        if use_1x1conv:\n            self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,\n                                       stride=strides)\n        else:\n            self.conv3 = None\n        self.bn1 = nn.LazyBatchNorm2d()\n        self.bn2 = nn.LazyBatchNorm2d()\n\n    def forward(self, X):\n        Y = F.relu(self.bn1(self.conv1(X)))\n        Y = self.bn2(self.conv2(Y))\n        if self.conv3:\n            X = self.conv3(X)\n        Y += X\n        return F.relu(Y)\n</pre> class Residual(nn.Module):     \"\"\"The Residual block of ResNet models.     Defined in :numref:`sec_resnet`\"\"\"      def __init__(self, num_channels, use_1x1conv=False, strides=1):         super().__init__()         self.conv1 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1,                                    stride=strides)         self.conv2 = nn.LazyConv2d(num_channels, kernel_size=3, padding=1)         if use_1x1conv:             self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1,                                        stride=strides)         else:             self.conv3 = None         self.bn1 = nn.LazyBatchNorm2d()         self.bn2 = nn.LazyBatchNorm2d()      def forward(self, X):         Y = F.relu(self.bn1(self.conv1(X)))         Y = self.bn2(self.conv2(Y))         if self.conv3:             X = self.conv3(X)         Y += X         return F.relu(Y) In\u00a0[\u00a0]: Copied! <pre>class ResNeXtBlock(nn.Module):\n    \"\"\"The ResNeXt block.\n    Defined in :numref:`subsec_residual-blks`\"\"\"\n\n    def __init__(self, num_channels, groups, bot_mul, use_1x1conv=False,\n                 strides=1):\n        super().__init__()\n        bot_channels = int(round(num_channels * bot_mul))\n        self.conv1 = nn.LazyConv2d(bot_channels, kernel_size=1, stride=1)\n        self.conv2 = nn.LazyConv2d(bot_channels, kernel_size=3,\n                                   stride=strides, padding=1,\n                                   groups=bot_channels // groups)\n        self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1, stride=1)\n        self.bn1 = nn.LazyBatchNorm2d()\n        self.bn2 = nn.LazyBatchNorm2d()\n        self.bn3 = nn.LazyBatchNorm2d()\n        if use_1x1conv:\n            self.conv4 = nn.LazyConv2d(num_channels, kernel_size=1,\n                                       stride=strides)\n            self.bn4 = nn.LazyBatchNorm2d()\n        else:\n            self.conv4 = None\n\n    def forward(self, X):\n        Y = F.relu(self.bn1(self.conv1(X)))\n        Y = F.relu(self.bn2(self.conv2(Y)))\n        Y = self.bn3(self.conv3(Y))\n        if self.conv4:\n            X = self.bn4(self.conv4(X))\n        return F.relu(Y + X)\n</pre> class ResNeXtBlock(nn.Module):     \"\"\"The ResNeXt block.     Defined in :numref:`subsec_residual-blks`\"\"\"      def __init__(self, num_channels, groups, bot_mul, use_1x1conv=False,                  strides=1):         super().__init__()         bot_channels = int(round(num_channels * bot_mul))         self.conv1 = nn.LazyConv2d(bot_channels, kernel_size=1, stride=1)         self.conv2 = nn.LazyConv2d(bot_channels, kernel_size=3,                                    stride=strides, padding=1,                                    groups=bot_channels // groups)         self.conv3 = nn.LazyConv2d(num_channels, kernel_size=1, stride=1)         self.bn1 = nn.LazyBatchNorm2d()         self.bn2 = nn.LazyBatchNorm2d()         self.bn3 = nn.LazyBatchNorm2d()         if use_1x1conv:             self.conv4 = nn.LazyConv2d(num_channels, kernel_size=1,                                        stride=strides)             self.bn4 = nn.LazyBatchNorm2d()         else:             self.conv4 = None      def forward(self, X):         Y = F.relu(self.bn1(self.conv1(X)))         Y = F.relu(self.bn2(self.conv2(Y)))         Y = self.bn3(self.conv3(Y))         if self.conv4:             X = self.bn4(self.conv4(X))         return F.relu(Y + X) In\u00a0[\u00a0]: Copied! <pre>class TimeMachine(myutils.DataModule):\n    \"\"\"The Time Machine dataset.\n    Defined in :numref:`sec_text-sequence`\"\"\"\n\n    def _download(self):\n        fname = myutils.download(myutils.DATA_URL + 'timemachine.txt', self.root,\n                                 '090b5e7e70c295757f55df93cb0a180b9691891a')\n        with open(fname) as f:\n            return f.read()\n\n    def _preprocess(self, text):\n        \"\"\"Defined in :numref:`sec_text-sequence`\"\"\"\n        return re.sub('[^A-Za-z]+', ' ', text).lower()\n\n    def _tokenize(self, text):\n        \"\"\"Defined in :numref:`sec_text-sequence`\"\"\"\n        return list(text)\n\n    def build(self, raw_text, vocab=None):\n        \"\"\"Defined in :numref:`sec_text-sequence`\"\"\"\n        tokens = self._tokenize(self._preprocess(raw_text))\n        if vocab is None: vocab = Vocab(tokens)\n        corpus = [vocab[token] for token in tokens]\n        return corpus, vocab\n\n    def __init__(self, batch_size, num_steps, num_train=10000, num_val=5000):\n        \"\"\"Defined in :numref:`sec_language-model`\"\"\"\n        super(myutils.TimeMachine, self).__init__()\n        self.save_hyperparameters()\n        corpus, self.vocab = self.build(self._download())\n        array = myutils.tensor([corpus[i:i + num_steps + 1]\n                                for i in range(len(corpus) - num_steps)])\n        self.X, self.Y = array[:, :-1], array[:, 1:]\n\n    def get_dataloader(self, train):\n        \"\"\"Defined in :numref:`subsec_partitioning-seqs`\"\"\"\n        idx = slice(0, self.num_train) if train else slice(\n            self.num_train, self.num_train + self.num_val)\n        return self.get_tensorloader([self.X, self.Y], train, idx)\n</pre> class TimeMachine(myutils.DataModule):     \"\"\"The Time Machine dataset.     Defined in :numref:`sec_text-sequence`\"\"\"      def _download(self):         fname = myutils.download(myutils.DATA_URL + 'timemachine.txt', self.root,                                  '090b5e7e70c295757f55df93cb0a180b9691891a')         with open(fname) as f:             return f.read()      def _preprocess(self, text):         \"\"\"Defined in :numref:`sec_text-sequence`\"\"\"         return re.sub('[^A-Za-z]+', ' ', text).lower()      def _tokenize(self, text):         \"\"\"Defined in :numref:`sec_text-sequence`\"\"\"         return list(text)      def build(self, raw_text, vocab=None):         \"\"\"Defined in :numref:`sec_text-sequence`\"\"\"         tokens = self._tokenize(self._preprocess(raw_text))         if vocab is None: vocab = Vocab(tokens)         corpus = [vocab[token] for token in tokens]         return corpus, vocab      def __init__(self, batch_size, num_steps, num_train=10000, num_val=5000):         \"\"\"Defined in :numref:`sec_language-model`\"\"\"         super(myutils.TimeMachine, self).__init__()         self.save_hyperparameters()         corpus, self.vocab = self.build(self._download())         array = myutils.tensor([corpus[i:i + num_steps + 1]                                 for i in range(len(corpus) - num_steps)])         self.X, self.Y = array[:, :-1], array[:, 1:]      def get_dataloader(self, train):         \"\"\"Defined in :numref:`subsec_partitioning-seqs`\"\"\"         idx = slice(0, self.num_train) if train else slice(             self.num_train, self.num_train + self.num_val)         return self.get_tensorloader([self.X, self.Y], train, idx) In\u00a0[\u00a0]: Copied! <pre>class Vocab:\n    \"\"\"Vocabulary for text.\"\"\"\n\n    def __init__(self, tokens=[], min_freq=0, reserved_tokens=[]):\n        \"\"\"Defined in :numref:`sec_text-sequence`\"\"\"\n        # Flatten a 2D list if needed\n        if tokens and isinstance(tokens[0], list):\n            tokens = [token for line in tokens for token in line]\n        # Count token frequencies\n        counter = collections.Counter(tokens)\n        self.token_freqs = sorted(counter.items(), key=lambda x: x[1],\n                                  reverse=True)\n        # The list of unique tokens\n        self.idx_to_token = list(sorted(set(['&lt;unk&gt;'] + reserved_tokens + [\n            token for token, freq in self.token_freqs if freq &gt;= min_freq])))\n        self.token_to_idx = {token: idx\n                             for idx, token in enumerate(self.idx_to_token)}\n\n    def __len__(self):\n        return len(self.idx_to_token)\n\n    def __getitem__(self, tokens):\n        if not isinstance(tokens, (list, tuple)):\n            return self.token_to_idx.get(tokens, self.unk)\n        return [self.__getitem__(token) for token in tokens]\n\n    def to_tokens(self, indices):\n        if hasattr(indices, '__len__') and len(indices) &gt; 1:\n            return [self.idx_to_token[int(index)] for index in indices]\n        return self.idx_to_token[indices]\n\n    @property\n    def unk(self):  # Index for the unknown token\n        return self.token_to_idx['&lt;unk&gt;']\n</pre> class Vocab:     \"\"\"Vocabulary for text.\"\"\"      def __init__(self, tokens=[], min_freq=0, reserved_tokens=[]):         \"\"\"Defined in :numref:`sec_text-sequence`\"\"\"         # Flatten a 2D list if needed         if tokens and isinstance(tokens[0], list):             tokens = [token for line in tokens for token in line]         # Count token frequencies         counter = collections.Counter(tokens)         self.token_freqs = sorted(counter.items(), key=lambda x: x[1],                                   reverse=True)         # The list of unique tokens         self.idx_to_token = list(sorted(set([''] + reserved_tokens + [             token for token, freq in self.token_freqs if freq &gt;= min_freq])))         self.token_to_idx = {token: idx                              for idx, token in enumerate(self.idx_to_token)}      def __len__(self):         return len(self.idx_to_token)      def __getitem__(self, tokens):         if not isinstance(tokens, (list, tuple)):             return self.token_to_idx.get(tokens, self.unk)         return [self.__getitem__(token) for token in tokens]      def to_tokens(self, indices):         if hasattr(indices, '__len__') and len(indices) &gt; 1:             return [self.idx_to_token[int(index)] for index in indices]         return self.idx_to_token[indices]      @property     def unk(self):  # Index for the unknown token         return self.token_to_idx[''] In\u00a0[\u00a0]: Copied! <pre>class RNNScratch(myutils.Module):\n    \"\"\"The RNN model implemented from scratch.\n    Defined in :numref:`sec_rnn-scratch`\"\"\"\n\n    def __init__(self, num_inputs, num_hiddens, sigma=0.01):\n        super().__init__()\n        self.save_hyperparameters()\n        self.W_xh = nn.Parameter(\n            myutils.randn(num_inputs, num_hiddens) * sigma)\n        self.W_hh = nn.Parameter(\n            myutils.randn(num_hiddens, num_hiddens) * sigma)\n        self.b_h = nn.Parameter(myutils.zeros(num_hiddens))\n\n    def forward(self, inputs, state=None):\n        \"\"\"Defined in :numref:`sec_rnn-scratch`\"\"\"\n        if state is None:\n            # Initial state with shape: (batch_size, num_hiddens)\n            state = myutils.zeros((inputs.shape[1], self.num_hiddens),\n                                  device=inputs.device)\n        else:\n            state, = state\n        outputs = []\n        for X in inputs:  # Shape of inputs: (num_steps, batch_size, num_inputs)\n            state = myutils.tanh(myutils.matmul(X, self.W_xh) +\n                                 myutils.matmul(state, self.W_hh) + self.b_h)\n            outputs.append(state)\n        return outputs, state\n</pre> class RNNScratch(myutils.Module):     \"\"\"The RNN model implemented from scratch.     Defined in :numref:`sec_rnn-scratch`\"\"\"      def __init__(self, num_inputs, num_hiddens, sigma=0.01):         super().__init__()         self.save_hyperparameters()         self.W_xh = nn.Parameter(             myutils.randn(num_inputs, num_hiddens) * sigma)         self.W_hh = nn.Parameter(             myutils.randn(num_hiddens, num_hiddens) * sigma)         self.b_h = nn.Parameter(myutils.zeros(num_hiddens))      def forward(self, inputs, state=None):         \"\"\"Defined in :numref:`sec_rnn-scratch`\"\"\"         if state is None:             # Initial state with shape: (batch_size, num_hiddens)             state = myutils.zeros((inputs.shape[1], self.num_hiddens),                                   device=inputs.device)         else:             state, = state         outputs = []         for X in inputs:  # Shape of inputs: (num_steps, batch_size, num_inputs)             state = myutils.tanh(myutils.matmul(X, self.W_xh) +                                  myutils.matmul(state, self.W_hh) + self.b_h)             outputs.append(state)         return outputs, state In\u00a0[\u00a0]: Copied! <pre>def check_len(a, n):\n    \"\"\"Check the length of a list.\n    Defined in :numref:`sec_rnn-scratch`\"\"\"\n    assert len(a) == n, f'list\\'s length {len(a)} != expected length {n}'\n</pre> def check_len(a, n):     \"\"\"Check the length of a list.     Defined in :numref:`sec_rnn-scratch`\"\"\"     assert len(a) == n, f'list\\'s length {len(a)} != expected length {n}' In\u00a0[\u00a0]: Copied! <pre>def check_shape(a, shape):\n    \"\"\"Check the shape of a tensor.\n    Defined in :numref:`sec_rnn-scratch`\"\"\"\n    assert a.shape == shape, \\\n        f'tensor\\'s shape {a.shape} != expected shape {shape}'\n</pre> def check_shape(a, shape):     \"\"\"Check the shape of a tensor.     Defined in :numref:`sec_rnn-scratch`\"\"\"     assert a.shape == shape, \\         f'tensor\\'s shape {a.shape} != expected shape {shape}' In\u00a0[\u00a0]: Copied! <pre>class RNNLMScratch(myutils.Classifier):\n    \"\"\"The RNN-based language model implemented from scratch.\n    Defined in :numref:`sec_rnn-scratch`\"\"\"\n\n    def __init__(self, rnn, vocab_size, lr=0.01):\n        super().__init__()\n        self.save_hyperparameters()\n        self.init_params()\n\n    def init_params(self):\n        self.W_hq = nn.Parameter(\n            myutils.randn(\n                self.rnn.num_hiddens, self.vocab_size) * self.rnn.sigma)\n        self.b_q = nn.Parameter(myutils.zeros(self.vocab_size))\n\n    def training_step(self, batch):\n        l = self.loss(self(*batch[:-1]), batch[-1])\n        self.plot('ppl', myutils.exp(l), train=True)\n        return l\n\n    def validation_step(self, batch):\n        l = self.loss(self(*batch[:-1]), batch[-1])\n        self.plot('ppl', myutils.exp(l), train=False)\n\n    def one_hot(self, X):\n        \"\"\"Defined in :numref:`sec_rnn-scratch`\"\"\"\n        # Output shape: (num_steps, batch_size, vocab_size)\n        return F.one_hot(X.T, self.vocab_size).type(torch.float32)\n\n    def output_layer(self, rnn_outputs):\n        \"\"\"Defined in :numref:`sec_rnn-scratch`\"\"\"\n        outputs = [myutils.matmul(H, self.W_hq) + self.b_q for H in rnn_outputs]\n        return myutils.stack(outputs, 1)\n\n    def forward(self, X, state=None):\n        \"\"\"Defined in :numref:`sec_rnn-scratch`\"\"\"\n        embs = self.one_hot(X)\n        rnn_outputs, _ = self.rnn(embs, state)\n        return self.output_layer(rnn_outputs)\n\n    def predict(self, prefix, num_preds, vocab, device=None):\n        \"\"\"Defined in :numref:`sec_rnn-scratch`\"\"\"\n        state, outputs = None, [vocab[prefix[0]]]\n        for i in range(len(prefix) + num_preds - 1):\n            X = myutils.tensor([[outputs[-1]]], device=device)\n            embs = self.one_hot(X)\n            rnn_outputs, state = self.rnn(embs, state)\n            if i &lt; len(prefix) - 1:  # Warm-up period\n                outputs.append(vocab[prefix[i + 1]])\n            else:  # Predict num_preds steps\n                Y = self.output_layer(rnn_outputs)\n                outputs.append(int(myutils.reshape(myutils.argmax(Y, axis=2), 1)))\n        return ''.join([vocab.idx_to_token[i] for i in outputs])\n</pre> class RNNLMScratch(myutils.Classifier):     \"\"\"The RNN-based language model implemented from scratch.     Defined in :numref:`sec_rnn-scratch`\"\"\"      def __init__(self, rnn, vocab_size, lr=0.01):         super().__init__()         self.save_hyperparameters()         self.init_params()      def init_params(self):         self.W_hq = nn.Parameter(             myutils.randn(                 self.rnn.num_hiddens, self.vocab_size) * self.rnn.sigma)         self.b_q = nn.Parameter(myutils.zeros(self.vocab_size))      def training_step(self, batch):         l = self.loss(self(*batch[:-1]), batch[-1])         self.plot('ppl', myutils.exp(l), train=True)         return l      def validation_step(self, batch):         l = self.loss(self(*batch[:-1]), batch[-1])         self.plot('ppl', myutils.exp(l), train=False)      def one_hot(self, X):         \"\"\"Defined in :numref:`sec_rnn-scratch`\"\"\"         # Output shape: (num_steps, batch_size, vocab_size)         return F.one_hot(X.T, self.vocab_size).type(torch.float32)      def output_layer(self, rnn_outputs):         \"\"\"Defined in :numref:`sec_rnn-scratch`\"\"\"         outputs = [myutils.matmul(H, self.W_hq) + self.b_q for H in rnn_outputs]         return myutils.stack(outputs, 1)      def forward(self, X, state=None):         \"\"\"Defined in :numref:`sec_rnn-scratch`\"\"\"         embs = self.one_hot(X)         rnn_outputs, _ = self.rnn(embs, state)         return self.output_layer(rnn_outputs)      def predict(self, prefix, num_preds, vocab, device=None):         \"\"\"Defined in :numref:`sec_rnn-scratch`\"\"\"         state, outputs = None, [vocab[prefix[0]]]         for i in range(len(prefix) + num_preds - 1):             X = myutils.tensor([[outputs[-1]]], device=device)             embs = self.one_hot(X)             rnn_outputs, state = self.rnn(embs, state)             if i &lt; len(prefix) - 1:  # Warm-up period                 outputs.append(vocab[prefix[i + 1]])             else:  # Predict num_preds steps                 Y = self.output_layer(rnn_outputs)                 outputs.append(int(myutils.reshape(myutils.argmax(Y, axis=2), 1)))         return ''.join([vocab.idx_to_token[i] for i in outputs]) In\u00a0[\u00a0]: Copied! <pre>class RNN(myutils.Module):\n    \"\"\"The RNN model implemented with high-level APIs.\n    Defined in :numref:`sec_rnn-concise`\"\"\"\n\n    def __init__(self, num_inputs, num_hiddens):\n        super().__init__()\n        self.save_hyperparameters()\n        self.rnn = nn.RNN(num_inputs, num_hiddens)\n\n    def forward(self, inputs, H=None):\n        return self.rnn(inputs, H)\n</pre> class RNN(myutils.Module):     \"\"\"The RNN model implemented with high-level APIs.     Defined in :numref:`sec_rnn-concise`\"\"\"      def __init__(self, num_inputs, num_hiddens):         super().__init__()         self.save_hyperparameters()         self.rnn = nn.RNN(num_inputs, num_hiddens)      def forward(self, inputs, H=None):         return self.rnn(inputs, H) In\u00a0[\u00a0]: Copied! <pre>class RNNLM(myutils.RNNLMScratch):\n    \"\"\"The RNN-based language model implemented with high-level APIs.\n    Defined in :numref:`sec_rnn-concise`\"\"\"\n\n    def init_params(self):\n        self.linear = nn.LazyLinear(self.vocab_size)\n\n    def output_layer(self, hiddens):\n        return myutils.swapaxes(self.linear(hiddens), 0, 1)\n</pre> class RNNLM(myutils.RNNLMScratch):     \"\"\"The RNN-based language model implemented with high-level APIs.     Defined in :numref:`sec_rnn-concise`\"\"\"      def init_params(self):         self.linear = nn.LazyLinear(self.vocab_size)      def output_layer(self, hiddens):         return myutils.swapaxes(self.linear(hiddens), 0, 1) In\u00a0[\u00a0]: Copied! <pre>class GRU(myutils.RNN):\n    \"\"\"The multi-layer GRU model.\n    Defined in :numref:`sec_deep_rnn`\"\"\"\n\n    def __init__(self, num_inputs, num_hiddens, num_layers, dropout=0):\n        myutils.Module.__init__(self)\n        self.save_hyperparameters()\n        self.rnn = nn.GRU(num_inputs, num_hiddens, num_layers,\n                          dropout=dropout)\n</pre> class GRU(myutils.RNN):     \"\"\"The multi-layer GRU model.     Defined in :numref:`sec_deep_rnn`\"\"\"      def __init__(self, num_inputs, num_hiddens, num_layers, dropout=0):         myutils.Module.__init__(self)         self.save_hyperparameters()         self.rnn = nn.GRU(num_inputs, num_hiddens, num_layers,                           dropout=dropout) In\u00a0[\u00a0]: Copied! <pre>class MTFraEng(myutils.DataModule):\n    \"\"\"The English-French dataset.\n    Defined in :numref:`sec_machine_translation`\"\"\"\n\n    def _download(self):\n        myutils.extract(myutils.download(\n            myutils.DATA_URL + 'fra-eng.zip', self.root,\n            '94646ad1522d915e7b0f9296181140edcf86a4f5'))\n        with open(self.root + '/fra-eng/fra.txt', encoding='utf-8') as f:\n            return f.read()\n\n    def _preprocess(self, text):\n        \"\"\"Defined in :numref:`sec_machine_translation`\"\"\"\n        # Replace non-breaking space with space\n        text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')\n        # Insert space between words and punctuation marks\n        no_space = lambda char, prev_char: char in ',.!?' and prev_char != ' '\n        out = [' ' + char if i &gt; 0 and no_space(char, text[i - 1]) else char\n               for i, char in enumerate(text.lower())]\n        return ''.join(out)\n\n    def _tokenize(self, text, max_examples=None):\n        \"\"\"Defined in :numref:`sec_machine_translation`\"\"\"\n        src, tgt = [], []\n        for i, line in enumerate(text.split('\\n')):\n            if max_examples and i &gt; max_examples: break\n            parts = line.split('\\t')\n            if len(parts) == 2:\n                # Skip empty tokens\n                src.append([t for t in f'{parts[0]} &lt;eos&gt;'.split(' ') if t])\n                tgt.append([t for t in f'{parts[1]} &lt;eos&gt;'.split(' ') if t])\n        return src, tgt\n\n    def __init__(self, batch_size, num_steps=9, num_train=512, num_val=128):\n        \"\"\"Defined in :numref:`sec_machine_translation`\"\"\"\n        super(MTFraEng, self).__init__()\n        self.save_hyperparameters()\n        self.arrays, self.src_vocab, self.tgt_vocab = self._build_arrays(\n            self._download())\n\n    def _build_arrays(self, raw_text, src_vocab=None, tgt_vocab=None):\n        \"\"\"Defined in :numref:`subsec_loading-seq-fixed-len`\"\"\"\n\n        def _build_array(sentences, vocab, is_tgt=False):\n            pad_or_trim = lambda seq, t: (\n                seq[:t] if len(seq) &gt; t else seq + ['&lt;pad&gt;'] * (t - len(seq)))\n            sentences = [pad_or_trim(s, self.num_steps) for s in sentences]\n            if is_tgt:\n                sentences = [['&lt;bos&gt;'] + s for s in sentences]\n            if vocab is None:\n                vocab = myutils.Vocab(sentences, min_freq=2)\n            array = myutils.tensor([vocab[s] for s in sentences])\n            valid_len = myutils.reduce_sum(\n                myutils.astype(array != vocab['&lt;pad&gt;'], myutils.int32), 1)\n            return array, vocab, valid_len\n\n        src, tgt = self._tokenize(self._preprocess(raw_text),\n                                  self.num_train + self.num_val)\n        src_array, src_vocab, src_valid_len = _build_array(src, src_vocab)\n        tgt_array, tgt_vocab, _ = _build_array(tgt, tgt_vocab, True)\n        return ((src_array, tgt_array[:, :-1], src_valid_len, tgt_array[:, 1:]),\n                src_vocab, tgt_vocab)\n\n    def get_dataloader(self, train):\n        \"\"\"Defined in :numref:`subsec_loading-seq-fixed-len`\"\"\"\n        idx = slice(0, self.num_train) if train else slice(self.num_train, None)\n        return self.get_tensorloader(self.arrays, train, idx)\n\n    def build(self, src_sentences, tgt_sentences):\n        \"\"\"Defined in :numref:`subsec_loading-seq-fixed-len`\"\"\"\n        raw_text = '\\n'.join([src + '\\t' + tgt for src, tgt in zip(\n            src_sentences, tgt_sentences)])\n        arrays, _, _ = self._build_arrays(\n            raw_text, self.src_vocab, self.tgt_vocab)\n        return arrays\n</pre> class MTFraEng(myutils.DataModule):     \"\"\"The English-French dataset.     Defined in :numref:`sec_machine_translation`\"\"\"      def _download(self):         myutils.extract(myutils.download(             myutils.DATA_URL + 'fra-eng.zip', self.root,             '94646ad1522d915e7b0f9296181140edcf86a4f5'))         with open(self.root + '/fra-eng/fra.txt', encoding='utf-8') as f:             return f.read()      def _preprocess(self, text):         \"\"\"Defined in :numref:`sec_machine_translation`\"\"\"         # Replace non-breaking space with space         text = text.replace('\\u202f', ' ').replace('\\xa0', ' ')         # Insert space between words and punctuation marks         no_space = lambda char, prev_char: char in ',.!?' and prev_char != ' '         out = [' ' + char if i &gt; 0 and no_space(char, text[i - 1]) else char                for i, char in enumerate(text.lower())]         return ''.join(out)      def _tokenize(self, text, max_examples=None):         \"\"\"Defined in :numref:`sec_machine_translation`\"\"\"         src, tgt = [], []         for i, line in enumerate(text.split('\\n')):             if max_examples and i &gt; max_examples: break             parts = line.split('\\t')             if len(parts) == 2:                 # Skip empty tokens                 src.append([t for t in f'{parts[0]} '.split(' ') if t])                 tgt.append([t for t in f'{parts[1]} '.split(' ') if t])         return src, tgt      def __init__(self, batch_size, num_steps=9, num_train=512, num_val=128):         \"\"\"Defined in :numref:`sec_machine_translation`\"\"\"         super(MTFraEng, self).__init__()         self.save_hyperparameters()         self.arrays, self.src_vocab, self.tgt_vocab = self._build_arrays(             self._download())      def _build_arrays(self, raw_text, src_vocab=None, tgt_vocab=None):         \"\"\"Defined in :numref:`subsec_loading-seq-fixed-len`\"\"\"          def _build_array(sentences, vocab, is_tgt=False):             pad_or_trim = lambda seq, t: (                 seq[:t] if len(seq) &gt; t else seq + [''] * (t - len(seq)))             sentences = [pad_or_trim(s, self.num_steps) for s in sentences]             if is_tgt:                 sentences = [[''] + s for s in sentences]             if vocab is None:                 vocab = myutils.Vocab(sentences, min_freq=2)             array = myutils.tensor([vocab[s] for s in sentences])             valid_len = myutils.reduce_sum(                 myutils.astype(array != vocab[''], myutils.int32), 1)             return array, vocab, valid_len          src, tgt = self._tokenize(self._preprocess(raw_text),                                   self.num_train + self.num_val)         src_array, src_vocab, src_valid_len = _build_array(src, src_vocab)         tgt_array, tgt_vocab, _ = _build_array(tgt, tgt_vocab, True)         return ((src_array, tgt_array[:, :-1], src_valid_len, tgt_array[:, 1:]),                 src_vocab, tgt_vocab)      def get_dataloader(self, train):         \"\"\"Defined in :numref:`subsec_loading-seq-fixed-len`\"\"\"         idx = slice(0, self.num_train) if train else slice(self.num_train, None)         return self.get_tensorloader(self.arrays, train, idx)      def build(self, src_sentences, tgt_sentences):         \"\"\"Defined in :numref:`subsec_loading-seq-fixed-len`\"\"\"         raw_text = '\\n'.join([src + '\\t' + tgt for src, tgt in zip(             src_sentences, tgt_sentences)])         arrays, _, _ = self._build_arrays(             raw_text, self.src_vocab, self.tgt_vocab)         return arrays In\u00a0[\u00a0]: Copied! <pre>def show_list_len_pair_hist(legend, xlabel, ylabel, xlist, ylist):\n    \"\"\"Plot the histogram for list length pairs.\n    Defined in :numref:`sec_machine_translation`\"\"\"\n    myutils.set_figsize()\n    _, _, patches = myutils.plt.hist(\n        [[len(l) for l in xlist], [len(l) for l in ylist]])\n    myutils.plt.xlabel(xlabel)\n    myutils.plt.ylabel(ylabel)\n    for patch in patches[1].patches:\n        patch.set_hatch('/')\n    myutils.plt.legend(legend)\n</pre> def show_list_len_pair_hist(legend, xlabel, ylabel, xlist, ylist):     \"\"\"Plot the histogram for list length pairs.     Defined in :numref:`sec_machine_translation`\"\"\"     myutils.set_figsize()     _, _, patches = myutils.plt.hist(         [[len(l) for l in xlist], [len(l) for l in ylist]])     myutils.plt.xlabel(xlabel)     myutils.plt.ylabel(ylabel)     for patch in patches[1].patches:         patch.set_hatch('/')     myutils.plt.legend(legend) In\u00a0[\u00a0]: Copied! <pre>class Encoder(nn.Module):\n    \"\"\"The base encoder interface for the encoder-decoder architecture.\n    Defined in :numref:`sec_encoder-decoder`\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    # Later there can be additional arguments (e.g., length excluding padding)\n    def forward(self, X, *args):\n        raise NotImplementedError\n</pre> class Encoder(nn.Module):     \"\"\"The base encoder interface for the encoder-decoder architecture.     Defined in :numref:`sec_encoder-decoder`\"\"\"      def __init__(self):         super().__init__()      # Later there can be additional arguments (e.g., length excluding padding)     def forward(self, X, *args):         raise NotImplementedError In\u00a0[\u00a0]: Copied! <pre>class Decoder(nn.Module):\n    \"\"\"The base decoder interface for the encoder-decoder architecture.\n    Defined in :numref:`sec_encoder-decoder`\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    # Later there can be additional arguments (e.g., length excluding padding)\n    def init_state(self, enc_all_outputs, *args):\n        raise NotImplementedError\n\n    def forward(self, X, state):\n        raise NotImplementedError\n</pre> class Decoder(nn.Module):     \"\"\"The base decoder interface for the encoder-decoder architecture.     Defined in :numref:`sec_encoder-decoder`\"\"\"      def __init__(self):         super().__init__()      # Later there can be additional arguments (e.g., length excluding padding)     def init_state(self, enc_all_outputs, *args):         raise NotImplementedError      def forward(self, X, state):         raise NotImplementedError In\u00a0[\u00a0]: Copied! <pre>class EncoderDecoder(myutils.Classifier):\n    \"\"\"The base class for the encoder-decoder architecture.\n    Defined in :numref:`sec_encoder-decoder`\"\"\"\n\n    def __init__(self, encoder, decoder):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, enc_X, dec_X, *args):\n        enc_all_outputs = self.encoder(enc_X, *args)\n        dec_state = self.decoder.init_state(enc_all_outputs, *args)\n        # Return decoder output only\n        return self.decoder(dec_X, dec_state)[0]\n\n    def predict_step(self, batch, device, num_steps,\n                     save_attention_weights=False):\n        \"\"\"Defined in :numref:`sec_seq2seq_training`\"\"\"\n        batch = [myutils.to(a, device) for a in batch]\n        src, tgt, src_valid_len, _ = batch\n        enc_all_outputs = self.encoder(src, src_valid_len)\n        dec_state = self.decoder.init_state(enc_all_outputs, src_valid_len)\n        outputs, attention_weights = [myutils.expand_dims(tgt[:, 0], 1), ], []\n        for _ in range(num_steps):\n            Y, dec_state = self.decoder(outputs[-1], dec_state)\n            outputs.append(myutils.argmax(Y, 2))\n            # Save attention weights (to be covered later)\n            if save_attention_weights:\n                attention_weights.append(self.decoder.attention_weights)\n        return myutils.concat(outputs[1:], 1), attention_weights\n</pre> class EncoderDecoder(myutils.Classifier):     \"\"\"The base class for the encoder-decoder architecture.     Defined in :numref:`sec_encoder-decoder`\"\"\"      def __init__(self, encoder, decoder):         super().__init__()         self.encoder = encoder         self.decoder = decoder      def forward(self, enc_X, dec_X, *args):         enc_all_outputs = self.encoder(enc_X, *args)         dec_state = self.decoder.init_state(enc_all_outputs, *args)         # Return decoder output only         return self.decoder(dec_X, dec_state)[0]      def predict_step(self, batch, device, num_steps,                      save_attention_weights=False):         \"\"\"Defined in :numref:`sec_seq2seq_training`\"\"\"         batch = [myutils.to(a, device) for a in batch]         src, tgt, src_valid_len, _ = batch         enc_all_outputs = self.encoder(src, src_valid_len)         dec_state = self.decoder.init_state(enc_all_outputs, src_valid_len)         outputs, attention_weights = [myutils.expand_dims(tgt[:, 0], 1), ], []         for _ in range(num_steps):             Y, dec_state = self.decoder(outputs[-1], dec_state)             outputs.append(myutils.argmax(Y, 2))             # Save attention weights (to be covered later)             if save_attention_weights:                 attention_weights.append(self.decoder.attention_weights)         return myutils.concat(outputs[1:], 1), attention_weights In\u00a0[\u00a0]: Copied! <pre>def init_seq2seq(module):\n    \"\"\"Initialize weights for Seq2Seq.\n    Defined in :numref:`sec_seq2seq`\"\"\"\n    if type(module) == nn.Linear:\n        nn.init.xavier_uniform_(module.weight)\n    if type(module) == nn.GRU:\n        for param in module._flat_weights_names:\n            if \"weight\" in param:\n                nn.init.xavier_uniform_(module._parameters[param])\n</pre> def init_seq2seq(module):     \"\"\"Initialize weights for Seq2Seq.     Defined in :numref:`sec_seq2seq`\"\"\"     if type(module) == nn.Linear:         nn.init.xavier_uniform_(module.weight)     if type(module) == nn.GRU:         for param in module._flat_weights_names:             if \"weight\" in param:                 nn.init.xavier_uniform_(module._parameters[param]) In\u00a0[\u00a0]: Copied! <pre>class Seq2SeqEncoder(myutils.Encoder):\n    \"\"\"The RNN encoder for sequence to sequence learning.\n    Defined in :numref:`sec_seq2seq`\"\"\"\n\n    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n                 dropout=0):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.rnn = myutils.GRU(embed_size, num_hiddens, num_layers, dropout)\n        self.apply(init_seq2seq)\n\n    def forward(self, X, *args):\n        # X shape: (batch_size, num_steps)\n        embs = self.embedding(myutils.astype(myutils.transpose(X), myutils.int64))\n        # embs shape: (num_steps, batch_size, embed_size)\n        outputs, state = self.rnn(embs)\n        # outputs shape: (num_steps, batch_size, num_hiddens)\n        # state shape: (num_layers, batch_size, num_hiddens)\n        return outputs, state\n</pre> class Seq2SeqEncoder(myutils.Encoder):     \"\"\"The RNN encoder for sequence to sequence learning.     Defined in :numref:`sec_seq2seq`\"\"\"      def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,                  dropout=0):         super().__init__()         self.embedding = nn.Embedding(vocab_size, embed_size)         self.rnn = myutils.GRU(embed_size, num_hiddens, num_layers, dropout)         self.apply(init_seq2seq)      def forward(self, X, *args):         # X shape: (batch_size, num_steps)         embs = self.embedding(myutils.astype(myutils.transpose(X), myutils.int64))         # embs shape: (num_steps, batch_size, embed_size)         outputs, state = self.rnn(embs)         # outputs shape: (num_steps, batch_size, num_hiddens)         # state shape: (num_layers, batch_size, num_hiddens)         return outputs, state In\u00a0[\u00a0]: Copied! <pre>class Seq2Seq(myutils.EncoderDecoder):\n    \"\"\"The RNN encoder-decoder for sequence to sequence learning.\n    Defined in :numref:`sec_seq2seq_decoder`\"\"\"\n\n    def __init__(self, encoder, decoder, tgt_pad, lr):\n        super().__init__(encoder, decoder)\n        self.save_hyperparameters()\n\n    def validation_step(self, batch):\n        Y_hat = self(*batch[:-1])\n        self.plot('loss', self.loss(Y_hat, batch[-1]), train=False)\n\n    def configure_optimizers(self):\n        # Adam optimizer is used here\n        return torch.optim.Adam(self.parameters(), lr=self.lr)\n</pre> class Seq2Seq(myutils.EncoderDecoder):     \"\"\"The RNN encoder-decoder for sequence to sequence learning.     Defined in :numref:`sec_seq2seq_decoder`\"\"\"      def __init__(self, encoder, decoder, tgt_pad, lr):         super().__init__(encoder, decoder)         self.save_hyperparameters()      def validation_step(self, batch):         Y_hat = self(*batch[:-1])         self.plot('loss', self.loss(Y_hat, batch[-1]), train=False)      def configure_optimizers(self):         # Adam optimizer is used here         return torch.optim.Adam(self.parameters(), lr=self.lr) In\u00a0[\u00a0]: Copied! <pre>def bleu(pred_seq, label_seq, k):\n    \"\"\"Compute the BLEU.\n    Defined in :numref:`sec_seq2seq_training`\"\"\"\n    pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')\n    len_pred, len_label = len(pred_tokens), len(label_tokens)\n    score = math.exp(min(0, 1 - len_label / len_pred))\n    for n in range(1, min(k, len_pred) + 1):\n        num_matches, label_subs = 0, collections.defaultdict(int)\n        for i in range(len_label - n + 1):\n            label_subs[' '.join(label_tokens[i: i + n])] += 1\n        for i in range(len_pred - n + 1):\n            if label_subs[' '.join(pred_tokens[i: i + n])] &gt; 0:\n                num_matches += 1\n                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n    return score\n</pre> def bleu(pred_seq, label_seq, k):     \"\"\"Compute the BLEU.     Defined in :numref:`sec_seq2seq_training`\"\"\"     pred_tokens, label_tokens = pred_seq.split(' '), label_seq.split(' ')     len_pred, len_label = len(pred_tokens), len(label_tokens)     score = math.exp(min(0, 1 - len_label / len_pred))     for n in range(1, min(k, len_pred) + 1):         num_matches, label_subs = 0, collections.defaultdict(int)         for i in range(len_label - n + 1):             label_subs[' '.join(label_tokens[i: i + n])] += 1         for i in range(len_pred - n + 1):             if label_subs[' '.join(pred_tokens[i: i + n])] &gt; 0:                 num_matches += 1                 label_subs[' '.join(pred_tokens[i: i + n])] -= 1         score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))     return score In\u00a0[\u00a0]: Copied! <pre>def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5),\n                  cmap='Reds'):\n    \"\"\"Show heatmaps of matrices.\n    Defined in :numref:`sec_queries-keys-values`\"\"\"\n    myutils.use_svg_display()\n    num_rows, num_cols, _, _ = matrices.shape\n    fig, axes = myutils.plt.subplots(num_rows, num_cols, figsize=figsize,\n                                     sharex=True, sharey=True, squeeze=False)\n    for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):\n        for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):\n            pcm = ax.imshow(myutils.numpy(matrix), cmap=cmap)\n            if i == num_rows - 1:\n                ax.set_xlabel(xlabel)\n            if j == 0:\n                ax.set_ylabel(ylabel)\n            if titles:\n                ax.set_title(titles[j])\n    fig.colorbar(pcm, ax=axes, shrink=0.6);\n</pre> def show_heatmaps(matrices, xlabel, ylabel, titles=None, figsize=(2.5, 2.5),                   cmap='Reds'):     \"\"\"Show heatmaps of matrices.     Defined in :numref:`sec_queries-keys-values`\"\"\"     myutils.use_svg_display()     num_rows, num_cols, _, _ = matrices.shape     fig, axes = myutils.plt.subplots(num_rows, num_cols, figsize=figsize,                                      sharex=True, sharey=True, squeeze=False)     for i, (row_axes, row_matrices) in enumerate(zip(axes, matrices)):         for j, (ax, matrix) in enumerate(zip(row_axes, row_matrices)):             pcm = ax.imshow(myutils.numpy(matrix), cmap=cmap)             if i == num_rows - 1:                 ax.set_xlabel(xlabel)             if j == 0:                 ax.set_ylabel(ylabel)             if titles:                 ax.set_title(titles[j])     fig.colorbar(pcm, ax=axes, shrink=0.6); In\u00a0[\u00a0]: Copied! <pre>def masked_softmax(X, valid_lens):\n    \"\"\"Perform softmax operation by masking elements on the last axis.\n    Defined in :numref:`sec_attention-scoring-functions`\"\"\"\n\n    # X: 3D tensor, valid_lens: 1D or 2D tensor\n    def _sequence_mask(X, valid_len, value=0):\n        maxlen = X.size(1)\n        mask = torch.arange((maxlen), dtype=torch.float32,\n                            device=X.device)[None, :] &lt; valid_len[:, None]\n        X[~mask] = value\n        return X\n\n    if valid_lens is None:\n        return nn.functional.softmax(X, dim=-1)\n    else:\n        shape = X.shape\n        if valid_lens.dim() == 1:\n            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n        else:\n            valid_lens = valid_lens.reshape(-1)\n        # On the last axis, replace masked elements with a very large negative\n        # value, whose exponentiation outputs 0\n        X = _sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)\n        return nn.functional.softmax(X.reshape(shape), dim=-1)\n</pre> def masked_softmax(X, valid_lens):     \"\"\"Perform softmax operation by masking elements on the last axis.     Defined in :numref:`sec_attention-scoring-functions`\"\"\"      # X: 3D tensor, valid_lens: 1D or 2D tensor     def _sequence_mask(X, valid_len, value=0):         maxlen = X.size(1)         mask = torch.arange((maxlen), dtype=torch.float32,                             device=X.device)[None, :] &lt; valid_len[:, None]         X[~mask] = value         return X      if valid_lens is None:         return nn.functional.softmax(X, dim=-1)     else:         shape = X.shape         if valid_lens.dim() == 1:             valid_lens = torch.repeat_interleave(valid_lens, shape[1])         else:             valid_lens = valid_lens.reshape(-1)         # On the last axis, replace masked elements with a very large negative         # value, whose exponentiation outputs 0         X = _sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)         return nn.functional.softmax(X.reshape(shape), dim=-1) In\u00a0[\u00a0]: Copied! <pre>class DotProductAttention(nn.Module):\n    \"\"\"Scaled dot product attention.\n    Defined in :numref:`subsec_batch_dot`\"\"\"\n\n    def __init__(self, dropout):\n        super().__init__()\n        self.dropout = nn.Dropout(dropout)\n\n    # Shape of queries: (batch_size, no. of queries, d)\n    # Shape of keys: (batch_size, no. of key-value pairs, d)\n    # Shape of values: (batch_size, no. of key-value pairs, value dimension)\n    # Shape of valid_lens: (batch_size,) or (batch_size, no. of queries)\n    def forward(self, queries, keys, values, valid_lens=None):\n        d = queries.shape[-1]\n        # Swap the last two dimensions of keys with keys.transpose(1, 2)\n        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)\n        self.attention_weights = masked_softmax(scores, valid_lens)\n        return torch.bmm(self.dropout(self.attention_weights), values)\n</pre> class DotProductAttention(nn.Module):     \"\"\"Scaled dot product attention.     Defined in :numref:`subsec_batch_dot`\"\"\"      def __init__(self, dropout):         super().__init__()         self.dropout = nn.Dropout(dropout)      # Shape of queries: (batch_size, no. of queries, d)     # Shape of keys: (batch_size, no. of key-value pairs, d)     # Shape of values: (batch_size, no. of key-value pairs, value dimension)     # Shape of valid_lens: (batch_size,) or (batch_size, no. of queries)     def forward(self, queries, keys, values, valid_lens=None):         d = queries.shape[-1]         # Swap the last two dimensions of keys with keys.transpose(1, 2)         scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)         self.attention_weights = masked_softmax(scores, valid_lens)         return torch.bmm(self.dropout(self.attention_weights), values) In\u00a0[\u00a0]: Copied! <pre>class AdditiveAttention(nn.Module):\n    \"\"\"Additive attention.\n    Defined in :numref:`subsec_batch_dot`\"\"\"\n\n    def __init__(self, num_hiddens, dropout, **kwargs):\n        super(AdditiveAttention, self).__init__(**kwargs)\n        self.W_k = nn.LazyLinear(num_hiddens, bias=False)\n        self.W_q = nn.LazyLinear(num_hiddens, bias=False)\n        self.w_v = nn.LazyLinear(1, bias=False)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, queries, keys, values, valid_lens):\n        queries, keys = self.W_q(queries), self.W_k(keys)\n        # After dimension expansion, shape of queries: (batch_size, no. of\n        # queries, 1, num_hiddens) and shape of keys: (batch_size, 1, no. of\n        # key-value pairs, num_hiddens). Sum them up with broadcasting\n        features = queries.unsqueeze(2) + keys.unsqueeze(1)\n        features = torch.tanh(features)\n        # There is only one output of self.w_v, so we remove the last\n        # one-dimensional entry from the shape. Shape of scores: (batch_size,\n        # no. of queries, no. of key-value pairs)\n        scores = self.w_v(features).squeeze(-1)\n        self.attention_weights = masked_softmax(scores, valid_lens)\n        # Shape of values: (batch_size, no. of key-value pairs, value\n        # dimension)\n        return torch.bmm(self.dropout(self.attention_weights), values)\n</pre> class AdditiveAttention(nn.Module):     \"\"\"Additive attention.     Defined in :numref:`subsec_batch_dot`\"\"\"      def __init__(self, num_hiddens, dropout, **kwargs):         super(AdditiveAttention, self).__init__(**kwargs)         self.W_k = nn.LazyLinear(num_hiddens, bias=False)         self.W_q = nn.LazyLinear(num_hiddens, bias=False)         self.w_v = nn.LazyLinear(1, bias=False)         self.dropout = nn.Dropout(dropout)      def forward(self, queries, keys, values, valid_lens):         queries, keys = self.W_q(queries), self.W_k(keys)         # After dimension expansion, shape of queries: (batch_size, no. of         # queries, 1, num_hiddens) and shape of keys: (batch_size, 1, no. of         # key-value pairs, num_hiddens). Sum them up with broadcasting         features = queries.unsqueeze(2) + keys.unsqueeze(1)         features = torch.tanh(features)         # There is only one output of self.w_v, so we remove the last         # one-dimensional entry from the shape. Shape of scores: (batch_size,         # no. of queries, no. of key-value pairs)         scores = self.w_v(features).squeeze(-1)         self.attention_weights = masked_softmax(scores, valid_lens)         # Shape of values: (batch_size, no. of key-value pairs, value         # dimension)         return torch.bmm(self.dropout(self.attention_weights), values) In\u00a0[\u00a0]: Copied! <pre>class AttentionDecoder(myutils.Decoder):\n    \"\"\"The base attention-based decoder interface.\n    Defined in :numref:`sec_seq2seq_attention`\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    @property\n    def attention_weights(self):\n        raise NotImplementedError\n</pre> class AttentionDecoder(myutils.Decoder):     \"\"\"The base attention-based decoder interface.     Defined in :numref:`sec_seq2seq_attention`\"\"\"      def __init__(self):         super().__init__()      @property     def attention_weights(self):         raise NotImplementedError In\u00a0[\u00a0]: Copied! <pre>class MultiHeadAttention(myutils.Module):\n    \"\"\"Multi-head attention.\n    Defined in :numref:`sec_multihead-attention`\"\"\"\n\n    def __init__(self, num_hiddens, num_heads, dropout, bias=False, **kwargs):\n        super().__init__()\n        self.num_heads = num_heads\n        self.attention = myutils.DotProductAttention(dropout)\n        self.W_q = nn.LazyLinear(num_hiddens, bias=bias)\n        self.W_k = nn.LazyLinear(num_hiddens, bias=bias)\n        self.W_v = nn.LazyLinear(num_hiddens, bias=bias)\n        self.W_o = nn.LazyLinear(num_hiddens, bias=bias)\n\n    def forward(self, queries, keys, values, valid_lens):\n        # Shape of queries, keys, or values:\n        # (batch_size, no. of queries or key-value pairs, num_hiddens)\n        # Shape of valid_lens: (batch_size,) or (batch_size, no. of queries)\n        # After transposing, shape of output queries, keys, or values:\n        # (batch_size * num_heads, no. of queries or key-value pairs,\n        # num_hiddens / num_heads)\n        queries = self.transpose_qkv(self.W_q(queries))\n        keys = self.transpose_qkv(self.W_k(keys))\n        values = self.transpose_qkv(self.W_v(values))\n\n        if valid_lens is not None:\n            # On axis 0, copy the first item (scalar or vector) for num_heads\n            # times, then copy the next item, and so on\n            valid_lens = torch.repeat_interleave(\n                valid_lens, repeats=self.num_heads, dim=0)\n\n        # Shape of output: (batch_size * num_heads, no. of queries,\n        # num_hiddens / num_heads)\n        output = self.attention(queries, keys, values, valid_lens)\n        # Shape of output_concat: (batch_size, no. of queries, num_hiddens)\n        output_concat = self.transpose_output(output)\n        return self.W_o(output_concat)\n\n    def transpose_qkv(self, X):\n        \"\"\"Transposition for parallel computation of multiple attention heads.\n    \n        Defined in :numref:`sec_multihead-attention`\"\"\"\n        # Shape of input X: (batch_size, no. of queries or key-value pairs,\n        # num_hiddens). Shape of output X: (batch_size, no. of queries or\n        # key-value pairs, num_heads, num_hiddens / num_heads)\n        X = X.reshape(X.shape[0], X.shape[1], self.num_heads, -1)\n        # Shape of output X: (batch_size, num_heads, no. of queries or key-value\n        # pairs, num_hiddens / num_heads)\n        X = X.permute(0, 2, 1, 3)\n        # Shape of output: (batch_size * num_heads, no. of queries or key-value\n        # pairs, num_hiddens / num_heads)\n        return X.reshape(-1, X.shape[2], X.shape[3])\n\n    def transpose_output(self, X):\n        \"\"\"Reverse the operation of transpose_qkv.\n    \n        Defined in :numref:`sec_multihead-attention`\"\"\"\n        X = X.reshape(-1, self.num_heads, X.shape[1], X.shape[2])\n        X = X.permute(0, 2, 1, 3)\n        return X.reshape(X.shape[0], X.shape[1], -1)\n</pre> class MultiHeadAttention(myutils.Module):     \"\"\"Multi-head attention.     Defined in :numref:`sec_multihead-attention`\"\"\"      def __init__(self, num_hiddens, num_heads, dropout, bias=False, **kwargs):         super().__init__()         self.num_heads = num_heads         self.attention = myutils.DotProductAttention(dropout)         self.W_q = nn.LazyLinear(num_hiddens, bias=bias)         self.W_k = nn.LazyLinear(num_hiddens, bias=bias)         self.W_v = nn.LazyLinear(num_hiddens, bias=bias)         self.W_o = nn.LazyLinear(num_hiddens, bias=bias)      def forward(self, queries, keys, values, valid_lens):         # Shape of queries, keys, or values:         # (batch_size, no. of queries or key-value pairs, num_hiddens)         # Shape of valid_lens: (batch_size,) or (batch_size, no. of queries)         # After transposing, shape of output queries, keys, or values:         # (batch_size * num_heads, no. of queries or key-value pairs,         # num_hiddens / num_heads)         queries = self.transpose_qkv(self.W_q(queries))         keys = self.transpose_qkv(self.W_k(keys))         values = self.transpose_qkv(self.W_v(values))          if valid_lens is not None:             # On axis 0, copy the first item (scalar or vector) for num_heads             # times, then copy the next item, and so on             valid_lens = torch.repeat_interleave(                 valid_lens, repeats=self.num_heads, dim=0)          # Shape of output: (batch_size * num_heads, no. of queries,         # num_hiddens / num_heads)         output = self.attention(queries, keys, values, valid_lens)         # Shape of output_concat: (batch_size, no. of queries, num_hiddens)         output_concat = self.transpose_output(output)         return self.W_o(output_concat)      def transpose_qkv(self, X):         \"\"\"Transposition for parallel computation of multiple attention heads.              Defined in :numref:`sec_multihead-attention`\"\"\"         # Shape of input X: (batch_size, no. of queries or key-value pairs,         # num_hiddens). Shape of output X: (batch_size, no. of queries or         # key-value pairs, num_heads, num_hiddens / num_heads)         X = X.reshape(X.shape[0], X.shape[1], self.num_heads, -1)         # Shape of output X: (batch_size, num_heads, no. of queries or key-value         # pairs, num_hiddens / num_heads)         X = X.permute(0, 2, 1, 3)         # Shape of output: (batch_size * num_heads, no. of queries or key-value         # pairs, num_hiddens / num_heads)         return X.reshape(-1, X.shape[2], X.shape[3])      def transpose_output(self, X):         \"\"\"Reverse the operation of transpose_qkv.              Defined in :numref:`sec_multihead-attention`\"\"\"         X = X.reshape(-1, self.num_heads, X.shape[1], X.shape[2])         X = X.permute(0, 2, 1, 3)         return X.reshape(X.shape[0], X.shape[1], -1) In\u00a0[\u00a0]: Copied! <pre>class PositionalEncoding(nn.Module):\n    \"\"\"Positional encoding.\n    Defined in :numref:`sec_self-attention-and-positional-encoding`\"\"\"\n\n    def __init__(self, num_hiddens, dropout, max_len=1000):\n        super().__init__()\n        self.dropout = nn.Dropout(dropout)\n        # Create a long enough P\n        self.P = myutils.zeros((1, max_len, num_hiddens))\n        X = myutils.arange(max_len, dtype=torch.float32).reshape(\n            -1, 1) / torch.pow(10000, torch.arange(\n            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n        self.P[:, :, 0::2] = torch.sin(X)\n        self.P[:, :, 1::2] = torch.cos(X)\n\n    def forward(self, X):\n        X = X + self.P[:, :X.shape[1], :].to(X.device)\n        return self.dropout(X)\n</pre> class PositionalEncoding(nn.Module):     \"\"\"Positional encoding.     Defined in :numref:`sec_self-attention-and-positional-encoding`\"\"\"      def __init__(self, num_hiddens, dropout, max_len=1000):         super().__init__()         self.dropout = nn.Dropout(dropout)         # Create a long enough P         self.P = myutils.zeros((1, max_len, num_hiddens))         X = myutils.arange(max_len, dtype=torch.float32).reshape(             -1, 1) / torch.pow(10000, torch.arange(             0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)         self.P[:, :, 0::2] = torch.sin(X)         self.P[:, :, 1::2] = torch.cos(X)      def forward(self, X):         X = X + self.P[:, :X.shape[1], :].to(X.device)         return self.dropout(X) In\u00a0[\u00a0]: Copied! <pre>class PositionWiseFFN(nn.Module):\n    \"\"\"The positionwise feed-forward network.\n    Defined in :numref:`sec_transformer`\"\"\"\n\n    def __init__(self, ffn_num_hiddens, ffn_num_outputs):\n        super().__init__()\n        self.dense1 = nn.LazyLinear(ffn_num_hiddens)\n        self.relu = nn.ReLU()\n        self.dense2 = nn.LazyLinear(ffn_num_outputs)\n\n    def forward(self, X):\n        return self.dense2(self.relu(self.dense1(X)))\n</pre> class PositionWiseFFN(nn.Module):     \"\"\"The positionwise feed-forward network.     Defined in :numref:`sec_transformer`\"\"\"      def __init__(self, ffn_num_hiddens, ffn_num_outputs):         super().__init__()         self.dense1 = nn.LazyLinear(ffn_num_hiddens)         self.relu = nn.ReLU()         self.dense2 = nn.LazyLinear(ffn_num_outputs)      def forward(self, X):         return self.dense2(self.relu(self.dense1(X))) In\u00a0[\u00a0]: Copied! <pre>class AddNorm(nn.Module):\n    \"\"\"The residual connection followed by layer normalization.\n    Defined in :numref:`subsec_positionwise-ffn`\"\"\"\n\n    def __init__(self, norm_shape, dropout):\n        super().__init__()\n        self.dropout = nn.Dropout(dropout)\n        self.ln = nn.LayerNorm(norm_shape)\n\n    def forward(self, X, Y):\n        return self.ln(self.dropout(Y) + X)\n</pre> class AddNorm(nn.Module):     \"\"\"The residual connection followed by layer normalization.     Defined in :numref:`subsec_positionwise-ffn`\"\"\"      def __init__(self, norm_shape, dropout):         super().__init__()         self.dropout = nn.Dropout(dropout)         self.ln = nn.LayerNorm(norm_shape)      def forward(self, X, Y):         return self.ln(self.dropout(Y) + X) In\u00a0[\u00a0]: Copied! <pre>class TransformerEncoderBlock(nn.Module):\n    \"\"\"The Transformer encoder block.\n    Defined in :numref:`subsec_positionwise-ffn`\"\"\"\n\n    def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout,\n                 use_bias=False):\n        super().__init__()\n        self.attention = myutils.MultiHeadAttention(num_hiddens, num_heads,\n                                                    dropout, use_bias)\n        self.addnorm1 = AddNorm(num_hiddens, dropout)\n        self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)\n        self.addnorm2 = AddNorm(num_hiddens, dropout)\n\n    def forward(self, X, valid_lens):\n        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))\n        return self.addnorm2(Y, self.ffn(Y))\n</pre> class TransformerEncoderBlock(nn.Module):     \"\"\"The Transformer encoder block.     Defined in :numref:`subsec_positionwise-ffn`\"\"\"      def __init__(self, num_hiddens, ffn_num_hiddens, num_heads, dropout,                  use_bias=False):         super().__init__()         self.attention = myutils.MultiHeadAttention(num_hiddens, num_heads,                                                     dropout, use_bias)         self.addnorm1 = AddNorm(num_hiddens, dropout)         self.ffn = PositionWiseFFN(ffn_num_hiddens, num_hiddens)         self.addnorm2 = AddNorm(num_hiddens, dropout)      def forward(self, X, valid_lens):         Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))         return self.addnorm2(Y, self.ffn(Y)) In\u00a0[\u00a0]: Copied! <pre>class TransformerEncoder(myutils.Encoder):\n    \"\"\"The Transformer encoder.\n    Defined in :numref:`subsec_transformer-encoder`\"\"\"\n\n    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens,\n                 num_heads, num_blks, dropout, use_bias=False):\n        super().__init__()\n        self.num_hiddens = num_hiddens\n        self.embedding = nn.Embedding(vocab_size, num_hiddens)\n        self.pos_encoding = myutils.PositionalEncoding(num_hiddens, dropout)\n        self.blks = nn.Sequential()\n        for i in range(num_blks):\n            self.blks.add_module(\"block\" + str(i), TransformerEncoderBlock(\n                num_hiddens, ffn_num_hiddens, num_heads, dropout, use_bias))\n\n    def forward(self, X, valid_lens):\n        # Since positional encoding values are between -1 and 1, the embedding\n        # values are multiplied by the square root of the embedding dimension\n        # to rescale before they are summed up\n        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))\n        self.attention_weights = [None] * len(self.blks)\n        for i, blk in enumerate(self.blks):\n            X = blk(X, valid_lens)\n            self.attention_weights[\n                i] = blk.attention.attention.attention_weights\n        return X\n</pre> class TransformerEncoder(myutils.Encoder):     \"\"\"The Transformer encoder.     Defined in :numref:`subsec_transformer-encoder`\"\"\"      def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens,                  num_heads, num_blks, dropout, use_bias=False):         super().__init__()         self.num_hiddens = num_hiddens         self.embedding = nn.Embedding(vocab_size, num_hiddens)         self.pos_encoding = myutils.PositionalEncoding(num_hiddens, dropout)         self.blks = nn.Sequential()         for i in range(num_blks):             self.blks.add_module(\"block\" + str(i), TransformerEncoderBlock(                 num_hiddens, ffn_num_hiddens, num_heads, dropout, use_bias))      def forward(self, X, valid_lens):         # Since positional encoding values are between -1 and 1, the embedding         # values are multiplied by the square root of the embedding dimension         # to rescale before they are summed up         X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))         self.attention_weights = [None] * len(self.blks)         for i, blk in enumerate(self.blks):             X = blk(X, valid_lens)             self.attention_weights[                 i] = blk.attention.attention.attention_weights         return X In\u00a0[\u00a0]: Copied! <pre>def annotate(text, xy, xytext):\n    \"\"\"Defined in :numref:`sec_optimization-intro`\"\"\"\n    myutils.plt.gca().annotate(text, xy=xy, xytext=xytext,\n                               arrowprops=dict(arrowstyle='-&gt;'))\n</pre> def annotate(text, xy, xytext):     \"\"\"Defined in :numref:`sec_optimization-intro`\"\"\"     myutils.plt.gca().annotate(text, xy=xy, xytext=xytext,                                arrowprops=dict(arrowstyle='-&gt;')) In\u00a0[\u00a0]: Copied! <pre>def train_2d(trainer, steps=20, f_grad=None):\n    \"\"\"Optimize a 2D objective function with a customized trainer.\n    Defined in :numref:`subsec_gd-learningrate`\"\"\"\n    # `s1` and `s2` are internal state variables that will be used in Momentum, adagrad, RMSProp\n    x1, x2, s1, s2 = -5, -2, 0, 0\n    results = [(x1, x2)]\n    for i in range(steps):\n        if f_grad:\n            x1, x2, s1, s2 = trainer(x1, x2, s1, s2, f_grad)\n        else:\n            x1, x2, s1, s2 = trainer(x1, x2, s1, s2)\n        results.append((x1, x2))\n    print(f'epoch {i + 1}, x1: {float(x1):f}, x2: {float(x2):f}')\n    return results\n</pre> def train_2d(trainer, steps=20, f_grad=None):     \"\"\"Optimize a 2D objective function with a customized trainer.     Defined in :numref:`subsec_gd-learningrate`\"\"\"     # `s1` and `s2` are internal state variables that will be used in Momentum, adagrad, RMSProp     x1, x2, s1, s2 = -5, -2, 0, 0     results = [(x1, x2)]     for i in range(steps):         if f_grad:             x1, x2, s1, s2 = trainer(x1, x2, s1, s2, f_grad)         else:             x1, x2, s1, s2 = trainer(x1, x2, s1, s2)         results.append((x1, x2))     print(f'epoch {i + 1}, x1: {float(x1):f}, x2: {float(x2):f}')     return results In\u00a0[\u00a0]: Copied! <pre>def show_trace_2d(f, results):\n    \"\"\"Show the trace of 2D variables during optimization.\n    Defined in :numref:`subsec_gd-learningrate`\"\"\"\n    myutils.set_figsize()\n    myutils.plt.plot(*zip(*results), '-o', color='#ff7f0e')\n    x1, x2 = myutils.meshgrid(myutils.arange(-5.5, 1.0, 0.1),\n                              myutils.arange(-3.0, 1.0, 0.1))\n    myutils.plt.contour(x1, x2, f(x1, x2), colors='#1f77b4')\n    myutils.plt.xlabel('x1')\n    myutils.plt.ylabel('x2')\n</pre> def show_trace_2d(f, results):     \"\"\"Show the trace of 2D variables during optimization.     Defined in :numref:`subsec_gd-learningrate`\"\"\"     myutils.set_figsize()     myutils.plt.plot(*zip(*results), '-o', color='#ff7f0e')     x1, x2 = myutils.meshgrid(myutils.arange(-5.5, 1.0, 0.1),                               myutils.arange(-3.0, 1.0, 0.1))     myutils.plt.contour(x1, x2, f(x1, x2), colors='#1f77b4')     myutils.plt.xlabel('x1')     myutils.plt.ylabel('x2') In\u00a0[\u00a0]: Copied! <pre>class Timer:\n    \"\"\"Record multiple running times.\"\"\"\n\n    def __init__(self):\n        \"\"\"Defined in :numref:`sec_minibatch_sgd`\"\"\"\n        self.times = []\n        self.start()\n\n    def start(self):\n        \"\"\"Start the timer.\"\"\"\n        self.tik = time.time()\n\n    def stop(self):\n        \"\"\"Stop the timer and record the time in a list.\"\"\"\n        self.times.append(time.time() - self.tik)\n        return self.times[-1]\n\n    def avg(self):\n        \"\"\"Return the average time.\"\"\"\n        return sum(self.times) / len(self.times)\n\n    def sum(self):\n        \"\"\"Return the sum of time.\"\"\"\n        return sum(self.times)\n\n    def cumsum(self):\n        \"\"\"Return the accumulated time.\"\"\"\n        return np.array(self.times).cumsum().tolist()\n</pre> class Timer:     \"\"\"Record multiple running times.\"\"\"      def __init__(self):         \"\"\"Defined in :numref:`sec_minibatch_sgd`\"\"\"         self.times = []         self.start()      def start(self):         \"\"\"Start the timer.\"\"\"         self.tik = time.time()      def stop(self):         \"\"\"Stop the timer and record the time in a list.\"\"\"         self.times.append(time.time() - self.tik)         return self.times[-1]      def avg(self):         \"\"\"Return the average time.\"\"\"         return sum(self.times) / len(self.times)      def sum(self):         \"\"\"Return the sum of time.\"\"\"         return sum(self.times)      def cumsum(self):         \"\"\"Return the accumulated time.\"\"\"         return np.array(self.times).cumsum().tolist() In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['airfoil'] = (myutils.DATA_URL + 'airfoil_self_noise.dat',\n                               '76e5be1548fd8222e5074cf0faae75edff8cf93f')\n</pre> myutils.DATA_HUB['airfoil'] = (myutils.DATA_URL + 'airfoil_self_noise.dat',                                '76e5be1548fd8222e5074cf0faae75edff8cf93f') In\u00a0[\u00a0]: Copied! <pre>def get_data_ch11(batch_size=10, n=1500):\n    \"\"\"Defined in :numref:`sec_minibatches`\"\"\"\n    data = np.genfromtxt(myutils.download('airfoil'),\n                         dtype=np.float32, delimiter='\\t')\n    data = torch.from_numpy((data - data.mean(axis=0)) / data.std(axis=0))\n    data_iter = myutils.load_array((data[:n, :-1], data[:n, -1]),\n                                   batch_size, is_train=True)\n    return data_iter, data.shape[1] - 1\n</pre> def get_data_ch11(batch_size=10, n=1500):     \"\"\"Defined in :numref:`sec_minibatches`\"\"\"     data = np.genfromtxt(myutils.download('airfoil'),                          dtype=np.float32, delimiter='\\t')     data = torch.from_numpy((data - data.mean(axis=0)) / data.std(axis=0))     data_iter = myutils.load_array((data[:n, :-1], data[:n, -1]),                                    batch_size, is_train=True)     return data_iter, data.shape[1] - 1 In\u00a0[\u00a0]: Copied! <pre>def train_ch11(trainer_fn, states, hyperparams, data_iter,\n               feature_dim, num_epochs=2):\n    \"\"\"Defined in :numref:`sec_minibatches`\"\"\"\n    # Initialization\n    w = torch.normal(mean=0.0, std=0.01, size=(feature_dim, 1),\n                     requires_grad=True)\n    b = torch.zeros((1), requires_grad=True)\n    net, loss = lambda X: myutils.linreg(X, w, b), myutils.squared_loss\n    # Train\n    animator = myutils.Animator(xlabel='epoch', ylabel='loss',\n                                xlim=[0, num_epochs], ylim=[0.22, 0.35])\n    n, timer = 0, myutils.Timer()\n    for _ in range(num_epochs):\n        for X, y in data_iter:\n            l = loss(net(X), y).mean()\n            l.backward()\n            trainer_fn([w, b], states, hyperparams)\n            n += X.shape[0]\n            if n % 200 == 0:\n                timer.stop()\n                animator.add(n / X.shape[0] / len(data_iter),\n                             (myutils.evaluate_loss(net, data_iter, loss),))\n                timer.start()\n    print(f'loss: {animator.Y[0][-1]:.3f}, {timer.sum() / num_epochs:.3f} sec/epoch')\n    return timer.cumsum(), animator.Y[0]\n</pre> def train_ch11(trainer_fn, states, hyperparams, data_iter,                feature_dim, num_epochs=2):     \"\"\"Defined in :numref:`sec_minibatches`\"\"\"     # Initialization     w = torch.normal(mean=0.0, std=0.01, size=(feature_dim, 1),                      requires_grad=True)     b = torch.zeros((1), requires_grad=True)     net, loss = lambda X: myutils.linreg(X, w, b), myutils.squared_loss     # Train     animator = myutils.Animator(xlabel='epoch', ylabel='loss',                                 xlim=[0, num_epochs], ylim=[0.22, 0.35])     n, timer = 0, myutils.Timer()     for _ in range(num_epochs):         for X, y in data_iter:             l = loss(net(X), y).mean()             l.backward()             trainer_fn([w, b], states, hyperparams)             n += X.shape[0]             if n % 200 == 0:                 timer.stop()                 animator.add(n / X.shape[0] / len(data_iter),                              (myutils.evaluate_loss(net, data_iter, loss),))                 timer.start()     print(f'loss: {animator.Y[0][-1]:.3f}, {timer.sum() / num_epochs:.3f} sec/epoch')     return timer.cumsum(), animator.Y[0] In\u00a0[\u00a0]: Copied! <pre>def train_concise_ch11(trainer_fn, hyperparams, data_iter, num_epochs=4):\n    \"\"\"Defined in :numref:`sec_minibatches`\"\"\"\n    # Initialization\n    net = nn.Sequential(nn.Linear(5, 1))\n\n    def init_weights(module):\n        if type(module) == nn.Linear:\n            torch.nn.init.normal_(module.weight, std=0.01)\n\n    net.apply(init_weights)\n\n    optimizer = trainer_fn(net.parameters(), **hyperparams)\n    loss = nn.MSELoss(reduction='none')\n    animator = myutils.Animator(xlabel='epoch', ylabel='loss',\n                                xlim=[0, num_epochs], ylim=[0.22, 0.35])\n    n, timer = 0, myutils.Timer()\n    for _ in range(num_epochs):\n        for X, y in data_iter:\n            optimizer.zero_grad()\n            out = net(X)\n            y = y.reshape(out.shape)\n            l = loss(out, y)\n            l.mean().backward()\n            optimizer.step()\n            n += X.shape[0]\n            if n % 200 == 0:\n                timer.stop()\n                # `MSELoss` computes squared error without the 1/2 factor\n                animator.add(n / X.shape[0] / len(data_iter),\n                             (myutils.evaluate_loss(net, data_iter, loss) / 2,))\n                timer.start()\n    print(f'loss: {animator.Y[0][-1]:.3f}, {timer.sum() / num_epochs:.3f} sec/epoch')\n</pre> def train_concise_ch11(trainer_fn, hyperparams, data_iter, num_epochs=4):     \"\"\"Defined in :numref:`sec_minibatches`\"\"\"     # Initialization     net = nn.Sequential(nn.Linear(5, 1))      def init_weights(module):         if type(module) == nn.Linear:             torch.nn.init.normal_(module.weight, std=0.01)      net.apply(init_weights)      optimizer = trainer_fn(net.parameters(), **hyperparams)     loss = nn.MSELoss(reduction='none')     animator = myutils.Animator(xlabel='epoch', ylabel='loss',                                 xlim=[0, num_epochs], ylim=[0.22, 0.35])     n, timer = 0, myutils.Timer()     for _ in range(num_epochs):         for X, y in data_iter:             optimizer.zero_grad()             out = net(X)             y = y.reshape(out.shape)             l = loss(out, y)             l.mean().backward()             optimizer.step()             n += X.shape[0]             if n % 200 == 0:                 timer.stop()                 # `MSELoss` computes squared error without the 1/2 factor                 animator.add(n / X.shape[0] / len(data_iter),                              (myutils.evaluate_loss(net, data_iter, loss) / 2,))                 timer.start()     print(f'loss: {animator.Y[0][-1]:.3f}, {timer.sum() / num_epochs:.3f} sec/epoch') In\u00a0[\u00a0]: Copied! <pre>class Benchmark:\n    \"\"\"For measuring running time.\"\"\"\n\n    def __init__(self, description='Done'):\n        \"\"\"Defined in :numref:`sec_hybridize`\"\"\"\n        self.description = description\n\n    def __enter__(self):\n        self.timer = myutils.Timer()\n        return self\n\n    def __exit__(self, *args):\n        print(f'{self.description}: {self.timer.stop():.4f} sec')\n</pre> class Benchmark:     \"\"\"For measuring running time.\"\"\"      def __init__(self, description='Done'):         \"\"\"Defined in :numref:`sec_hybridize`\"\"\"         self.description = description      def __enter__(self):         self.timer = myutils.Timer()         return self      def __exit__(self, *args):         print(f'{self.description}: {self.timer.stop():.4f} sec') In\u00a0[\u00a0]: Copied! <pre>def split_batch(X, y, devices):\n    \"\"\"Split `X` and `y` into multiple devices.\n    Defined in :numref:`sec_multi_gpu`\"\"\"\n    assert X.shape[0] == y.shape[0]\n    return (nn.parallel.scatter(X, devices),\n            nn.parallel.scatter(y, devices))\n</pre> def split_batch(X, y, devices):     \"\"\"Split `X` and `y` into multiple devices.     Defined in :numref:`sec_multi_gpu`\"\"\"     assert X.shape[0] == y.shape[0]     return (nn.parallel.scatter(X, devices),             nn.parallel.scatter(y, devices)) In\u00a0[\u00a0]: Copied! <pre>def resnet18(num_classes, in_channels=1):\n    \"\"\"A slightly modified ResNet-18 model.\n    Defined in :numref:`sec_multi_gpu_concise`\"\"\"\n\n    def resnet_block(in_channels, out_channels, num_residuals,\n                     first_block=False):\n        blk = []\n        for i in range(num_residuals):\n            if i == 0 and not first_block:\n                blk.append(myutils.Residual(out_channels, use_1x1conv=True,\n                                            strides=2))\n            else:\n                blk.append(myutils.Residual(out_channels))\n        return nn.Sequential(*blk)\n\n    # This model uses a smaller convolution kernel, stride, and padding and\n    # removes the max-pooling layer\n    net = nn.Sequential(\n        nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),\n        nn.BatchNorm2d(64),\n        nn.ReLU())\n    net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))\n    net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))\n    net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))\n    net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))\n    net.add_module(\"global_avg_pool\", nn.AdaptiveAvgPool2d((1, 1)))\n    net.add_module(\"fc\", nn.Sequential(nn.Flatten(),\n                                       nn.Linear(512, num_classes)))\n    return net\n</pre> def resnet18(num_classes, in_channels=1):     \"\"\"A slightly modified ResNet-18 model.     Defined in :numref:`sec_multi_gpu_concise`\"\"\"      def resnet_block(in_channels, out_channels, num_residuals,                      first_block=False):         blk = []         for i in range(num_residuals):             if i == 0 and not first_block:                 blk.append(myutils.Residual(out_channels, use_1x1conv=True,                                             strides=2))             else:                 blk.append(myutils.Residual(out_channels))         return nn.Sequential(*blk)      # This model uses a smaller convolution kernel, stride, and padding and     # removes the max-pooling layer     net = nn.Sequential(         nn.Conv2d(in_channels, 64, kernel_size=3, stride=1, padding=1),         nn.BatchNorm2d(64),         nn.ReLU())     net.add_module(\"resnet_block1\", resnet_block(64, 64, 2, first_block=True))     net.add_module(\"resnet_block2\", resnet_block(64, 128, 2))     net.add_module(\"resnet_block3\", resnet_block(128, 256, 2))     net.add_module(\"resnet_block4\", resnet_block(256, 512, 2))     net.add_module(\"global_avg_pool\", nn.AdaptiveAvgPool2d((1, 1)))     net.add_module(\"fc\", nn.Sequential(nn.Flatten(),                                        nn.Linear(512, num_classes)))     return net In\u00a0[\u00a0]: Copied! <pre>def train_batch_ch13(net, X, y, loss, trainer, devices):\n    \"\"\"Train for a minibatch with multiple GPUs (defined in Chapter 13).\n    Defined in :numref:`sec_image_augmentation`\"\"\"\n    if isinstance(X, list):\n        # Required for BERT fine-tuning (to be covered later)\n        X = [x.to(devices[0]) for x in X]\n    else:\n        X = X.to(devices[0])\n    y = y.to(devices[0])\n    net.train()\n    trainer.zero_grad()\n    pred = net(X)\n    l = loss(pred, y)\n    l.sum().backward()\n    trainer.step()\n    train_loss_sum = l.sum()\n    train_acc_sum = myutils.accuracy(pred, y)\n    return train_loss_sum, train_acc_sum\n</pre> def train_batch_ch13(net, X, y, loss, trainer, devices):     \"\"\"Train for a minibatch with multiple GPUs (defined in Chapter 13).     Defined in :numref:`sec_image_augmentation`\"\"\"     if isinstance(X, list):         # Required for BERT fine-tuning (to be covered later)         X = [x.to(devices[0]) for x in X]     else:         X = X.to(devices[0])     y = y.to(devices[0])     net.train()     trainer.zero_grad()     pred = net(X)     l = loss(pred, y)     l.sum().backward()     trainer.step()     train_loss_sum = l.sum()     train_acc_sum = myutils.accuracy(pred, y)     return train_loss_sum, train_acc_sum In\u00a0[\u00a0]: Copied! <pre>def train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,\n               devices=myutils.try_all_gpus()):\n    \"\"\"Train a model with multiple GPUs (defined in Chapter 13).\n    Defined in :numref:`sec_image_augmentation`\"\"\"\n    timer, num_batches = myutils.Timer(), len(train_iter)\n    animator = myutils.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1],\n                                legend=['train loss', 'train acc', 'test acc'])\n    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n    for epoch in range(num_epochs):\n        # Sum of training loss, sum of training accuracy, no. of examples,\n        # no. of predictions\n        metric = myutils.Accumulator(4)\n        for i, (features, labels) in enumerate(train_iter):\n            timer.start()\n            l, acc = train_batch_ch13(\n                net, features, labels, loss, trainer, devices)\n            metric.add(l, acc, labels.shape[0], labels.numel())\n            timer.stop()\n            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n                animator.add(epoch + (i + 1) / num_batches,\n                             (metric[0] / metric[2], metric[1] / metric[3],\n                              None))\n        test_acc = myutils.evaluate_accuracy_gpu(net, test_iter)\n        animator.add(epoch + 1, (None, None, test_acc))\n    print(f'loss {metric[0] / metric[2]:.3f}, train acc '\n          f'{metric[1] / metric[3]:.3f}, test acc {test_acc:.3f}')\n    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on '\n          f'{str(devices)}')\n</pre> def train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs,                devices=myutils.try_all_gpus()):     \"\"\"Train a model with multiple GPUs (defined in Chapter 13).     Defined in :numref:`sec_image_augmentation`\"\"\"     timer, num_batches = myutils.Timer(), len(train_iter)     animator = myutils.Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0, 1],                                 legend=['train loss', 'train acc', 'test acc'])     net = nn.DataParallel(net, device_ids=devices).to(devices[0])     for epoch in range(num_epochs):         # Sum of training loss, sum of training accuracy, no. of examples,         # no. of predictions         metric = myutils.Accumulator(4)         for i, (features, labels) in enumerate(train_iter):             timer.start()             l, acc = train_batch_ch13(                 net, features, labels, loss, trainer, devices)             metric.add(l, acc, labels.shape[0], labels.numel())             timer.stop()             if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:                 animator.add(epoch + (i + 1) / num_batches,                              (metric[0] / metric[2], metric[1] / metric[3],                               None))         test_acc = myutils.evaluate_accuracy_gpu(net, test_iter)         animator.add(epoch + 1, (None, None, test_acc))     print(f'loss {metric[0] / metric[2]:.3f}, train acc '           f'{metric[1] / metric[3]:.3f}, test acc {test_acc:.3f}')     print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec on '           f'{str(devices)}') In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['hotdog'] = (myutils.DATA_URL + 'hotdog.zip',\n                              'fba480ffa8aa7e0febbb511d181409f899b9baa5')\n</pre> myutils.DATA_HUB['hotdog'] = (myutils.DATA_URL + 'hotdog.zip',                               'fba480ffa8aa7e0febbb511d181409f899b9baa5') In\u00a0[\u00a0]: Copied! <pre>def box_corner_to_center(boxes):\n    \"\"\"Convert from (upper-left, lower-right) to (center, width, height).\n    Defined in :numref:`sec_bbox`\"\"\"\n    x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n    cx = (x1 + x2) / 2\n    cy = (y1 + y2) / 2\n    w = x2 - x1\n    h = y2 - y1\n    boxes = myutils.stack((cx, cy, w, h), axis=-1)\n    return boxes\n</pre> def box_corner_to_center(boxes):     \"\"\"Convert from (upper-left, lower-right) to (center, width, height).     Defined in :numref:`sec_bbox`\"\"\"     x1, y1, x2, y2 = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]     cx = (x1 + x2) / 2     cy = (y1 + y2) / 2     w = x2 - x1     h = y2 - y1     boxes = myutils.stack((cx, cy, w, h), axis=-1)     return boxes In\u00a0[\u00a0]: Copied! <pre>def box_center_to_corner(boxes):\n    \"\"\"Convert from (center, width, height) to (upper-left, lower-right).\n    Defined in :numref:`sec_bbox`\"\"\"\n    cx, cy, w, h = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]\n    x1 = cx - 0.5 * w\n    y1 = cy - 0.5 * h\n    x2 = cx + 0.5 * w\n    y2 = cy + 0.5 * h\n    boxes = myutils.stack((x1, y1, x2, y2), axis=-1)\n    return boxes\n</pre> def box_center_to_corner(boxes):     \"\"\"Convert from (center, width, height) to (upper-left, lower-right).     Defined in :numref:`sec_bbox`\"\"\"     cx, cy, w, h = boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]     x1 = cx - 0.5 * w     y1 = cy - 0.5 * h     x2 = cx + 0.5 * w     y2 = cy + 0.5 * h     boxes = myutils.stack((x1, y1, x2, y2), axis=-1)     return boxes In\u00a0[\u00a0]: Copied! <pre>def bbox_to_rect(bbox, color):\n    \"\"\"Convert bounding box to matplotlib format.\n    Defined in :numref:`sec_bbox`\"\"\"\n    # Convert the bounding box (upper-left x, upper-left y, lower-right x,\n    # lower-right y) format to the matplotlib format: ((upper-left x,\n    # upper-left y), width, height)\n    return myutils.plt.Rectangle(\n        xy=(bbox[0], bbox[1]), width=bbox[2] - bbox[0], height=bbox[3] - bbox[1],\n        fill=False, edgecolor=color, linewidth=2)\n</pre> def bbox_to_rect(bbox, color):     \"\"\"Convert bounding box to matplotlib format.     Defined in :numref:`sec_bbox`\"\"\"     # Convert the bounding box (upper-left x, upper-left y, lower-right x,     # lower-right y) format to the matplotlib format: ((upper-left x,     # upper-left y), width, height)     return myutils.plt.Rectangle(         xy=(bbox[0], bbox[1]), width=bbox[2] - bbox[0], height=bbox[3] - bbox[1],         fill=False, edgecolor=color, linewidth=2) In\u00a0[\u00a0]: Copied! <pre>def multibox_prior(data, sizes, ratios):\n    \"\"\"Generate anchor boxes with different shapes centered on each pixel.\n    Defined in :numref:`sec_anchor`\"\"\"\n    in_height, in_width = data.shape[-2:]\n    device, num_sizes, num_ratios = data.device, len(sizes), len(ratios)\n    boxes_per_pixel = (num_sizes + num_ratios - 1)\n    size_tensor = myutils.tensor(sizes, device=device)\n    ratio_tensor = myutils.tensor(ratios, device=device)\n    # Offsets are required to move the anchor to the center of a pixel. Since\n    # a pixel has height=1 and width=1, we choose to offset our centers by 0.5\n    offset_h, offset_w = 0.5, 0.5\n    steps_h = 1.0 / in_height  # Scaled steps in y axis\n    steps_w = 1.0 / in_width  # Scaled steps in x axis\n\n    # Generate all center points for the anchor boxes\n    center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h\n    center_w = (torch.arange(in_width, device=device) + offset_w) * steps_w\n    shift_y, shift_x = torch.meshgrid(center_h, center_w, indexing='ij')\n    shift_y, shift_x = shift_y.reshape(-1), shift_x.reshape(-1)\n\n    # Generate `boxes_per_pixel` number of heights and widths that are later\n    # used to create anchor box corner coordinates (xmin, xmax, ymin, ymax)\n    w = torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]),\n                   sizes[0] * torch.sqrt(ratio_tensor[1:]))) \\\n        * in_height / in_width  # Handle rectangular inputs\n    h = torch.cat((size_tensor / torch.sqrt(ratio_tensor[0]),\n                   sizes[0] / torch.sqrt(ratio_tensor[1:])))\n    # Divide by 2 to get half height and half width\n    anchor_manipulations = torch.stack((-w, -h, w, h)).T.repeat(\n        in_height * in_width, 1) / 2\n\n    # Each center point will have `boxes_per_pixel` number of anchor boxes, so\n    # generate a grid of all anchor box centers with `boxes_per_pixel` repeats\n    out_grid = torch.stack([shift_x, shift_y, shift_x, shift_y],\n                           dim=1).repeat_interleave(boxes_per_pixel, dim=0)\n    output = out_grid + anchor_manipulations\n    return output.unsqueeze(0)\n</pre> def multibox_prior(data, sizes, ratios):     \"\"\"Generate anchor boxes with different shapes centered on each pixel.     Defined in :numref:`sec_anchor`\"\"\"     in_height, in_width = data.shape[-2:]     device, num_sizes, num_ratios = data.device, len(sizes), len(ratios)     boxes_per_pixel = (num_sizes + num_ratios - 1)     size_tensor = myutils.tensor(sizes, device=device)     ratio_tensor = myutils.tensor(ratios, device=device)     # Offsets are required to move the anchor to the center of a pixel. Since     # a pixel has height=1 and width=1, we choose to offset our centers by 0.5     offset_h, offset_w = 0.5, 0.5     steps_h = 1.0 / in_height  # Scaled steps in y axis     steps_w = 1.0 / in_width  # Scaled steps in x axis      # Generate all center points for the anchor boxes     center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h     center_w = (torch.arange(in_width, device=device) + offset_w) * steps_w     shift_y, shift_x = torch.meshgrid(center_h, center_w, indexing='ij')     shift_y, shift_x = shift_y.reshape(-1), shift_x.reshape(-1)      # Generate `boxes_per_pixel` number of heights and widths that are later     # used to create anchor box corner coordinates (xmin, xmax, ymin, ymax)     w = torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]),                    sizes[0] * torch.sqrt(ratio_tensor[1:]))) \\         * in_height / in_width  # Handle rectangular inputs     h = torch.cat((size_tensor / torch.sqrt(ratio_tensor[0]),                    sizes[0] / torch.sqrt(ratio_tensor[1:])))     # Divide by 2 to get half height and half width     anchor_manipulations = torch.stack((-w, -h, w, h)).T.repeat(         in_height * in_width, 1) / 2      # Each center point will have `boxes_per_pixel` number of anchor boxes, so     # generate a grid of all anchor box centers with `boxes_per_pixel` repeats     out_grid = torch.stack([shift_x, shift_y, shift_x, shift_y],                            dim=1).repeat_interleave(boxes_per_pixel, dim=0)     output = out_grid + anchor_manipulations     return output.unsqueeze(0) In\u00a0[\u00a0]: Copied! <pre>def show_bboxes(axes, bboxes, labels=None, colors=None):\n    \"\"\"Show bounding boxes.\n    Defined in :numref:`sec_anchor`\"\"\"\n\n    def make_list(obj, default_values=None):\n        if obj is None:\n            obj = default_values\n        elif not isinstance(obj, (list, tuple)):\n            obj = [obj]\n        return obj\n\n    labels = make_list(labels)\n    colors = make_list(colors, ['b', 'g', 'r', 'm', 'c'])\n    for i, bbox in enumerate(bboxes):\n        color = colors[i % len(colors)]\n        rect = myutils.bbox_to_rect(myutils.numpy(bbox), color)\n        axes.add_patch(rect)\n        if labels and len(labels) &gt; i:\n            text_color = 'k' if color == 'w' else 'w'\n            axes.text(rect.xy[0], rect.xy[1], labels[i],\n                      va='center', ha='center', fontsize=9, color=text_color,\n                      bbox=dict(facecolor=color, lw=0))\n</pre> def show_bboxes(axes, bboxes, labels=None, colors=None):     \"\"\"Show bounding boxes.     Defined in :numref:`sec_anchor`\"\"\"      def make_list(obj, default_values=None):         if obj is None:             obj = default_values         elif not isinstance(obj, (list, tuple)):             obj = [obj]         return obj      labels = make_list(labels)     colors = make_list(colors, ['b', 'g', 'r', 'm', 'c'])     for i, bbox in enumerate(bboxes):         color = colors[i % len(colors)]         rect = myutils.bbox_to_rect(myutils.numpy(bbox), color)         axes.add_patch(rect)         if labels and len(labels) &gt; i:             text_color = 'k' if color == 'w' else 'w'             axes.text(rect.xy[0], rect.xy[1], labels[i],                       va='center', ha='center', fontsize=9, color=text_color,                       bbox=dict(facecolor=color, lw=0)) In\u00a0[\u00a0]: Copied! <pre>def box_iou(boxes1, boxes2):\n    \"\"\"Compute pairwise IoU across two lists of anchor or bounding boxes.\n    Defined in :numref:`sec_anchor`\"\"\"\n    box_area = lambda boxes: ((boxes[:, 2] - boxes[:, 0]) *\n                              (boxes[:, 3] - boxes[:, 1]))\n    # Shape of `boxes1`, `boxes2`, `areas1`, `areas2`: (no. of boxes1, 4),\n    # (no. of boxes2, 4), (no. of boxes1,), (no. of boxes2,)\n    areas1 = box_area(boxes1)\n    areas2 = box_area(boxes2)\n    # Shape of `inter_upperlefts`, `inter_lowerrights`, `inters`: (no. of\n    # boxes1, no. of boxes2, 2)\n    inter_upperlefts = torch.max(boxes1[:, None, :2], boxes2[:, :2])\n    inter_lowerrights = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])\n    inters = (inter_lowerrights - inter_upperlefts).clamp(min=0)\n    # Shape of `inter_areas` and `union_areas`: (no. of boxes1, no. of boxes2)\n    inter_areas = inters[:, :, 0] * inters[:, :, 1]\n    union_areas = areas1[:, None] + areas2 - inter_areas\n    return inter_areas / union_areas\n</pre> def box_iou(boxes1, boxes2):     \"\"\"Compute pairwise IoU across two lists of anchor or bounding boxes.     Defined in :numref:`sec_anchor`\"\"\"     box_area = lambda boxes: ((boxes[:, 2] - boxes[:, 0]) *                               (boxes[:, 3] - boxes[:, 1]))     # Shape of `boxes1`, `boxes2`, `areas1`, `areas2`: (no. of boxes1, 4),     # (no. of boxes2, 4), (no. of boxes1,), (no. of boxes2,)     areas1 = box_area(boxes1)     areas2 = box_area(boxes2)     # Shape of `inter_upperlefts`, `inter_lowerrights`, `inters`: (no. of     # boxes1, no. of boxes2, 2)     inter_upperlefts = torch.max(boxes1[:, None, :2], boxes2[:, :2])     inter_lowerrights = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])     inters = (inter_lowerrights - inter_upperlefts).clamp(min=0)     # Shape of `inter_areas` and `union_areas`: (no. of boxes1, no. of boxes2)     inter_areas = inters[:, :, 0] * inters[:, :, 1]     union_areas = areas1[:, None] + areas2 - inter_areas     return inter_areas / union_areas In\u00a0[\u00a0]: Copied! <pre>def assign_anchor_to_bbox(ground_truth, anchors, device, iou_threshold=0.5):\n    \"\"\"Assign closest ground-truth bounding boxes to anchor boxes.\n    Defined in :numref:`sec_anchor`\"\"\"\n    num_anchors, num_gt_boxes = anchors.shape[0], ground_truth.shape[0]\n    # Element x_ij in the i-th row and j-th column is the IoU of the anchor\n    # box i and the ground-truth bounding box j\n    jaccard = box_iou(anchors, ground_truth)\n    # Initialize the tensor to hold the assigned ground-truth bounding box for\n    # each anchor\n    anchors_bbox_map = torch.full((num_anchors,), -1, dtype=torch.long,\n                                  device=device)\n    # Assign ground-truth bounding boxes according to the threshold\n    max_ious, indices = torch.max(jaccard, dim=1)\n    anc_i = torch.nonzero(max_ious &gt;= iou_threshold).reshape(-1)\n    box_j = indices[max_ious &gt;= iou_threshold]\n    anchors_bbox_map[anc_i] = box_j\n    col_discard = torch.full((num_anchors,), -1)\n    row_discard = torch.full((num_gt_boxes,), -1)\n    for _ in range(num_gt_boxes):\n        max_idx = torch.argmax(jaccard)  # Find the largest IoU\n        box_idx = (max_idx % num_gt_boxes).long()\n        anc_idx = (max_idx / num_gt_boxes).long()\n        anchors_bbox_map[anc_idx] = box_idx\n        jaccard[:, box_idx] = col_discard\n        jaccard[anc_idx, :] = row_discard\n    return anchors_bbox_map\n</pre> def assign_anchor_to_bbox(ground_truth, anchors, device, iou_threshold=0.5):     \"\"\"Assign closest ground-truth bounding boxes to anchor boxes.     Defined in :numref:`sec_anchor`\"\"\"     num_anchors, num_gt_boxes = anchors.shape[0], ground_truth.shape[0]     # Element x_ij in the i-th row and j-th column is the IoU of the anchor     # box i and the ground-truth bounding box j     jaccard = box_iou(anchors, ground_truth)     # Initialize the tensor to hold the assigned ground-truth bounding box for     # each anchor     anchors_bbox_map = torch.full((num_anchors,), -1, dtype=torch.long,                                   device=device)     # Assign ground-truth bounding boxes according to the threshold     max_ious, indices = torch.max(jaccard, dim=1)     anc_i = torch.nonzero(max_ious &gt;= iou_threshold).reshape(-1)     box_j = indices[max_ious &gt;= iou_threshold]     anchors_bbox_map[anc_i] = box_j     col_discard = torch.full((num_anchors,), -1)     row_discard = torch.full((num_gt_boxes,), -1)     for _ in range(num_gt_boxes):         max_idx = torch.argmax(jaccard)  # Find the largest IoU         box_idx = (max_idx % num_gt_boxes).long()         anc_idx = (max_idx / num_gt_boxes).long()         anchors_bbox_map[anc_idx] = box_idx         jaccard[:, box_idx] = col_discard         jaccard[anc_idx, :] = row_discard     return anchors_bbox_map In\u00a0[\u00a0]: Copied! <pre>def offset_boxes(anchors, assigned_bb, eps=1e-6):\n    \"\"\"Transform for anchor box offsets.\n    Defined in :numref:`subsec_labeling-anchor-boxes`\"\"\"\n    c_anc = myutils.box_corner_to_center(anchors)\n    c_assigned_bb = myutils.box_corner_to_center(assigned_bb)\n    offset_xy = 10 * (c_assigned_bb[:, :2] - c_anc[:, :2]) / c_anc[:, 2:]\n    offset_wh = 5 * myutils.log(eps + c_assigned_bb[:, 2:] / c_anc[:, 2:])\n    offset = myutils.concat([offset_xy, offset_wh], axis=1)\n    return offset\n</pre> def offset_boxes(anchors, assigned_bb, eps=1e-6):     \"\"\"Transform for anchor box offsets.     Defined in :numref:`subsec_labeling-anchor-boxes`\"\"\"     c_anc = myutils.box_corner_to_center(anchors)     c_assigned_bb = myutils.box_corner_to_center(assigned_bb)     offset_xy = 10 * (c_assigned_bb[:, :2] - c_anc[:, :2]) / c_anc[:, 2:]     offset_wh = 5 * myutils.log(eps + c_assigned_bb[:, 2:] / c_anc[:, 2:])     offset = myutils.concat([offset_xy, offset_wh], axis=1)     return offset In\u00a0[\u00a0]: Copied! <pre>def multibox_target(anchors, labels):\n    \"\"\"Label anchor boxes using ground-truth bounding boxes.\n    Defined in :numref:`subsec_labeling-anchor-boxes`\"\"\"\n    batch_size, anchors = labels.shape[0], anchors.squeeze(0)\n    batch_offset, batch_mask, batch_class_labels = [], [], []\n    device, num_anchors = anchors.device, anchors.shape[0]\n    for i in range(batch_size):\n        label = labels[i, :, :]\n        anchors_bbox_map = assign_anchor_to_bbox(\n            label[:, 1:], anchors, device)\n        bbox_mask = ((anchors_bbox_map &gt;= 0).float().unsqueeze(-1)).repeat(\n            1, 4)\n        # Initialize class labels and assigned bounding box coordinates with\n        # zeros\n        class_labels = torch.zeros(num_anchors, dtype=torch.long,\n                                   device=device)\n        assigned_bb = torch.zeros((num_anchors, 4), dtype=torch.float32,\n                                  device=device)\n        # Label classes of anchor boxes using their assigned ground-truth\n        # bounding boxes. If an anchor box is not assigned any, we label its\n        # class as background (the value remains zero)\n        indices_true = torch.nonzero(anchors_bbox_map &gt;= 0)\n        bb_idx = anchors_bbox_map[indices_true]\n        class_labels[indices_true] = label[bb_idx, 0].long() + 1\n        assigned_bb[indices_true] = label[bb_idx, 1:]\n        # Offset transformation\n        offset = offset_boxes(anchors, assigned_bb) * bbox_mask\n        batch_offset.append(offset.reshape(-1))\n        batch_mask.append(bbox_mask.reshape(-1))\n        batch_class_labels.append(class_labels)\n    bbox_offset = torch.stack(batch_offset)\n    bbox_mask = torch.stack(batch_mask)\n    class_labels = torch.stack(batch_class_labels)\n    return (bbox_offset, bbox_mask, class_labels)\n</pre> def multibox_target(anchors, labels):     \"\"\"Label anchor boxes using ground-truth bounding boxes.     Defined in :numref:`subsec_labeling-anchor-boxes`\"\"\"     batch_size, anchors = labels.shape[0], anchors.squeeze(0)     batch_offset, batch_mask, batch_class_labels = [], [], []     device, num_anchors = anchors.device, anchors.shape[0]     for i in range(batch_size):         label = labels[i, :, :]         anchors_bbox_map = assign_anchor_to_bbox(             label[:, 1:], anchors, device)         bbox_mask = ((anchors_bbox_map &gt;= 0).float().unsqueeze(-1)).repeat(             1, 4)         # Initialize class labels and assigned bounding box coordinates with         # zeros         class_labels = torch.zeros(num_anchors, dtype=torch.long,                                    device=device)         assigned_bb = torch.zeros((num_anchors, 4), dtype=torch.float32,                                   device=device)         # Label classes of anchor boxes using their assigned ground-truth         # bounding boxes. If an anchor box is not assigned any, we label its         # class as background (the value remains zero)         indices_true = torch.nonzero(anchors_bbox_map &gt;= 0)         bb_idx = anchors_bbox_map[indices_true]         class_labels[indices_true] = label[bb_idx, 0].long() + 1         assigned_bb[indices_true] = label[bb_idx, 1:]         # Offset transformation         offset = offset_boxes(anchors, assigned_bb) * bbox_mask         batch_offset.append(offset.reshape(-1))         batch_mask.append(bbox_mask.reshape(-1))         batch_class_labels.append(class_labels)     bbox_offset = torch.stack(batch_offset)     bbox_mask = torch.stack(batch_mask)     class_labels = torch.stack(batch_class_labels)     return (bbox_offset, bbox_mask, class_labels) In\u00a0[\u00a0]: Copied! <pre>def offset_inverse(anchors, offset_preds):\n    \"\"\"Predict bounding boxes based on anchor boxes with predicted offsets.\n    Defined in :numref:`subsec_labeling-anchor-boxes`\"\"\"\n    anc = myutils.box_corner_to_center(anchors)\n    pred_bbox_xy = (offset_preds[:, :2] * anc[:, 2:] / 10) + anc[:, :2]\n    pred_bbox_wh = myutils.exp(offset_preds[:, 2:] / 5) * anc[:, 2:]\n    pred_bbox = myutils.concat((pred_bbox_xy, pred_bbox_wh), axis=1)\n    predicted_bbox = myutils.box_center_to_corner(pred_bbox)\n    return predicted_bbox\n</pre> def offset_inverse(anchors, offset_preds):     \"\"\"Predict bounding boxes based on anchor boxes with predicted offsets.     Defined in :numref:`subsec_labeling-anchor-boxes`\"\"\"     anc = myutils.box_corner_to_center(anchors)     pred_bbox_xy = (offset_preds[:, :2] * anc[:, 2:] / 10) + anc[:, :2]     pred_bbox_wh = myutils.exp(offset_preds[:, 2:] / 5) * anc[:, 2:]     pred_bbox = myutils.concat((pred_bbox_xy, pred_bbox_wh), axis=1)     predicted_bbox = myutils.box_center_to_corner(pred_bbox)     return predicted_bbox In\u00a0[\u00a0]: Copied! <pre>def nms(boxes, scores, iou_threshold):\n    \"\"\"Sort confidence scores of predicted bounding boxes.\n    Defined in :numref:`subsec_predicting-bounding-boxes-nms`\"\"\"\n    B = torch.argsort(scores, dim=-1, descending=True)\n    keep = []  # Indices of predicted bounding boxes that will be kept\n    while B.numel() &gt; 0:\n        i = B[0]\n        keep.append(i)\n        if B.numel() == 1: break\n        iou = box_iou(boxes[i, :].reshape(-1, 4),\n                      boxes[B[1:], :].reshape(-1, 4)).reshape(-1)\n        inds = torch.nonzero(iou &lt;= iou_threshold).reshape(-1)\n        B = B[inds + 1]\n    return myutils.tensor(keep, device=boxes.device)\n</pre> def nms(boxes, scores, iou_threshold):     \"\"\"Sort confidence scores of predicted bounding boxes.     Defined in :numref:`subsec_predicting-bounding-boxes-nms`\"\"\"     B = torch.argsort(scores, dim=-1, descending=True)     keep = []  # Indices of predicted bounding boxes that will be kept     while B.numel() &gt; 0:         i = B[0]         keep.append(i)         if B.numel() == 1: break         iou = box_iou(boxes[i, :].reshape(-1, 4),                       boxes[B[1:], :].reshape(-1, 4)).reshape(-1)         inds = torch.nonzero(iou &lt;= iou_threshold).reshape(-1)         B = B[inds + 1]     return myutils.tensor(keep, device=boxes.device) In\u00a0[\u00a0]: Copied! <pre>def multibox_detection(cls_probs, offset_preds, anchors, nms_threshold=0.5,\n                       pos_threshold=0.009999999):\n    \"\"\"Predict bounding boxes using non-maximum suppression.\n    Defined in :numref:`subsec_predicting-bounding-boxes-nms`\"\"\"\n    device, batch_size = cls_probs.device, cls_probs.shape[0]\n    anchors = anchors.squeeze(0)\n    num_classes, num_anchors = cls_probs.shape[1], cls_probs.shape[2]\n    out = []\n    for i in range(batch_size):\n        cls_prob, offset_pred = cls_probs[i], offset_preds[i].reshape(-1, 4)\n        conf, class_id = torch.max(cls_prob[1:], 0)\n        predicted_bb = offset_inverse(anchors, offset_pred)\n        keep = nms(predicted_bb, conf, nms_threshold)\n        # Find all non-`keep` indices and set the class to background\n        all_idx = torch.arange(num_anchors, dtype=torch.long, device=device)\n        combined = torch.cat((keep, all_idx))\n        uniques, counts = combined.unique(return_counts=True)\n        non_keep = uniques[counts == 1]\n        all_id_sorted = torch.cat((keep, non_keep))\n        class_id[non_keep] = -1\n        class_id = class_id[all_id_sorted]\n        conf, predicted_bb = conf[all_id_sorted], predicted_bb[all_id_sorted]\n        # Here `pos_threshold` is a threshold for positive (non-background)\n        # predictions\n        below_min_idx = (conf &lt; pos_threshold)\n        class_id[below_min_idx] = -1\n        conf[below_min_idx] = 1 - conf[below_min_idx]\n        pred_info = torch.cat((class_id.unsqueeze(1),\n                               conf.unsqueeze(1),\n                               predicted_bb), dim=1)\n        out.append(pred_info)\n    return myutils.stack(out)\n</pre> def multibox_detection(cls_probs, offset_preds, anchors, nms_threshold=0.5,                        pos_threshold=0.009999999):     \"\"\"Predict bounding boxes using non-maximum suppression.     Defined in :numref:`subsec_predicting-bounding-boxes-nms`\"\"\"     device, batch_size = cls_probs.device, cls_probs.shape[0]     anchors = anchors.squeeze(0)     num_classes, num_anchors = cls_probs.shape[1], cls_probs.shape[2]     out = []     for i in range(batch_size):         cls_prob, offset_pred = cls_probs[i], offset_preds[i].reshape(-1, 4)         conf, class_id = torch.max(cls_prob[1:], 0)         predicted_bb = offset_inverse(anchors, offset_pred)         keep = nms(predicted_bb, conf, nms_threshold)         # Find all non-`keep` indices and set the class to background         all_idx = torch.arange(num_anchors, dtype=torch.long, device=device)         combined = torch.cat((keep, all_idx))         uniques, counts = combined.unique(return_counts=True)         non_keep = uniques[counts == 1]         all_id_sorted = torch.cat((keep, non_keep))         class_id[non_keep] = -1         class_id = class_id[all_id_sorted]         conf, predicted_bb = conf[all_id_sorted], predicted_bb[all_id_sorted]         # Here `pos_threshold` is a threshold for positive (non-background)         # predictions         below_min_idx = (conf &lt; pos_threshold)         class_id[below_min_idx] = -1         conf[below_min_idx] = 1 - conf[below_min_idx]         pred_info = torch.cat((class_id.unsqueeze(1),                                conf.unsqueeze(1),                                predicted_bb), dim=1)         out.append(pred_info)     return myutils.stack(out) In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['banana-detection'] = (\n    myutils.DATA_URL + 'banana-detection.zip',\n    '5de26c8fce5ccdea9f91267273464dc968d20d72')\n</pre> myutils.DATA_HUB['banana-detection'] = (     myutils.DATA_URL + 'banana-detection.zip',     '5de26c8fce5ccdea9f91267273464dc968d20d72') In\u00a0[\u00a0]: Copied! <pre>def read_data_bananas(is_train=True):\n    \"\"\"Read the banana detection dataset images and labels.\n    Defined in :numref:`sec_object-detection-dataset`\"\"\"\n    data_dir = myutils.download_extract('banana-detection')\n    csv_fname = os.path.join(data_dir, 'bananas_train' if is_train\n    else 'bananas_val', 'label.csv')\n    csv_data = pd.read_csv(csv_fname)\n    csv_data = csv_data.set_index('img_name')\n    images, targets = [], []\n    for img_name, target in csv_data.iterrows():\n        images.append(torchvision.io.read_image(\n            os.path.join(data_dir, 'bananas_train' if is_train else\n            'bananas_val', 'images', f'{img_name}')))\n        # Here `target` contains (class, upper-left x, upper-left y,\n        # lower-right x, lower-right y), where all the images have the same\n        # banana class (index 0)\n        targets.append(list(target))\n    return images, torch.tensor(targets).unsqueeze(1) / 256\n</pre> def read_data_bananas(is_train=True):     \"\"\"Read the banana detection dataset images and labels.     Defined in :numref:`sec_object-detection-dataset`\"\"\"     data_dir = myutils.download_extract('banana-detection')     csv_fname = os.path.join(data_dir, 'bananas_train' if is_train     else 'bananas_val', 'label.csv')     csv_data = pd.read_csv(csv_fname)     csv_data = csv_data.set_index('img_name')     images, targets = [], []     for img_name, target in csv_data.iterrows():         images.append(torchvision.io.read_image(             os.path.join(data_dir, 'bananas_train' if is_train else             'bananas_val', 'images', f'{img_name}')))         # Here `target` contains (class, upper-left x, upper-left y,         # lower-right x, lower-right y), where all the images have the same         # banana class (index 0)         targets.append(list(target))     return images, torch.tensor(targets).unsqueeze(1) / 256 In\u00a0[\u00a0]: Copied! <pre>class BananasDataset(torch.utils.data.Dataset):\n    \"\"\"A customized dataset to load the banana detection dataset.\n    Defined in :numref:`sec_object-detection-dataset`\"\"\"\n\n    def __init__(self, is_train):\n        self.features, self.labels = read_data_bananas(is_train)\n        print('read ' + str(len(self.features)) + (f' training examples' if\n                                                   is_train else f' validation examples'))\n\n    def __getitem__(self, idx):\n        return (self.features[idx].float(), self.labels[idx])\n\n    def __len__(self):\n        return len(self.features)\n</pre> class BananasDataset(torch.utils.data.Dataset):     \"\"\"A customized dataset to load the banana detection dataset.     Defined in :numref:`sec_object-detection-dataset`\"\"\"      def __init__(self, is_train):         self.features, self.labels = read_data_bananas(is_train)         print('read ' + str(len(self.features)) + (f' training examples' if                                                    is_train else f' validation examples'))      def __getitem__(self, idx):         return (self.features[idx].float(), self.labels[idx])      def __len__(self):         return len(self.features) In\u00a0[\u00a0]: Copied! <pre>def load_data_bananas(batch_size):\n    \"\"\"Load the banana detection dataset.\n    Defined in :numref:`sec_object-detection-dataset`\"\"\"\n    train_iter = torch.utils.data.DataLoader(BananasDataset(is_train=True),\n                                             batch_size, shuffle=True)\n    val_iter = torch.utils.data.DataLoader(BananasDataset(is_train=False),\n                                           batch_size)\n    return train_iter, val_iter\n</pre> def load_data_bananas(batch_size):     \"\"\"Load the banana detection dataset.     Defined in :numref:`sec_object-detection-dataset`\"\"\"     train_iter = torch.utils.data.DataLoader(BananasDataset(is_train=True),                                              batch_size, shuffle=True)     val_iter = torch.utils.data.DataLoader(BananasDataset(is_train=False),                                            batch_size)     return train_iter, val_iter In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['voc2012'] = (myutils.DATA_URL + 'VOCtrainval_11-May-2012.tar',\n                               '4e443f8a2eca6b1dac8a6c57641b67dd40621a49')\n</pre> myutils.DATA_HUB['voc2012'] = (myutils.DATA_URL + 'VOCtrainval_11-May-2012.tar',                                '4e443f8a2eca6b1dac8a6c57641b67dd40621a49') In\u00a0[\u00a0]: Copied! <pre>def read_voc_images(voc_dir, is_train=True):\n    \"\"\"Read all VOC feature and label images.\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    txt_fname = os.path.join(voc_dir, 'ImageSets', 'Segmentation',\n                             'train.txt' if is_train else 'val.txt')\n    mode = torchvision.io.image.ImageReadMode.RGB\n    with open(txt_fname, 'r') as f:\n        images = f.read().split()\n    features, labels = [], []\n    for i, fname in enumerate(images):\n        features.append(torchvision.io.read_image(os.path.join(\n            voc_dir, 'JPEGImages', f'{fname}.jpg')))\n        labels.append(torchvision.io.read_image(os.path.join(\n            voc_dir, 'SegmentationClass', f'{fname}.png'), mode))\n    return features, labels\n</pre> def read_voc_images(voc_dir, is_train=True):     \"\"\"Read all VOC feature and label images.     Defined in :numref:`sec_semantic_segmentation`\"\"\"     txt_fname = os.path.join(voc_dir, 'ImageSets', 'Segmentation',                              'train.txt' if is_train else 'val.txt')     mode = torchvision.io.image.ImageReadMode.RGB     with open(txt_fname, 'r') as f:         images = f.read().split()     features, labels = [], []     for i, fname in enumerate(images):         features.append(torchvision.io.read_image(os.path.join(             voc_dir, 'JPEGImages', f'{fname}.jpg')))         labels.append(torchvision.io.read_image(os.path.join(             voc_dir, 'SegmentationClass', f'{fname}.png'), mode))     return features, labels In\u00a0[\u00a0]: Copied! <pre>VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n                [0, 64, 128]]\n</pre> VOC_COLORMAP = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],                 [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],                 [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],                 [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],                 [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],                 [0, 64, 128]] In\u00a0[\u00a0]: Copied! <pre>VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',\n               'bottle', 'bus', 'car', 'cat', 'chair', 'cow',\n               'diningtable', 'dog', 'horse', 'motorbike', 'person',\n               'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor']\n</pre> VOC_CLASSES = ['background', 'aeroplane', 'bicycle', 'bird', 'boat',                'bottle', 'bus', 'car', 'cat', 'chair', 'cow',                'diningtable', 'dog', 'horse', 'motorbike', 'person',                'potted plant', 'sheep', 'sofa', 'train', 'tv/monitor'] In\u00a0[\u00a0]: Copied! <pre>def voc_colormap2label():\n    \"\"\"Build the mapping from RGB to class indices for VOC labels.\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    colormap2label = torch.zeros(256 ** 3, dtype=torch.long)\n    for i, colormap in enumerate(VOC_COLORMAP):\n        colormap2label[\n            (colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] = i\n    return colormap2label\n</pre> def voc_colormap2label():     \"\"\"Build the mapping from RGB to class indices for VOC labels.     Defined in :numref:`sec_semantic_segmentation`\"\"\"     colormap2label = torch.zeros(256 ** 3, dtype=torch.long)     for i, colormap in enumerate(VOC_COLORMAP):         colormap2label[             (colormap[0] * 256 + colormap[1]) * 256 + colormap[2]] = i     return colormap2label In\u00a0[\u00a0]: Copied! <pre>def voc_label_indices(colormap, colormap2label):\n    \"\"\"Map any RGB values in VOC labels to their class indices.\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    colormap = colormap.permute(1, 2, 0).numpy().astype('int32')\n    idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256\n           + colormap[:, :, 2])\n    return colormap2label[idx]\n</pre> def voc_label_indices(colormap, colormap2label):     \"\"\"Map any RGB values in VOC labels to their class indices.     Defined in :numref:`sec_semantic_segmentation`\"\"\"     colormap = colormap.permute(1, 2, 0).numpy().astype('int32')     idx = ((colormap[:, :, 0] * 256 + colormap[:, :, 1]) * 256            + colormap[:, :, 2])     return colormap2label[idx] In\u00a0[\u00a0]: Copied! <pre>def voc_rand_crop(feature, label, height, width):\n    \"\"\"Randomly crop both feature and label images.\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    rect = torchvision.transforms.RandomCrop.get_params(\n        feature, (height, width))\n    feature = torchvision.transforms.functional.crop(feature, *rect)\n    label = torchvision.transforms.functional.crop(label, *rect)\n    return feature, label\n</pre> def voc_rand_crop(feature, label, height, width):     \"\"\"Randomly crop both feature and label images.     Defined in :numref:`sec_semantic_segmentation`\"\"\"     rect = torchvision.transforms.RandomCrop.get_params(         feature, (height, width))     feature = torchvision.transforms.functional.crop(feature, *rect)     label = torchvision.transforms.functional.crop(label, *rect)     return feature, label In\u00a0[\u00a0]: Copied! <pre>class VOCSegDataset(torch.utils.data.Dataset):\n    \"\"\"A customized dataset to load the VOC dataset.\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n\n    def __init__(self, is_train, crop_size, voc_dir):\n        self.transform = torchvision.transforms.Normalize(\n            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n        self.crop_size = crop_size\n        features, labels = read_voc_images(voc_dir, is_train=is_train)\n        self.features = [self.normalize_image(feature)\n                         for feature in self.filter(features)]\n        self.labels = self.filter(labels)\n        self.colormap2label = voc_colormap2label()\n        print('read ' + str(len(self.features)) + ' examples')\n\n    def normalize_image(self, img):\n        return self.transform(img.float() / 255)\n\n    def filter(self, imgs):\n        return [img for img in imgs if (\n                img.shape[1] &gt;= self.crop_size[0] and\n                img.shape[2] &gt;= self.crop_size[1])]\n\n    def __getitem__(self, idx):\n        feature, label = voc_rand_crop(self.features[idx], self.labels[idx],\n                                       *self.crop_size)\n        return (feature, voc_label_indices(label, self.colormap2label))\n\n    def __len__(self):\n        return len(self.features)\n</pre> class VOCSegDataset(torch.utils.data.Dataset):     \"\"\"A customized dataset to load the VOC dataset.     Defined in :numref:`sec_semantic_segmentation`\"\"\"      def __init__(self, is_train, crop_size, voc_dir):         self.transform = torchvision.transforms.Normalize(             mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])         self.crop_size = crop_size         features, labels = read_voc_images(voc_dir, is_train=is_train)         self.features = [self.normalize_image(feature)                          for feature in self.filter(features)]         self.labels = self.filter(labels)         self.colormap2label = voc_colormap2label()         print('read ' + str(len(self.features)) + ' examples')      def normalize_image(self, img):         return self.transform(img.float() / 255)      def filter(self, imgs):         return [img for img in imgs if (                 img.shape[1] &gt;= self.crop_size[0] and                 img.shape[2] &gt;= self.crop_size[1])]      def __getitem__(self, idx):         feature, label = voc_rand_crop(self.features[idx], self.labels[idx],                                        *self.crop_size)         return (feature, voc_label_indices(label, self.colormap2label))      def __len__(self):         return len(self.features) In\u00a0[\u00a0]: Copied! <pre>def load_data_voc(batch_size, crop_size):\n    \"\"\"Load the VOC semantic segmentation dataset.\n    Defined in :numref:`sec_semantic_segmentation`\"\"\"\n    voc_dir = myutils.download_extract('voc2012', os.path.join(\n        'VOCdevkit', 'VOC2012'))\n    num_workers = myutils.get_dataloader_workers()\n    train_iter = torch.utils.data.DataLoader(\n        VOCSegDataset(True, crop_size, voc_dir), batch_size,\n        shuffle=True, drop_last=True, num_workers=num_workers)\n    test_iter = torch.utils.data.DataLoader(\n        VOCSegDataset(False, crop_size, voc_dir), batch_size,\n        drop_last=True, num_workers=num_workers)\n    return train_iter, test_iter\n</pre> def load_data_voc(batch_size, crop_size):     \"\"\"Load the VOC semantic segmentation dataset.     Defined in :numref:`sec_semantic_segmentation`\"\"\"     voc_dir = myutils.download_extract('voc2012', os.path.join(         'VOCdevkit', 'VOC2012'))     num_workers = myutils.get_dataloader_workers()     train_iter = torch.utils.data.DataLoader(         VOCSegDataset(True, crop_size, voc_dir), batch_size,         shuffle=True, drop_last=True, num_workers=num_workers)     test_iter = torch.utils.data.DataLoader(         VOCSegDataset(False, crop_size, voc_dir), batch_size,         drop_last=True, num_workers=num_workers)     return train_iter, test_iter In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['cifar10_tiny'] = (myutils.DATA_URL + 'kaggle_cifar10_tiny.zip',\n                                    '2068874e4b9a9f0fb07ebe0ad2b29754449ccacd')\n</pre> myutils.DATA_HUB['cifar10_tiny'] = (myutils.DATA_URL + 'kaggle_cifar10_tiny.zip',                                     '2068874e4b9a9f0fb07ebe0ad2b29754449ccacd') In\u00a0[\u00a0]: Copied! <pre>def read_csv_labels(fname):\n    \"\"\"Read `fname` to return a filename to label dictionary.\n    Defined in :numref:`sec_kaggle_cifar10`\"\"\"\n    with open(fname, 'r') as f:\n        # Skip the file header line (column name)\n        lines = f.readlines()[1:]\n    tokens = [l.rstrip().split(',') for l in lines]\n    return dict(((name, label) for name, label in tokens))\n</pre> def read_csv_labels(fname):     \"\"\"Read `fname` to return a filename to label dictionary.     Defined in :numref:`sec_kaggle_cifar10`\"\"\"     with open(fname, 'r') as f:         # Skip the file header line (column name)         lines = f.readlines()[1:]     tokens = [l.rstrip().split(',') for l in lines]     return dict(((name, label) for name, label in tokens)) In\u00a0[\u00a0]: Copied! <pre>def copyfile(filename, target_dir):\n    \"\"\"Copy a file into a target directory.\n    Defined in :numref:`sec_kaggle_cifar10`\"\"\"\n    os.makedirs(target_dir, exist_ok=True)\n    shutil.copy(filename, target_dir)\n</pre> def copyfile(filename, target_dir):     \"\"\"Copy a file into a target directory.     Defined in :numref:`sec_kaggle_cifar10`\"\"\"     os.makedirs(target_dir, exist_ok=True)     shutil.copy(filename, target_dir) In\u00a0[\u00a0]: Copied! <pre>def reorg_train_valid(data_dir, labels, valid_ratio):\n    \"\"\"Split the validation set out of the original training set.\n    Defined in :numref:`sec_kaggle_cifar10`\"\"\"\n    # The number of examples of the class that has the fewest examples in the\n    # training dataset\n    n = collections.Counter(labels.values()).most_common()[-1][1]\n    # The number of examples per class for the validation set\n    n_valid_per_label = max(1, math.floor(n * valid_ratio))\n    label_count = {}\n    for train_file in os.listdir(os.path.join(data_dir, 'train')):\n        label = labels[train_file.split('.')[0]]\n        fname = os.path.join(data_dir, 'train', train_file)\n        copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                     'train_valid', label))\n        if label not in label_count or label_count[label] &lt; n_valid_per_label:\n            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                         'valid', label))\n            label_count[label] = label_count.get(label, 0) + 1\n        else:\n            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                         'train', label))\n    return n_valid_per_label\n</pre> def reorg_train_valid(data_dir, labels, valid_ratio):     \"\"\"Split the validation set out of the original training set.     Defined in :numref:`sec_kaggle_cifar10`\"\"\"     # The number of examples of the class that has the fewest examples in the     # training dataset     n = collections.Counter(labels.values()).most_common()[-1][1]     # The number of examples per class for the validation set     n_valid_per_label = max(1, math.floor(n * valid_ratio))     label_count = {}     for train_file in os.listdir(os.path.join(data_dir, 'train')):         label = labels[train_file.split('.')[0]]         fname = os.path.join(data_dir, 'train', train_file)         copyfile(fname, os.path.join(data_dir, 'train_valid_test',                                      'train_valid', label))         if label not in label_count or label_count[label] &lt; n_valid_per_label:             copyfile(fname, os.path.join(data_dir, 'train_valid_test',                                          'valid', label))             label_count[label] = label_count.get(label, 0) + 1         else:             copyfile(fname, os.path.join(data_dir, 'train_valid_test',                                          'train', label))     return n_valid_per_label In\u00a0[\u00a0]: Copied! <pre>def reorg_test(data_dir):\n    \"\"\"Organize the testing set for data loading during prediction.\n    Defined in :numref:`sec_kaggle_cifar10`\"\"\"\n    for test_file in os.listdir(os.path.join(data_dir, 'test')):\n        copyfile(os.path.join(data_dir, 'test', test_file),\n                 os.path.join(data_dir, 'train_valid_test', 'test',\n                              'unknown'))\n</pre> def reorg_test(data_dir):     \"\"\"Organize the testing set for data loading during prediction.     Defined in :numref:`sec_kaggle_cifar10`\"\"\"     for test_file in os.listdir(os.path.join(data_dir, 'test')):         copyfile(os.path.join(data_dir, 'test', test_file),                  os.path.join(data_dir, 'train_valid_test', 'test',                               'unknown')) In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['dog_tiny'] = (myutils.DATA_URL + 'kaggle_dog_tiny.zip',\n                                '0cb91d09b814ecdc07b50f31f8dcad3e81d6a86d')\n</pre> myutils.DATA_HUB['dog_tiny'] = (myutils.DATA_URL + 'kaggle_dog_tiny.zip',                                 '0cb91d09b814ecdc07b50f31f8dcad3e81d6a86d') In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['ptb'] = (myutils.DATA_URL + 'ptb.zip',\n                           '319d85e578af0cdc590547f26231e4e31cdf1e42')\n</pre> myutils.DATA_HUB['ptb'] = (myutils.DATA_URL + 'ptb.zip',                            '319d85e578af0cdc590547f26231e4e31cdf1e42') In\u00a0[\u00a0]: Copied! <pre>def read_ptb():\n    \"\"\"Load the PTB dataset into a list of text lines.\n    Defined in :numref:`sec_word2vec_data`\"\"\"\n    data_dir = myutils.download_extract('ptb')\n    # Read the training set\n    with open(os.path.join(data_dir, 'ptb.train.txt')) as f:\n        raw_text = f.read()\n    return [line.split() for line in raw_text.split('\\n')]\n</pre> def read_ptb():     \"\"\"Load the PTB dataset into a list of text lines.     Defined in :numref:`sec_word2vec_data`\"\"\"     data_dir = myutils.download_extract('ptb')     # Read the training set     with open(os.path.join(data_dir, 'ptb.train.txt')) as f:         raw_text = f.read()     return [line.split() for line in raw_text.split('\\n')] In\u00a0[\u00a0]: Copied! <pre>def subsample(sentences, vocab):\n    \"\"\"Subsample high-frequency words.\n    Defined in :numref:`sec_word2vec_data`\"\"\"\n    # Exclude unknown tokens ('&lt;unk&gt;')\n    sentences = [[token for token in line if vocab[token] != vocab.unk]\n                 for line in sentences]\n    counter = collections.Counter([\n        token for line in sentences for token in line])\n    num_tokens = sum(counter.values())\n\n    # Return True if `token` is kept during subsampling\n    def keep(token):\n        return (random.uniform(0, 1) &lt;\n                math.sqrt(1e-4 / counter[token] * num_tokens))\n\n    return ([[token for token in line if keep(token)] for line in sentences],\n            counter)\n</pre> def subsample(sentences, vocab):     \"\"\"Subsample high-frequency words.     Defined in :numref:`sec_word2vec_data`\"\"\"     # Exclude unknown tokens ('')     sentences = [[token for token in line if vocab[token] != vocab.unk]                  for line in sentences]     counter = collections.Counter([         token for line in sentences for token in line])     num_tokens = sum(counter.values())      # Return True if `token` is kept during subsampling     def keep(token):         return (random.uniform(0, 1) &lt;                 math.sqrt(1e-4 / counter[token] * num_tokens))      return ([[token for token in line if keep(token)] for line in sentences],             counter) In\u00a0[\u00a0]: Copied! <pre>def get_centers_and_contexts(corpus, max_window_size):\n    \"\"\"Return center words and context words in skip-gram.\n    Defined in :numref:`sec_word2vec_data`\"\"\"\n    centers, contexts = [], []\n    for line in corpus:\n        # To form a \"center word--context word\" pair, each sentence needs to\n        # have at least 2 words\n        if len(line) &lt; 2:\n            continue\n        centers += line\n        for i in range(len(line)):  # Context window centered at `i`\n            window_size = random.randint(1, max_window_size)\n            indices = list(range(max(0, i - window_size),\n                                 min(len(line), i + 1 + window_size)))\n            # Exclude the center word from the context words\n            indices.remove(i)\n            contexts.append([line[idx] for idx in indices])\n    return centers, contexts\n</pre> def get_centers_and_contexts(corpus, max_window_size):     \"\"\"Return center words and context words in skip-gram.     Defined in :numref:`sec_word2vec_data`\"\"\"     centers, contexts = [], []     for line in corpus:         # To form a \"center word--context word\" pair, each sentence needs to         # have at least 2 words         if len(line) &lt; 2:             continue         centers += line         for i in range(len(line)):  # Context window centered at `i`             window_size = random.randint(1, max_window_size)             indices = list(range(max(0, i - window_size),                                  min(len(line), i + 1 + window_size)))             # Exclude the center word from the context words             indices.remove(i)             contexts.append([line[idx] for idx in indices])     return centers, contexts In\u00a0[\u00a0]: Copied! <pre>class RandomGenerator:\n    \"\"\"Randomly draw among {1, ..., n} according to n sampling weights.\"\"\"\n\n    def __init__(self, sampling_weights):\n        \"\"\"Defined in :numref:`sec_word2vec_data`\"\"\"\n        # Exclude\n        self.population = list(range(1, len(sampling_weights) + 1))\n        self.sampling_weights = sampling_weights\n        self.candidates = []\n        self.i = 0\n\n    def draw(self):\n        if self.i == len(self.candidates):\n            # Cache `k` random sampling results\n            self.candidates = random.choices(\n                self.population, self.sampling_weights, k=10000)\n            self.i = 0\n        self.i += 1\n        return self.candidates[self.i - 1]\n</pre> class RandomGenerator:     \"\"\"Randomly draw among {1, ..., n} according to n sampling weights.\"\"\"      def __init__(self, sampling_weights):         \"\"\"Defined in :numref:`sec_word2vec_data`\"\"\"         # Exclude         self.population = list(range(1, len(sampling_weights) + 1))         self.sampling_weights = sampling_weights         self.candidates = []         self.i = 0      def draw(self):         if self.i == len(self.candidates):             # Cache `k` random sampling results             self.candidates = random.choices(                 self.population, self.sampling_weights, k=10000)             self.i = 0         self.i += 1         return self.candidates[self.i - 1] In\u00a0[\u00a0]: Copied! <pre>def get_negatives(all_contexts, vocab, counter, K):\n    \"\"\"Return noise words in negative sampling.\n    Defined in :numref:`sec_word2vec_data`\"\"\"\n    # Sampling weights for words with indices 1, 2, ... (index 0 is the\n    # excluded unknown token) in the vocabulary\n    sampling_weights = [counter[vocab.to_tokens(i)] ** 0.75\n                        for i in range(1, len(vocab))]\n    all_negatives, generator = [], RandomGenerator(sampling_weights)\n    for contexts in all_contexts:\n        negatives = []\n        while len(negatives) &lt; len(contexts) * K:\n            neg = generator.draw()\n            # Noise words cannot be context words\n            if neg not in contexts:\n                negatives.append(neg)\n        all_negatives.append(negatives)\n    return all_negatives\n</pre> def get_negatives(all_contexts, vocab, counter, K):     \"\"\"Return noise words in negative sampling.     Defined in :numref:`sec_word2vec_data`\"\"\"     # Sampling weights for words with indices 1, 2, ... (index 0 is the     # excluded unknown token) in the vocabulary     sampling_weights = [counter[vocab.to_tokens(i)] ** 0.75                         for i in range(1, len(vocab))]     all_negatives, generator = [], RandomGenerator(sampling_weights)     for contexts in all_contexts:         negatives = []         while len(negatives) &lt; len(contexts) * K:             neg = generator.draw()             # Noise words cannot be context words             if neg not in contexts:                 negatives.append(neg)         all_negatives.append(negatives)     return all_negatives In\u00a0[\u00a0]: Copied! <pre>def batchify(data):\n    \"\"\"Return a minibatch of examples for skip-gram with negative sampling.\n    Defined in :numref:`sec_word2vec_data`\"\"\"\n    max_len = max(len(c) + len(n) for _, c, n in data)\n    centers, contexts_negatives, masks, labels = [], [], [], []\n    for center, context, negative in data:\n        cur_len = len(context) + len(negative)\n        centers += [center]\n        contexts_negatives += [context + negative + [0] * (max_len - cur_len)]\n        masks += [[1] * cur_len + [0] * (max_len - cur_len)]\n        labels += [[1] * len(context) + [0] * (max_len - len(context))]\n    return (myutils.reshape(myutils.tensor(centers), (-1, 1)), myutils.tensor(\n        contexts_negatives), myutils.tensor(masks), myutils.tensor(labels))\n</pre> def batchify(data):     \"\"\"Return a minibatch of examples for skip-gram with negative sampling.     Defined in :numref:`sec_word2vec_data`\"\"\"     max_len = max(len(c) + len(n) for _, c, n in data)     centers, contexts_negatives, masks, labels = [], [], [], []     for center, context, negative in data:         cur_len = len(context) + len(negative)         centers += [center]         contexts_negatives += [context + negative + [0] * (max_len - cur_len)]         masks += [[1] * cur_len + [0] * (max_len - cur_len)]         labels += [[1] * len(context) + [0] * (max_len - len(context))]     return (myutils.reshape(myutils.tensor(centers), (-1, 1)), myutils.tensor(         contexts_negatives), myutils.tensor(masks), myutils.tensor(labels)) In\u00a0[\u00a0]: Copied! <pre>def load_data_ptb(batch_size, max_window_size, num_noise_words):\n    \"\"\"Download the PTB dataset and then load it into memory.\n    Defined in :numref:`subsec_word2vec-minibatch-loading`\"\"\"\n    num_workers = myutils.get_dataloader_workers()\n    sentences = read_ptb()\n    vocab = myutils.Vocab(sentences, min_freq=10)\n    subsampled, counter = subsample(sentences, vocab)\n    corpus = [vocab[line] for line in subsampled]\n    all_centers, all_contexts = get_centers_and_contexts(\n        corpus, max_window_size)\n    all_negatives = get_negatives(\n        all_contexts, vocab, counter, num_noise_words)\n\n    class PTBDataset(torch.utils.data.Dataset):\n        def __init__(self, centers, contexts, negatives):\n            assert len(centers) == len(contexts) == len(negatives)\n            self.centers = centers\n            self.contexts = contexts\n            self.negatives = negatives\n\n        def __getitem__(self, index):\n            return (self.centers[index], self.contexts[index],\n                    self.negatives[index])\n\n        def __len__(self):\n            return len(self.centers)\n\n    dataset = PTBDataset(all_centers, all_contexts, all_negatives)\n\n    data_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True,\n                                            collate_fn=batchify,\n                                            num_workers=num_workers)\n    return data_iter, vocab\n</pre> def load_data_ptb(batch_size, max_window_size, num_noise_words):     \"\"\"Download the PTB dataset and then load it into memory.     Defined in :numref:`subsec_word2vec-minibatch-loading`\"\"\"     num_workers = myutils.get_dataloader_workers()     sentences = read_ptb()     vocab = myutils.Vocab(sentences, min_freq=10)     subsampled, counter = subsample(sentences, vocab)     corpus = [vocab[line] for line in subsampled]     all_centers, all_contexts = get_centers_and_contexts(         corpus, max_window_size)     all_negatives = get_negatives(         all_contexts, vocab, counter, num_noise_words)      class PTBDataset(torch.utils.data.Dataset):         def __init__(self, centers, contexts, negatives):             assert len(centers) == len(contexts) == len(negatives)             self.centers = centers             self.contexts = contexts             self.negatives = negatives          def __getitem__(self, index):             return (self.centers[index], self.contexts[index],                     self.negatives[index])          def __len__(self):             return len(self.centers)      dataset = PTBDataset(all_centers, all_contexts, all_negatives)      data_iter = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True,                                             collate_fn=batchify,                                             num_workers=num_workers)     return data_iter, vocab In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['glove.6b.50d'] = (myutils.DATA_URL + 'glove.6B.50d.zip',\n                                    '0b8703943ccdb6eb788e6f091b8946e82231bc4d')\n</pre> myutils.DATA_HUB['glove.6b.50d'] = (myutils.DATA_URL + 'glove.6B.50d.zip',                                     '0b8703943ccdb6eb788e6f091b8946e82231bc4d') In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['glove.6b.100d'] = (myutils.DATA_URL + 'glove.6B.100d.zip',\n                                     'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a')\n</pre> myutils.DATA_HUB['glove.6b.100d'] = (myutils.DATA_URL + 'glove.6B.100d.zip',                                      'cd43bfb07e44e6f27cbcc7bc9ae3d80284fdaf5a') In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['glove.42b.300d'] = (myutils.DATA_URL + 'glove.42B.300d.zip',\n                                      'b5116e234e9eb9076672cfeabf5469f3eec904fa')\n</pre> myutils.DATA_HUB['glove.42b.300d'] = (myutils.DATA_URL + 'glove.42B.300d.zip',                                       'b5116e234e9eb9076672cfeabf5469f3eec904fa') In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['wiki.en'] = (myutils.DATA_URL + 'wiki.en.zip',\n                               'c1816da3821ae9f43899be655002f6c723e91b88')\n</pre> myutils.DATA_HUB['wiki.en'] = (myutils.DATA_URL + 'wiki.en.zip',                                'c1816da3821ae9f43899be655002f6c723e91b88') In\u00a0[\u00a0]: Copied! <pre>class TokenEmbedding:\n    \"\"\"Token Embedding.\"\"\"\n\n    def __init__(self, embedding_name):\n        \"\"\"Defined in :numref:`sec_synonyms`\"\"\"\n        self.idx_to_token, self.idx_to_vec = self._load_embedding(\n            embedding_name)\n        self.unknown_idx = 0\n        self.token_to_idx = {token: idx for idx, token in\n                             enumerate(self.idx_to_token)}\n\n    def _load_embedding(self, embedding_name):\n        idx_to_token, idx_to_vec = ['&lt;unk&gt;'], []\n        data_dir = myutils.download_extract(embedding_name)\n        # GloVe website: https://nlp.stanford.edu/projects/glove/\n        # fastText website: https://fasttext.cc/\n        with open(os.path.join(data_dir, 'vec.txt'), 'r') as f:\n            for line in f:\n                elems = line.rstrip().split(' ')\n                token, elems = elems[0], [float(elem) for elem in elems[1:]]\n                # Skip header information, such as the top row in fastText\n                if len(elems) &gt; 1:\n                    idx_to_token.append(token)\n                    idx_to_vec.append(elems)\n        idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec\n        return idx_to_token, myutils.tensor(idx_to_vec)\n\n    def __getitem__(self, tokens):\n        indices = [self.token_to_idx.get(token, self.unknown_idx)\n                   for token in tokens]\n        vecs = self.idx_to_vec[myutils.tensor(indices)]\n        return vecs\n\n    def __len__(self):\n        return len(self.idx_to_token)\n</pre> class TokenEmbedding:     \"\"\"Token Embedding.\"\"\"      def __init__(self, embedding_name):         \"\"\"Defined in :numref:`sec_synonyms`\"\"\"         self.idx_to_token, self.idx_to_vec = self._load_embedding(             embedding_name)         self.unknown_idx = 0         self.token_to_idx = {token: idx for idx, token in                              enumerate(self.idx_to_token)}      def _load_embedding(self, embedding_name):         idx_to_token, idx_to_vec = [''], []         data_dir = myutils.download_extract(embedding_name)         # GloVe website: https://nlp.stanford.edu/projects/glove/         # fastText website: https://fasttext.cc/         with open(os.path.join(data_dir, 'vec.txt'), 'r') as f:             for line in f:                 elems = line.rstrip().split(' ')                 token, elems = elems[0], [float(elem) for elem in elems[1:]]                 # Skip header information, such as the top row in fastText                 if len(elems) &gt; 1:                     idx_to_token.append(token)                     idx_to_vec.append(elems)         idx_to_vec = [[0] * len(idx_to_vec[0])] + idx_to_vec         return idx_to_token, myutils.tensor(idx_to_vec)      def __getitem__(self, tokens):         indices = [self.token_to_idx.get(token, self.unknown_idx)                    for token in tokens]         vecs = self.idx_to_vec[myutils.tensor(indices)]         return vecs      def __len__(self):         return len(self.idx_to_token) In\u00a0[\u00a0]: Copied! <pre>def get_tokens_and_segments(tokens_a, tokens_b=None):\n    \"\"\"Get tokens of the BERT input sequence and their segment IDs.\n    Defined in :numref:`sec_bert`\"\"\"\n    tokens = ['&lt;cls&gt;'] + tokens_a + ['&lt;sep&gt;']\n    # 0 and 1 are marking segment A and B, respectively\n    segments = [0] * (len(tokens_a) + 2)\n    if tokens_b is not None:\n        tokens += tokens_b + ['&lt;sep&gt;']\n        segments += [1] * (len(tokens_b) + 1)\n    return tokens, segments\n</pre> def get_tokens_and_segments(tokens_a, tokens_b=None):     \"\"\"Get tokens of the BERT input sequence and their segment IDs.     Defined in :numref:`sec_bert`\"\"\"     tokens = [''] + tokens_a + ['']     # 0 and 1 are marking segment A and B, respectively     segments = [0] * (len(tokens_a) + 2)     if tokens_b is not None:         tokens += tokens_b + ['']         segments += [1] * (len(tokens_b) + 1)     return tokens, segments In\u00a0[\u00a0]: Copied! <pre>class BERTEncoder(nn.Module):\n    \"\"\"BERT encoder.\n    Defined in :numref:`subsec_bert_input_rep`\"\"\"\n\n    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads,\n                 num_blks, dropout, max_len=1000, **kwargs):\n        super(BERTEncoder, self).__init__(**kwargs)\n        self.token_embedding = nn.Embedding(vocab_size, num_hiddens)\n        self.segment_embedding = nn.Embedding(2, num_hiddens)\n        self.blks = nn.Sequential()\n        for i in range(num_blks):\n            self.blks.add_module(f\"{i}\", myutils.TransformerEncoderBlock(\n                num_hiddens, ffn_num_hiddens, num_heads, dropout, True))\n        # In BERT, positional embeddings are learnable, thus we create a\n        # parameter of positional embeddings that are long enough\n        self.pos_embedding = nn.Parameter(torch.randn(1, max_len,\n                                                      num_hiddens))\n\n    def forward(self, tokens, segments, valid_lens):\n        # Shape of `X` remains unchanged in the following code snippet:\n        # (batch size, max sequence length, `num_hiddens`)\n        X = self.token_embedding(tokens) + self.segment_embedding(segments)\n        X = X + self.pos_embedding[:, :X.shape[1], :]\n        for blk in self.blks:\n            X = blk(X, valid_lens)\n        return X\n</pre> class BERTEncoder(nn.Module):     \"\"\"BERT encoder.     Defined in :numref:`subsec_bert_input_rep`\"\"\"      def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens, num_heads,                  num_blks, dropout, max_len=1000, **kwargs):         super(BERTEncoder, self).__init__(**kwargs)         self.token_embedding = nn.Embedding(vocab_size, num_hiddens)         self.segment_embedding = nn.Embedding(2, num_hiddens)         self.blks = nn.Sequential()         for i in range(num_blks):             self.blks.add_module(f\"{i}\", myutils.TransformerEncoderBlock(                 num_hiddens, ffn_num_hiddens, num_heads, dropout, True))         # In BERT, positional embeddings are learnable, thus we create a         # parameter of positional embeddings that are long enough         self.pos_embedding = nn.Parameter(torch.randn(1, max_len,                                                       num_hiddens))      def forward(self, tokens, segments, valid_lens):         # Shape of `X` remains unchanged in the following code snippet:         # (batch size, max sequence length, `num_hiddens`)         X = self.token_embedding(tokens) + self.segment_embedding(segments)         X = X + self.pos_embedding[:, :X.shape[1], :]         for blk in self.blks:             X = blk(X, valid_lens)         return X In\u00a0[\u00a0]: Copied! <pre>class MaskLM(nn.Module):\n    \"\"\"The masked language model task of BERT.\n    Defined in :numref:`subsec_bert_input_rep`\"\"\"\n\n    def __init__(self, vocab_size, num_hiddens, **kwargs):\n        super(MaskLM, self).__init__(**kwargs)\n        self.mlp = nn.Sequential(nn.LazyLinear(num_hiddens),\n                                 nn.ReLU(),\n                                 nn.LayerNorm(num_hiddens),\n                                 nn.LazyLinear(vocab_size))\n\n    def forward(self, X, pred_positions):\n        num_pred_positions = pred_positions.shape[1]\n        pred_positions = pred_positions.reshape(-1)\n        batch_size = X.shape[0]\n        batch_idx = torch.arange(0, batch_size)\n        # Suppose that `batch_size` = 2, `num_pred_positions` = 3, then\n        # `batch_idx` is `torch.tensor([0, 0, 0, 1, 1, 1])`\n        batch_idx = torch.repeat_interleave(batch_idx, num_pred_positions)\n        masked_X = X[batch_idx, pred_positions]\n        masked_X = masked_X.reshape((batch_size, num_pred_positions, -1))\n        mlm_Y_hat = self.mlp(masked_X)\n        return mlm_Y_hat\n</pre> class MaskLM(nn.Module):     \"\"\"The masked language model task of BERT.     Defined in :numref:`subsec_bert_input_rep`\"\"\"      def __init__(self, vocab_size, num_hiddens, **kwargs):         super(MaskLM, self).__init__(**kwargs)         self.mlp = nn.Sequential(nn.LazyLinear(num_hiddens),                                  nn.ReLU(),                                  nn.LayerNorm(num_hiddens),                                  nn.LazyLinear(vocab_size))      def forward(self, X, pred_positions):         num_pred_positions = pred_positions.shape[1]         pred_positions = pred_positions.reshape(-1)         batch_size = X.shape[0]         batch_idx = torch.arange(0, batch_size)         # Suppose that `batch_size` = 2, `num_pred_positions` = 3, then         # `batch_idx` is `torch.tensor([0, 0, 0, 1, 1, 1])`         batch_idx = torch.repeat_interleave(batch_idx, num_pred_positions)         masked_X = X[batch_idx, pred_positions]         masked_X = masked_X.reshape((batch_size, num_pred_positions, -1))         mlm_Y_hat = self.mlp(masked_X)         return mlm_Y_hat In\u00a0[\u00a0]: Copied! <pre>class NextSentencePred(nn.Module):\n    \"\"\"The next sentence prediction task of BERT.\n    Defined in :numref:`subsec_mlm`\"\"\"\n\n    def __init__(self, **kwargs):\n        super(NextSentencePred, self).__init__(**kwargs)\n        self.output = nn.LazyLinear(2)\n\n    def forward(self, X):\n        # `X` shape: (batch size, `num_hiddens`)\n        return self.output(X)\n</pre> class NextSentencePred(nn.Module):     \"\"\"The next sentence prediction task of BERT.     Defined in :numref:`subsec_mlm`\"\"\"      def __init__(self, **kwargs):         super(NextSentencePred, self).__init__(**kwargs)         self.output = nn.LazyLinear(2)      def forward(self, X):         # `X` shape: (batch size, `num_hiddens`)         return self.output(X) In\u00a0[\u00a0]: Copied! <pre>class BERTModel(nn.Module):\n    \"\"\"The BERT model.\n    Defined in :numref:`subsec_nsp`\"\"\"\n\n    def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens,\n                 num_heads, num_blks, dropout, max_len=1000):\n        super(BERTModel, self).__init__()\n        self.encoder = BERTEncoder(vocab_size, num_hiddens, ffn_num_hiddens,\n                                   num_heads, num_blks, dropout,\n                                   max_len=max_len)\n        self.hidden = nn.Sequential(nn.LazyLinear(num_hiddens),\n                                    nn.Tanh())\n        self.mlm = MaskLM(vocab_size, num_hiddens)\n        self.nsp = NextSentencePred()\n\n    def forward(self, tokens, segments, valid_lens=None, pred_positions=None):\n        encoded_X = self.encoder(tokens, segments, valid_lens)\n        if pred_positions is not None:\n            mlm_Y_hat = self.mlm(encoded_X, pred_positions)\n        else:\n            mlm_Y_hat = None\n        # The hidden layer of the MLP classifier for next sentence prediction.\n        # 0 is the index of the '&lt;cls&gt;' token\n        nsp_Y_hat = self.nsp(self.hidden(encoded_X[:, 0, :]))\n        return encoded_X, mlm_Y_hat, nsp_Y_hat\n</pre> class BERTModel(nn.Module):     \"\"\"The BERT model.     Defined in :numref:`subsec_nsp`\"\"\"      def __init__(self, vocab_size, num_hiddens, ffn_num_hiddens,                  num_heads, num_blks, dropout, max_len=1000):         super(BERTModel, self).__init__()         self.encoder = BERTEncoder(vocab_size, num_hiddens, ffn_num_hiddens,                                    num_heads, num_blks, dropout,                                    max_len=max_len)         self.hidden = nn.Sequential(nn.LazyLinear(num_hiddens),                                     nn.Tanh())         self.mlm = MaskLM(vocab_size, num_hiddens)         self.nsp = NextSentencePred()      def forward(self, tokens, segments, valid_lens=None, pred_positions=None):         encoded_X = self.encoder(tokens, segments, valid_lens)         if pred_positions is not None:             mlm_Y_hat = self.mlm(encoded_X, pred_positions)         else:             mlm_Y_hat = None         # The hidden layer of the MLP classifier for next sentence prediction.         # 0 is the index of the '' token         nsp_Y_hat = self.nsp(self.hidden(encoded_X[:, 0, :]))         return encoded_X, mlm_Y_hat, nsp_Y_hat In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['wikitext-2'] = (\n    'https://s3.amazonaws.com/research.metamind.io/wikitext/'\n    'wikitext-2-v1.zip', '3c914d17d80b1459be871a5039ac23e752a53cbe')\n</pre> myutils.DATA_HUB['wikitext-2'] = (     'https://s3.amazonaws.com/research.metamind.io/wikitext/'     'wikitext-2-v1.zip', '3c914d17d80b1459be871a5039ac23e752a53cbe') In\u00a0[\u00a0]: Copied! <pre>def _read_wiki(data_dir):\n    \"\"\"Defined in :numref:`sec_bert-dataset`\"\"\"\n    file_name = os.path.join(data_dir, 'wiki.train.tokens')\n    with open(file_name, 'r') as f:\n        lines = f.readlines()\n    # Uppercase letters are converted to lowercase ones\n    paragraphs = [line.strip().lower().split(' . ')\n                  for line in lines if len(line.split(' . ')) &gt;= 2]\n    random.shuffle(paragraphs)\n    return paragraphs\n</pre> def _read_wiki(data_dir):     \"\"\"Defined in :numref:`sec_bert-dataset`\"\"\"     file_name = os.path.join(data_dir, 'wiki.train.tokens')     with open(file_name, 'r') as f:         lines = f.readlines()     # Uppercase letters are converted to lowercase ones     paragraphs = [line.strip().lower().split(' . ')                   for line in lines if len(line.split(' . ')) &gt;= 2]     random.shuffle(paragraphs)     return paragraphs In\u00a0[\u00a0]: Copied! <pre>def _get_next_sentence(sentence, next_sentence, paragraphs):\n    \"\"\"Defined in :numref:`sec_bert-dataset`\"\"\"\n    if random.random() &lt; 0.5:\n        is_next = True\n    else:\n        # `paragraphs` is a list of lists of lists\n        next_sentence = random.choice(random.choice(paragraphs))\n        is_next = False\n    return sentence, next_sentence, is_next\n</pre> def _get_next_sentence(sentence, next_sentence, paragraphs):     \"\"\"Defined in :numref:`sec_bert-dataset`\"\"\"     if random.random() &lt; 0.5:         is_next = True     else:         # `paragraphs` is a list of lists of lists         next_sentence = random.choice(random.choice(paragraphs))         is_next = False     return sentence, next_sentence, is_next In\u00a0[\u00a0]: Copied! <pre>def _get_nsp_data_from_paragraph(paragraph, paragraphs, vocab, max_len):\n    \"\"\"Defined in :numref:`sec_bert-dataset`\"\"\"\n    nsp_data_from_paragraph = []\n    for i in range(len(paragraph) - 1):\n        tokens_a, tokens_b, is_next = _get_next_sentence(\n            paragraph[i], paragraph[i + 1], paragraphs)\n        # Consider 1 '&lt;cls&gt;' token and 2 '&lt;sep&gt;' tokens\n        if len(tokens_a) + len(tokens_b) + 3 &gt; max_len:\n            continue\n        tokens, segments = myutils.get_tokens_and_segments(tokens_a, tokens_b)\n        nsp_data_from_paragraph.append((tokens, segments, is_next))\n    return nsp_data_from_paragraph\n</pre> def _get_nsp_data_from_paragraph(paragraph, paragraphs, vocab, max_len):     \"\"\"Defined in :numref:`sec_bert-dataset`\"\"\"     nsp_data_from_paragraph = []     for i in range(len(paragraph) - 1):         tokens_a, tokens_b, is_next = _get_next_sentence(             paragraph[i], paragraph[i + 1], paragraphs)         # Consider 1 '' token and 2 '' tokens         if len(tokens_a) + len(tokens_b) + 3 &gt; max_len:             continue         tokens, segments = myutils.get_tokens_and_segments(tokens_a, tokens_b)         nsp_data_from_paragraph.append((tokens, segments, is_next))     return nsp_data_from_paragraph In\u00a0[\u00a0]: Copied! <pre>def _replace_mlm_tokens(tokens, candidate_pred_positions, num_mlm_preds,\n                        vocab):\n    \"\"\"Defined in :numref:`sec_bert-dataset`\"\"\"\n    # For the input of a masked language model, make a new copy of tokens and\n    # replace some of them by '&lt;mask&gt;' or random tokens\n    mlm_input_tokens = [token for token in tokens]\n    pred_positions_and_labels = []\n    # Shuffle for getting 15% random tokens for prediction in the masked\n    # language modeling task\n    random.shuffle(candidate_pred_positions)\n    for mlm_pred_position in candidate_pred_positions:\n        if len(pred_positions_and_labels) &gt;= num_mlm_preds:\n            break\n        masked_token = None\n        # 80% of the time: replace the word with the '&lt;mask&gt;' token\n        if random.random() &lt; 0.8:\n            masked_token = '&lt;mask&gt;'\n        else:\n            # 10% of the time: keep the word unchanged\n            if random.random() &lt; 0.5:\n                masked_token = tokens[mlm_pred_position]\n            # 10% of the time: replace the word with a random word\n            else:\n                masked_token = random.choice(vocab.idx_to_token)\n        mlm_input_tokens[mlm_pred_position] = masked_token\n        pred_positions_and_labels.append(\n            (mlm_pred_position, tokens[mlm_pred_position]))\n    return mlm_input_tokens, pred_positions_and_labels\n</pre> def _replace_mlm_tokens(tokens, candidate_pred_positions, num_mlm_preds,                         vocab):     \"\"\"Defined in :numref:`sec_bert-dataset`\"\"\"     # For the input of a masked language model, make a new copy of tokens and     # replace some of them by '' or random tokens     mlm_input_tokens = [token for token in tokens]     pred_positions_and_labels = []     # Shuffle for getting 15% random tokens for prediction in the masked     # language modeling task     random.shuffle(candidate_pred_positions)     for mlm_pred_position in candidate_pred_positions:         if len(pred_positions_and_labels) &gt;= num_mlm_preds:             break         masked_token = None         # 80% of the time: replace the word with the '' token         if random.random() &lt; 0.8:             masked_token = ''         else:             # 10% of the time: keep the word unchanged             if random.random() &lt; 0.5:                 masked_token = tokens[mlm_pred_position]             # 10% of the time: replace the word with a random word             else:                 masked_token = random.choice(vocab.idx_to_token)         mlm_input_tokens[mlm_pred_position] = masked_token         pred_positions_and_labels.append(             (mlm_pred_position, tokens[mlm_pred_position]))     return mlm_input_tokens, pred_positions_and_labels In\u00a0[\u00a0]: Copied! <pre>def _get_mlm_data_from_tokens(tokens, vocab):\n    \"\"\"Defined in :numref:`subsec_prepare_mlm_data`\"\"\"\n    candidate_pred_positions = []\n    # `tokens` is a list of strings\n    for i, token in enumerate(tokens):\n        # Special tokens are not predicted in the masked language modeling\n        # task\n        if token in ['&lt;cls&gt;', '&lt;sep&gt;']:\n            continue\n        candidate_pred_positions.append(i)\n    # 15% of random tokens are predicted in the masked language modeling task\n    num_mlm_preds = max(1, round(len(tokens) * 0.15))\n    mlm_input_tokens, pred_positions_and_labels = _replace_mlm_tokens(\n        tokens, candidate_pred_positions, num_mlm_preds, vocab)\n    pred_positions_and_labels = sorted(pred_positions_and_labels,\n                                       key=lambda x: x[0])\n    pred_positions = [v[0] for v in pred_positions_and_labels]\n    mlm_pred_labels = [v[1] for v in pred_positions_and_labels]\n    return vocab[mlm_input_tokens], pred_positions, vocab[mlm_pred_labels]\n</pre> def _get_mlm_data_from_tokens(tokens, vocab):     \"\"\"Defined in :numref:`subsec_prepare_mlm_data`\"\"\"     candidate_pred_positions = []     # `tokens` is a list of strings     for i, token in enumerate(tokens):         # Special tokens are not predicted in the masked language modeling         # task         if token in ['', '']:             continue         candidate_pred_positions.append(i)     # 15% of random tokens are predicted in the masked language modeling task     num_mlm_preds = max(1, round(len(tokens) * 0.15))     mlm_input_tokens, pred_positions_and_labels = _replace_mlm_tokens(         tokens, candidate_pred_positions, num_mlm_preds, vocab)     pred_positions_and_labels = sorted(pred_positions_and_labels,                                        key=lambda x: x[0])     pred_positions = [v[0] for v in pred_positions_and_labels]     mlm_pred_labels = [v[1] for v in pred_positions_and_labels]     return vocab[mlm_input_tokens], pred_positions, vocab[mlm_pred_labels] In\u00a0[\u00a0]: Copied! <pre>def _pad_bert_inputs(examples, max_len, vocab):\n    \"\"\"Defined in :numref:`subsec_prepare_mlm_data`\"\"\"\n    max_num_mlm_preds = round(max_len * 0.15)\n    all_token_ids, all_segments, valid_lens, = [], [], []\n    all_pred_positions, all_mlm_weights, all_mlm_labels = [], [], []\n    nsp_labels = []\n    for (token_ids, pred_positions, mlm_pred_label_ids, segments,\n         is_next) in examples:\n        all_token_ids.append(torch.tensor(token_ids + [vocab['&lt;pad&gt;']] * (\n                max_len - len(token_ids)), dtype=torch.long))\n        all_segments.append(torch.tensor(segments + [0] * (\n                max_len - len(segments)), dtype=torch.long))\n        # `valid_lens` excludes count of '&lt;pad&gt;' tokens\n        valid_lens.append(torch.tensor(len(token_ids), dtype=torch.float32))\n        all_pred_positions.append(torch.tensor(pred_positions + [0] * (\n                max_num_mlm_preds - len(pred_positions)), dtype=torch.long))\n        # Predictions of padded tokens will be filtered out in the loss via\n        # multiplication of 0 weights\n        all_mlm_weights.append(\n            torch.tensor([1.0] * len(mlm_pred_label_ids) + [0.0] * (\n                    max_num_mlm_preds - len(pred_positions)),\n                         dtype=torch.float32))\n        all_mlm_labels.append(torch.tensor(mlm_pred_label_ids + [0] * (\n                max_num_mlm_preds - len(mlm_pred_label_ids)), dtype=torch.long))\n        nsp_labels.append(torch.tensor(is_next, dtype=torch.long))\n    return (all_token_ids, all_segments, valid_lens, all_pred_positions,\n            all_mlm_weights, all_mlm_labels, nsp_labels)\n</pre> def _pad_bert_inputs(examples, max_len, vocab):     \"\"\"Defined in :numref:`subsec_prepare_mlm_data`\"\"\"     max_num_mlm_preds = round(max_len * 0.15)     all_token_ids, all_segments, valid_lens, = [], [], []     all_pred_positions, all_mlm_weights, all_mlm_labels = [], [], []     nsp_labels = []     for (token_ids, pred_positions, mlm_pred_label_ids, segments,          is_next) in examples:         all_token_ids.append(torch.tensor(token_ids + [vocab['']] * (                 max_len - len(token_ids)), dtype=torch.long))         all_segments.append(torch.tensor(segments + [0] * (                 max_len - len(segments)), dtype=torch.long))         # `valid_lens` excludes count of '' tokens         valid_lens.append(torch.tensor(len(token_ids), dtype=torch.float32))         all_pred_positions.append(torch.tensor(pred_positions + [0] * (                 max_num_mlm_preds - len(pred_positions)), dtype=torch.long))         # Predictions of padded tokens will be filtered out in the loss via         # multiplication of 0 weights         all_mlm_weights.append(             torch.tensor([1.0] * len(mlm_pred_label_ids) + [0.0] * (                     max_num_mlm_preds - len(pred_positions)),                          dtype=torch.float32))         all_mlm_labels.append(torch.tensor(mlm_pred_label_ids + [0] * (                 max_num_mlm_preds - len(mlm_pred_label_ids)), dtype=torch.long))         nsp_labels.append(torch.tensor(is_next, dtype=torch.long))     return (all_token_ids, all_segments, valid_lens, all_pred_positions,             all_mlm_weights, all_mlm_labels, nsp_labels) In\u00a0[\u00a0]: Copied! <pre>class _WikiTextDataset(torch.utils.data.Dataset):\n    \"\"\"Defined in :numref:`subsec_prepare_mlm_data`\"\"\"\n\n    def __init__(self, paragraphs, max_len):\n        # Input `paragraphs[i]` is a list of sentence strings representing a\n        # paragraph; while output `paragraphs[i]` is a list of sentences\n        # representing a paragraph, where each sentence is a list of tokens\n        paragraphs = [myutils.tokenize(\n            paragraph, token='word') for paragraph in paragraphs]\n        sentences = [sentence for paragraph in paragraphs\n                     for sentence in paragraph]\n        self.vocab = myutils.Vocab(sentences, min_freq=5, reserved_tokens=[\n            '&lt;pad&gt;', '&lt;mask&gt;', '&lt;cls&gt;', '&lt;sep&gt;'])\n        # Get data for the next sentence prediction task\n        examples = []\n        for paragraph in paragraphs:\n            examples.extend(_get_nsp_data_from_paragraph(\n                paragraph, paragraphs, self.vocab, max_len))\n        # Get data for the masked language model task\n        examples = [(_get_mlm_data_from_tokens(tokens, self.vocab)\n                     + (segments, is_next))\n                    for tokens, segments, is_next in examples]\n        # Pad inputs\n        (self.all_token_ids, self.all_segments, self.valid_lens,\n         self.all_pred_positions, self.all_mlm_weights,\n         self.all_mlm_labels, self.nsp_labels) = _pad_bert_inputs(\n            examples, max_len, self.vocab)\n\n    def __getitem__(self, idx):\n        return (self.all_token_ids[idx], self.all_segments[idx],\n                self.valid_lens[idx], self.all_pred_positions[idx],\n                self.all_mlm_weights[idx], self.all_mlm_labels[idx],\n                self.nsp_labels[idx])\n\n    def __len__(self):\n        return len(self.all_token_ids)\n</pre> class _WikiTextDataset(torch.utils.data.Dataset):     \"\"\"Defined in :numref:`subsec_prepare_mlm_data`\"\"\"      def __init__(self, paragraphs, max_len):         # Input `paragraphs[i]` is a list of sentence strings representing a         # paragraph; while output `paragraphs[i]` is a list of sentences         # representing a paragraph, where each sentence is a list of tokens         paragraphs = [myutils.tokenize(             paragraph, token='word') for paragraph in paragraphs]         sentences = [sentence for paragraph in paragraphs                      for sentence in paragraph]         self.vocab = myutils.Vocab(sentences, min_freq=5, reserved_tokens=[             '', '', '', ''])         # Get data for the next sentence prediction task         examples = []         for paragraph in paragraphs:             examples.extend(_get_nsp_data_from_paragraph(                 paragraph, paragraphs, self.vocab, max_len))         # Get data for the masked language model task         examples = [(_get_mlm_data_from_tokens(tokens, self.vocab)                      + (segments, is_next))                     for tokens, segments, is_next in examples]         # Pad inputs         (self.all_token_ids, self.all_segments, self.valid_lens,          self.all_pred_positions, self.all_mlm_weights,          self.all_mlm_labels, self.nsp_labels) = _pad_bert_inputs(             examples, max_len, self.vocab)      def __getitem__(self, idx):         return (self.all_token_ids[idx], self.all_segments[idx],                 self.valid_lens[idx], self.all_pred_positions[idx],                 self.all_mlm_weights[idx], self.all_mlm_labels[idx],                 self.nsp_labels[idx])      def __len__(self):         return len(self.all_token_ids) In\u00a0[\u00a0]: Copied! <pre>def load_data_wiki(batch_size, max_len):\n    \"\"\"Load the WikiText-2 dataset.\n    Defined in :numref:`subsec_prepare_mlm_data`\"\"\"\n    num_workers = myutils.get_dataloader_workers()\n    data_dir = myutils.download_extract('wikitext-2', 'wikitext-2')\n    paragraphs = _read_wiki(data_dir)\n    train_set = _WikiTextDataset(paragraphs, max_len)\n    train_iter = torch.utils.data.DataLoader(train_set, batch_size,\n                                             shuffle=True, num_workers=num_workers)\n    return train_iter, train_set.vocab\n</pre> def load_data_wiki(batch_size, max_len):     \"\"\"Load the WikiText-2 dataset.     Defined in :numref:`subsec_prepare_mlm_data`\"\"\"     num_workers = myutils.get_dataloader_workers()     data_dir = myutils.download_extract('wikitext-2', 'wikitext-2')     paragraphs = _read_wiki(data_dir)     train_set = _WikiTextDataset(paragraphs, max_len)     train_iter = torch.utils.data.DataLoader(train_set, batch_size,                                              shuffle=True, num_workers=num_workers)     return train_iter, train_set.vocab In\u00a0[\u00a0]: Copied! <pre>def _get_batch_loss_bert(net, loss, vocab_size, tokens_X,\n                         segments_X, valid_lens_x,\n                         pred_positions_X, mlm_weights_X,\n                         mlm_Y, nsp_y):\n    \"\"\"Defined in :numref:`sec_bert-pretraining`\"\"\"\n    # Forward pass\n    _, mlm_Y_hat, nsp_Y_hat = net(tokens_X, segments_X,\n                                  valid_lens_x.reshape(-1),\n                                  pred_positions_X)\n    # Compute masked language model loss\n    mlm_l = loss(mlm_Y_hat.reshape(-1, vocab_size), mlm_Y.reshape(-1)) * \\\n            mlm_weights_X.reshape(-1, 1)\n    mlm_l = mlm_l.sum() / (mlm_weights_X.sum() + 1e-8)\n    # Compute next sentence prediction loss\n    nsp_l = loss(nsp_Y_hat, nsp_y)\n    l = mlm_l + nsp_l\n    return mlm_l, nsp_l, l\n</pre> def _get_batch_loss_bert(net, loss, vocab_size, tokens_X,                          segments_X, valid_lens_x,                          pred_positions_X, mlm_weights_X,                          mlm_Y, nsp_y):     \"\"\"Defined in :numref:`sec_bert-pretraining`\"\"\"     # Forward pass     _, mlm_Y_hat, nsp_Y_hat = net(tokens_X, segments_X,                                   valid_lens_x.reshape(-1),                                   pred_positions_X)     # Compute masked language model loss     mlm_l = loss(mlm_Y_hat.reshape(-1, vocab_size), mlm_Y.reshape(-1)) * \\             mlm_weights_X.reshape(-1, 1)     mlm_l = mlm_l.sum() / (mlm_weights_X.sum() + 1e-8)     # Compute next sentence prediction loss     nsp_l = loss(nsp_Y_hat, nsp_y)     l = mlm_l + nsp_l     return mlm_l, nsp_l, l In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['aclImdb'] = (myutils.DATA_URL + 'aclImdb_v1.tar.gz',\n                               '01ada507287d82875905620988597833ad4e0903')\n</pre> myutils.DATA_HUB['aclImdb'] = (myutils.DATA_URL + 'aclImdb_v1.tar.gz',                                '01ada507287d82875905620988597833ad4e0903') In\u00a0[\u00a0]: Copied! <pre>def read_imdb(data_dir, is_train):\n    \"\"\"Read the IMDb review dataset text sequences and labels.\n    Defined in :numref:`sec_sentiment`\"\"\"\n    data, labels = [], []\n    for label in ('pos', 'neg'):\n        folder_name = os.path.join(data_dir, 'train' if is_train else 'test',\n                                   label)\n        for file in os.listdir(folder_name):\n            with open(os.path.join(folder_name, file), 'rb') as f:\n                review = f.read().decode('utf-8').replace('\\n', '')\n                data.append(review)\n                labels.append(1 if label == 'pos' else 0)\n    return data, labels\n</pre> def read_imdb(data_dir, is_train):     \"\"\"Read the IMDb review dataset text sequences and labels.     Defined in :numref:`sec_sentiment`\"\"\"     data, labels = [], []     for label in ('pos', 'neg'):         folder_name = os.path.join(data_dir, 'train' if is_train else 'test',                                    label)         for file in os.listdir(folder_name):             with open(os.path.join(folder_name, file), 'rb') as f:                 review = f.read().decode('utf-8').replace('\\n', '')                 data.append(review)                 labels.append(1 if label == 'pos' else 0)     return data, labels In\u00a0[\u00a0]: Copied! <pre>def load_data_imdb(batch_size, num_steps=500):\n    \"\"\"Return data iterators and the vocabulary of the IMDb review dataset.\n    Defined in :numref:`sec_sentiment`\"\"\"\n    data_dir = myutils.download_extract('aclImdb', 'aclImdb')\n    train_data = read_imdb(data_dir, True)\n    test_data = read_imdb(data_dir, False)\n    train_tokens = myutils.tokenize(train_data[0], token='word')\n    test_tokens = myutils.tokenize(test_data[0], token='word')\n    vocab = myutils.Vocab(train_tokens, min_freq=5)\n    train_features = torch.tensor([myutils.truncate_pad(\n        vocab[line], num_steps, vocab['&lt;pad&gt;']) for line in train_tokens])\n    test_features = torch.tensor([myutils.truncate_pad(\n        vocab[line], num_steps, vocab['&lt;pad&gt;']) for line in test_tokens])\n    train_iter = myutils.load_array((train_features, torch.tensor(train_data[1])),\n                                    batch_size)\n    test_iter = myutils.load_array((test_features, torch.tensor(test_data[1])),\n                                   batch_size,\n                                   is_train=False)\n    return train_iter, test_iter, vocab\n</pre> def load_data_imdb(batch_size, num_steps=500):     \"\"\"Return data iterators and the vocabulary of the IMDb review dataset.     Defined in :numref:`sec_sentiment`\"\"\"     data_dir = myutils.download_extract('aclImdb', 'aclImdb')     train_data = read_imdb(data_dir, True)     test_data = read_imdb(data_dir, False)     train_tokens = myutils.tokenize(train_data[0], token='word')     test_tokens = myutils.tokenize(test_data[0], token='word')     vocab = myutils.Vocab(train_tokens, min_freq=5)     train_features = torch.tensor([myutils.truncate_pad(         vocab[line], num_steps, vocab['']) for line in train_tokens])     test_features = torch.tensor([myutils.truncate_pad(         vocab[line], num_steps, vocab['']) for line in test_tokens])     train_iter = myutils.load_array((train_features, torch.tensor(train_data[1])),                                     batch_size)     test_iter = myutils.load_array((test_features, torch.tensor(test_data[1])),                                    batch_size,                                    is_train=False)     return train_iter, test_iter, vocab In\u00a0[\u00a0]: Copied! <pre>def predict_sentiment(net, vocab, sequence):\n    \"\"\"Predict the sentiment of a text sequence.\n    Defined in :numref:`sec_sentiment_rnn`\"\"\"\n    sequence = torch.tensor(vocab[sequence.split()], device=myutils.try_gpu())\n    label = torch.argmax(net(sequence.reshape(1, -1)), dim=1)\n    return 'positive' if label == 1 else 'negative'\n</pre> def predict_sentiment(net, vocab, sequence):     \"\"\"Predict the sentiment of a text sequence.     Defined in :numref:`sec_sentiment_rnn`\"\"\"     sequence = torch.tensor(vocab[sequence.split()], device=myutils.try_gpu())     label = torch.argmax(net(sequence.reshape(1, -1)), dim=1)     return 'positive' if label == 1 else 'negative' In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['SNLI'] = (\n    'https://nlp.stanford.edu/projects/snli/snli_1.0.zip',\n    '9fcde07509c7e87ec61c640c1b2753d9041758e4')\n</pre> myutils.DATA_HUB['SNLI'] = (     'https://nlp.stanford.edu/projects/snli/snli_1.0.zip',     '9fcde07509c7e87ec61c640c1b2753d9041758e4') In\u00a0[\u00a0]: Copied! <pre>def read_snli(data_dir, is_train):\n    \"\"\"Read the SNLI dataset into premises, hypotheses, and labels.\n    Defined in :numref:`sec_natural-language-inference-and-dataset`\"\"\"\n\n    def extract_text(s):\n        # Remove information that will not be used by us\n        s = re.sub('\\\\(', '', s)\n        s = re.sub('\\\\)', '', s)\n        # Substitute two or more consecutive whitespace with space\n        s = re.sub('\\\\s{2,}', ' ', s)\n        return s.strip()\n\n    label_set = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n    file_name = os.path.join(data_dir, 'snli_1.0_train.txt'\n    if is_train else 'snli_1.0_test.txt')\n    with open(file_name, 'r') as f:\n        rows = [row.split('\\t') for row in f.readlines()[1:]]\n    premises = [extract_text(row[1]) for row in rows if row[0] in label_set]\n    hypotheses = [extract_text(row[2]) for row in rows if row[0] in label_set]\n    labels = [label_set[row[0]] for row in rows if row[0] in label_set]\n    return premises, hypotheses, labels\n</pre> def read_snli(data_dir, is_train):     \"\"\"Read the SNLI dataset into premises, hypotheses, and labels.     Defined in :numref:`sec_natural-language-inference-and-dataset`\"\"\"      def extract_text(s):         # Remove information that will not be used by us         s = re.sub('\\\\(', '', s)         s = re.sub('\\\\)', '', s)         # Substitute two or more consecutive whitespace with space         s = re.sub('\\\\s{2,}', ' ', s)         return s.strip()      label_set = {'entailment': 0, 'contradiction': 1, 'neutral': 2}     file_name = os.path.join(data_dir, 'snli_1.0_train.txt'     if is_train else 'snli_1.0_test.txt')     with open(file_name, 'r') as f:         rows = [row.split('\\t') for row in f.readlines()[1:]]     premises = [extract_text(row[1]) for row in rows if row[0] in label_set]     hypotheses = [extract_text(row[2]) for row in rows if row[0] in label_set]     labels = [label_set[row[0]] for row in rows if row[0] in label_set]     return premises, hypotheses, labels In\u00a0[\u00a0]: Copied! <pre>class SNLIDataset(torch.utils.data.Dataset):\n    \"\"\"A customized dataset to load the SNLI dataset.\n    Defined in :numref:`sec_natural-language-inference-and-dataset`\"\"\"\n\n    def __init__(self, dataset, num_steps, vocab=None):\n        self.num_steps = num_steps\n        all_premise_tokens = myutils.tokenize(dataset[0])\n        all_hypothesis_tokens = myutils.tokenize(dataset[1])\n        if vocab is None:\n            self.vocab = myutils.Vocab(all_premise_tokens + all_hypothesis_tokens,\n                                       min_freq=5, reserved_tokens=['&lt;pad&gt;'])\n        else:\n            self.vocab = vocab\n        self.premises = self._pad(all_premise_tokens)\n        self.hypotheses = self._pad(all_hypothesis_tokens)\n        self.labels = torch.tensor(dataset[2])\n        print('read ' + str(len(self.premises)) + ' examples')\n\n    def _pad(self, lines):\n        return torch.tensor([myutils.truncate_pad(\n            self.vocab[line], self.num_steps, self.vocab['&lt;pad&gt;'])\n            for line in lines])\n\n    def __getitem__(self, idx):\n        return (self.premises[idx], self.hypotheses[idx]), self.labels[idx]\n\n    def __len__(self):\n        return len(self.premises)\n</pre> class SNLIDataset(torch.utils.data.Dataset):     \"\"\"A customized dataset to load the SNLI dataset.     Defined in :numref:`sec_natural-language-inference-and-dataset`\"\"\"      def __init__(self, dataset, num_steps, vocab=None):         self.num_steps = num_steps         all_premise_tokens = myutils.tokenize(dataset[0])         all_hypothesis_tokens = myutils.tokenize(dataset[1])         if vocab is None:             self.vocab = myutils.Vocab(all_premise_tokens + all_hypothesis_tokens,                                        min_freq=5, reserved_tokens=[''])         else:             self.vocab = vocab         self.premises = self._pad(all_premise_tokens)         self.hypotheses = self._pad(all_hypothesis_tokens)         self.labels = torch.tensor(dataset[2])         print('read ' + str(len(self.premises)) + ' examples')      def _pad(self, lines):         return torch.tensor([myutils.truncate_pad(             self.vocab[line], self.num_steps, self.vocab[''])             for line in lines])      def __getitem__(self, idx):         return (self.premises[idx], self.hypotheses[idx]), self.labels[idx]      def __len__(self):         return len(self.premises) In\u00a0[\u00a0]: Copied! <pre>def load_data_snli(batch_size, num_steps=50):\n    \"\"\"Download the SNLI dataset and return data iterators and vocabulary.\n    Defined in :numref:`sec_natural-language-inference-and-dataset`\"\"\"\n    num_workers = myutils.get_dataloader_workers()\n    data_dir = myutils.download_extract('SNLI')\n    train_data = read_snli(data_dir, True)\n    test_data = read_snli(data_dir, False)\n    train_set = SNLIDataset(train_data, num_steps)\n    test_set = SNLIDataset(test_data, num_steps, train_set.vocab)\n    train_iter = torch.utils.data.DataLoader(train_set, batch_size,\n                                             shuffle=True,\n                                             num_workers=num_workers)\n    test_iter = torch.utils.data.DataLoader(test_set, batch_size,\n                                            shuffle=False,\n                                            num_workers=num_workers)\n    return train_iter, test_iter, train_set.vocab\n</pre> def load_data_snli(batch_size, num_steps=50):     \"\"\"Download the SNLI dataset and return data iterators and vocabulary.     Defined in :numref:`sec_natural-language-inference-and-dataset`\"\"\"     num_workers = myutils.get_dataloader_workers()     data_dir = myutils.download_extract('SNLI')     train_data = read_snli(data_dir, True)     test_data = read_snli(data_dir, False)     train_set = SNLIDataset(train_data, num_steps)     test_set = SNLIDataset(test_data, num_steps, train_set.vocab)     train_iter = torch.utils.data.DataLoader(train_set, batch_size,                                              shuffle=True,                                              num_workers=num_workers)     test_iter = torch.utils.data.DataLoader(test_set, batch_size,                                             shuffle=False,                                             num_workers=num_workers)     return train_iter, test_iter, train_set.vocab In\u00a0[\u00a0]: Copied! <pre>def predict_snli(net, vocab, premise, hypothesis):\n    \"\"\"Predict the logical relationship between the premise and hypothesis.\n    Defined in :numref:`sec_natural-language-inference-attention`\"\"\"\n    net.eval()\n    premise = torch.tensor(vocab[premise], device=myutils.try_gpu())\n    hypothesis = torch.tensor(vocab[hypothesis], device=myutils.try_gpu())\n    label = torch.argmax(net([premise.reshape((1, -1)),\n                              hypothesis.reshape((1, -1))]), dim=1)\n    return 'entailment' if label == 0 else 'contradiction' if label == 1 \\\n        else 'neutral'\n</pre> def predict_snli(net, vocab, premise, hypothesis):     \"\"\"Predict the logical relationship between the premise and hypothesis.     Defined in :numref:`sec_natural-language-inference-attention`\"\"\"     net.eval()     premise = torch.tensor(vocab[premise], device=myutils.try_gpu())     hypothesis = torch.tensor(vocab[hypothesis], device=myutils.try_gpu())     label = torch.argmax(net([premise.reshape((1, -1)),                               hypothesis.reshape((1, -1))]), dim=1)     return 'entailment' if label == 0 else 'contradiction' if label == 1 \\         else 'neutral' In\u00a0[\u00a0]: Copied! <pre>def rbfkernel(x1, x2, ls=4.):\n    dist = distance_matrix(np.expand_dims(x1, 1), np.expand_dims(x2, 1))\n    return np.exp(-(1. / ls / 2) * (dist ** 2))\n</pre> def rbfkernel(x1, x2, ls=4.):     dist = distance_matrix(np.expand_dims(x1, 1), np.expand_dims(x2, 1))     return np.exp(-(1. / ls / 2) * (dist ** 2)) In\u00a0[\u00a0]: Copied! <pre>class HPOTrainer(myutils.Trainer):\n    \"\"\"Defined in :numref:`sec_definition_hpo`\"\"\"\n\n    def validation_error(self):\n        self.model.eval()\n        accuracy = 0\n        val_batch_idx = 0\n        for batch in self.val_dataloader:\n            with torch.no_grad():\n                x, y = self.prepare_batch(batch)\n                y_hat = self.model(x)\n                accuracy += self.model.accuracy(y_hat, y)\n            val_batch_idx += 1\n        return 1 - accuracy / val_batch_idx\n</pre> class HPOTrainer(myutils.Trainer):     \"\"\"Defined in :numref:`sec_definition_hpo`\"\"\"      def validation_error(self):         self.model.eval()         accuracy = 0         val_batch_idx = 0         for batch in self.val_dataloader:             with torch.no_grad():                 x, y = self.prepare_batch(batch)                 y_hat = self.model(x)                 accuracy += self.model.accuracy(y_hat, y)             val_batch_idx += 1         return 1 - accuracy / val_batch_idx In\u00a0[\u00a0]: Copied! <pre>class HPOSearcher(myutils.HyperParameters):\n    \"\"\"Defined in :numref:`sec_api_hpo`\"\"\"\n\n    def sample_configuration() -&gt; dict:\n        raise NotImplementedError\n\n    def update(self, config: dict, error: float, additional_info=None):\n        pass\n</pre> class HPOSearcher(myutils.HyperParameters):     \"\"\"Defined in :numref:`sec_api_hpo`\"\"\"      def sample_configuration() -&gt; dict:         raise NotImplementedError      def update(self, config: dict, error: float, additional_info=None):         pass In\u00a0[\u00a0]: Copied! <pre>class RandomSearcher(HPOSearcher):\n    \"\"\"Defined in :numref:`sec_api_hpo`\"\"\"\n\n    def __init__(self, config_space: dict, initial_config=None):\n        self.save_hyperparameters()\n\n    def sample_configuration(self) -&gt; dict:\n        if self.initial_config is not None:\n            result = self.initial_config\n            self.initial_config = None\n        else:\n            result = {\n                name: domain.rvs()\n                for name, domain in self.config_space.items()\n            }\n        return result\n</pre> class RandomSearcher(HPOSearcher):     \"\"\"Defined in :numref:`sec_api_hpo`\"\"\"      def __init__(self, config_space: dict, initial_config=None):         self.save_hyperparameters()      def sample_configuration(self) -&gt; dict:         if self.initial_config is not None:             result = self.initial_config             self.initial_config = None         else:             result = {                 name: domain.rvs()                 for name, domain in self.config_space.items()             }         return result In\u00a0[\u00a0]: Copied! <pre>class HPOScheduler(myutils.HyperParameters):\n    \"\"\"Defined in :numref:`sec_api_hpo`\"\"\"\n\n    def suggest(self) -&gt; dict:\n        raise NotImplementedError\n\n    def update(self, config: dict, error: float, info=None):\n        raise NotImplementedError\n</pre> class HPOScheduler(myutils.HyperParameters):     \"\"\"Defined in :numref:`sec_api_hpo`\"\"\"      def suggest(self) -&gt; dict:         raise NotImplementedError      def update(self, config: dict, error: float, info=None):         raise NotImplementedError In\u00a0[\u00a0]: Copied! <pre>class BasicScheduler(HPOScheduler):\n    \"\"\"Defined in :numref:`sec_api_hpo`\"\"\"\n\n    def __init__(self, searcher: HPOSearcher):\n        self.save_hyperparameters()\n\n    def suggest(self) -&gt; dict:\n        return self.searcher.sample_configuration()\n\n    def update(self, config: dict, error: float, info=None):\n        self.searcher.update(config, error, additional_info=info)\n</pre> class BasicScheduler(HPOScheduler):     \"\"\"Defined in :numref:`sec_api_hpo`\"\"\"      def __init__(self, searcher: HPOSearcher):         self.save_hyperparameters()      def suggest(self) -&gt; dict:         return self.searcher.sample_configuration()      def update(self, config: dict, error: float, info=None):         self.searcher.update(config, error, additional_info=info) In\u00a0[\u00a0]: Copied! <pre>class HPOTuner(myutils.HyperParameters):\n    \"\"\"Defined in :numref:`sec_api_hpo`\"\"\"\n\n    def __init__(self, scheduler: HPOScheduler, objective: callable):\n        self.save_hyperparameters()\n        # Bookeeping results for plotting\n        self.incumbent = None\n        self.incumbent_error = None\n        self.incumbent_trajectory = []\n        self.cumulative_runtime = []\n        self.current_runtime = 0\n        self.records = []\n\n    def run(self, number_of_trials):\n        for i in range(number_of_trials):\n            start_time = time.time()\n            config = self.scheduler.suggest()\n            print(f\"Trial {i}: config = {config}\")\n            error = self.objective(**config)\n            error = float(myutils.numpy(error.cpu()))\n            self.scheduler.update(config, error)\n            runtime = time.time() - start_time\n            self.bookkeeping(config, error, runtime)\n            print(f\"    error = {error}, runtime = {runtime}\")\n\n    def bookkeeping(self, config: dict, error: float, runtime: float):\n        \"\"\"Defined in :numref:`sec_api_hpo`\"\"\"\n        self.records.append({\"config\": config, \"error\": error, \"runtime\": runtime})\n        # Check if the last hyperparameter configuration performs better\n        # than the incumbent\n        if self.incumbent is None or self.incumbent_error &gt; error:\n            self.incumbent = config\n            self.incumbent_error = error\n        # Add current best observed performance to the optimization trajectory\n        self.incumbent_trajectory.append(self.incumbent_error)\n        # Update runtime\n        self.current_runtime += runtime\n        self.cumulative_runtime.append(self.current_runtime)\n</pre> class HPOTuner(myutils.HyperParameters):     \"\"\"Defined in :numref:`sec_api_hpo`\"\"\"      def __init__(self, scheduler: HPOScheduler, objective: callable):         self.save_hyperparameters()         # Bookeeping results for plotting         self.incumbent = None         self.incumbent_error = None         self.incumbent_trajectory = []         self.cumulative_runtime = []         self.current_runtime = 0         self.records = []      def run(self, number_of_trials):         for i in range(number_of_trials):             start_time = time.time()             config = self.scheduler.suggest()             print(f\"Trial {i}: config = {config}\")             error = self.objective(**config)             error = float(myutils.numpy(error.cpu()))             self.scheduler.update(config, error)             runtime = time.time() - start_time             self.bookkeeping(config, error, runtime)             print(f\"    error = {error}, runtime = {runtime}\")      def bookkeeping(self, config: dict, error: float, runtime: float):         \"\"\"Defined in :numref:`sec_api_hpo`\"\"\"         self.records.append({\"config\": config, \"error\": error, \"runtime\": runtime})         # Check if the last hyperparameter configuration performs better         # than the incumbent         if self.incumbent is None or self.incumbent_error &gt; error:             self.incumbent = config             self.incumbent_error = error         # Add current best observed performance to the optimization trajectory         self.incumbent_trajectory.append(self.incumbent_error)         # Update runtime         self.current_runtime += runtime         self.cumulative_runtime.append(self.current_runtime) In\u00a0[\u00a0]: Copied! <pre>def hpo_objective_lenet(learning_rate, batch_size, max_epochs=10):\n    \"\"\"Defined in :numref:`sec_api_hpo`\"\"\"\n    model = myutils.LeNet(lr=learning_rate, num_classes=10)\n    trainer = myutils.HPOTrainer(max_epochs=max_epochs, num_gpus=1)\n    data = myutils.FashionMNIST(batch_size=batch_size)\n    model.apply_init([next(iter(data.get_dataloader(True)))[0]], myutils.init_cnn)\n    trainer.fit(model=model, data=data)\n    validation_error = trainer.validation_error()\n    return validation_error\n</pre> def hpo_objective_lenet(learning_rate, batch_size, max_epochs=10):     \"\"\"Defined in :numref:`sec_api_hpo`\"\"\"     model = myutils.LeNet(lr=learning_rate, num_classes=10)     trainer = myutils.HPOTrainer(max_epochs=max_epochs, num_gpus=1)     data = myutils.FashionMNIST(batch_size=batch_size)     model.apply_init([next(iter(data.get_dataloader(True)))[0]], myutils.init_cnn)     trainer.fit(model=model, data=data)     validation_error = trainer.validation_error()     return validation_error In\u00a0[\u00a0]: Copied! <pre>class SuccessiveHalvingScheduler(myutils.HPOScheduler):\n    \"\"\"Defined in :numref:`sec_mf_hpo`\"\"\"\n\n    def __init__(self, searcher, eta, r_min, r_max, prefact=1):\n        self.save_hyperparameters()\n        # Compute K, which is later used to determine the number of configurations\n        self.K = int(np.log(r_max / r_min) / np.log(eta))\n        # Define the rungs\n        self.rung_levels = [r_min * eta ** k for k in range(self.K + 1)]\n        if r_max not in self.rung_levels:\n            # The final rung should be r_max\n            self.rung_levels.append(r_max)\n            self.K += 1\n        # Bookkeeping\n        self.observed_error_at_rungs = defaultdict(list)\n        self.all_observed_error_at_rungs = defaultdict(list)\n        # Our processing queue\n        self.queue = []\n\n    def suggest(self):\n        \"\"\"Defined in :numref:`sec_mf_hpo_sh`\"\"\"\n        if len(self.queue) == 0:\n            # Start a new round of successive halving\n            # Number of configurations for the first rung:\n            n0 = int(self.prefact * self.eta ** self.K)\n            for _ in range(n0):\n                config = self.searcher.sample_configuration()\n                config[\"max_epochs\"] = self.r_min  # Set r = r_min\n                self.queue.append(config)\n        # Return an element from the queue\n        return self.queue.pop()\n\n    def update(self, config: dict, error: float, info=None):\n        \"\"\"Defined in :numref:`sec_mf_hpo_sh`\"\"\"\n        ri = int(config[\"max_epochs\"])  # Rung r_i\n        # Update our searcher, e.g if we use Bayesian optimization later\n        self.searcher.update(config, error, additional_info=info)\n        self.all_observed_error_at_rungs[ri].append((config, error))\n        if ri &lt; self.r_max:\n            # Bookkeeping\n            self.observed_error_at_rungs[ri].append((config, error))\n            # Determine how many configurations should be evaluated on this rung\n            ki = self.K - self.rung_levels.index(ri)\n            ni = int(self.prefact * self.eta ** ki)\n            # If we observed all configuration on this rung r_i, we estimate the\n            # top 1 / eta configuration, add them to queue and promote them for\n            # the next rung r_{i+1}\n            if len(self.observed_error_at_rungs[ri]) &gt;= ni:\n                kiplus1 = ki - 1\n                niplus1 = int(self.prefact * self.eta ** kiplus1)\n                best_performing_configurations = self.get_top_n_configurations(\n                    rung_level=ri, n=niplus1\n                )\n                riplus1 = self.rung_levels[self.K - kiplus1]  # r_{i+1}\n                # Queue may not be empty: insert new entries at the beginning\n                self.queue = [\n                                 dict(config, max_epochs=riplus1)\n                                 for config in best_performing_configurations\n                             ] + self.queue\n                self.observed_error_at_rungs[ri] = []  # Reset\n\n    def get_top_n_configurations(self, rung_level, n):\n        \"\"\"Defined in :numref:`sec_mf_hpo_sh`\"\"\"\n        rung = self.observed_error_at_rungs[rung_level]\n        if not rung:\n            return []\n        sorted_rung = sorted(rung, key=lambda x: x[1])\n        return [x[0] for x in sorted_rung[:n]]\n</pre> class SuccessiveHalvingScheduler(myutils.HPOScheduler):     \"\"\"Defined in :numref:`sec_mf_hpo`\"\"\"      def __init__(self, searcher, eta, r_min, r_max, prefact=1):         self.save_hyperparameters()         # Compute K, which is later used to determine the number of configurations         self.K = int(np.log(r_max / r_min) / np.log(eta))         # Define the rungs         self.rung_levels = [r_min * eta ** k for k in range(self.K + 1)]         if r_max not in self.rung_levels:             # The final rung should be r_max             self.rung_levels.append(r_max)             self.K += 1         # Bookkeeping         self.observed_error_at_rungs = defaultdict(list)         self.all_observed_error_at_rungs = defaultdict(list)         # Our processing queue         self.queue = []      def suggest(self):         \"\"\"Defined in :numref:`sec_mf_hpo_sh`\"\"\"         if len(self.queue) == 0:             # Start a new round of successive halving             # Number of configurations for the first rung:             n0 = int(self.prefact * self.eta ** self.K)             for _ in range(n0):                 config = self.searcher.sample_configuration()                 config[\"max_epochs\"] = self.r_min  # Set r = r_min                 self.queue.append(config)         # Return an element from the queue         return self.queue.pop()      def update(self, config: dict, error: float, info=None):         \"\"\"Defined in :numref:`sec_mf_hpo_sh`\"\"\"         ri = int(config[\"max_epochs\"])  # Rung r_i         # Update our searcher, e.g if we use Bayesian optimization later         self.searcher.update(config, error, additional_info=info)         self.all_observed_error_at_rungs[ri].append((config, error))         if ri &lt; self.r_max:             # Bookkeeping             self.observed_error_at_rungs[ri].append((config, error))             # Determine how many configurations should be evaluated on this rung             ki = self.K - self.rung_levels.index(ri)             ni = int(self.prefact * self.eta ** ki)             # If we observed all configuration on this rung r_i, we estimate the             # top 1 / eta configuration, add them to queue and promote them for             # the next rung r_{i+1}             if len(self.observed_error_at_rungs[ri]) &gt;= ni:                 kiplus1 = ki - 1                 niplus1 = int(self.prefact * self.eta ** kiplus1)                 best_performing_configurations = self.get_top_n_configurations(                     rung_level=ri, n=niplus1                 )                 riplus1 = self.rung_levels[self.K - kiplus1]  # r_{i+1}                 # Queue may not be empty: insert new entries at the beginning                 self.queue = [                                  dict(config, max_epochs=riplus1)                                  for config in best_performing_configurations                              ] + self.queue                 self.observed_error_at_rungs[ri] = []  # Reset      def get_top_n_configurations(self, rung_level, n):         \"\"\"Defined in :numref:`sec_mf_hpo_sh`\"\"\"         rung = self.observed_error_at_rungs[rung_level]         if not rung:             return []         sorted_rung = sorted(rung, key=lambda x: x[1])         return [x[0] for x in sorted_rung[:n]] In\u00a0[\u00a0]: Copied! <pre>def update_D(X, Z, net_D, net_G, loss, trainer_D):\n    \"\"\"Update discriminator.\n    Defined in :numref:`sec_basic_gan`\"\"\"\n    batch_size = X.shape[0]\n    ones = torch.ones((batch_size,), device=X.device)\n    zeros = torch.zeros((batch_size,), device=X.device)\n    trainer_D.zero_grad()\n    real_Y = net_D(X)\n    fake_X = net_G(Z)\n    # Do not need to compute gradient for `net_G`, detach it from\n    # computing gradients.\n    fake_Y = net_D(fake_X.detach())\n    loss_D = (loss(real_Y, ones.reshape(real_Y.shape)) +\n              loss(fake_Y, zeros.reshape(fake_Y.shape))) / 2\n    loss_D.backward()\n    trainer_D.step()\n    return loss_D\n</pre> def update_D(X, Z, net_D, net_G, loss, trainer_D):     \"\"\"Update discriminator.     Defined in :numref:`sec_basic_gan`\"\"\"     batch_size = X.shape[0]     ones = torch.ones((batch_size,), device=X.device)     zeros = torch.zeros((batch_size,), device=X.device)     trainer_D.zero_grad()     real_Y = net_D(X)     fake_X = net_G(Z)     # Do not need to compute gradient for `net_G`, detach it from     # computing gradients.     fake_Y = net_D(fake_X.detach())     loss_D = (loss(real_Y, ones.reshape(real_Y.shape)) +               loss(fake_Y, zeros.reshape(fake_Y.shape))) / 2     loss_D.backward()     trainer_D.step()     return loss_D In\u00a0[\u00a0]: Copied! <pre>def update_G(Z, net_D, net_G, loss, trainer_G):\n    \"\"\"Update generator.\n    Defined in :numref:`sec_basic_gan`\"\"\"\n    batch_size = Z.shape[0]\n    ones = torch.ones((batch_size,), device=Z.device)\n    trainer_G.zero_grad()\n    # We could reuse `fake_X` from `update_D` to save computation\n    fake_X = net_G(Z)\n    # Recomputing `fake_Y` is needed since `net_D` is changed\n    fake_Y = net_D(fake_X)\n    loss_G = loss(fake_Y, ones.reshape(fake_Y.shape))\n    loss_G.backward()\n    trainer_G.step()\n    return loss_G\n</pre> def update_G(Z, net_D, net_G, loss, trainer_G):     \"\"\"Update generator.     Defined in :numref:`sec_basic_gan`\"\"\"     batch_size = Z.shape[0]     ones = torch.ones((batch_size,), device=Z.device)     trainer_G.zero_grad()     # We could reuse `fake_X` from `update_D` to save computation     fake_X = net_G(Z)     # Recomputing `fake_Y` is needed since `net_D` is changed     fake_Y = net_D(fake_X)     loss_G = loss(fake_Y, ones.reshape(fake_Y.shape))     loss_G.backward()     trainer_G.step()     return loss_G In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['pokemon'] = (myutils.DATA_URL + 'pokemon.zip',\n                               'c065c0e2593b8b161a2d7873e42418bf6a21106c')\n</pre> myutils.DATA_HUB['pokemon'] = (myutils.DATA_URL + 'pokemon.zip',                                'c065c0e2593b8b161a2d7873e42418bf6a21106c') In\u00a0[\u00a0]: Copied! <pre>def frozen_lake(seed):\n    \"\"\"Defined in :numref:`sec_utils`\"\"\"\n    # See https://www.gymlibrary.dev/environments/toy_text/frozen_lake/ to learn more about this env\n    # How to process env.P.items is adpated from https://sites.google.com/view/deep-rl-bootcamp/labs\n\n    env = gym.make('FrozenLake-v1', is_slippery=False)\n    env.seed(seed)\n    env.action_space.np_random.seed(seed)\n    env.action_space.seed(seed)\n    env_info = {}\n    env_info['desc'] = env.desc  # 2D array specifying what each grid item means\n    env_info['num_states'] = env.nS  # Number of observations/states or obs/state dim\n    env_info['num_actions'] = env.nA  # Number of actions or action dim\n    # Define indices for (transition probability, nextstate, reward, done) tuple\n    env_info['trans_prob_idx'] = 0  # Index of transition probability entry\n    env_info['nextstate_idx'] = 1  # Index of next state entry\n    env_info['reward_idx'] = 2  # Index of reward entry\n    env_info['done_idx'] = 3  # Index of done entry\n    env_info['mdp'] = {}\n    env_info['env'] = env\n\n    for (s, others) in env.P.items():\n        # others(s) = {a0: [ (p(s'|s,a0), s', reward, done),...], a1:[...], ...}\n\n        for (a, pxrds) in others.items():\n            # pxrds is [(p1,next1,r1,d1),(p2,next2,r2,d2),..].\n            # e.g. [(0.3, 0, 0, False), (0.3, 0, 0, False), (0.3, 4, 1, False)]\n            env_info['mdp'][(s, a)] = pxrds\n\n    return env_info\n</pre> def frozen_lake(seed):     \"\"\"Defined in :numref:`sec_utils`\"\"\"     # See https://www.gymlibrary.dev/environments/toy_text/frozen_lake/ to learn more about this env     # How to process env.P.items is adpated from https://sites.google.com/view/deep-rl-bootcamp/labs      env = gym.make('FrozenLake-v1', is_slippery=False)     env.seed(seed)     env.action_space.np_random.seed(seed)     env.action_space.seed(seed)     env_info = {}     env_info['desc'] = env.desc  # 2D array specifying what each grid item means     env_info['num_states'] = env.nS  # Number of observations/states or obs/state dim     env_info['num_actions'] = env.nA  # Number of actions or action dim     # Define indices for (transition probability, nextstate, reward, done) tuple     env_info['trans_prob_idx'] = 0  # Index of transition probability entry     env_info['nextstate_idx'] = 1  # Index of next state entry     env_info['reward_idx'] = 2  # Index of reward entry     env_info['done_idx'] = 3  # Index of done entry     env_info['mdp'] = {}     env_info['env'] = env      for (s, others) in env.P.items():         # others(s) = {a0: [ (p(s'|s,a0), s', reward, done),...], a1:[...], ...}          for (a, pxrds) in others.items():             # pxrds is [(p1,next1,r1,d1),(p2,next2,r2,d2),..].             # e.g. [(0.3, 0, 0, False), (0.3, 0, 0, False), (0.3, 4, 1, False)]             env_info['mdp'][(s, a)] = pxrds      return env_info In\u00a0[\u00a0]: Copied! <pre>def make_env(name='', seed=0):\n    \"\"\"Defined in :numref:`sec_utils`\"\"\"\n    # Input parameters:\n    # name: specifies a gym environment.\n    # For Value iteration, only FrozenLake-v1 is supported.\n    if name == 'FrozenLake-v1':\n        return frozen_lake(seed)\n\n    else:\n        raise ValueError(\"%s env is not supported in this Notebook\")\n</pre> def make_env(name='', seed=0):     \"\"\"Defined in :numref:`sec_utils`\"\"\"     # Input parameters:     # name: specifies a gym environment.     # For Value iteration, only FrozenLake-v1 is supported.     if name == 'FrozenLake-v1':         return frozen_lake(seed)      else:         raise ValueError(\"%s env is not supported in this Notebook\") In\u00a0[\u00a0]: Copied! <pre>def show_value_function_progress(env_desc, V, pi):\n    \"\"\"Defined in :numref:`sec_utils`\"\"\"\n    # This function visualizes how value and policy changes over time.\n    # V: [num_iters, num_states]\n    # pi: [num_iters, num_states]\n    # How to visualize value function is adapted (but changed) from: https://sites.google.com/view/deep-rl-bootcamp/labs\n\n    num_iters = V.shape[0]\n    fig, ax = plt.subplots(figsize=(15, 15))\n\n    for k in range(V.shape[0]):\n        plt.subplot(4, 4, k + 1)\n        plt.imshow(V[k].reshape(4, 4), cmap=\"bone\")\n        ax = plt.gca()\n        ax.set_xticks(np.arange(0, 5) - .5, minor=True)\n        ax.set_yticks(np.arange(0, 5) - .5, minor=True)\n        ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n        ax.tick_params(which=\"minor\", bottom=False, left=False)\n        ax.set_xticks([])\n        ax.set_yticks([])\n\n        # LEFT action: 0, DOWN action: 1\n        # RIGHT action: 2, UP action: 3\n        action2dxdy = {0: (-.25, 0), 1: (0, .25),\n                       2: (0.25, 0), 3: (-.25, 0)}\n\n        for y in range(4):\n            for x in range(4):\n                action = pi[k].reshape(4, 4)[y, x]\n                dx, dy = action2dxdy[action]\n\n                if env_desc[y, x].decode() == 'H':\n                    ax.text(x, y, str(env_desc[y, x].decode()),\n                            ha=\"center\", va=\"center\", color=\"y\",\n                            size=20, fontweight='bold')\n\n                elif env_desc[y, x].decode() == 'G':\n                    ax.text(x, y, str(env_desc[y, x].decode()),\n                            ha=\"center\", va=\"center\", color=\"w\",\n                            size=20, fontweight='bold')\n\n                else:\n                    ax.text(x, y, str(env_desc[y, x].decode()),\n                            ha=\"center\", va=\"center\", color=\"g\",\n                            size=15, fontweight='bold')\n\n                # No arrow for cells with G and H labels\n                if env_desc[y, x].decode() != 'G' and env_desc[y, x].decode() != 'H':\n                    ax.arrow(x, y, dx, dy, color='r', head_width=0.2, head_length=0.15)\n\n        ax.set_title(\"Step = \" + str(k + 1), fontsize=20)\n\n    fig.tight_layout()\n    plt.show()\n</pre> def show_value_function_progress(env_desc, V, pi):     \"\"\"Defined in :numref:`sec_utils`\"\"\"     # This function visualizes how value and policy changes over time.     # V: [num_iters, num_states]     # pi: [num_iters, num_states]     # How to visualize value function is adapted (but changed) from: https://sites.google.com/view/deep-rl-bootcamp/labs      num_iters = V.shape[0]     fig, ax = plt.subplots(figsize=(15, 15))      for k in range(V.shape[0]):         plt.subplot(4, 4, k + 1)         plt.imshow(V[k].reshape(4, 4), cmap=\"bone\")         ax = plt.gca()         ax.set_xticks(np.arange(0, 5) - .5, minor=True)         ax.set_yticks(np.arange(0, 5) - .5, minor=True)         ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)         ax.tick_params(which=\"minor\", bottom=False, left=False)         ax.set_xticks([])         ax.set_yticks([])          # LEFT action: 0, DOWN action: 1         # RIGHT action: 2, UP action: 3         action2dxdy = {0: (-.25, 0), 1: (0, .25),                        2: (0.25, 0), 3: (-.25, 0)}          for y in range(4):             for x in range(4):                 action = pi[k].reshape(4, 4)[y, x]                 dx, dy = action2dxdy[action]                  if env_desc[y, x].decode() == 'H':                     ax.text(x, y, str(env_desc[y, x].decode()),                             ha=\"center\", va=\"center\", color=\"y\",                             size=20, fontweight='bold')                  elif env_desc[y, x].decode() == 'G':                     ax.text(x, y, str(env_desc[y, x].decode()),                             ha=\"center\", va=\"center\", color=\"w\",                             size=20, fontweight='bold')                  else:                     ax.text(x, y, str(env_desc[y, x].decode()),                             ha=\"center\", va=\"center\", color=\"g\",                             size=15, fontweight='bold')                  # No arrow for cells with G and H labels                 if env_desc[y, x].decode() != 'G' and env_desc[y, x].decode() != 'H':                     ax.arrow(x, y, dx, dy, color='r', head_width=0.2, head_length=0.15)          ax.set_title(\"Step = \" + str(k + 1), fontsize=20)      fig.tight_layout()     plt.show() In\u00a0[\u00a0]: Copied! <pre>def show_Q_function_progress(env_desc, V_all, pi_all):\n    \"\"\"Defined in :numref:`sec_utils`\"\"\"\n    # This function visualizes how value and policy changes over time.\n    # V: [num_iters, num_states]\n    # pi: [num_iters, num_states]\n\n    # We want to only shows few values\n    num_iters_all = V_all.shape[0]\n    num_iters = num_iters_all // 10\n\n    vis_indx = np.arange(0, num_iters_all, num_iters).tolist()\n    vis_indx.append(num_iters_all - 1)\n    V = np.zeros((len(vis_indx), V_all.shape[1]))\n    pi = np.zeros((len(vis_indx), V_all.shape[1]))\n\n    for c, i in enumerate(vis_indx):\n        V[c] = V_all[i]\n        pi[c] = pi_all[i]\n\n    num_iters = V.shape[0]\n    fig, ax = plt.subplots(figsize=(15, 15))\n\n    for k in range(V.shape[0]):\n        plt.subplot(4, 4, k + 1)\n        plt.imshow(V[k].reshape(4, 4), cmap=\"bone\")\n        ax = plt.gca()\n        ax.set_xticks(np.arange(0, 5) - .5, minor=True)\n        ax.set_yticks(np.arange(0, 5) - .5, minor=True)\n        ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n        ax.tick_params(which=\"minor\", bottom=False, left=False)\n        ax.set_xticks([])\n        ax.set_yticks([])\n\n        # LEFT action: 0, DOWN action: 1\n        # RIGHT action: 2, UP action: 3\n        action2dxdy = {0: (-.25, 0), 1: (0, .25),\n                       2: (0.25, 0), 3: (-.25, 0)}\n\n        for y in range(4):\n            for x in range(4):\n                action = pi[k].reshape(4, 4)[y, x]\n                dx, dy = action2dxdy[action]\n\n                if env_desc[y, x].decode() == 'H':\n                    ax.text(x, y, str(env_desc[y, x].decode()),\n                            ha=\"center\", va=\"center\", color=\"y\",\n                            size=20, fontweight='bold')\n\n                elif env_desc[y, x].decode() == 'G':\n                    ax.text(x, y, str(env_desc[y, x].decode()),\n                            ha=\"center\", va=\"center\", color=\"w\",\n                            size=20, fontweight='bold')\n\n                else:\n                    ax.text(x, y, str(env_desc[y, x].decode()),\n                            ha=\"center\", va=\"center\", color=\"g\",\n                            size=15, fontweight='bold')\n\n                # No arrow for cells with G and H labels\n                if env_desc[y, x].decode() != 'G' and env_desc[y, x].decode() != 'H':\n                    ax.arrow(x, y, dx, dy, color='r', head_width=0.2, head_length=0.15)\n\n        ax.set_title(\"Step = \" + str(vis_indx[k] + 1), fontsize=20)\n\n    fig.tight_layout()\n    plt.show()\n</pre> def show_Q_function_progress(env_desc, V_all, pi_all):     \"\"\"Defined in :numref:`sec_utils`\"\"\"     # This function visualizes how value and policy changes over time.     # V: [num_iters, num_states]     # pi: [num_iters, num_states]      # We want to only shows few values     num_iters_all = V_all.shape[0]     num_iters = num_iters_all // 10      vis_indx = np.arange(0, num_iters_all, num_iters).tolist()     vis_indx.append(num_iters_all - 1)     V = np.zeros((len(vis_indx), V_all.shape[1]))     pi = np.zeros((len(vis_indx), V_all.shape[1]))      for c, i in enumerate(vis_indx):         V[c] = V_all[i]         pi[c] = pi_all[i]      num_iters = V.shape[0]     fig, ax = plt.subplots(figsize=(15, 15))      for k in range(V.shape[0]):         plt.subplot(4, 4, k + 1)         plt.imshow(V[k].reshape(4, 4), cmap=\"bone\")         ax = plt.gca()         ax.set_xticks(np.arange(0, 5) - .5, minor=True)         ax.set_yticks(np.arange(0, 5) - .5, minor=True)         ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)         ax.tick_params(which=\"minor\", bottom=False, left=False)         ax.set_xticks([])         ax.set_yticks([])          # LEFT action: 0, DOWN action: 1         # RIGHT action: 2, UP action: 3         action2dxdy = {0: (-.25, 0), 1: (0, .25),                        2: (0.25, 0), 3: (-.25, 0)}          for y in range(4):             for x in range(4):                 action = pi[k].reshape(4, 4)[y, x]                 dx, dy = action2dxdy[action]                  if env_desc[y, x].decode() == 'H':                     ax.text(x, y, str(env_desc[y, x].decode()),                             ha=\"center\", va=\"center\", color=\"y\",                             size=20, fontweight='bold')                  elif env_desc[y, x].decode() == 'G':                     ax.text(x, y, str(env_desc[y, x].decode()),                             ha=\"center\", va=\"center\", color=\"w\",                             size=20, fontweight='bold')                  else:                     ax.text(x, y, str(env_desc[y, x].decode()),                             ha=\"center\", va=\"center\", color=\"g\",                             size=15, fontweight='bold')                  # No arrow for cells with G and H labels                 if env_desc[y, x].decode() != 'G' and env_desc[y, x].decode() != 'H':                     ax.arrow(x, y, dx, dy, color='r', head_width=0.2, head_length=0.15)          ax.set_title(\"Step = \" + str(vis_indx[k] + 1), fontsize=20)      fig.tight_layout()     plt.show() In\u00a0[\u00a0]: Copied! <pre>def load_array(data_arrays, batch_size, is_train=True):\n    \"\"\"Construct a PyTorch data iterator.\n    Defined in :numref:`sec_utils`\"\"\"\n    dataset = torch.utils.data.TensorDataset(*data_arrays)\n    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train)\n</pre> def load_array(data_arrays, batch_size, is_train=True):     \"\"\"Construct a PyTorch data iterator.     Defined in :numref:`sec_utils`\"\"\"     dataset = torch.utils.data.TensorDataset(*data_arrays)     return torch.utils.data.DataLoader(dataset, batch_size, shuffle=is_train) In\u00a0[\u00a0]: Copied! <pre>def synthetic_data(w, b, num_examples):\n    \"\"\"Generate y = Xw + b + noise.\n    Defined in :numref:`sec_utils`\"\"\"\n    X = myutils.normal(0, 1, (num_examples, len(w)))\n    y = myutils.matmul(X, w) + b\n    y += myutils.normal(0, 0.01, y.shape)\n    return X, myutils.reshape(y, (-1, 1))\n</pre> def synthetic_data(w, b, num_examples):     \"\"\"Generate y = Xw + b + noise.     Defined in :numref:`sec_utils`\"\"\"     X = myutils.normal(0, 1, (num_examples, len(w)))     y = myutils.matmul(X, w) + b     y += myutils.normal(0, 0.01, y.shape)     return X, myutils.reshape(y, (-1, 1)) In\u00a0[\u00a0]: Copied! <pre>def sgd(params, lr, batch_size):\n    \"\"\"Minibatch stochastic gradient descent.\n    Defined in :numref:`sec_utils`\"\"\"\n    with torch.no_grad():\n        for param in params:\n            param -= lr * param.grad / batch_size\n            param.grad.zero_()\n</pre> def sgd(params, lr, batch_size):     \"\"\"Minibatch stochastic gradient descent.     Defined in :numref:`sec_utils`\"\"\"     with torch.no_grad():         for param in params:             param -= lr * param.grad / batch_size             param.grad.zero_() In\u00a0[\u00a0]: Copied! <pre>def get_dataloader_workers():\n    \"\"\"Use 4 processes to read the data.\n    Defined in :numref:`sec_utils`\"\"\"\n    return 4\n</pre> def get_dataloader_workers():     \"\"\"Use 4 processes to read the data.     Defined in :numref:`sec_utils`\"\"\"     return 4 In\u00a0[\u00a0]: Copied! <pre>def load_data_fashion_mnist(batch_size, resize=None):\n    \"\"\"Download the Fashion-MNIST dataset and then load it into memory.\n    Defined in :numref:`sec_utils`\"\"\"\n    trans = [transforms.ToTensor()]\n    if resize:\n        trans.insert(0, transforms.Resize(resize))\n    trans = transforms.Compose(trans)\n    mnist_train = torchvision.datasets.FashionMNIST(\n        root=\"./chpdata/data\", train=True, transform=trans, download=True)\n    mnist_test = torchvision.datasets.FashionMNIST(\n        root=\"./chpdata/data\", train=False, transform=trans, download=True)\n    return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,\n                                        num_workers=get_dataloader_workers()),\n            torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,\n                                        num_workers=get_dataloader_workers()))\n</pre> def load_data_fashion_mnist(batch_size, resize=None):     \"\"\"Download the Fashion-MNIST dataset and then load it into memory.     Defined in :numref:`sec_utils`\"\"\"     trans = [transforms.ToTensor()]     if resize:         trans.insert(0, transforms.Resize(resize))     trans = transforms.Compose(trans)     mnist_train = torchvision.datasets.FashionMNIST(         root=\"./chpdata/data\", train=True, transform=trans, download=True)     mnist_test = torchvision.datasets.FashionMNIST(         root=\"./chpdata/data\", train=False, transform=trans, download=True)     return (torch.utils.data.DataLoader(mnist_train, batch_size, shuffle=True,                                         num_workers=get_dataloader_workers()),             torch.utils.data.DataLoader(mnist_test, batch_size, shuffle=False,                                         num_workers=get_dataloader_workers())) In\u00a0[\u00a0]: Copied! <pre>def evaluate_accuracy_gpu(net, data_iter, device=None):\n    \"\"\"Compute the accuracy for a model on a dataset using a GPU.\n    Defined in :numref:`sec_utils`\"\"\"\n    if isinstance(net, nn.Module):\n        net.eval()  # Set the model to evaluation mode\n        if not device:\n            device = next(iter(net.parameters())).device\n    # No. of correct predictions, no. of predictions\n    metric = myutils.Accumulator(2)\n\n    with torch.no_grad():\n        for X, y in data_iter:\n            if isinstance(X, list):\n                # Required for BERT Fine-tuning (to be covered later)\n                X = [x.to(device) for x in X]\n            else:\n                X = X.to(device)\n            y = y.to(device)\n            metric.add(myutils.accuracy(net(X), y), myutils.size(y))\n    return metric[0] / metric[1]\n</pre> def evaluate_accuracy_gpu(net, data_iter, device=None):     \"\"\"Compute the accuracy for a model on a dataset using a GPU.     Defined in :numref:`sec_utils`\"\"\"     if isinstance(net, nn.Module):         net.eval()  # Set the model to evaluation mode         if not device:             device = next(iter(net.parameters())).device     # No. of correct predictions, no. of predictions     metric = myutils.Accumulator(2)      with torch.no_grad():         for X, y in data_iter:             if isinstance(X, list):                 # Required for BERT Fine-tuning (to be covered later)                 X = [x.to(device) for x in X]             else:                 X = X.to(device)             y = y.to(device)             metric.add(myutils.accuracy(net(X), y), myutils.size(y))     return metric[0] / metric[1] In\u00a0[\u00a0]: Copied! <pre>def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n    \"\"\"Train a model with a GPU (defined in Chapter 6).\n    Defined in :numref:`sec_utils`\"\"\"\n\n    def init_weights(m):\n        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n            nn.init.xavier_uniform_(m.weight)\n\n    net.apply(init_weights)\n    print('training on', device)\n    net.to(device)\n    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n    loss = nn.CrossEntropyLoss()\n    animator = myutils.Animator(xlabel='epoch', xlim=[1, num_epochs],\n                                legend=['train loss', 'train acc', 'test acc'])\n    timer, num_batches = myutils.Timer(), len(train_iter)\n    for epoch in range(num_epochs):\n        # Sum of training loss, sum of training accuracy, no. of examples\n        metric = myutils.Accumulator(3)\n        net.train()\n        for i, (X, y) in enumerate(train_iter):\n            timer.start()\n            optimizer.zero_grad()\n            X, y = X.to(device), y.to(device)\n            y_hat = net(X)\n            l = loss(y_hat, y)\n            l.backward()\n            optimizer.step()\n            with torch.no_grad():\n                metric.add(l * X.shape[0], myutils.accuracy(y_hat, y), X.shape[0])\n            timer.stop()\n            train_l = metric[0] / metric[2]\n            train_acc = metric[1] / metric[2]\n            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n                animator.add(epoch + (i + 1) / num_batches,\n                             (train_l, train_acc, None))\n        test_acc = evaluate_accuracy_gpu(net, test_iter)\n        animator.add(epoch + 1, (None, None, test_acc))\n    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n          f'test acc {test_acc:.3f}')\n    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '\n          f'on {str(device)}')\n</pre> def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):     \"\"\"Train a model with a GPU (defined in Chapter 6).     Defined in :numref:`sec_utils`\"\"\"      def init_weights(m):         if type(m) == nn.Linear or type(m) == nn.Conv2d:             nn.init.xavier_uniform_(m.weight)      net.apply(init_weights)     print('training on', device)     net.to(device)     optimizer = torch.optim.SGD(net.parameters(), lr=lr)     loss = nn.CrossEntropyLoss()     animator = myutils.Animator(xlabel='epoch', xlim=[1, num_epochs],                                 legend=['train loss', 'train acc', 'test acc'])     timer, num_batches = myutils.Timer(), len(train_iter)     for epoch in range(num_epochs):         # Sum of training loss, sum of training accuracy, no. of examples         metric = myutils.Accumulator(3)         net.train()         for i, (X, y) in enumerate(train_iter):             timer.start()             optimizer.zero_grad()             X, y = X.to(device), y.to(device)             y_hat = net(X)             l = loss(y_hat, y)             l.backward()             optimizer.step()             with torch.no_grad():                 metric.add(l * X.shape[0], myutils.accuracy(y_hat, y), X.shape[0])             timer.stop()             train_l = metric[0] / metric[2]             train_acc = metric[1] / metric[2]             if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:                 animator.add(epoch + (i + 1) / num_batches,                              (train_l, train_acc, None))         test_acc = evaluate_accuracy_gpu(net, test_iter)         animator.add(epoch + 1, (None, None, test_acc))     print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '           f'test acc {test_acc:.3f}')     print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec '           f'on {str(device)}') In\u00a0[\u00a0]: Copied! <pre>def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):\n    \"\"\"Plot a list of images.\n    Defined in :numref:`sec_utils`\"\"\"\n    figsize = (num_cols * scale, num_rows * scale)\n    _, axes = myutils.plt.subplots(num_rows, num_cols, figsize=figsize)\n    axes = axes.flatten()\n    for i, (ax, img) in enumerate(zip(axes, imgs)):\n        try:\n            img = myutils.numpy(img)\n        except:\n            pass\n        ax.imshow(img)\n        ax.axes.get_xaxis().set_visible(False)\n        ax.axes.get_yaxis().set_visible(False)\n        if titles:\n            ax.set_title(titles[i])\n    return axes\n</pre> def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):     \"\"\"Plot a list of images.     Defined in :numref:`sec_utils`\"\"\"     figsize = (num_cols * scale, num_rows * scale)     _, axes = myutils.plt.subplots(num_rows, num_cols, figsize=figsize)     axes = axes.flatten()     for i, (ax, img) in enumerate(zip(axes, imgs)):         try:             img = myutils.numpy(img)         except:             pass         ax.imshow(img)         ax.axes.get_xaxis().set_visible(False)         ax.axes.get_yaxis().set_visible(False)         if titles:             ax.set_title(titles[i])     return axes In\u00a0[\u00a0]: Copied! <pre>def linreg(X, w, b):\n    \"\"\"The linear regression model.\n    Defined in :numref:`sec_utils`\"\"\"\n    return myutils.matmul(X, w) + b\n</pre> def linreg(X, w, b):     \"\"\"The linear regression model.     Defined in :numref:`sec_utils`\"\"\"     return myutils.matmul(X, w) + b In\u00a0[\u00a0]: Copied! <pre>def squared_loss(y_hat, y):\n    \"\"\"Squared loss.\n    Defined in :numref:`sec_utils`\"\"\"\n    return (y_hat - myutils.reshape(y, y_hat.shape)) ** 2 / 2\n</pre> def squared_loss(y_hat, y):     \"\"\"Squared loss.     Defined in :numref:`sec_utils`\"\"\"     return (y_hat - myutils.reshape(y, y_hat.shape)) ** 2 / 2 In\u00a0[\u00a0]: Copied! <pre>def get_fashion_mnist_labels(labels):\n    \"\"\"Return text labels for the Fashion-MNIST dataset.\n    Defined in :numref:`sec_utils`\"\"\"\n    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n    return [text_labels[int(i)] for i in labels]\n</pre> def get_fashion_mnist_labels(labels):     \"\"\"Return text labels for the Fashion-MNIST dataset.     Defined in :numref:`sec_utils`\"\"\"     text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',                    'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']     return [text_labels[int(i)] for i in labels] In\u00a0[\u00a0]: Copied! <pre>class Animator:\n    \"\"\"For plotting data in animation.\"\"\"\n\n    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n                 ylim=None, xscale='linear', yscale='linear',\n                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n                 figsize=(3.5, 2.5)):\n        \"\"\"Defined in :numref:`sec_utils`\"\"\"\n        # Incrementally plot multiple lines\n        if legend is None:\n            legend = []\n        myutils.use_svg_display()\n        self.fig, self.axes = myutils.plt.subplots(nrows, ncols, figsize=figsize)\n        if nrows * ncols == 1:\n            self.axes = [self.axes, ]\n        # Use a lambda function to capture arguments\n        self.config_axes = lambda: myutils.set_axes(\n            self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n        self.X, self.Y, self.fmts = None, None, fmts\n\n    def add(self, x, y):\n        # Add multiple data points into the figure\n        if not hasattr(y, \"__len__\"):\n            y = [y]\n        n = len(y)\n        if not hasattr(x, \"__len__\"):\n            x = [x] * n\n        if not self.X:\n            self.X = [[] for _ in range(n)]\n        if not self.Y:\n            self.Y = [[] for _ in range(n)]\n        for i, (a, b) in enumerate(zip(x, y)):\n            if a is not None and b is not None:\n                self.X[i].append(a)\n                self.Y[i].append(b)\n        self.axes[0].cla()\n        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n            self.axes[0].plot(x, y, fmt)\n        self.config_axes()\n        display.display(self.fig)\n        display.clear_output(wait=True)\n</pre> class Animator:     \"\"\"For plotting data in animation.\"\"\"      def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,                  ylim=None, xscale='linear', yscale='linear',                  fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,                  figsize=(3.5, 2.5)):         \"\"\"Defined in :numref:`sec_utils`\"\"\"         # Incrementally plot multiple lines         if legend is None:             legend = []         myutils.use_svg_display()         self.fig, self.axes = myutils.plt.subplots(nrows, ncols, figsize=figsize)         if nrows * ncols == 1:             self.axes = [self.axes, ]         # Use a lambda function to capture arguments         self.config_axes = lambda: myutils.set_axes(             self.axes[0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)         self.X, self.Y, self.fmts = None, None, fmts      def add(self, x, y):         # Add multiple data points into the figure         if not hasattr(y, \"__len__\"):             y = [y]         n = len(y)         if not hasattr(x, \"__len__\"):             x = [x] * n         if not self.X:             self.X = [[] for _ in range(n)]         if not self.Y:             self.Y = [[] for _ in range(n)]         for i, (a, b) in enumerate(zip(x, y)):             if a is not None and b is not None:                 self.X[i].append(a)                 self.Y[i].append(b)         self.axes[0].cla()         for x, y, fmt in zip(self.X, self.Y, self.fmts):             self.axes[0].plot(x, y, fmt)         self.config_axes()         display.display(self.fig)         display.clear_output(wait=True) In\u00a0[\u00a0]: Copied! <pre>class Accumulator:\n    \"\"\"For accumulating sums over `n` variables.\"\"\"\n\n    def __init__(self, n):\n        \"\"\"Defined in :numref:`sec_utils`\"\"\"\n        self.data = [0.0] * n\n\n    def add(self, *args):\n        self.data = [a + float(b) for a, b in zip(self.data, args)]\n\n    def reset(self):\n        self.data = [0.0] * len(self.data)\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n</pre> class Accumulator:     \"\"\"For accumulating sums over `n` variables.\"\"\"      def __init__(self, n):         \"\"\"Defined in :numref:`sec_utils`\"\"\"         self.data = [0.0] * n      def add(self, *args):         self.data = [a + float(b) for a, b in zip(self.data, args)]      def reset(self):         self.data = [0.0] * len(self.data)      def __getitem__(self, idx):         return self.data[idx] In\u00a0[\u00a0]: Copied! <pre>def accuracy(y_hat, y):\n    \"\"\"Compute the number of correct predictions.\n    Defined in :numref:`sec_utils`\"\"\"\n    if len(y_hat.shape) &gt; 1 and y_hat.shape[1] &gt; 1:\n        y_hat = myutils.argmax(y_hat, axis=1)\n    cmp = myutils.astype(y_hat, y.dtype) == y\n    return float(myutils.reduce_sum(myutils.astype(cmp, y.dtype)))\n</pre> def accuracy(y_hat, y):     \"\"\"Compute the number of correct predictions.     Defined in :numref:`sec_utils`\"\"\"     if len(y_hat.shape) &gt; 1 and y_hat.shape[1] &gt; 1:         y_hat = myutils.argmax(y_hat, axis=1)     cmp = myutils.astype(y_hat, y.dtype) == y     return float(myutils.reduce_sum(myutils.astype(cmp, y.dtype))) In\u00a0[\u00a0]: Copied! <pre>def download(url, folder='./chpdata/data', sha1_hash=None):\n    \"\"\"Download a file to folder and return the local filepath.\n    Defined in :numref:`sec_utils`\"\"\"\n    if not url.startswith('http'):\n        # For back compatability\n        url, sha1_hash = DATA_HUB[url]\n    os.makedirs(folder, exist_ok=True)\n    fname = os.path.join(folder, url.split('/')[-1])\n    # Check if hit cache\n    if os.path.exists(fname) and sha1_hash:\n        sha1 = hashlib.sha1()\n        with open(fname, 'rb') as f:\n            while True:\n                data = f.read(1048576)\n                if not data:\n                    break\n                sha1.update(data)\n        if sha1.hexdigest() == sha1_hash:\n            return fname\n    # Download\n    print(f'Downloading {fname} from {url}...')\n    r = requests.get(url, stream=True, verify=True)\n    with open(fname, 'wb') as f:\n        f.write(r.content)\n    return fname\n</pre> def download(url, folder='./chpdata/data', sha1_hash=None):     \"\"\"Download a file to folder and return the local filepath.     Defined in :numref:`sec_utils`\"\"\"     if not url.startswith('http'):         # For back compatability         url, sha1_hash = DATA_HUB[url]     os.makedirs(folder, exist_ok=True)     fname = os.path.join(folder, url.split('/')[-1])     # Check if hit cache     if os.path.exists(fname) and sha1_hash:         sha1 = hashlib.sha1()         with open(fname, 'rb') as f:             while True:                 data = f.read(1048576)                 if not data:                     break                 sha1.update(data)         if sha1.hexdigest() == sha1_hash:             return fname     # Download     print(f'Downloading {fname} from {url}...')     r = requests.get(url, stream=True, verify=True)     with open(fname, 'wb') as f:         f.write(r.content)     return fname In\u00a0[\u00a0]: Copied! <pre>def extract(filename, folder=None):\n    \"\"\"Extract a zip/tar file into folder.\n    Defined in :numref:`sec_utils`\"\"\"\n    base_dir = os.path.dirname(filename)\n    _, ext = os.path.splitext(filename)\n    assert ext in ('.zip', '.tar', '.gz'), 'Only support zip/tar files.'\n    if ext == '.zip':\n        fp = zipfile.ZipFile(filename, 'r')\n    else:\n        fp = tarfile.open(filename, 'r')\n    if folder is None:\n        folder = base_dir\n    fp.extractall(folder)\n</pre> def extract(filename, folder=None):     \"\"\"Extract a zip/tar file into folder.     Defined in :numref:`sec_utils`\"\"\"     base_dir = os.path.dirname(filename)     _, ext = os.path.splitext(filename)     assert ext in ('.zip', '.tar', '.gz'), 'Only support zip/tar files.'     if ext == '.zip':         fp = zipfile.ZipFile(filename, 'r')     else:         fp = tarfile.open(filename, 'r')     if folder is None:         folder = base_dir     fp.extractall(folder) In\u00a0[\u00a0]: Copied! <pre>def download_extract(name, folder=None):\n    \"\"\"Download and extract a zip/tar file.\n    Defined in :numref:`sec_utils`\"\"\"\n    fname = download(name)\n    base_dir = os.path.dirname(fname)\n    data_dir, ext = os.path.splitext(fname)\n    if ext == '.zip':\n        fp = zipfile.ZipFile(fname, 'r')\n    elif ext in ('.tar', '.gz'):\n        fp = tarfile.open(fname, 'r')\n    else:\n        assert False, 'Only zip/tar files can be extracted.'\n    fp.extractall(base_dir)\n    return os.path.join(base_dir, folder) if folder else data_dir\n</pre> def download_extract(name, folder=None):     \"\"\"Download and extract a zip/tar file.     Defined in :numref:`sec_utils`\"\"\"     fname = download(name)     base_dir = os.path.dirname(fname)     data_dir, ext = os.path.splitext(fname)     if ext == '.zip':         fp = zipfile.ZipFile(fname, 'r')     elif ext in ('.tar', '.gz'):         fp = tarfile.open(fname, 'r')     else:         assert False, 'Only zip/tar files can be extracted.'     fp.extractall(base_dir)     return os.path.join(base_dir, folder) if folder else data_dir In\u00a0[\u00a0]: Copied! <pre>def tokenize(lines, token='word'):\n    \"\"\"Split text lines into word or character tokens.\n    Defined in :numref:`sec_utils`\"\"\"\n    assert token in ('word', 'char'), 'Unknown token type: ' + token\n    return [line.split() if token == 'word' else list(line) for line in lines]\n</pre> def tokenize(lines, token='word'):     \"\"\"Split text lines into word or character tokens.     Defined in :numref:`sec_utils`\"\"\"     assert token in ('word', 'char'), 'Unknown token type: ' + token     return [line.split() if token == 'word' else list(line) for line in lines] In\u00a0[\u00a0]: Copied! <pre>def evaluate_loss(net, data_iter, loss):\n    \"\"\"Evaluate the loss of a model on the given dataset.\n    Defined in :numref:`sec_utils`\"\"\"\n    metric = myutils.Accumulator(2)  # Sum of losses, no. of examples\n    for X, y in data_iter:\n        out = net(X)\n        y = myutils.reshape(y, out.shape)\n        l = loss(out, y)\n        metric.add(myutils.reduce_sum(l), myutils.size(l))\n    return metric[0] / metric[1]\n</pre> def evaluate_loss(net, data_iter, loss):     \"\"\"Evaluate the loss of a model on the given dataset.     Defined in :numref:`sec_utils`\"\"\"     metric = myutils.Accumulator(2)  # Sum of losses, no. of examples     for X, y in data_iter:         out = net(X)         y = myutils.reshape(y, out.shape)         l = loss(out, y)         metric.add(myutils.reduce_sum(l), myutils.size(l))     return metric[0] / metric[1] In\u00a0[\u00a0]: Copied! <pre>def grad_clipping(net, theta):\n    \"\"\"Clip the gradient.\n    Defined in :numref:`sec_utils`\"\"\"\n    if isinstance(net, nn.Module):\n        params = [p for p in net.parameters() if p.requires_grad]\n    else:\n        params = net.params\n    norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n    if norm &gt; theta:\n        for param in params:\n            param.grad[:] *= theta / norm\n</pre> def grad_clipping(net, theta):     \"\"\"Clip the gradient.     Defined in :numref:`sec_utils`\"\"\"     if isinstance(net, nn.Module):         params = [p for p in net.parameters() if p.requires_grad]     else:         params = net.params     norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))     if norm &gt; theta:         for param in params:             param.grad[:] *= theta / norm In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['fra-eng'] = (myutils.DATA_URL + 'fra-eng.zip',\n                               '94646ad1522d915e7b0f9296181140edcf86a4f5')\n</pre> myutils.DATA_HUB['fra-eng'] = (myutils.DATA_URL + 'fra-eng.zip',                                '94646ad1522d915e7b0f9296181140edcf86a4f5') In\u00a0[\u00a0]: Copied! <pre>def read_data_nmt():\n    \"\"\"Load the English-French dataset.\n    Defined in :numref:`sec_utils`\"\"\"\n    data_dir = myutils.download_extract('fra-eng')\n    with open(os.path.join(data_dir, 'fra.txt'), 'r', encoding='utf-8') as f:\n        return f.read()\n</pre> def read_data_nmt():     \"\"\"Load the English-French dataset.     Defined in :numref:`sec_utils`\"\"\"     data_dir = myutils.download_extract('fra-eng')     with open(os.path.join(data_dir, 'fra.txt'), 'r', encoding='utf-8') as f:         return f.read() In\u00a0[\u00a0]: Copied! <pre>def preprocess_nmt(text):\n    \"\"\"Preprocess the English-French dataset.\n    Defined in :numref:`sec_utils`\"\"\"\n\n    def no_space(char, prev_char):\n        return char in set(',.!?') and prev_char != ' '\n\n    # Replace non-breaking space with space, and convert uppercase letters to\n    # lowercase ones\n    text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()\n    # Insert space between words and punctuation marks\n    out = [' ' + char if i &gt; 0 and no_space(char, text[i - 1]) else char\n           for i, char in enumerate(text)]\n    return ''.join(out)\n</pre> def preprocess_nmt(text):     \"\"\"Preprocess the English-French dataset.     Defined in :numref:`sec_utils`\"\"\"      def no_space(char, prev_char):         return char in set(',.!?') and prev_char != ' '      # Replace non-breaking space with space, and convert uppercase letters to     # lowercase ones     text = text.replace('\\u202f', ' ').replace('\\xa0', ' ').lower()     # Insert space between words and punctuation marks     out = [' ' + char if i &gt; 0 and no_space(char, text[i - 1]) else char            for i, char in enumerate(text)]     return ''.join(out) In\u00a0[\u00a0]: Copied! <pre>def tokenize_nmt(text, num_examples=None):\n    \"\"\"Tokenize the English-French dataset.\n    Defined in :numref:`sec_utils`\"\"\"\n    source, target = [], []\n    for i, line in enumerate(text.split('\\n')):\n        if num_examples and i &gt; num_examples:\n            break\n        parts = line.split('\\t')\n        if len(parts) == 2:\n            source.append(parts[0].split(' '))\n            target.append(parts[1].split(' '))\n    return source, target\n</pre> def tokenize_nmt(text, num_examples=None):     \"\"\"Tokenize the English-French dataset.     Defined in :numref:`sec_utils`\"\"\"     source, target = [], []     for i, line in enumerate(text.split('\\n')):         if num_examples and i &gt; num_examples:             break         parts = line.split('\\t')         if len(parts) == 2:             source.append(parts[0].split(' '))             target.append(parts[1].split(' '))     return source, target In\u00a0[\u00a0]: Copied! <pre>def truncate_pad(line, num_steps, padding_token):\n    \"\"\"Truncate or pad sequences.\n    Defined in :numref:`sec_utils`\"\"\"\n    if len(line) &gt; num_steps:\n        return line[:num_steps]  # Truncate\n    return line + [padding_token] * (num_steps - len(line))  # Pad\n</pre> def truncate_pad(line, num_steps, padding_token):     \"\"\"Truncate or pad sequences.     Defined in :numref:`sec_utils`\"\"\"     if len(line) &gt; num_steps:         return line[:num_steps]  # Truncate     return line + [padding_token] * (num_steps - len(line))  # Pad In\u00a0[\u00a0]: Copied! <pre>def build_array_nmt(lines, vocab, num_steps):\n    \"\"\"Transform text sequences of machine translation into minibatches.\n    Defined in :numref:`sec_utils`\"\"\"\n    lines = [vocab[l] for l in lines]\n    lines = [l + [vocab['&lt;eos&gt;']] for l in lines]\n    array = myutils.tensor([truncate_pad(\n        l, num_steps, vocab['&lt;pad&gt;']) for l in lines])\n    valid_len = myutils.reduce_sum(\n        myutils.astype(array != vocab['&lt;pad&gt;'], myutils.int32), 1)\n    return array, valid_len\n</pre> def build_array_nmt(lines, vocab, num_steps):     \"\"\"Transform text sequences of machine translation into minibatches.     Defined in :numref:`sec_utils`\"\"\"     lines = [vocab[l] for l in lines]     lines = [l + [vocab['']] for l in lines]     array = myutils.tensor([truncate_pad(         l, num_steps, vocab['']) for l in lines])     valid_len = myutils.reduce_sum(         myutils.astype(array != vocab[''], myutils.int32), 1)     return array, valid_len In\u00a0[\u00a0]: Copied! <pre>def load_data_nmt(batch_size, num_steps, num_examples=600):\n    \"\"\"Return the iterator and the vocabularies of the translation dataset.\n    Defined in :numref:`sec_utils`\"\"\"\n    text = preprocess_nmt(read_data_nmt())\n    source, target = tokenize_nmt(text, num_examples)\n    src_vocab = myutils.Vocab(source, min_freq=2,\n                              reserved_tokens=['&lt;pad&gt;', '&lt;bos&gt;', '&lt;eos&gt;'])\n    tgt_vocab = myutils.Vocab(target, min_freq=2,\n                              reserved_tokens=['&lt;pad&gt;', '&lt;bos&gt;', '&lt;eos&gt;'])\n    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n    data_iter = myutils.load_array(data_arrays, batch_size)\n    return data_iter, src_vocab, tgt_vocab\n</pre> def load_data_nmt(batch_size, num_steps, num_examples=600):     \"\"\"Return the iterator and the vocabularies of the translation dataset.     Defined in :numref:`sec_utils`\"\"\"     text = preprocess_nmt(read_data_nmt())     source, target = tokenize_nmt(text, num_examples)     src_vocab = myutils.Vocab(source, min_freq=2,                               reserved_tokens=['', '', ''])     tgt_vocab = myutils.Vocab(target, min_freq=2,                               reserved_tokens=['', '', ''])     src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)     tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)     data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)     data_iter = myutils.load_array(data_arrays, batch_size)     return data_iter, src_vocab, tgt_vocab In\u00a0[\u00a0]: Copied! <pre>def sequence_mask(X, valid_len, value=0):\n    \"\"\"Mask irrelevant entries in sequences.\n    Defined in :numref:`sec_utils`\"\"\"\n    maxlen = X.size(1)\n    mask = torch.arange((maxlen), dtype=torch.float32,\n                        device=X.device)[None, :] &lt; valid_len[:, None]\n    X[~mask] = value\n    return X\n</pre> def sequence_mask(X, valid_len, value=0):     \"\"\"Mask irrelevant entries in sequences.     Defined in :numref:`sec_utils`\"\"\"     maxlen = X.size(1)     mask = torch.arange((maxlen), dtype=torch.float32,                         device=X.device)[None, :] &lt; valid_len[:, None]     X[~mask] = value     return X In\u00a0[\u00a0]: Copied! <pre>class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n    \"\"\"The softmax cross-entropy loss with masks.\n    Defined in :numref:`sec_utils`\"\"\"\n\n    # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\n    # `label` shape: (`batch_size`, `num_steps`)\n    # `valid_len` shape: (`batch_size`,)\n    def forward(self, pred, label, valid_len):\n        weights = torch.ones_like(label)\n        weights = sequence_mask(weights, valid_len)\n        self.reduction = 'none'\n        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(\n            pred.permute(0, 2, 1), label)\n        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n        return weighted_loss\n</pre> class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):     \"\"\"The softmax cross-entropy loss with masks.     Defined in :numref:`sec_utils`\"\"\"      # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)     # `label` shape: (`batch_size`, `num_steps`)     # `valid_len` shape: (`batch_size`,)     def forward(self, pred, label, valid_len):         weights = torch.ones_like(label)         weights = sequence_mask(weights, valid_len)         self.reduction = 'none'         unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(             pred.permute(0, 2, 1), label)         weighted_loss = (unweighted_loss * weights).mean(dim=1)         return weighted_loss In\u00a0[\u00a0]: Copied! <pre>def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n    \"\"\"Train a model for sequence to sequence.\n    Defined in :numref:`sec_utils`\"\"\"\n\n    def xavier_init_weights(m):\n        if type(m) == nn.Linear:\n            nn.init.xavier_uniform_(m.weight)\n        if type(m) == nn.GRU:\n            for param in m._flat_weights_names:\n                if \"weight\" in param:\n                    nn.init.xavier_uniform_(m._parameters[param])\n\n    net.apply(xavier_init_weights)\n    net.to(device)\n    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n    loss = MaskedSoftmaxCELoss()\n    net.train()\n    animator = myutils.Animator(xlabel='epoch', ylabel='loss',\n                                xlim=[10, num_epochs])\n    for epoch in range(num_epochs):\n        timer = myutils.Timer()\n        metric = myutils.Accumulator(2)  # Sum of training loss, no. of tokens\n        for batch in data_iter:\n            optimizer.zero_grad()\n            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n            bos = torch.tensor([tgt_vocab['&lt;bos&gt;']] * Y.shape[0],\n                               device=device).reshape(-1, 1)\n            dec_input = myutils.concat([bos, Y[:, :-1]], 1)  # Teacher forcing\n            Y_hat = net(X, dec_input, X_valid_len)\n            l = loss(Y_hat, Y, Y_valid_len)\n            l.sum().backward()  # Make the loss scalar for `backward`\n            myutils.grad_clipping(net, 1)\n            num_tokens = Y_valid_len.sum()\n            optimizer.step()\n            with torch.no_grad():\n                metric.add(l.sum(), num_tokens)\n        if (epoch + 1) % 10 == 0:\n            animator.add(epoch + 1, (metric[0] / metric[1],))\n    print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '\n          f'tokens/sec on {str(device)}')\n</pre> def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):     \"\"\"Train a model for sequence to sequence.     Defined in :numref:`sec_utils`\"\"\"      def xavier_init_weights(m):         if type(m) == nn.Linear:             nn.init.xavier_uniform_(m.weight)         if type(m) == nn.GRU:             for param in m._flat_weights_names:                 if \"weight\" in param:                     nn.init.xavier_uniform_(m._parameters[param])      net.apply(xavier_init_weights)     net.to(device)     optimizer = torch.optim.Adam(net.parameters(), lr=lr)     loss = MaskedSoftmaxCELoss()     net.train()     animator = myutils.Animator(xlabel='epoch', ylabel='loss',                                 xlim=[10, num_epochs])     for epoch in range(num_epochs):         timer = myutils.Timer()         metric = myutils.Accumulator(2)  # Sum of training loss, no. of tokens         for batch in data_iter:             optimizer.zero_grad()             X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]             bos = torch.tensor([tgt_vocab['']] * Y.shape[0],                                device=device).reshape(-1, 1)             dec_input = myutils.concat([bos, Y[:, :-1]], 1)  # Teacher forcing             Y_hat = net(X, dec_input, X_valid_len)             l = loss(Y_hat, Y, Y_valid_len)             l.sum().backward()  # Make the loss scalar for `backward`             myutils.grad_clipping(net, 1)             num_tokens = Y_valid_len.sum()             optimizer.step()             with torch.no_grad():                 metric.add(l.sum(), num_tokens)         if (epoch + 1) % 10 == 0:             animator.add(epoch + 1, (metric[0] / metric[1],))     print(f'loss {metric[0] / metric[1]:.3f}, {metric[1] / timer.stop():.1f} '           f'tokens/sec on {str(device)}') In\u00a0[\u00a0]: Copied! <pre>def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,\n                    device, save_attention_weights=False):\n    \"\"\"Predict for sequence to sequence.\n    Defined in :numref:`sec_utils`\"\"\"\n    # Set `net` to eval mode for inference\n    net.eval()\n    src_tokens = src_vocab[src_sentence.lower().split(' ')] + [\n        src_vocab['&lt;eos&gt;']]\n    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n    src_tokens = myutils.truncate_pad(src_tokens, num_steps, src_vocab['&lt;pad&gt;'])\n    # Add the batch axis\n    enc_X = torch.unsqueeze(\n        torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n    enc_outputs = net.encoder(enc_X, enc_valid_len)\n    dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)\n    # Add the batch axis\n    dec_X = torch.unsqueeze(torch.tensor(\n        [tgt_vocab['&lt;bos&gt;']], dtype=torch.long, device=device), dim=0)\n    output_seq, attention_weight_seq = [], []\n    for _ in range(num_steps):\n        Y, dec_state = net.decoder(dec_X, dec_state)\n        # We use the token with the highest prediction likelihood as input\n        # of the decoder at the next time step\n        dec_X = Y.argmax(dim=2)\n        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n        # Save attention weights (to be covered later)\n        if save_attention_weights:\n            attention_weight_seq.append(net.decoder.attention_weights)\n        # Once the end-of-sequence token is predicted, the generation of the\n        # output sequence is complete\n        if pred == tgt_vocab['&lt;eos&gt;']:\n            break\n        output_seq.append(pred)\n    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq\n</pre> def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps,                     device, save_attention_weights=False):     \"\"\"Predict for sequence to sequence.     Defined in :numref:`sec_utils`\"\"\"     # Set `net` to eval mode for inference     net.eval()     src_tokens = src_vocab[src_sentence.lower().split(' ')] + [         src_vocab['']]     enc_valid_len = torch.tensor([len(src_tokens)], device=device)     src_tokens = myutils.truncate_pad(src_tokens, num_steps, src_vocab[''])     # Add the batch axis     enc_X = torch.unsqueeze(         torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)     enc_outputs = net.encoder(enc_X, enc_valid_len)     dec_state = net.decoder.init_state(enc_outputs, enc_valid_len)     # Add the batch axis     dec_X = torch.unsqueeze(torch.tensor(         [tgt_vocab['']], dtype=torch.long, device=device), dim=0)     output_seq, attention_weight_seq = [], []     for _ in range(num_steps):         Y, dec_state = net.decoder(dec_X, dec_state)         # We use the token with the highest prediction likelihood as input         # of the decoder at the next time step         dec_X = Y.argmax(dim=2)         pred = dec_X.squeeze(dim=0).type(torch.int32).item()         # Save attention weights (to be covered later)         if save_attention_weights:             attention_weight_seq.append(net.decoder.attention_weights)         # Once the end-of-sequence token is predicted, the generation of the         # output sequence is complete         if pred == tgt_vocab['']:             break         output_seq.append(pred)     return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq <p>chapter 8</p> In\u00a0[\u00a0]: Copied! <pre>myutils.DATA_HUB['time_machine'] = (myutils.DATA_URL + 'timemachine.txt',\n                                    '090b5e7e70c295757f55df93cb0a180b9691891a')\n</pre> myutils.DATA_HUB['time_machine'] = (myutils.DATA_URL + 'timemachine.txt',                                     '090b5e7e70c295757f55df93cb0a180b9691891a') In\u00a0[\u00a0]: Copied! <pre>def read_time_machine():\n    \"\"\"\u5c06\u65f6\u95f4\u673a\u5668\u6570\u636e\u96c6\u52a0\u8f7d\u5230\u2f42\u672c\u2f8f\u7684\u5217\u8868\u4e2d\"\"\"\n    with open(myutils.download('time_machine'), 'r') as f:\n        lines = f.readlines()\n    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]\n</pre> def read_time_machine():     \"\"\"\u5c06\u65f6\u95f4\u673a\u5668\u6570\u636e\u96c6\u52a0\u8f7d\u5230\u2f42\u672c\u2f8f\u7684\u5217\u8868\u4e2d\"\"\"     with open(myutils.download('time_machine'), 'r') as f:         lines = f.readlines()     return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines] In\u00a0[\u00a0]: Copied! <pre>def tokenize(lines, token='word'):  # @save\n    if token == 'word':\n        return [line.split() for line in lines]\n    elif token == 'char':\n        return [list(line) for line in lines]\n    else:\n        print('\u9519\u8bef\uff1a\u672a\u77e5\u8bcd\u5143\u7c7b\u578b\uff1a' + token)\n</pre> def tokenize(lines, token='word'):  # @save     if token == 'word':         return [line.split() for line in lines]     elif token == 'char':         return [list(line) for line in lines]     else:         print('\u9519\u8bef\uff1a\u672a\u77e5\u8bcd\u5143\u7c7b\u578b\uff1a' + token) In\u00a0[\u00a0]: Copied! <pre>class Vocab:  # @save\n    \"\"\"\u2f42\u672c\u8bcd\u8868\"\"\"\n\n    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):\n        if tokens is None:\n            tokens = []\n        if reserved_tokens is None:\n            reserved_tokens = []\n\n        # \u6309\u51fa\u73b0\u9891\u7387\u6392\u5e8f\n        counter = count_corpus(tokens)\n        self._token_freqs = sorted(counter.items(), key=lambda x: x[1],\n                                   reverse=True)\n        # \u672a\u77e5\u8bcd\u5143\u7684\u7d22\u5f15\u4e3a0\n        self.idx_to_token = ['&lt;unk&gt;'] + reserved_tokens\n        self.token_to_idx = {token: idx\n                             for idx, token in enumerate(self.idx_to_token)}\n\n        for token, freq in self._token_freqs:\n            if freq &lt; min_freq:\n                break\n            if token not in self.token_to_idx:\n                self.idx_to_token.append(token)\n                self.token_to_idx[token] = len(self.idx_to_token) - 1\n\n    def __len__(self):\n        return len(self.idx_to_token)\n\n    def __getitem__(self, tokens):\n        if not isinstance(tokens, (list, tuple)):\n            return self.token_to_idx.get(tokens, self.unk)\n        return [self.__getitem__(token) for token in tokens]\n\n    def to_tokens(self, indices):\n        if not isinstance(indices, (list, tuple)):\n            return self.idx_to_token[indices]\n        return [self.idx_to_token[index] for index in indices]\n\n    @property\n    def unk(self):  # \u672a\u77e5\u8bcd\u5143\u7684\u7d22\u5f15\u4e3a0\n        return 0\n\n    @property\n    def token_freqs(self):\n        return self._token_freqs\n</pre> class Vocab:  # @save     \"\"\"\u2f42\u672c\u8bcd\u8868\"\"\"      def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):         if tokens is None:             tokens = []         if reserved_tokens is None:             reserved_tokens = []          # \u6309\u51fa\u73b0\u9891\u7387\u6392\u5e8f         counter = count_corpus(tokens)         self._token_freqs = sorted(counter.items(), key=lambda x: x[1],                                    reverse=True)         # \u672a\u77e5\u8bcd\u5143\u7684\u7d22\u5f15\u4e3a0         self.idx_to_token = [''] + reserved_tokens         self.token_to_idx = {token: idx                              for idx, token in enumerate(self.idx_to_token)}          for token, freq in self._token_freqs:             if freq &lt; min_freq:                 break             if token not in self.token_to_idx:                 self.idx_to_token.append(token)                 self.token_to_idx[token] = len(self.idx_to_token) - 1      def __len__(self):         return len(self.idx_to_token)      def __getitem__(self, tokens):         if not isinstance(tokens, (list, tuple)):             return self.token_to_idx.get(tokens, self.unk)         return [self.__getitem__(token) for token in tokens]      def to_tokens(self, indices):         if not isinstance(indices, (list, tuple)):             return self.idx_to_token[indices]         return [self.idx_to_token[index] for index in indices]      @property     def unk(self):  # \u672a\u77e5\u8bcd\u5143\u7684\u7d22\u5f15\u4e3a0         return 0      @property     def token_freqs(self):         return self._token_freqs In\u00a0[\u00a0]: Copied! <pre>def count_corpus(tokens):  # @save\n    \"\"\"\u7edf\u8ba1\u8bcd\u5143\u7684\u9891\u7387\"\"\"\n    # \u8fd9\u2fa5\u7684tokens\u662f1D\u5217\u8868\u62162D\u5217\u8868\n    if len(tokens) == 0 or isinstance(tokens[0], list):\n        # \u5c06\u8bcd\u5143\u5217\u8868\u5c55\u5e73\u6210\u2f00\u4e2a\u5217\u8868\n        tokens = [token for line in tokens for token in line]\n    return collections.Counter(tokens)\n</pre> def count_corpus(tokens):  # @save     \"\"\"\u7edf\u8ba1\u8bcd\u5143\u7684\u9891\u7387\"\"\"     # \u8fd9\u2fa5\u7684tokens\u662f1D\u5217\u8868\u62162D\u5217\u8868     if len(tokens) == 0 or isinstance(tokens[0], list):         # \u5c06\u8bcd\u5143\u5217\u8868\u5c55\u5e73\u6210\u2f00\u4e2a\u5217\u8868         tokens = [token for line in tokens for token in line]     return collections.Counter(tokens) In\u00a0[\u00a0]: Copied! <pre>def load_corpus_time_machine(max_tokens=-1):  # @save\n    \"\"\"\u8fd4\u56de\u65f6\u5149\u673a\u5668\u6570\u636e\u96c6\u7684\u8bcd\u5143\u7d22\u5f15\u5217\u8868\u548c\u8bcd\u8868\"\"\"\n    lines = read_time_machine()\n    tokens = tokenize(lines, 'char')\n    vocab = Vocab(tokens)\n    # \u56e0\u4e3a\u65f6\u5149\u673a\u5668\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e2a\u2f42\u672c\u2f8f\u4e0d\u2f00\u5b9a\u662f\u2f00\u4e2a\u53e5\u2f26\u6216\u2f00\u4e2a\u6bb5\u843d\uff0c\n    # \u6240\u4ee5\u5c06\u6240\u6709\u2f42\u672c\u2f8f\u5c55\u5e73\u5230\u2f00\u4e2a\u5217\u8868\u4e2d\n    corpus = [vocab[token] for line in tokens for token in line]\n    if max_tokens &gt; 0:\n        corpus = corpus[:max_tokens]\n    return corpus, vocab\n</pre> def load_corpus_time_machine(max_tokens=-1):  # @save     \"\"\"\u8fd4\u56de\u65f6\u5149\u673a\u5668\u6570\u636e\u96c6\u7684\u8bcd\u5143\u7d22\u5f15\u5217\u8868\u548c\u8bcd\u8868\"\"\"     lines = read_time_machine()     tokens = tokenize(lines, 'char')     vocab = Vocab(tokens)     # \u56e0\u4e3a\u65f6\u5149\u673a\u5668\u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e2a\u2f42\u672c\u2f8f\u4e0d\u2f00\u5b9a\u662f\u2f00\u4e2a\u53e5\u2f26\u6216\u2f00\u4e2a\u6bb5\u843d\uff0c     # \u6240\u4ee5\u5c06\u6240\u6709\u2f42\u672c\u2f8f\u5c55\u5e73\u5230\u2f00\u4e2a\u5217\u8868\u4e2d     corpus = [vocab[token] for line in tokens for token in line]     if max_tokens &gt; 0:         corpus = corpus[:max_tokens]     return corpus, vocab In\u00a0[\u00a0]: Copied! <pre>def seq_data_iter_random(corpus, batch_size, num_steps):  # @save\n    \"\"\"\u4f7f\u2f64\u968f\u673a\u62bd\u6837\u2f63\u6210\u2f00\u4e2a\u2f29\u6279\u91cf\u2f26\u5e8f\u5217\"\"\"\n    # \u4ece\u968f\u673a\u504f\u79fb\u91cf\u5f00\u59cb\u5bf9\u5e8f\u5217\u8fdb\u2f8f\u5206\u533a\uff0c\u968f\u673a\u8303\u56f4\u5305\u62ecnum_steps-1\n    corpus = corpus[random.randint(0, num_steps - 1):]\n    # \u51cf\u53bb1\uff0c\u662f\u56e0\u4e3a\u6211\u4eec\u9700\u8981\u8003\u8651\u6807\u7b7e\n    num_subseqs = (len(corpus) - 1) // num_steps\n    # \u2ed3\u5ea6\u4e3anum_steps\u7684\u2f26\u5e8f\u5217\u7684\u8d77\u59cb\u7d22\u5f15\n    initial_indices = list(range(0, num_subseqs * num_steps, num_steps))\n    # \u5728\u968f\u673a\u62bd\u6837\u7684\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\uff0c\n    # \u6765\u2f83\u4e24\u4e2a\u76f8\u90bb\u7684\u3001\u968f\u673a\u7684\u3001\u2f29\u6279\u91cf\u4e2d\u7684\u2f26\u5e8f\u5217\u4e0d\u2f00\u5b9a\u5728\u539f\u59cb\u5e8f\u5217\u4e0a\u76f8\u90bb\n    random.shuffle(initial_indices)\n\n    def data(pos):\n        # \u8fd4\u56de\u4ecepos\u4f4d\u7f6e\u5f00\u59cb\u7684\u2ed3\u5ea6\u4e3anum_steps\u7684\u5e8f\u5217\n        return corpus[pos: pos + num_steps]\n\n    num_batches = num_subseqs // batch_size\n    for i in range(0, batch_size * num_batches, batch_size):\n        # \u5728\u8fd9\u2fa5\uff0cinitial_indices\u5305\u542b\u2f26\u5e8f\u5217\u7684\u968f\u673a\u8d77\u59cb\u7d22\u5f15\n        initial_indices_per_batch = initial_indices[i: i + batch_size]\n        X = [data(j) for j in initial_indices_per_batch]\n        Y = [data(j + 1) for j in initial_indices_per_batch]\n        yield torch.tensor(X), torch.tensor(Y)\n</pre> def seq_data_iter_random(corpus, batch_size, num_steps):  # @save     \"\"\"\u4f7f\u2f64\u968f\u673a\u62bd\u6837\u2f63\u6210\u2f00\u4e2a\u2f29\u6279\u91cf\u2f26\u5e8f\u5217\"\"\"     # \u4ece\u968f\u673a\u504f\u79fb\u91cf\u5f00\u59cb\u5bf9\u5e8f\u5217\u8fdb\u2f8f\u5206\u533a\uff0c\u968f\u673a\u8303\u56f4\u5305\u62ecnum_steps-1     corpus = corpus[random.randint(0, num_steps - 1):]     # \u51cf\u53bb1\uff0c\u662f\u56e0\u4e3a\u6211\u4eec\u9700\u8981\u8003\u8651\u6807\u7b7e     num_subseqs = (len(corpus) - 1) // num_steps     # \u2ed3\u5ea6\u4e3anum_steps\u7684\u2f26\u5e8f\u5217\u7684\u8d77\u59cb\u7d22\u5f15     initial_indices = list(range(0, num_subseqs * num_steps, num_steps))     # \u5728\u968f\u673a\u62bd\u6837\u7684\u8fed\u4ee3\u8fc7\u7a0b\u4e2d\uff0c     # \u6765\u2f83\u4e24\u4e2a\u76f8\u90bb\u7684\u3001\u968f\u673a\u7684\u3001\u2f29\u6279\u91cf\u4e2d\u7684\u2f26\u5e8f\u5217\u4e0d\u2f00\u5b9a\u5728\u539f\u59cb\u5e8f\u5217\u4e0a\u76f8\u90bb     random.shuffle(initial_indices)      def data(pos):         # \u8fd4\u56de\u4ecepos\u4f4d\u7f6e\u5f00\u59cb\u7684\u2ed3\u5ea6\u4e3anum_steps\u7684\u5e8f\u5217         return corpus[pos: pos + num_steps]      num_batches = num_subseqs // batch_size     for i in range(0, batch_size * num_batches, batch_size):         # \u5728\u8fd9\u2fa5\uff0cinitial_indices\u5305\u542b\u2f26\u5e8f\u5217\u7684\u968f\u673a\u8d77\u59cb\u7d22\u5f15         initial_indices_per_batch = initial_indices[i: i + batch_size]         X = [data(j) for j in initial_indices_per_batch]         Y = [data(j + 1) for j in initial_indices_per_batch]         yield torch.tensor(X), torch.tensor(Y) In\u00a0[\u00a0]: Copied! <pre>def seq_data_iter_sequential(corpus, batch_size, num_steps):  # @save\n    \"\"\"\u4f7f\u2f64\u987a\u5e8f\u5206\u533a\u2f63\u6210\u2f00\u4e2a\u2f29\u6279\u91cf\u2f26\u5e8f\u5217\"\"\"\n    # \u4ece\u968f\u673a\u504f\u79fb\u91cf\u5f00\u59cb\u5212\u5206\u5e8f\u5217\n    offset = random.randint(0, num_steps)\n    num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size\n    Xs = torch.tensor(corpus[offset: offset + num_tokens])\n    Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])\n    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n\n    num_batches = Xs.shape[1] // num_steps\n    for i in range(0, num_steps * num_batches, num_steps):\n        X = Xs[:, i: i + num_steps]\n        Y = Ys[:, i: i + num_steps]\n        yield X, Y\n</pre> def seq_data_iter_sequential(corpus, batch_size, num_steps):  # @save     \"\"\"\u4f7f\u2f64\u987a\u5e8f\u5206\u533a\u2f63\u6210\u2f00\u4e2a\u2f29\u6279\u91cf\u2f26\u5e8f\u5217\"\"\"     # \u4ece\u968f\u673a\u504f\u79fb\u91cf\u5f00\u59cb\u5212\u5206\u5e8f\u5217     offset = random.randint(0, num_steps)     num_tokens = ((len(corpus) - offset - 1) // batch_size) * batch_size     Xs = torch.tensor(corpus[offset: offset + num_tokens])     Ys = torch.tensor(corpus[offset + 1: offset + 1 + num_tokens])     Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)      num_batches = Xs.shape[1] // num_steps     for i in range(0, num_steps * num_batches, num_steps):         X = Xs[:, i: i + num_steps]         Y = Ys[:, i: i + num_steps]         yield X, Y In\u00a0[\u00a0]: Copied! <pre>class SeqDataLoader:  # @save\n    \"\"\"\u52a0\u8f7d\u5e8f\u5217\u6570\u636e\u7684\u8fed\u4ee3\u5668\"\"\"\n\n    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):\n        if use_random_iter:\n            self.data_iter_fn = myutils.seq_data_iter_random\n        else:\n            self.data_iter_fn = myutils.seq_data_iter_sequential\n        self.corpus, self.vocab = myutils.load_corpus_time_machine(max_tokens)\n        self.batch_size, self.num_steps = batch_size, num_steps\n\n    def __iter__(self):\n        return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps)\n</pre> class SeqDataLoader:  # @save     \"\"\"\u52a0\u8f7d\u5e8f\u5217\u6570\u636e\u7684\u8fed\u4ee3\u5668\"\"\"      def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):         if use_random_iter:             self.data_iter_fn = myutils.seq_data_iter_random         else:             self.data_iter_fn = myutils.seq_data_iter_sequential         self.corpus, self.vocab = myutils.load_corpus_time_machine(max_tokens)         self.batch_size, self.num_steps = batch_size, num_steps      def __iter__(self):         return self.data_iter_fn(self.corpus, self.batch_size, self.num_steps) In\u00a0[\u00a0]: Copied! <pre>def load_data_time_machine(batch_size, num_steps, use_random_iter=False, max_tokens=10000):\n    \"\"\"\u8fd4\u56de\u65f6\u5149\u673a\u5668\u6570\u636e\u96c6\u7684\u8fed\u4ee3\u5668\u548c\u8bcd\u8868\"\"\"\n    data_iter = SeqDataLoader(\n        batch_size, num_steps, use_random_iter, max_tokens)\n    return data_iter, data_iter.vocab\n</pre> def load_data_time_machine(batch_size, num_steps, use_random_iter=False, max_tokens=10000):     \"\"\"\u8fd4\u56de\u65f6\u5149\u673a\u5668\u6570\u636e\u96c6\u7684\u8fed\u4ee3\u5668\u548c\u8bcd\u8868\"\"\"     data_iter = SeqDataLoader(         batch_size, num_steps, use_random_iter, max_tokens)     return data_iter, data_iter.vocab In\u00a0[\u00a0]: Copied! <pre># Alias defined in config.ini\nnn_Module = nn.Module\n</pre> # Alias defined in config.ini nn_Module = nn.Module In\u00a0[\u00a0]: Copied! <pre>ones_like = torch.ones_like\nones = torch.ones\nzeros_like = torch.zeros_like\nzeros = torch.zeros\ntensor = torch.tensor\narange = torch.arange\nmeshgrid = torch.meshgrid\nsin = torch.sin\nsinh = torch.sinh\ncos = torch.cos\ncosh = torch.cosh\ntanh = torch.tanh\nlinspace = torch.linspace\nexp = torch.exp\nlog = torch.log\nnormal = torch.normal\nrand = torch.rand\nrandn = torch.randn\nmatmul = torch.matmul\nint32 = torch.int32\nint64 = torch.int64\nfloat32 = torch.float32\nconcat = torch.cat\nstack = torch.stack\nabs = torch.abs\neye = torch.eye\nsigmoid = torch.sigmoid\nbatch_matmul = torch.bmm\nnumpy = lambda x, *args, **kwargs: x.detach().numpy(*args, **kwargs)\nsize = lambda x, *args, **kwargs: x.numel(*args, **kwargs)\nreshape = lambda x, *args, **kwargs: x.reshape(*args, **kwargs)\nto = lambda x, *args, **kwargs: x.to(*args, **kwargs)\nreduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs)\nargmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs)\nastype = lambda x, *args, **kwargs: x.type(*args, **kwargs)\ntranspose = lambda x, *args, **kwargs: x.t(*args, **kwargs)\nreduce_mean = lambda x, *args, **kwargs: x.mean(*args, **kwargs)\nexpand_dims = lambda x, *args, **kwargs: x.unsqueeze(*args, **kwargs)\nswapaxes = lambda x, *args, **kwargs: x.swapaxes(*args, **kwargs)\nrepeat = lambda x, *args, **kwargs: x.repeat(*args, **kwargs)\n</pre> ones_like = torch.ones_like ones = torch.ones zeros_like = torch.zeros_like zeros = torch.zeros tensor = torch.tensor arange = torch.arange meshgrid = torch.meshgrid sin = torch.sin sinh = torch.sinh cos = torch.cos cosh = torch.cosh tanh = torch.tanh linspace = torch.linspace exp = torch.exp log = torch.log normal = torch.normal rand = torch.rand randn = torch.randn matmul = torch.matmul int32 = torch.int32 int64 = torch.int64 float32 = torch.float32 concat = torch.cat stack = torch.stack abs = torch.abs eye = torch.eye sigmoid = torch.sigmoid batch_matmul = torch.bmm numpy = lambda x, *args, **kwargs: x.detach().numpy(*args, **kwargs) size = lambda x, *args, **kwargs: x.numel(*args, **kwargs) reshape = lambda x, *args, **kwargs: x.reshape(*args, **kwargs) to = lambda x, *args, **kwargs: x.to(*args, **kwargs) reduce_sum = lambda x, *args, **kwargs: x.sum(*args, **kwargs) argmax = lambda x, *args, **kwargs: x.argmax(*args, **kwargs) astype = lambda x, *args, **kwargs: x.type(*args, **kwargs) transpose = lambda x, *args, **kwargs: x.t(*args, **kwargs) reduce_mean = lambda x, *args, **kwargs: x.mean(*args, **kwargs) expand_dims = lambda x, *args, **kwargs: x.unsqueeze(*args, **kwargs) swapaxes = lambda x, *args, **kwargs: x.swapaxes(*args, **kwargs) repeat = lambda x, *args, **kwargs: x.repeat(*args, **kwargs)"},{"location":"markdown/knowledge/deep_learning_notebook/pytorch_basic/","title":"Pytorch Notes: Overview","text":"In\u00a0[2]: Copied! <pre># =============================\n# import some libraries\n# make sure to install all potential required libraries\n# =============================\nimport collections\n# import hashlib\nimport math\nimport os\nimport random\nimport re\n# import shutil\nimport sys\nimport tarfile\nimport time\nimport zipfile\nfrom collections import defaultdict\nimport pandas as pd\nimport requests\nfrom IPython import display\nfrom matplotlib import pyplot as plt\n# from matplotlib_inline import backend_inline\nimport myutils\n</pre> # ============================= # import some libraries # make sure to install all potential required libraries # ============================= import collections # import hashlib import math import os import random import re # import shutil import sys import tarfile import time import zipfile from collections import defaultdict import pandas as pd import requests from IPython import display from matplotlib import pyplot as plt # from matplotlib_inline import backend_inline import myutils In\u00a0[3]: Copied! <pre># two important libraries\nimport numpy as np\nimport torch\n</pre> # two important libraries import numpy as np import torch In\u00a0[4]: Copied! <pre># some support libraries and modules for neural nerwork implementation\nimport torchvision\nfrom PIL import Image\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils import data\nfrom torchvision import transforms\n</pre> # some support libraries and modules for neural nerwork implementation import torchvision from PIL import Image from torch import nn from torch.nn import functional as F from torch.utils import data from torchvision import transforms In\u00a0[5]: Copied! <pre># resolve an issue in plotting the figure\n# you may not need this\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n</pre> # resolve an issue in plotting the figure # you may not need this os.environ['KMP_DUPLICATE_LIB_OK'] = 'True' In\u00a0[6]: Copied! <pre># a convention to start a new programming language\nprint(\"Hello World!\")\n</pre> # a convention to start a new programming language print(\"Hello World!\") <pre>Hello World!\n</pre> In\u00a0[9]: Copied! <pre># create a torch tensor\nn = 12\nx = torch.arange(n)\nprint(x)\n# get its shape and length\nprint(x.shape)\nprint(x.numel())\n</pre> # create a torch tensor n = 12 x = torch.arange(n) print(x) # get its shape and length print(x.shape) print(x.numel()) <pre>tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\ntorch.Size([12])\n12\n</pre> In\u00a0[10]: Copied! <pre># reshape the tensor\nX = x.reshape(6,2)\nprint(X)\nX = x.view(4,3)\nprint(X)\n</pre> # reshape the tensor X = x.reshape(6,2) print(X) X = x.view(4,3) print(X) <pre>tensor([[ 0,  1],\n        [ 2,  3],\n        [ 4,  5],\n        [ 6,  7],\n        [ 8,  9],\n        [10, 11]])\ntensor([[ 0,  1,  2],\n        [ 3,  4,  5],\n        [ 6,  7,  8],\n        [ 9, 10, 11]])\n</pre> In\u00a0[11]: Copied! <pre># create a zero tensor\ntorch.zeros((2, 3, 4))\n</pre> # create a zero tensor torch.zeros((2, 3, 4)) Out[11]: <pre>tensor([[[0., 0., 0., 0.],\n         [0., 0., 0., 0.],\n         [0., 0., 0., 0.]],\n\n        [[0., 0., 0., 0.],\n         [0., 0., 0., 0.],\n         [0., 0., 0., 0.]]])</pre> In\u00a0[12]: Copied! <pre># create an all-one tensor\ntorch.ones((2, 3, 4))\n</pre> # create an all-one tensor torch.ones((2, 3, 4)) Out[12]: <pre>tensor([[[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]],\n\n        [[1., 1., 1., 1.],\n         [1., 1., 1., 1.],\n         [1., 1., 1., 1.]]])</pre> In\u00a0[17]: Copied! <pre># create a random (normally distributed) tensor\ntorch.randn(3,4)\n# torch.randn(3,4)   uniformly random tensor\n</pre> # create a random (normally distributed) tensor torch.randn(3,4) # torch.randn(3,4)   uniformly random tensor Out[17]: <pre>tensor([[ 0.7679,  0.4737,  0.2935, -2.7588],\n        [-0.1369, -1.2027,  2.0478,  1.2149],\n        [-0.7671, -0.2859, -0.8393,  0.1257]])</pre> In\u00a0[18]: Copied! <pre># convert a list to torch tensor\ntorch.tensor([[2,1,4,3], [1,2,3,4], [4,3,2,1]], dtype = torch.int64)\n</pre> # convert a list to torch tensor torch.tensor([[2,1,4,3], [1,2,3,4], [4,3,2,1]], dtype = torch.int64) Out[18]: <pre>tensor([[2, 1, 4, 3],\n        [1, 2, 3, 4],\n        [4, 3, 2, 1]])</pre> In\u00a0[19]: Copied! <pre># element-wise operations for pytorch tensor\nx = torch.tensor([1.0, 2, 4, 8])\ny = torch.tensor([2, 2, 2 ,2])\nx + y, x - y, x * y, x / y, x ** y\ntorch.exp(x)\n</pre> # element-wise operations for pytorch tensor x = torch.tensor([1.0, 2, 4, 8]) y = torch.tensor([2, 2, 2 ,2]) x + y, x - y, x * y, x / y, x ** y torch.exp(x) Out[19]: <pre>tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])</pre> In\u00a0[20]: Copied! <pre># concatenation of two tensors\nX = torch.arange(12, dtype=torch.float32).reshape((3,4))\nY = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\ntorch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)\n</pre> # concatenation of two tensors X = torch.arange(12, dtype=torch.float32).reshape((3,4)) Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]]) torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1) Out[20]: <pre>(tensor([[ 0.,  1.,  2.,  3.],\n         [ 4.,  5.,  6.,  7.],\n         [ 8.,  9., 10., 11.],\n         [ 2.,  1.,  4.,  3.],\n         [ 1.,  2.,  3.,  4.],\n         [ 4.,  3.,  2.,  1.]]),\n tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))</pre> In\u00a0[21]: Copied! <pre># change the tensor's data type\nX.to(torch.float64)\n</pre> # change the tensor's data type X.to(torch.float64) Out[21]: <pre>tensor([[ 0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.]], dtype=torch.float64)</pre> In\u00a0[22]: Copied! <pre># element-wise logic operation\nX == Y\n</pre> # element-wise logic operation X == Y Out[22]: <pre>tensor([[False,  True, False,  True],\n        [False, False, False, False],\n        [False, False, False, False]])</pre> In\u00a0[23]: Copied! <pre># aggregation \nprint(X.sum())\nprint(torch.sum(X))\n</pre> # aggregation  print(X.sum()) print(torch.sum(X)) <pre>tensor(66.)\ntensor(66.)\n</pre> In\u00a0[24]: Copied! <pre># add with different shape\na = torch.arange(3).reshape((3, 1))\nb = torch.arange(2).reshape((1, 2)) + 1\na, b, a + b\n</pre> # add with different shape a = torch.arange(3).reshape((3, 1)) b = torch.arange(2).reshape((1, 2)) + 1 a, b, a + b Out[24]: <pre>(tensor([[0],\n         [1],\n         [2]]),\n tensor([[1, 2]]),\n tensor([[1, 2],\n         [2, 3],\n         [3, 4]]))</pre> In\u00a0[25]: Copied! <pre># indexing of torch tensor\nX[-1], X[1:3,]\n</pre> # indexing of torch tensor X[-1], X[1:3,] Out[25]: <pre>(tensor([ 8.,  9., 10., 11.]),\n tensor([[ 4.,  5.,  6.,  7.],\n         [ 8.,  9., 10., 11.]]))</pre> In\u00a0[22]: Copied! <pre># change the element of torch tensor\nX[1, 2] = 9\nprint(X)\n\nX[0: 2, :] = 12\nprint(X)\n</pre> # change the element of torch tensor X[1, 2] = 9 print(X)  X[0: 2, :] = 12 print(X) <pre>tensor([[12, 12, 12],\n        [12, 12,  9],\n        [ 6,  7,  8],\n        [ 9, 10, 11]])\ntensor([[12, 12, 12],\n        [12, 12, 12],\n        [ 6,  7,  8],\n        [ 9, 10, 11]])\n</pre> In\u00a0[25]: Copied! <pre># saving memory\n# in-place operation\nbefore = id(Y)\n# \u65b0\u5f00\u8f9f\u7a7a\u95f4\u5b58\u653e\u5de6\u8fb9\u65b0\u8d4b\u503c\u7684Y\nY = Y + X\nid(Y) == before\n# Memory id changes!\n</pre> # saving memory # in-place operation before = id(Y) # \u65b0\u5f00\u8f9f\u7a7a\u95f4\u5b58\u653e\u5de6\u8fb9\u65b0\u8d4b\u503c\u7684Y Y = Y + X id(Y) == before # Memory id changes! Out[25]: <pre>False</pre> In\u00a0[48]: Copied! <pre>before = id(Y)\n# \u65b0\u7684Y\u5b58\u653e\u7a7a\u95f4\u8986\u76d6\u539f\u6765\u7684Y\nY += X\nid(Y) == before\n# Memory id does not change!\n</pre> before = id(Y) # \u65b0\u7684Y\u5b58\u653e\u7a7a\u95f4\u8986\u76d6\u539f\u6765\u7684Y Y += X id(Y) == before # Memory id does not change! Out[48]: <pre>True</pre> In\u00a0[26]: Copied! <pre># change type, numpy array to torch tensor\nA = X.numpy()\nB = torch.tensor(A)\ntype(A), type(B)\n</pre> # change type, numpy array to torch tensor A = X.numpy() B = torch.tensor(A) type(A), type(B) Out[26]: <pre>(numpy.ndarray, torch.Tensor)</pre> In\u00a0[27]: Copied! <pre># get scalar, tensor to value\na = torch.tensor([5.5])\nprint(a.dtype)\na, a.item(), float(a), int(a), a.numel()\n</pre> # get scalar, tensor to value a = torch.tensor([5.5]) print(a.dtype) a, a.item(), float(a), int(a), a.numel() <pre>torch.float32\n</pre> Out[27]: <pre>(tensor([5.5000]), 5.5, 5.5, 5, 1)</pre> In\u00a0[28]: Copied! <pre># create a directory\nos.makedirs(\"./chpdata\", exist_ok = True)\n</pre> # create a directory os.makedirs(\"./chpdata\", exist_ok = True) In\u00a0[29]: Copied! <pre># create a csv file\ndata_file = './chpdata/house_tiny.csv'\nwith open(data_file, 'w') as f:\n    f.write('NumRooms,Alley,Price\\n') # \u5217\u540d\n    f.write('NA,Pave,127500\\n') # \u6bcf\u2f8f\u8868\u2f70\u2f00\u4e2a\u6570\u636e\u6837\u672c\n    f.write('2,NA,106000\\n')\n    f.write('4,NA,178100\\n')\n    f.write('NA,NA,140000\\n')\n</pre> # create a csv file data_file = './chpdata/house_tiny.csv' with open(data_file, 'w') as f:     f.write('NumRooms,Alley,Price\\n') # \u5217\u540d     f.write('NA,Pave,127500\\n') # \u6bcf\u2f8f\u8868\u2f70\u2f00\u4e2a\u6570\u636e\u6837\u672c     f.write('2,NA,106000\\n')     f.write('4,NA,178100\\n')     f.write('NA,NA,140000\\n') In\u00a0[30]: Copied! <pre># read csv file through pandas library\ndata = pd.read_csv(data_file)\nprint(data)\n</pre> # read csv file through pandas library data = pd.read_csv(data_file) print(data) <pre>   NumRooms Alley   Price\n0       NaN  Pave  127500\n1       2.0   NaN  106000\n2       4.0   NaN  178100\n3       NaN   NaN  140000\n</pre> In\u00a0[31]: Copied! <pre># deal with NaN\ninputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\ninputs = inputs.fillna(inputs.mean())\nprint(inputs)\n</pre> # deal with NaN inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2] inputs = inputs.fillna(inputs.mean()) print(inputs) <pre>   NumRooms Alley\n0       3.0  Pave\n1       2.0   NaN\n2       4.0   NaN\n3       3.0   NaN\n</pre> In\u00a0[32]: Copied! <pre># make NaN to dummy variables\ninputs = pd.get_dummies(inputs, dummy_na=True)\nprint(inputs)\n</pre> # make NaN to dummy variables inputs = pd.get_dummies(inputs, dummy_na=True) print(inputs) <pre>   NumRooms  Alley_Pave  Alley_nan\n0       3.0           1          0\n1       2.0           0          1\n2       4.0           0          1\n3       3.0           0          1\n</pre> In\u00a0[33]: Copied! <pre>X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\nX, y\n</pre> X, y = torch.tensor(inputs.values), torch.tensor(outputs.values) X, y Out[33]: <pre>(tensor([[3., 1., 0.],\n         [2., 0., 1.],\n         [4., 0., 1.],\n         [3., 0., 1.]], dtype=torch.float64),\n tensor([127500, 106000, 178100, 140000]))</pre> In\u00a0[50]: Copied! <pre>x = torch.tensor(3.0)\ny = torch.tensor(2.0)\nx + y, x * y, x / y, x**y\n</pre> x = torch.tensor(3.0) y = torch.tensor(2.0) x + y, x * y, x / y, x**y Out[50]: <pre>(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))</pre> In\u00a0[51]: Copied! <pre># vector\nx = torch.arange(4)\nx, len(x), x.shape\n</pre> # vector x = torch.arange(4) x, len(x), x.shape Out[51]: <pre>(tensor([0, 1, 2, 3]), 4, torch.Size([4]))</pre> In\u00a0[29]: Copied! <pre># create a matrix\nA = torch.arange(20).reshape(5, 4)\nA\n</pre> # create a matrix A = torch.arange(20).reshape(5, 4) A Out[29]: <pre>tensor([[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11],\n        [12, 13, 14, 15],\n        [16, 17, 18, 19]])</pre> In\u00a0[33]: Copied! <pre>np.exp(1) / (np.exp(1) + np.exp(2) + np.exp(3) + np.exp(4))\n</pre> np.exp(1) / (np.exp(1) + np.exp(2) + np.exp(3) + np.exp(4)) Out[33]: <pre>0.03205860328008499</pre> In\u00a0[30]: Copied! <pre># get familiar with softmax function\ntorch.softmax(A.float(), dim=1)\n</pre> # get familiar with softmax function torch.softmax(A.float(), dim=1) Out[30]: <pre>tensor([[0.0321, 0.0871, 0.2369, 0.6439],\n        [0.0321, 0.0871, 0.2369, 0.6439],\n        [0.0321, 0.0871, 0.2369, 0.6439],\n        [0.0321, 0.0871, 0.2369, 0.6439],\n        [0.0321, 0.0871, 0.2369, 0.6439]])</pre> In\u00a0[54]: Copied! <pre># transpose A\nA.T\n</pre> # transpose A A.T Out[54]: <pre>tensor([[ 0,  4,  8, 12, 16],\n        [ 1,  5,  9, 13, 17],\n        [ 2,  6, 10, 14, 18],\n        [ 3,  7, 11, 15, 19]])</pre> In\u00a0[35]: Copied! <pre># symmetric matrix\nB = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\nB == B.T\n</pre> # symmetric matrix B = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]]) B == B.T Out[35]: <pre>tensor([[True, True, True],\n        [True, True, True],\n        [True, True, True]])</pre> In\u00a0[56]: Copied! <pre># high-order tensor (three way)\nX = torch.arange(24).reshape(2, 3, 4)\nX\n</pre> # high-order tensor (three way) X = torch.arange(24).reshape(2, 3, 4) X Out[56]: <pre>tensor([[[ 0,  1,  2,  3],\n         [ 4,  5,  6,  7],\n         [ 8,  9, 10, 11]],\n\n        [[12, 13, 14, 15],\n         [16, 17, 18, 19],\n         [20, 21, 22, 23]]])</pre> In\u00a0[39]: Copied! <pre>A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n# \u8fd9\u6837\u6539\u53d8B\uff0c\u4e5f\u4e0d\u4f1a\u6539\u53d8\u539f\u6765\u7684A\uff0cclone\u7c7b\u4f3c\u4e8enumpy\u4e2d\u7684copy\nB = A.clone() # \u901a\u8fc7\u5206\u914d\u65b0\u5185\u5b58\uff0c\u5c06A\u7684\u2f00\u4e2a\u526f\u672c\u5206\u914d\u7ed9B\nA, B, A + B\n</pre> A = torch.arange(20, dtype=torch.float32).reshape(5, 4) # \u8fd9\u6837\u6539\u53d8B\uff0c\u4e5f\u4e0d\u4f1a\u6539\u53d8\u539f\u6765\u7684A\uff0cclone\u7c7b\u4f3c\u4e8enumpy\u4e2d\u7684copy B = A.clone() # \u901a\u8fc7\u5206\u914d\u65b0\u5185\u5b58\uff0c\u5c06A\u7684\u2f00\u4e2a\u526f\u672c\u5206\u914d\u7ed9B A, B, A + B Out[39]: <pre>(tensor([[ 0.,  1.,  2.,  3.],\n         [ 4.,  5.,  6.,  7.],\n         [ 8.,  9., 10., 11.],\n         [12., 13., 14., 15.],\n         [16., 17., 18., 19.]]),\n tensor([[ 0.,  1.,  2.,  3.],\n         [ 4.,  5.,  6.,  7.],\n         [ 8.,  9., 10., 11.],\n         [12., 13., 14., 15.],\n         [16., 17., 18., 19.]]),\n tensor([[ 0.,  2.,  4.,  6.],\n         [ 8., 10., 12., 14.],\n         [16., 18., 20., 22.],\n         [24., 26., 28., 30.],\n         [32., 34., 36., 38.]]))</pre> In\u00a0[40]: Copied! <pre># hardmard product\nA * B\n</pre> # hardmard product A * B Out[40]: <pre>tensor([[  0.,   1.,   4.,   9.],\n        [ 16.,  25.,  36.,  49.],\n        [ 64.,  81., 100., 121.],\n        [144., 169., 196., 225.],\n        [256., 289., 324., 361.]])</pre> In\u00a0[59]: Copied! <pre># operation with scalar\na = 2\nX = torch.arange(24).reshape(2, 3, 4)\na + X, (a * X).shape\n</pre> # operation with scalar a = 2 X = torch.arange(24).reshape(2, 3, 4) a + X, (a * X).shape Out[59]: <pre>(tensor([[[ 2,  3,  4,  5],\n          [ 6,  7,  8,  9],\n          [10, 11, 12, 13]],\n \n         [[14, 15, 16, 17],\n          [18, 19, 20, 21],\n          [22, 23, 24, 25]]]),\n torch.Size([2, 3, 4]))</pre> In\u00a0[42]: Copied! <pre>x = torch.arange(4, dtype=torch.float32)\nx, x.sum()\n</pre> x = torch.arange(4, dtype=torch.float32) x, x.sum() Out[42]: <pre>(tensor([0., 1., 2., 3.]), tensor(6.))</pre> In\u00a0[43]: Copied! <pre>A.shape, A.sum()\n</pre> A.shape, A.sum() Out[43]: <pre>(torch.Size([5, 4]), tensor(190.))</pre> In\u00a0[44]: Copied! <pre>A_sum_axis0 = A.sum(axis=0) # sum along axis 0\nA_sum_axis0, A_sum_axis0.shape\n</pre> A_sum_axis0 = A.sum(axis=0) # sum along axis 0 A_sum_axis0, A_sum_axis0.shape Out[44]: <pre>(tensor([40., 45., 50., 55.]), torch.Size([4]))</pre> In\u00a0[45]: Copied! <pre>A_sum_axis1 = A.sum(axis=1) # sum along axis 1\nA_sum_axis1, A_sum_axis1.shape\n</pre> A_sum_axis1 = A.sum(axis=1) # sum along axis 1 A_sum_axis1, A_sum_axis1.shape Out[45]: <pre>(tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))</pre> In\u00a0[77]: Copied! <pre>A.sum(axis=[0, 1]), A.sum() # sum along two axis \n</pre> A.sum(axis=[0, 1]), A.sum() # sum along two axis  Out[77]: <pre>(tensor(190.), tensor(190.))</pre> In\u00a0[78]: Copied! <pre>A.mean(), A.sum() / A.numel() # overall mean\n</pre> A.mean(), A.sum() / A.numel() # overall mean Out[78]: <pre>(tensor(9.5000), tensor(9.5000))</pre> In\u00a0[79]: Copied! <pre>A.mean(axis=0), A.sum(axis=0) / A.shape[0] # mean along axis 0\n</pre> A.mean(axis=0), A.sum(axis=0) / A.shape[0] # mean along axis 0 Out[79]: <pre>(tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))</pre> In\u00a0[47]: Copied! <pre>sum_A = A.sum(axis=1, keepdims=True) # keep dim to be the same size\nsum_A, sum_A.shape\n</pre> sum_A = A.sum(axis=1, keepdims=True) # keep dim to be the same size sum_A, sum_A.shape Out[47]: <pre>(tensor([[ 6.],\n         [22.],\n         [38.],\n         [54.],\n         [70.]]),\n torch.Size([5, 1]))</pre> In\u00a0[81]: Copied! <pre>A / sum_A # row normalization\n</pre> A / sum_A # row normalization Out[81]: <pre>tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n        [0.1818, 0.2273, 0.2727, 0.3182],\n        [0.2105, 0.2368, 0.2632, 0.2895],\n        [0.2222, 0.2407, 0.2593, 0.2778],\n        [0.2286, 0.2429, 0.2571, 0.2714]])</pre> In\u00a0[82]: Copied! <pre>A.cumsum(axis=0)  # cumulative sum along row\n</pre> A.cumsum(axis=0)  # cumulative sum along row Out[82]: <pre>tensor([[ 0.,  1.,  2.,  3.],\n        [ 4.,  6.,  8., 10.],\n        [12., 15., 18., 21.],\n        [24., 28., 32., 36.],\n        [40., 45., 50., 55.]])</pre> In\u00a0[35]: Copied! <pre>y = torch.ones(4, dtype = torch.float32)\nx, y, torch.dot(x, y)\n</pre> y = torch.ones(4, dtype = torch.float32) x, y, torch.dot(x, y) Out[35]: <pre>(tensor([1., 2., 4., 8.]), tensor([1., 1., 1., 1.]), tensor(15.))</pre> In\u00a0[34]: Copied! <pre>A\n</pre> A Out[34]: <pre>array([[ 0.,  1.,  2.,  3.],\n       [ 4.,  5.,  6.,  7.],\n       [ 8.,  9., 10., 11.]], dtype=float32)</pre> In\u00a0[51]: Copied! <pre>A.shape, x.shape, torch.mv(A, x), torch.matmul(A, x)\n</pre> A.shape, x.shape, torch.mv(A, x), torch.matmul(A, x) Out[51]: <pre>(torch.Size([5, 4]),\n torch.Size([4]),\n tensor([ 14.,  38.,  62.,  86., 110.]),\n tensor([ 14.,  38.,  62.,  86., 110.]))</pre> In\u00a0[41]: Copied! <pre>B = torch.ones(4, 3)\ntorch.mm(A, B)\n</pre> B = torch.ones(4, 3) torch.mm(A, B) Out[41]: <pre>tensor([[ 6.,  6.,  6.],\n        [22., 22., 22.],\n        [38., 38., 38.],\n        [54., 54., 54.],\n        [70., 70., 70.]])</pre> In\u00a0[86]: Copied! <pre>u = torch.tensor([3.0, -4.0])\ntorch.norm(u)\n</pre> u = torch.tensor([3.0, -4.0]) torch.norm(u) Out[86]: <pre>tensor(5.)</pre> In\u00a0[87]: Copied! <pre>torch.abs(u).sum() # L1-norm\n</pre> torch.abs(u).sum() # L1-norm Out[87]: <pre>tensor(7.)</pre> In\u00a0[88]: Copied! <pre>torch.norm(torch.ones((4, 9))) # Frobenius norm\n</pre> torch.norm(torch.ones((4, 9))) # Frobenius norm Out[88]: <pre>tensor(6.)</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[36]: Copied! <pre>def f(x):\n    return 3 * x ** 2 - 4 * x\n</pre> def f(x):     return 3 * x ** 2 - 4 * x In\u00a0[39]: Copied! <pre>def numerical_lim(f, x, h):\n    return (f(x + h) - f(x)) / h\n\nh = 0.1\nfor i in range(5):\n    print(f'h={h:.5f}, numerical limit={numerical_lim(f, 1, h):.5f}')\n    h *= 0.1\n</pre> def numerical_lim(f, x, h):     return (f(x + h) - f(x)) / h  h = 0.1 for i in range(5):     print(f'h={h:.5f}, numerical limit={numerical_lim(f, 1, h):.5f}')     h *= 0.1 <pre>h=0.10000, numerical limit=2.30000\nh=0.01000, numerical limit=2.03000\nh=0.00100, numerical limit=2.00300\nh=0.00010, numerical limit=2.00030\nh=0.00001, numerical limit=2.00003\n</pre> In\u00a0[40]: Copied! <pre>x = np.arange(0, 3, 0.1)\nmyutils.plot(x, [f(x), 2 * x - 3], 'x', 'f(x)', legend=['f(x)', 'Tangent line (x=1)'])\n</pre> x = np.arange(0, 3, 0.1) myutils.plot(x, [f(x), 2 * x - 3], 'x', 'f(x)', legend=['f(x)', 'Tangent line (x=1)']) In\u00a0[11]: Copied! <pre>x = torch.arange(4.0)\nx.requires_grad_(True)\n# \u7b49\u4ef7\u5199\u6cd5\uff1a\n# x = torch.arange(4.0, requires_grad=True)\nprint(x.grad)\nx\n</pre> x = torch.arange(4.0) x.requires_grad_(True) # \u7b49\u4ef7\u5199\u6cd5\uff1a # x = torch.arange(4.0, requires_grad=True) print(x.grad) x <pre>None\n</pre> Out[11]: <pre>tensor([0., 1., 2., 3.], requires_grad=True)</pre> In\u00a0[12]: Copied! <pre>y = 2 * torch.dot(x, x)\ny\n</pre> y = 2 * torch.dot(x, x) y Out[12]: <pre>tensor(28., grad_fn=&lt;MulBackward0&gt;)</pre> In\u00a0[13]: Copied! <pre># \u8fdb\u884c\u81ea\u52a8\u5fae\u5206\uff0c pytorch \u52a8\u6001\u5730\u6784\u9020\u8ba1\u7b97\u56fe\u3002\n# \u8fd0\u884cbackawrd\u65b9\u6cd5\u540e\uff0c\u4f1a\u542f\u52a8\u8ba1\u7b97\u56fe\uff0cy\u5173\u4e8e\u81ea\u53d8\u91cfx\u7684\u68af\u5ea6\u4f1a\u88ab\u8ba1\u7b97\u51fa\u6765\uff0c\u5e76\u4e14\u7d2f\u52a0\u5230x.grad\n# \u56e0\u6b64\uff0c\u5982\u679c\u9700\u8981\u91cd\u65b0\u8ba1\u7b97\u65b0\u7684\u68af\u5ea6\uff0c\u9700\u8981\u5148\u5c06\u539f\u6765\u7684\u68af\u5ea6\u6e05\u7a7a(e.g. x.grad.zero_())\ny.backward()\nprint(x.grad)\nprint(y.grad) # y\u662f\u6ca1\u6709\u68af\u5ea6\u7684\n</pre> # \u8fdb\u884c\u81ea\u52a8\u5fae\u5206\uff0c pytorch \u52a8\u6001\u5730\u6784\u9020\u8ba1\u7b97\u56fe\u3002 # \u8fd0\u884cbackawrd\u65b9\u6cd5\u540e\uff0c\u4f1a\u542f\u52a8\u8ba1\u7b97\u56fe\uff0cy\u5173\u4e8e\u81ea\u53d8\u91cfx\u7684\u68af\u5ea6\u4f1a\u88ab\u8ba1\u7b97\u51fa\u6765\uff0c\u5e76\u4e14\u7d2f\u52a0\u5230x.grad # \u56e0\u6b64\uff0c\u5982\u679c\u9700\u8981\u91cd\u65b0\u8ba1\u7b97\u65b0\u7684\u68af\u5ea6\uff0c\u9700\u8981\u5148\u5c06\u539f\u6765\u7684\u68af\u5ea6\u6e05\u7a7a(e.g. x.grad.zero_()) y.backward() print(x.grad) print(y.grad) # y\u662f\u6ca1\u6709\u68af\u5ea6\u7684 <pre>tensor([ 0.,  4.,  8., 12.])\nNone\n</pre> In\u00a0[62]: Copied! <pre>z = 2 * torch.dot(x, x)\nz.backward()\nx.grad # \u68af\u5ea6\u4f1a\u81ea\u52a8\u7d2f\u79ef\n</pre> z = 2 * torch.dot(x, x) z.backward() x.grad # \u68af\u5ea6\u4f1a\u81ea\u52a8\u7d2f\u79ef Out[62]: <pre>tensor([ 0.,  8., 16., 24.])</pre> In\u00a0[63]: Copied! <pre>x.grad.zero_() # \u68af\u5ea6\u6e05\u96f6\ny = x.sum()\ny.backward()\nx.grad\n</pre> x.grad.zero_() # \u68af\u5ea6\u6e05\u96f6 y = x.sum() y.backward() x.grad Out[63]: <pre>tensor([1., 1., 1., 1.])</pre> <p>\u53e6\u5916\u4e00\u4e2a\u4f8b\u5b50\uff1a\u81ea\u52a8\u5fae\u5206\u90e8\u5206\uff0c\u9700\u8981\u7279\u522b\u6ce8\u610f\u53ea\u80fd\u5bf9\u4e00\u4e2ascalar output\u4f7f\u7528backward\uff0c\u5426\u5219\u5728backward\u5185\u9700\u8981\u52a0\u4e0agradient\u53c2\u6570</p> In\u00a0[73]: Copied! <pre>a = torch.tensor([2., 3.], requires_grad=True)\nb = torch.tensor([6., 4.], requires_grad=True)\nQ = 3*a**3 - b**2\nQ\n</pre> a = torch.tensor([2., 3.], requires_grad=True) b = torch.tensor([6., 4.], requires_grad=True) Q = 3*a**3 - b**2 Q Out[73]: <pre>tensor([-12.,  65.], grad_fn=&lt;SubBackward0&gt;)</pre> In\u00a0[74]: Copied! <pre># Q\u662f\u4e00\u4e2a\u5411\u91cf\uff0c\u5fc5\u987b\u8981\u52a0\u4e0a\u4e00\u4e2agradient\u65b9\u6cd5\uff0c\u8868\u793a\u5c06Q\u7684\u5206\u91cf\u6c42sum\nQ.backward(gradient=torch.tensor([1, 1]))\n# \u7b49\u4ef7\u4e8e: \n# Q = Q.sum()\n# Q.backward()\n</pre> # Q\u662f\u4e00\u4e2a\u5411\u91cf\uff0c\u5fc5\u987b\u8981\u52a0\u4e0a\u4e00\u4e2agradient\u65b9\u6cd5\uff0c\u8868\u793a\u5c06Q\u7684\u5206\u91cf\u6c42sum Q.backward(gradient=torch.tensor([1, 1])) # \u7b49\u4ef7\u4e8e:  # Q = Q.sum() # Q.backward() In\u00a0[75]: Copied! <pre>a.grad, 9 * a**2, b.grad, - 2 * b\n</pre> a.grad, 9 * a**2, b.grad, - 2 * b Out[75]: <pre>(tensor([36., 81.]),\n tensor([36., 81.], grad_fn=&lt;MulBackward0&gt;),\n tensor([-12.,  -8.]),\n tensor([-12.,  -8.], grad_fn=&lt;MulBackward0&gt;))</pre> <p>\u6700\u5173\u952e\u7684\u5c31\u662f\uff0c\u5728with torch.no_grad()\u91cc\u9762\u7684\u5b9a\u4e49\u7684tensor\u7684requires_grad\u5c5e\u6027\u662fFalse\uff0c\u65e0\u6cd5\u8c03\u7528backward\u65b9\u6cd5\u3002\u8fd9\u6837\u64cd\u4f5c\u53ef\u4ee5\u8282\u7701\u5185\u5b58\u3002</p> In\u00a0[116]: Copied! <pre># with torch.no_grad()\u662f\u4e00\u4e2a\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\uff0c\u7528\u4e8e\u7981\u7528\u68af\u5ea6\u8ba1\u7b97\u3002\n# \u5728PyTorch\u4e2d\uff0c\u5982\u679c\u4e00\u4e2a\u5f20\u91cf\u7684requires_grad\u5c5e\u6027\u88ab\u8bbe\u7f6e\u4e3aTrue\uff0c\u5219\u53cd\u5411\u4f20\u64ad\u65f6\uff0c\u8be5\u5f20\u91cf\u5c31\u4f1a\u81ea\u52a8\u6c42\u5bfc\u3002\n# \u4f46\u662f\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u4e0d\u9700\u8981\u8ba1\u7b97\u68af\u5ea6\uff0c\u4f8b\u5982\u5728\u6a21\u578b\u6d4b\u8bd5\u65f6\u3002\u8fd9\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528with torch.no_grad()\u6765\u7981\u7528\u68af\u5ea6\u8ba1\u7b97\uff0c\n# \u4ee5\u51cf\u5c11\u5185\u5b58\u7684\u4f7f\u7528\u5e76\u52a0\u5feb\u4ee3\u7801\u7684\u8fd0\u884c\u901f\u5ea6\u3002\n# \u5728with torch.no_grad()\u4ee3\u7801\u5757\u4e2d\u8ba1\u7b97\u5f97\u5230\u7684\u5f20\u91cf\u7684requires_grad\u5c5e\u6027\u90fd\u4f1a\u88ab\u81ea\u52a8\u8bbe\u7f6e\u4e3aFalse\uff0c\n# \u4ee5\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u5185\u5b58\u6d88\u8017\u548c\u8ba1\u7b97\u5f00\u9500\u3002\u901a\u5e38\u60c5\u51b5\u4e0b\uff0cwith torch.no_grad()\u4f1a\u5728\u6d4b\u8bd5\u6a21\u578b\u65f6\u4f7f\u7528\u3002\n# \u90e8\u5206\u53d8\u91cf\u4e0d\u9700\u8981\u68af\u5ea6\u56de\u4f20\uff0c\u6211\u4eec\u4f7f\u7528with torch.no_grad()\nx = torch.tensor(1.0, requires_grad=True)\ny1 = x ** 2 \nwith torch.no_grad():\n    # \u4e0d\u56de\u4f20\u68af\u5ea6\n    y2 = x ** 3\ny3 = y1 + y2\n    \nprint(x.requires_grad)  # True\nprint(y1, y1.requires_grad)  # True\nprint(y2, y2.requires_grad)  # False\nprint(y3, y3.requires_grad)  # True\n</pre> # with torch.no_grad()\u662f\u4e00\u4e2a\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668\uff0c\u7528\u4e8e\u7981\u7528\u68af\u5ea6\u8ba1\u7b97\u3002 # \u5728PyTorch\u4e2d\uff0c\u5982\u679c\u4e00\u4e2a\u5f20\u91cf\u7684requires_grad\u5c5e\u6027\u88ab\u8bbe\u7f6e\u4e3aTrue\uff0c\u5219\u53cd\u5411\u4f20\u64ad\u65f6\uff0c\u8be5\u5f20\u91cf\u5c31\u4f1a\u81ea\u52a8\u6c42\u5bfc\u3002 # \u4f46\u662f\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u6211\u4eec\u4e0d\u9700\u8981\u8ba1\u7b97\u68af\u5ea6\uff0c\u4f8b\u5982\u5728\u6a21\u578b\u6d4b\u8bd5\u65f6\u3002\u8fd9\u65f6\uff0c\u6211\u4eec\u53ef\u4ee5\u4f7f\u7528with torch.no_grad()\u6765\u7981\u7528\u68af\u5ea6\u8ba1\u7b97\uff0c # \u4ee5\u51cf\u5c11\u5185\u5b58\u7684\u4f7f\u7528\u5e76\u52a0\u5feb\u4ee3\u7801\u7684\u8fd0\u884c\u901f\u5ea6\u3002 # \u5728with torch.no_grad()\u4ee3\u7801\u5757\u4e2d\u8ba1\u7b97\u5f97\u5230\u7684\u5f20\u91cf\u7684requires_grad\u5c5e\u6027\u90fd\u4f1a\u88ab\u81ea\u52a8\u8bbe\u7f6e\u4e3aFalse\uff0c # \u4ee5\u907f\u514d\u4e0d\u5fc5\u8981\u7684\u5185\u5b58\u6d88\u8017\u548c\u8ba1\u7b97\u5f00\u9500\u3002\u901a\u5e38\u60c5\u51b5\u4e0b\uff0cwith torch.no_grad()\u4f1a\u5728\u6d4b\u8bd5\u6a21\u578b\u65f6\u4f7f\u7528\u3002 # \u90e8\u5206\u53d8\u91cf\u4e0d\u9700\u8981\u68af\u5ea6\u56de\u4f20\uff0c\u6211\u4eec\u4f7f\u7528with torch.no_grad() x = torch.tensor(1.0, requires_grad=True) y1 = x ** 2  with torch.no_grad():     # \u4e0d\u56de\u4f20\u68af\u5ea6     y2 = x ** 3 y3 = y1 + y2      print(x.requires_grad)  # True print(y1, y1.requires_grad)  # True print(y2, y2.requires_grad)  # False print(y3, y3.requires_grad)  # True <pre>True\ntensor(1., grad_fn=&lt;PowBackward0&gt;) True\ntensor(1.) False\ntensor(2., grad_fn=&lt;AddBackward0&gt;) True\n</pre> In\u00a0[113]: Copied! <pre>#  \u83b7\u53d6\u4e2d\u95f4\u53d8\u91cf\u7684\u68af\u5ea6\nx = torch.tensor(3., requires_grad=True)\ny = x ** 2\nz = 4 * y\n\n# \u8fd9\u91ccy\u662f\u4e2d\u95f4\u53d8\u91cf\uff0c\u9ed8\u8ba4\u4e0d\u4fdd\u5b58y\u7684\u68af\u5ea6\n# y.retain_grad()   # \u4f7f\u7528 retain_grad \u53ef\u4ee5\u7528\u6765\u83b7\u53d6\u4e2d\u95f4\u53d8\u91cf\u7684\u68af\u5ea6\n\nz.backward()\nprint(x.grad)   # tensor(24.)\nprint(y.grad)   # None\n</pre> #  \u83b7\u53d6\u4e2d\u95f4\u53d8\u91cf\u7684\u68af\u5ea6 x = torch.tensor(3., requires_grad=True) y = x ** 2 z = 4 * y  # \u8fd9\u91ccy\u662f\u4e2d\u95f4\u53d8\u91cf\uff0c\u9ed8\u8ba4\u4e0d\u4fdd\u5b58y\u7684\u68af\u5ea6 # y.retain_grad()   # \u4f7f\u7528 retain_grad \u53ef\u4ee5\u7528\u6765\u83b7\u53d6\u4e2d\u95f4\u53d8\u91cf\u7684\u68af\u5ea6  z.backward() print(x.grad)   # tensor(24.) print(y.grad)   # None <pre>tensor(24.)\ntensor(4.)\n</pre>"},{"location":"markdown/knowledge/deep_learning_notebook/pytorch_basic/#pytorch-notes-overview","title":"Pytorch Notes: Overview\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/pytorch_basic/#basic-operation","title":"Basic Operation\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/pytorch_basic/#read-data","title":"Read Data\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/pytorch_basic/#more-stuff-on-linear-algebra","title":"more stuff on linear algebra\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/pytorch_basic/","title":"\u81ea\u52a8\u5fae\u5206\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/pytorch_basic/","title":"\u5bfc\u6570\u5b9a\u4e49\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/pytorch_basic/#y","title":"\u5bf9\u4e00\u4e2a\u6807\u91cfy\u81ea\u52a8\u5fae\u5206\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/pytorch_basic/#with-torchno_grad","title":"with torch.no_grad()\u00b6","text":""},{"location":"markdown/knowledge/deep_learning_notebook/pytorch_basic/#retain_grad","title":"retain_grad()\u00b6","text":""},{"location":"markdown/knowledge/notability_notes/%E8%AF%B4%E6%98%8E/","title":"\u8bf4\u660e","text":"<p>\u76ee\u524d\u5173\u4e8enotability\u7684\u7b14\u8bb0\u6ca1\u6709\u627e\u5230\u5f88\u597d\u7684\u65b9\u6cd5\u5feb\u901f\u5c06pdf\u6587\u4ef6\u76f4\u63a5\u6dfb\u52a0\u5230\u9875\u9762\u4e0a\uff0c\u800c\u662f\u5fc5\u987b\u5728 md\u6587\u4ef6\u4e2d\u5f15\u7528pdf\u6587\u4ef6\u3002\u5373\u4f7f\u6210\u529f\u6dfb\u52a0\u5c06\u6765\u66f4\u65b0pdf\u6587\u4ef6\u4e5f\u4e0d\u591f\u65b9\u4fbf\u3002\u56e0\u6b64\uff0c\u76f4\u63a5\u4f7f\u7528notability \u540c\u65f6\u52a0\u4e0agoogle drive\u8fdb\u884c\u7b14\u8bb0\u7684\u540c\u6b65\u3002 google drive</p>"},{"location":"markdown/knowledge/quant/%E6%94%B6%E7%9B%8A%E7%8E%87/","title":"\u6536\u76ca\u7387","text":"In\u00a0[44]: Copied! <pre>import numpy as np\nfrom lwpackage.lwdata import get_stock_price\n</pre> import numpy as np from lwpackage.lwdata import get_stock_price In\u00a0[45]: Copied! <pre>data = get_stock_price(frequency='1m',\n                start_time='20190101',\n                end_time='20210101',\n                from_database=True)\n</pre> data = get_stock_price(frequency='1m',                 start_time='20190101',                 end_time='20210101',                 from_database=True) In\u00a0[47]: Copied! <pre>data['ret'] = data.groupby('instrument_id')['close'].transform(lambda x: x.pct_change())\ndata\n</pre> data['ret'] = data.groupby('instrument_id')['close'].transform(lambda x: x.pct_change()) data Out[47]: time instrument_id open high low close volume ret 0 2019-12-05 09:31:00 600747 0.26 0.27 0.26 0.26 1690401 NaN 1 2019-12-05 09:32:00 600747 0.26 0.26 0.26 0.26 170100 0.000000 2 2019-12-05 09:33:00 600747 0.26 0.27 0.26 0.27 623300 0.038462 3 2019-12-05 09:34:00 600747 0.26 0.27 0.26 0.26 23800 -0.037037 4 2019-12-05 09:35:00 600747 0.26 0.27 0.26 0.26 330800 0.000000 ... ... ... ... ... ... ... ... ... 5102 2020-09-15 14:56:00 300216 0.19 0.20 0.19 0.20 63526 0.052632 5103 2020-09-15 14:57:00 300216 0.20 0.21 0.19 0.19 86800 -0.050000 5104 2020-09-15 15:00:00 300216 0.19 0.19 0.19 0.19 590900 0.000000 16925 2020-11-09 15:00:00 300431 0.28 0.28 0.28 0.28 1786880 NaN 16926 2020-12-16 15:00:00 000939 0.15 0.15 0.15 0.15 1784153 NaN <p>16934 rows \u00d7 8 columns</p> In\u00a0[98]: Copied! <pre>data1 = data.loc[data['instrument_id'] == '002509'].fillna(0).copy()\ndata1\n</pre> data1 = data.loc[data['instrument_id'] == '002509'].fillna(0).copy() data1 Out[98]: time instrument_id open high low close volume ret 7075 2020-07-07 10:16:00 002509 0.19 0.19 0.18 0.18 126900 0.000000 7076 2020-07-07 10:17:00 002509 0.18 0.18 0.18 0.18 32900 0.000000 7077 2020-07-07 10:18:00 002509 0.18 0.18 0.18 0.18 35300 0.000000 7078 2020-07-07 10:19:00 002509 0.18 0.18 0.18 0.18 12600 0.000000 7079 2020-07-07 10:20:00 002509 0.18 0.18 0.18 0.18 12200 0.000000 ... ... ... ... ... ... ... ... ... 9040 2020-07-17 14:54:00 002509 0.15 0.15 0.15 0.15 11257972 0.000000 9041 2020-07-17 14:55:00 002509 0.14 0.15 0.14 0.15 4442500 0.000000 9042 2020-07-17 14:56:00 002509 0.15 0.16 0.15 0.15 1885700 0.000000 9043 2020-07-17 14:57:00 002509 0.15 0.16 0.15 0.16 2977200 0.066667 9044 2020-07-17 15:00:00 002509 0.15 0.15 0.15 0.15 7177463 -0.062500 <p>1970 rows \u00d7 8 columns</p> In\u00a0[100]: Copied! <pre>data1['ret'].plot()\n</pre> data1['ret'].plot() Out[100]: <pre>&lt;Axes: &gt;</pre> In\u00a0[72]: Copied! <pre># \u6574\u4e2a\u65f6\u95f4\u533a\u95f4\u5185\u5355\u5229\u8ba1\u7b97\u7684\u6536\u76ca\u7387\ndata1['ret'].sum()\n</pre> # \u6574\u4e2a\u65f6\u95f4\u533a\u95f4\u5185\u5355\u5229\u8ba1\u7b97\u7684\u6536\u76ca\u7387 data1['ret'].sum() Out[72]: <pre>0.6626117991055903</pre> In\u00a0[73]: Copied! <pre># \u6574\u4e2a\u65f6\u95f4\u533a\u95f4\u5185\u5355\u5229\u8ba1\u7b97\u7684\u5e74\u5316\u6536\u76ca\u7387\ndata1['ret'].mean() * 4 * 60 * 252\n</pre> # \u6574\u4e2a\u65f6\u95f4\u533a\u95f4\u5185\u5355\u5229\u8ba1\u7b97\u7684\u5e74\u5316\u6536\u76ca\u7387 data1['ret'].mean() * 4 * 60 * 252 Out[73]: <pre>20.35284997963743</pre> In\u00a0[99]: Copied! <pre># \u6574\u4e2a\u65f6\u95f4\u533a\u95f4\u5185\u590d\u5229\u8ba1\u7b97\u7684\u6536\u76ca\u7387\n(data1['ret'] + 1).prod() - 1\n</pre> # \u6574\u4e2a\u65f6\u95f4\u533a\u95f4\u5185\u590d\u5229\u8ba1\u7b97\u7684\u6536\u76ca\u7387 (data1['ret'] + 1).prod() - 1 Out[99]: <pre>-0.16666666666667074</pre> In\u00a0[92]: Copied! <pre># \u6574\u4e2a\u65f6\u95f4\u533a\u95f4\u5185\u590d\u5229\u8ba1\u7b97\u7684\u5e74\u5316\u6536\u76ca\u7387\ncum_ret = (data1['ret'] + 1).cumprod()\n(cum_ret.iloc[-1] / cum_ret.iloc[0]) ** int((252 * 4 * 60 / len(data1)))\n</pre> # \u6574\u4e2a\u65f6\u95f4\u533a\u95f4\u5185\u590d\u5229\u8ba1\u7b97\u7684\u5e74\u5316\u6536\u76ca\u7387 cum_ret = (data1['ret'] + 1).cumprod() (cum_ret.iloc[-1] / cum_ret.iloc[0]) ** int((252 * 4 * 60 / len(data1))) Out[92]: <pre>0.004212720233086807</pre> <p>\u5355\u5229\u548c\u590d\u5229\u8ba1\u7b97\uff0c\u5e74\u5316\u6536\u76ca\u7387\u5dee\u522b\u8fd8\u662f\u5f88\u5927\u7684\u3002\u6240\u4ee5\uff0c\u5230\u5e95\u548b\u7b97\u5462\uff1f</p> In\u00a0[101]: Copied! <pre># \u80dc\u7387\nlen(data1.loc[data1['ret'] &gt; 0]) / len(data1)\n</pre> # \u80dc\u7387 len(data1.loc[data1['ret'] &gt; 0]) / len(data1) Out[101]: <pre>0.12791878172588833</pre> <p>\u4ece\u80dc\u7387\u770b\u51fa\uff0c\u8fd9\u4e2a\u80a1\u7968\u5927\u4e8e0\u7684\u6536\u76ca\u7387\u7684\u65f6\u95f4\u622a\u9762\u5f88\u5c11\uff0c\u6240\u4ee5\u4e00\u822c\u7b97\u51fa\u6765\u8868\u73b0\u5e94\u8be5\u6bd4\u8f83\u5dee\u624d\u5bf9\u3002\u6240\u4ee5\u5efa\u8bae\u4f7f\u7528\u590d\u5229\u6536\u76ca\u7387</p> <p>\u800c\u4e14\uff0c\u6211\u8ba4\u4e3a\u91c7\u53d6\u7684\u8ba1\u7b97\u65b9\u5f0f\u548c\u80a1\u7968\u672c\u8eab\u7684\u4ef7\u683c\u4e5f\u6709\u5173\u7cfb\uff1a\u5982\u679c\u80a1\u7968\u672c\u8eab\u4ef7\u683c\u5f88\u9ad8\uff0c\u5c31\u4e0d\u5bb9\u6613\u51fa\u73b0\u8f83\u5927\u7684\u5206\u949f\u9891\u6536\u76ca\u7387\u6570\u636e\uff1b\u5982\u679c\u80a1\u7968\u672c\u8eab\u4ef7\u683c\u5f88\u4f4e\uff0c\u5c31\u5bb9\u6613\u51fa\u73b0\u5f88\u5927\u7684\u751a\u81f3\u8d85\u8fc7100%\u7684\u5206\u949f\u9891\u6536\u76ca\u7387\u6570\u636e\u3002</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[97]: Copied! <pre>data1\n</pre> data1 Out[97]: time instrument_id open high low close volume ret 7075 2020-07-07 10:16:00 002509 0.19 0.19 0.18 0.18 126900 0.000000 7076 2020-07-07 10:17:00 002509 0.18 0.18 0.18 0.18 32900 0.000000 7077 2020-07-07 10:18:00 002509 0.18 0.18 0.18 0.18 35300 0.000000 7078 2020-07-07 10:19:00 002509 0.18 0.18 0.18 0.18 12600 0.000000 7079 2020-07-07 10:20:00 002509 0.18 0.18 0.18 0.18 12200 0.000000 ... ... ... ... ... ... ... ... ... 9040 2020-07-17 14:54:00 002509 0.15 0.15 0.15 0.15 11257972 0.000000 9041 2020-07-17 14:55:00 002509 0.14 0.15 0.14 0.15 4442500 0.000000 9042 2020-07-17 14:56:00 002509 0.15 0.16 0.15 0.15 1885700 0.000000 9043 2020-07-17 14:57:00 002509 0.15 0.16 0.15 0.16 2977200 0.066667 9044 2020-07-17 15:00:00 002509 0.15 0.15 0.15 0.15 7177463 -0.062500 <p>1970 rows \u00d7 8 columns</p> In\u00a0[43]: Copied! <pre># \u6536\u76ca\u7387\u5e73\u5747\u6309\u7167\u5e74\u531610%\u8ba1\u7b97\n# \u751f\u6210\u4e00\u5217\u968f\u673a\u6570\uff0c\u4ee3\u8868\u4e00\u5e74\u5185\u7684\u5206\u949f\u9891\u7387\u6536\u76ca\u7387\u5e8f\u5217\nret_min = np.random.uniform(0, 1, 100)\nret_min\n</pre> # \u6536\u76ca\u7387\u5e73\u5747\u6309\u7167\u5e74\u531610%\u8ba1\u7b97 # \u751f\u6210\u4e00\u5217\u968f\u673a\u6570\uff0c\u4ee3\u8868\u4e00\u5e74\u5185\u7684\u5206\u949f\u9891\u7387\u6536\u76ca\u7387\u5e8f\u5217 ret_min = np.random.uniform(0, 1, 100) ret_min Out[43]: <pre>0.49361133870316715</pre> In\u00a0[12]: Copied! <pre>ret_min\n</pre> ret_min Out[12]: <pre>array([0.83987101, 0.00855818, 0.12596678, 0.79139499, 0.77511673,\n       0.63056422, 0.1865663 , 0.60380636, 0.01257613, 0.39190333,\n       0.09662536, 0.56933204, 0.79183219, 0.24541147, 0.67493415,\n       0.01807613, 0.48139499, 0.80868593, 0.59970467, 0.6845612 ,\n       0.24490179, 0.21754866, 0.08214964, 0.31792024, 0.49672592,\n       0.87149834, 0.28523248, 0.25932262, 0.98340711, 0.68463726,\n       0.35654246, 0.47900416, 0.20803741, 0.88756198, 0.3115285 ,\n       0.40751455, 0.21536112, 0.80246623, 0.82314135, 0.32720983,\n       0.85033713, 0.22446929, 0.22625491, 0.23977427, 0.16694997,\n       0.92316527, 0.03204837, 0.86200176, 0.81107338, 0.51076136,\n       0.6849264 , 0.08695985, 0.06596985, 0.45955778, 0.75808796,\n       0.95648838, 0.43804183, 0.30281118, 0.10681298, 0.07594969,\n       0.66692265, 0.55733348, 0.99462595, 0.25923312, 0.39783426,\n       0.17660617, 0.94880641, 0.82622754, 0.17387448, 0.44954379,\n       0.39211478, 0.5790725 , 0.38605053, 0.89432424, 0.26705324,\n       0.09038284, 0.36210047, 0.25550985, 0.38814205, 0.4538711 ,\n       0.06587962, 0.14667322, 0.89751125, 0.09654217, 0.05065183,\n       0.40874516, 0.84745474, 0.26310243, 0.05854267, 0.53540252,\n       0.51862065, 0.98075995, 0.98657275, 0.12737851, 0.8964873 ,\n       0.28540162, 0.35622518, 0.29299146, 0.67104759, 0.47680314])</pre>"},{"location":"markdown/knowledge/quant/%E6%94%B6%E7%9B%8A%E7%8E%87/","title":"\u5355\u5229\u00b6","text":""},{"location":"markdown/knowledge/quant/%E6%94%B6%E7%9B%8A%E7%8E%87/","title":"\u590d\u5229\u00b6","text":""},{"location":"markdown/links/package_documents/","title":"\u5b98\u65b9\u6587\u6863\u94fe\u63a5","text":"<ul> <li>pandas_api</li> <li>numpy_api</li> <li>matplotlib_api</li> <li>mkdocs</li> <li></li> </ul>"},{"location":"markdown/links/useful_webs/","title":"\u4e00\u4e9b\u6709\u7528\u7684\u7f51\u5740","text":"<ul> <li>gitee</li> <li>github</li> <li>git\u6559\u7a0b</li> <li>Alpha Vantage</li> <li>\u4e0b\u8f7d\u8f6f\u4ef6 kitdown</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/","title":"Linux\u57fa\u7840\u547d\u4ee4","text":""},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#linux_1","title":"Linux\u7684\u76ee\u5f55\u7ed3\u6784","text":"<ul> <li><code>/</code>\uff0c\u6839\u76ee\u5f55\u662f\u6700\u9876\u7ea7\u7684\u76ee\u5f55\u4e86</li> <li>Linux\u53ea\u6709\u4e00\u4e2a\u9876\u7ea7\u76ee\u5f55\uff1a<code>/</code></li> <li>\u8def\u5f84\u63cf\u8ff0\u7684\u5c42\u6b21\u5173\u7cfb\u540c\u6837\u9002\u7528<code>/</code>\u6765\u8868\u793a</li> <li>/home/itheima/a.txt\uff0c\u8868\u793a\u6839\u76ee\u5f55\u4e0b\u7684home\u6587\u4ef6\u5939\u5185\u6709itheima\u6587\u4ef6\u5939\uff0c\u5185\u6709a.txt</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#ls","title":"ls\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u5217\u51fa\u6587\u4ef6\u5939\u4fe1\u606f</p> <p>\u8bed\u6cd5\uff1a<code>ls [-l -h -a] [\u53c2\u6570]</code></p> <ul> <li>\u53c2\u6570\uff1a\u88ab\u67e5\u770b\u7684\u6587\u4ef6\u5939\uff0c\u4e0d\u63d0\u4f9b\u53c2\u6570\uff0c\u8868\u793a\u67e5\u770b\u5f53\u524d\u5de5\u4f5c\u76ee\u5f55</li> <li>-l\uff0c\u4ee5\u5217\u8868\u5f62\u5f0f\u67e5\u770b</li> <li>-h\uff0c\u914d\u5408-l\uff0c\u4ee5\u66f4\u52a0\u4eba\u6027\u5316\u7684\u65b9\u5f0f\u663e\u793a\u6587\u4ef6\u5927\u5c0f</li> <li>-a\uff0c\u663e\u793a\u9690\u85cf\u6587\u4ef6</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#_1","title":"\u9690\u85cf\u6587\u4ef6\u3001\u6587\u4ef6\u5939","text":"<p>\u5728Linux\u4e2d\u4ee5<code>.</code>\u5f00\u5934\u7684\uff0c\u5747\u662f\u9690\u85cf\u7684\u3002</p> <p>\u9ed8\u8ba4\u4e0d\u663e\u793a\u51fa\u6765\uff0c\u9700\u8981<code>-a</code>\u9009\u9879\u624d\u53ef\u67e5\u770b\u5230\u3002</p>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#pwd","title":"pwd\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u5c55\u793a\u5f53\u524d\u5de5\u4f5c\u76ee\u5f55</p> <p>\u8bed\u6cd5\uff1a<code>pwd</code></p>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#cd","title":"cd\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u5207\u6362\u5de5\u4f5c\u76ee\u5f55</p> <p>\u8bed\u6cd5\uff1a<code>cd [\u76ee\u6807\u76ee\u5f55]</code></p> <p>\u53c2\u6570\uff1a\u76ee\u6807\u76ee\u5f55\uff0c\u8981\u5207\u6362\u53bb\u7684\u5730\u65b9\uff0c\u4e0d\u63d0\u4f9b\u9ed8\u8ba4\u5207\u6362\u5230<code>\u5f53\u524d\u767b\u5f55\u7528\u6237HOME\u76ee\u5f55</code></p>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#home","title":"HOME\u76ee\u5f55","text":"<p>\u6bcf\u4e00\u4e2a\u7528\u6237\u5728Linux\u7cfb\u7edf\u4e2d\u90fd\u6709\u81ea\u5df1\u7684\u4e13\u5c5e\u5de5\u4f5c\u76ee\u5f55\uff0c\u79f0\u4e4b\u4e3aHOME\u76ee\u5f55\u3002</p> <ul> <li> <p>\u666e\u901a\u7528\u6237\u7684HOME\u76ee\u5f55\uff0c\u9ed8\u8ba4\u5728\uff1a<code>/home/\u7528\u6237\u540d</code></p> </li> <li> <p>root\u7528\u6237\u7684HOME\u76ee\u5f55\uff0c\u5728\uff1a<code>/root</code></p> </li> </ul> <p>FinalShell\u767b\u9646\u7ec8\u7aef\u540e\uff0c\u9ed8\u8ba4\u7684\u5de5\u4f5c\u76ee\u5f55\u5c31\u662f\u7528\u6237\u7684HOME\u76ee\u5f55</p>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#_2","title":"\u76f8\u5bf9\u8def\u5f84\u3001\u7edd\u5bf9\u8def\u5f84","text":"<ul> <li>\u76f8\u5bf9\u8def\u5f84\uff0c\u975e<code>/</code>\u5f00\u5934\u7684\u79f0\u4e4b\u4e3a\u76f8\u5bf9\u8def\u5f84</li> </ul> <p>\u76f8\u5bf9\u8def\u5f84\u8868\u793a\u4ee5<code>\u5f53\u524d\u76ee\u5f55</code>\u4f5c\u4e3a\u8d77\u70b9\uff0c\u53bb\u63cf\u8ff0\u8def\u5f84\uff0c\u5982<code>test/a.txt</code>\uff0c\u8868\u793a\u5f53\u524d\u5de5\u4f5c\u76ee\u5f55\u5185\u7684test\u6587\u4ef6\u5939\u5185\u7684a.txt\u6587\u4ef6</p> <ul> <li>\u7edd\u5bf9\u8def\u5f84\uff0c\u4ee5<code>/</code>\u5f00\u5934\u7684\u79f0\u4e4b\u4e3a\u7edd\u5bf9\u8def\u5f84</li> </ul> <p>\u7edd\u5bf9\u8def\u5f84\u4ece<code>\u6839</code>\u5f00\u59cb\u63cf\u8ff0\u8def\u5f84</p>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#_3","title":"\u7279\u6b8a\u8def\u5f84\u7b26","text":"<ul> <li><code>.</code>\uff0c\u8868\u793a\u5f53\u524d\uff0c\u6bd4\u5982./a.txt\uff0c\u8868\u793a\u5f53\u524d\u6587\u4ef6\u5939\u5185\u7684<code>a.txt</code>\u6587\u4ef6</li> <li><code>..</code>\uff0c\u8868\u793a\u4e0a\u7ea7\u76ee\u5f55\uff0c\u6bd4\u5982<code>../</code>\u8868\u793a\u4e0a\u7ea7\u76ee\u5f55\uff0c<code>../../</code>\u8868\u793a\u4e0a\u7ea7\u7684\u4e0a\u7ea7\u76ee\u5f55</li> <li><code>~</code>\uff0c\u8868\u793a\u7528\u6237\u7684HOME\u76ee\u5f55\uff0c\u6bd4\u5982<code>cd ~</code>\uff0c\u5373\u53ef\u5207\u56de\u7528\u6237HOME\u76ee\u5f55</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#mkdir","title":"mkdir\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u521b\u5efa\u6587\u4ef6\u5939</p> <p>\u8bed\u6cd5\uff1a<code>mkdir [-p] \u53c2\u6570</code></p> <ul> <li>\u53c2\u6570\uff1a\u88ab\u521b\u5efa\u6587\u4ef6\u5939\u7684\u8def\u5f84</li> <li>\u9009\u9879\uff1a-p\uff0c\u53ef\u9009\uff0c\u8868\u793a\u521b\u5efa\u524d\u7f6e\u8def\u5f84\uff0c\u9002\u7528\u4e8e\u4e00\u6b21\u6027\u521b\u5efa\u591a\u4e2a\u5c42\u7ea7\u7684\u76ee\u5f55</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#touch","title":"touch\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u521b\u5efa\u6587\u4ef6</p> <p>\u8bed\u6cd5\uff1a<code>touch \u53c2\u6570</code></p> <ul> <li>\u53c2\u6570\uff1a\u88ab\u521b\u5efa\u7684\u6587\u4ef6\u8def\u5f84</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#cat","title":"cat\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u67e5\u770b\u6587\u4ef6\u5185\u5bb9</p> <p>\u8bed\u6cd5\uff1a<code>cat \u53c2\u6570</code></p> <ul> <li>\u53c2\u6570\uff1a\u88ab\u67e5\u770b\u7684\u6587\u4ef6\u8def\u5f84</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#more","title":"more\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u67e5\u770b\u6587\u4ef6\uff0c\u53ef\u4ee5\u652f\u6301\u7ffb\u9875\u67e5\u770b</p> <p>\u8bed\u6cd5\uff1a<code>more \u53c2\u6570</code></p> <ul> <li>\u53c2\u6570\uff1a\u88ab\u67e5\u770b\u7684\u6587\u4ef6\u8def\u5f84</li> <li>\u5728\u67e5\u770b\u8fc7\u7a0b\u4e2d\uff1a</li> <li><code>\u7a7a\u683c</code>\u952e\u7ffb\u9875</li> <li><code>q</code>\u9000\u51fa\u67e5\u770b</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#cp","title":"cp\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u590d\u5236\u6587\u4ef6\u3001\u6587\u4ef6\u5939</p> <p>\u8bed\u6cd5\uff1a<code>cp [-r] \u53c2\u65701 \u53c2\u65702</code></p> <ul> <li>\u53c2\u65701\uff0c\u88ab\u590d\u5236\u7684</li> <li>\u53c2\u65702\uff0c\u8981\u590d\u5236\u53bb\u7684\u5730\u65b9</li> <li>\u9009\u9879\uff1a-r\uff0c\u53ef\u9009\uff0c\u590d\u5236\u6587\u4ef6\u5939\u4f7f\u7528</li> </ul> <p>\u793a\u4f8b\uff1a</p> <ul> <li>cp a.txt b.txt\uff0c\u590d\u5236\u5f53\u524d\u76ee\u5f55\u4e0ba.txt\u4e3ab.txt</li> <li>cp a.txt test/\uff0c\u590d\u5236\u5f53\u524d\u76ee\u5f55a.txt\u5230test\u6587\u4ef6\u5939\u5185</li> <li>cp -r test test2\uff0c\u590d\u5236\u6587\u4ef6\u5939test\u5230\u5f53\u524d\u6587\u4ef6\u5939\u5185\u4e3atest2\u5b58\u5728</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#mv","title":"mv\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u79fb\u52a8\u6587\u4ef6\u3001\u6587\u4ef6\u5939</p> <p>\u8bed\u6cd5\uff1a<code>mv \u53c2\u65701 \u53c2\u65702</code></p> <ul> <li>\u53c2\u65701\uff1a\u88ab\u79fb\u52a8\u7684</li> <li>\u53c2\u65702\uff1a\u8981\u79fb\u52a8\u53bb\u7684\u5730\u65b9\uff0c\u53c2\u65702\u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5219\u4f1a\u8fdb\u884c\u6539\u540d</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#rm","title":"rm\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u5220\u9664\u6587\u4ef6\u3001\u6587\u4ef6\u5939</p> <p>\u8bed\u6cd5\uff1a<code>rm [-r -f] \u53c2\u6570...\u53c2\u6570</code></p> <ul> <li>\u53c2\u6570\uff1a\u652f\u6301\u591a\u4e2a\uff0c\u6bcf\u4e00\u4e2a\u8868\u793a\u88ab\u5220\u9664\u7684\uff0c\u7a7a\u683c\u8fdb\u884c\u5206\u9694</li> <li>\u9009\u9879\uff1a-r\uff0c\u5220\u9664\u6587\u4ef6\u5939\u4f7f\u7528</li> <li>\u9009\u9879\uff1a-f\uff0c\u5f3a\u5236\u5220\u9664\uff0c\u4e0d\u4f1a\u7ed9\u51fa\u786e\u8ba4\u63d0\u793a\uff0c\u4e00\u822croot\u7528\u6237\u4f1a\u7528\u5230</li> </ul> <p>rm\u547d\u4ee4\u5f88\u5371\u9669\uff0c\u4e00\u5b9a\u8981\u6ce8\u610f\uff0c\u7279\u522b\u662f\u5207\u6362\u5230root\u7528\u6237\u7684\u65f6\u5019\u3002</p>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#which","title":"which\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u67e5\u770b\u547d\u4ee4\u7684\u7a0b\u5e8f\u672c\u4f53\u6587\u4ef6\u8def\u5f84</p> <p>\u8bed\u6cd5\uff1a<code>which \u53c2\u6570</code></p> <ul> <li>\u53c2\u6570\uff1a\u88ab\u67e5\u770b\u7684\u547d\u4ee4</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#find","title":"find\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u641c\u7d22\u6587\u4ef6</p> <p>\u8bed\u6cd51\u6309\u6587\u4ef6\u540d\u641c\u7d22\uff1a<code>find \u8def\u5f84 -name \u53c2\u6570</code></p> <ul> <li>\u8def\u5f84\uff0c\u641c\u7d22\u7684\u8d77\u59cb\u8def\u5f84</li> <li>\u53c2\u6570\uff0c\u641c\u7d22\u7684\u5173\u952e\u5b57\uff0c\u652f\u6301\u901a\u914d\u7b26*\uff0c \u6bd4\u5982\uff1a<code>*</code>test\u8868\u793a\u641c\u7d22\u4efb\u610f\u4ee5test\u7ed3\u5c3e\u7684\u6587\u4ef6</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#grep","title":"grep\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u8fc7\u6ee4\u5173\u952e\u5b57</p> <p>\u8bed\u6cd5\uff1a<code>grep [-n] \u5173\u952e\u5b57 \u6587\u4ef6\u8def\u5f84</code></p> <ul> <li>\u9009\u9879-n\uff0c\u53ef\u9009\uff0c\u8868\u793a\u5728\u7ed3\u679c\u4e2d\u663e\u793a\u5339\u914d\u7684\u884c\u7684\u884c\u53f7\u3002</li> <li>\u53c2\u6570\uff0c\u5173\u952e\u5b57\uff0c\u5fc5\u586b\uff0c\u8868\u793a\u8fc7\u6ee4\u7684\u5173\u952e\u5b57\uff0c\u5e26\u6709\u7a7a\u683c\u6216\u5176\u5b83\u7279\u6b8a\u7b26\u53f7\uff0c\u5efa\u8bae\u4f7f\u7528\u201d\u201d\u5c06\u5173\u952e\u5b57\u5305\u56f4\u8d77\u6765</li> <li>\u53c2\u6570\uff0c\u6587\u4ef6\u8def\u5f84\uff0c\u5fc5\u586b\uff0c\u8868\u793a\u8981\u8fc7\u6ee4\u5185\u5bb9\u7684\u6587\u4ef6\u8def\u5f84\uff0c\u53ef\u4f5c\u4e3a\u5185\u5bb9\u8f93\u5165\u7aef\u53e3</li> </ul> <p>\u53c2\u6570\u6587\u4ef6\u8def\u5f84\uff0c\u53ef\u4ee5\u4f5c\u4e3a\u7ba1\u9053\u7b26\u7684\u8f93\u5165</p>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#wc","title":"wc\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u7edf\u8ba1</p> <p>\u8bed\u6cd5\uff1a<code>wc [-c -m -l -w] \u6587\u4ef6\u8def\u5f84</code></p> <ul> <li>\u9009\u9879\uff0c-c\uff0c\u7edf\u8ba1bytes\u6570\u91cf</li> <li>\u9009\u9879\uff0c-m\uff0c\u7edf\u8ba1\u5b57\u7b26\u6570\u91cf</li> <li>\u9009\u9879\uff0c-l\uff0c\u7edf\u8ba1\u884c\u6570</li> <li>\u9009\u9879\uff0c-w\uff0c\u7edf\u8ba1\u5355\u8bcd\u6570\u91cf</li> <li>\u53c2\u6570\uff0c\u6587\u4ef6\u8def\u5f84\uff0c\u88ab\u7edf\u8ba1\u7684\u6587\u4ef6\uff0c\u53ef\u4f5c\u4e3a\u5185\u5bb9\u8f93\u5165\u7aef\u53e3</li> </ul> <p>\u53c2\u6570\u6587\u4ef6\u8def\u5f84\uff0c\u53ef\u4f5c\u4e3a\u7ba1\u9053\u7b26\u7684\u8f93\u5165</p>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#_4","title":"\u7ba1\u9053\u7b26|","text":"<p>\u5199\u6cd5\uff1a<code>|</code></p> <p>\u529f\u80fd\uff1a\u5c06\u7b26\u53f7\u5de6\u8fb9\u7684\u7ed3\u679c\uff0c\u4f5c\u4e3a\u7b26\u53f7\u53f3\u8fb9\u7684\u8f93\u5165</p> <p>\u793a\u4f8b\uff1a</p> <p><code>cat a.txt | grep itheima</code>\uff0c\u5c06cat a.txt\u7684\u7ed3\u679c\uff0c\u4f5c\u4e3agrep\u547d\u4ee4\u7684\u8f93\u5165\uff0c\u7528\u6765\u8fc7\u6ee4<code>itheima</code>\u5173\u952e\u5b57</p> <p>\u53ef\u4ee5\u652f\u6301\u5d4c\u5957\uff1a</p> <p><code>cat a.txt | grep itheima | grep itcast</code></p>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#echo","title":"echo\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u8f93\u51fa\u5185\u5bb9</p> <p>\u8bed\u6cd5\uff1a<code>echo \u53c2\u6570</code></p> <ul> <li>\u53c2\u6570\uff1a\u88ab\u8f93\u51fa\u7684\u5185\u5bb9</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#_5","title":"`\u53cd\u5f15\u53f7","text":"<p>\u529f\u80fd\uff1a\u88ab\u4e24\u4e2a\u53cd\u5f15\u53f7\u5305\u56f4\u7684\u5185\u5bb9\uff0c\u4f1a\u4f5c\u4e3a\u547d\u4ee4\u6267\u884c</p> <p>\u793a\u4f8b\uff1a</p> <ul> <li>echo `pwd`\uff0c\u4f1a\u8f93\u51fa\u5f53\u524d\u5de5\u4f5c\u76ee\u5f55</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#tail","title":"tail\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u67e5\u770b\u6587\u4ef6\u5c3e\u90e8\u5185\u5bb9</p> <p>\u8bed\u6cd5\uff1a<code>tail [-f] \u53c2\u6570</code></p> <ul> <li>\u53c2\u6570\uff1a\u88ab\u67e5\u770b\u7684\u6587\u4ef6</li> <li>\u9009\u9879\uff1a-f\uff0c\u6301\u7eed\u8ddf\u8e2a\u6587\u4ef6\u4fee\u6539</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#head","title":"head\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u67e5\u770b\u6587\u4ef6\u5934\u90e8\u5185\u5bb9</p> <p>\u8bed\u6cd5\uff1a<code>head [-n] \u53c2\u6570</code></p> <ul> <li>\u53c2\u6570\uff1a\u88ab\u67e5\u770b\u7684\u6587\u4ef6</li> <li>\u9009\u9879\uff1a-n\uff0c\u67e5\u770b\u7684\u884c\u6570</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#_6","title":"\u91cd\u5b9a\u5411\u7b26","text":"<p>\u529f\u80fd\uff1a\u5c06\u7b26\u53f7\u5de6\u8fb9\u7684\u7ed3\u679c\uff0c\u8f93\u51fa\u5230\u53f3\u8fb9\u6307\u5b9a\u7684\u6587\u4ef6\u4e2d\u53bb</p> <ul> <li><code>&gt;</code>\uff0c\u8868\u793a\u8986\u76d6\u8f93\u51fa</li> <li><code>&gt;&gt;</code>\uff0c\u8868\u793a\u8ffd\u52a0\u8f93\u51fa</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#vi","title":"vi\u7f16\u8f91\u5668","text":""},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#_7","title":"\u547d\u4ee4\u6a21\u5f0f\u5feb\u6377\u952e","text":""},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#_8","title":"\u5e95\u7ebf\u547d\u4ee4\u5feb\u6377\u952e","text":""},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#_9","title":"\u547d\u4ee4\u7684\u9009\u9879","text":"<p>\u6211\u4eec\u5b66\u4e60\u7684\u4e00\u7cfb\u5217Linux\u547d\u4ee4\uff0c\u5b83\u4eec\u6240\u62e5\u6709\u7684\u9009\u9879\u90fd\u662f\u975e\u5e38\u591a\u7684\u3002</p> <p>\u6bd4\u5982\uff0c\u7b80\u5355\u7684ls\u547d\u4ee4\u5c31\u6709\uff1a-a -A -b -c -C -d -D -f -F -g -G -h -H -i -I -k -l -L -m -n -N -o -p -q -Q -r-R -s -S -t -T -u -U -v -w -x -X -1\u7b49\u9009\u9879\uff0c\u53ef\u4ee5\u53d1\u73b0\u9009\u9879\u662f\u6781\u5176\u591a\u7684\u3002</p> <p>\u8bfe\u7a0b\u4e2d\uff0c \u5e76\u4e0d\u4f1a\u5c06\u5168\u90e8\u7684\u9009\u9879\u90fd\u8fdb\u884c\u8bb2\u89e3\uff0c\u5426\u5219\uff0c\u4e00\u4e2als\u547d\u4ee4\u5c31\u53ef\u80fd\u8bb2\u89e32\u5c0f\u65f6\u4e4b\u4e45\u3002</p> <p>\u8bfe\u7a0b\u4e2d\uff0c\u4f1a\u5bf9\u5e38\u89c1\u7684\u9009\u9879\u8fdb\u884c\u8bb2\u89e3\uff0c \u8db3\u591f\u6ee1\u8db3\u7edd\u5927\u591a\u6570\u7684\u5b66\u4e60\u3001\u5de5\u4f5c\u573a\u666f\u3002</p>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#_10","title":"\u67e5\u770b\u547d\u4ee4\u7684\u5e2e\u52a9","text":"<p>\u53ef\u4ee5\u901a\u8fc7\uff1a<code>\u547d\u4ee4 --help</code>\u67e5\u770b\u547d\u4ee4\u7684\u5e2e\u52a9\u624b\u518c</p> <p></p>"},{"location":"markdown/operation_utils/Linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/#_11","title":"\u67e5\u770b\u547d\u4ee4\u7684\u8be6\u7ec6\u624b\u518c","text":"<p>\u53ef\u4ee5\u901a\u8fc7\uff1a<code>man \u547d\u4ee4</code>\u67e5\u770b\u67d0\u547d\u4ee4\u7684\u8be6\u7ec6\u624b\u518c</p> <p></p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/","title":"Linux\u5e38\u7528\u64cd\u4f5c","text":""},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#_1","title":"\u8f6f\u4ef6\u5b89\u88c5","text":"<ul> <li>CentOS\u7cfb\u7edf\u4f7f\u7528\uff1a</li> <li>yum [install remove search] [-y] \u8f6f\u4ef6\u540d\u79f0<ul> <li>install \u5b89\u88c5</li> <li>remove \u5378\u8f7d</li> <li>search \u641c\u7d22</li> <li>-y\uff0c\u81ea\u52a8\u786e\u8ba4</li> </ul> </li> <li>Ubuntu\u7cfb\u7edf\u4f7f\u7528</li> <li>apt [install remove search] [-y] \u8f6f\u4ef6\u540d\u79f0<ul> <li>install \u5b89\u88c5</li> <li>remove \u5378\u8f7d</li> <li>search \u641c\u7d22  </li> <li>-y\uff0c\u81ea\u52a8\u786e\u8ba4</li> </ul> </li> </ul> <p>yum \u548c apt \u5747\u9700\u8981root\u6743\u9650</p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#systemctl","title":"systemctl","text":"<p>\u529f\u80fd\uff1a\u63a7\u5236\u7cfb\u7edf\u670d\u52a1\u7684\u542f\u52a8\u5173\u95ed\u7b49</p> <p>\u8bed\u6cd5\uff1a<code>systemctl start | stop | restart | disable | enable | status \u670d\u52a1\u540d</code></p> <ul> <li>start\uff0c\u542f\u52a8</li> <li>stop\uff0c\u505c\u6b62</li> <li>status\uff0c\u67e5\u770b\u72b6\u6001</li> <li>disable\uff0c\u5173\u95ed\u5f00\u673a\u81ea\u542f</li> <li>enable\uff0c\u5f00\u542f\u5f00\u673a\u81ea\u542f</li> <li>restart\uff0c\u91cd\u542f </li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#_2","title":"\u8f6f\u94fe\u63a5","text":"<p> \u529f\u80fd\uff1a\u521b\u5efa\u6587\u4ef6\u3001\u6587\u4ef6\u5939\u8f6f\u94fe\u63a5\uff08\u5feb\u6377\u65b9\u5f0f\uff09</p> <p>\u8bed\u6cd5\uff1a<code>ln -s \u53c2\u65701 \u53c2\u65702</code></p> <ul> <li>\u53c2\u65701\uff1a\u88ab\u94fe\u63a5\u7684</li> <li>\u53c2\u65702\uff1a\u8981\u94fe\u63a5\u53bb\u7684\u5730\u65b9\uff08\u5feb\u6377\u65b9\u5f0f\u7684\u540d\u79f0\u548c\u5b58\u653e\u4f4d\u7f6e\uff09</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#_3","title":"\u65e5\u671f","text":"<p>\u8bed\u6cd5\uff1a<code>date [-d] [+\u683c\u5f0f\u5316\u5b57\u7b26\u4e32]</code></p> <ul> <li> <p>-d \u6309\u7167\u7ed9\u5b9a\u7684\u5b57\u7b26\u4e32\u663e\u793a\u65e5\u671f\uff0c\u4e00\u822c\u7528\u4e8e\u65e5\u671f\u8ba1\u7b97</p> </li> <li> <p>\u683c\u5f0f\u5316\u5b57\u7b26\u4e32\uff1a\u901a\u8fc7\u7279\u5b9a\u7684\u5b57\u7b26\u4e32\u6807\u8bb0\uff0c\u6765\u63a7\u5236\u663e\u793a\u7684\u65e5\u671f\u683c\u5f0f</p> </li> <li>%Y   \u5e74%y   \u5e74\u4efd\u540e\u4e24\u4f4d\u6570\u5b57 (00..99)</li> <li>%m   \u6708\u4efd (01..12)</li> <li>%d   \u65e5 (01..31)</li> <li>%H   \u5c0f\u65f6 (00..23)</li> <li>%M   \u5206\u949f (00..59)</li> <li>%S   \u79d2 (00..60)</li> <li>%s   \u81ea 1970-01-01 00:00:00 UTC \u5230\u73b0\u5728\u7684\u79d2\u6570</li> </ul> <p>\u793a\u4f8b\uff1a</p> <ul> <li>\u6309\u71672022-01-01\u7684\u683c\u5f0f\u663e\u793a\u65e5\u671f</li> </ul> <p></p> <ul> <li>\u6309\u71672022-01-01 10:00:00\u7684\u683c\u5f0f\u663e\u793a\u65e5\u671f</li> </ul> <p></p> <ul> <li>-d\u9009\u9879\u65e5\u671f\u8ba1\u7b97</li> </ul> <p></p> <ul> <li> <p>\u652f\u6301\u7684\u65f6\u95f4\u6807\u8bb0\u4e3a\uff1a</p> <p></p> </li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#_4","title":"\u65f6\u533a","text":"<p>\u4fee\u6539\u65f6\u533a\u4e3a\u4e2d\u56fd\u65f6\u533a</p> <p></p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#ntp","title":"ntp","text":"<p>\u529f\u80fd\uff1a\u540c\u6b65\u65f6\u95f4</p> <p>\u5b89\u88c5\uff1a<code>yum install -y ntp</code></p> <p>\u542f\u52a8\u7ba1\u7406\uff1a<code>systemctl start | stop | restart | status | disable | enable ntpd</code></p> <p>\u901a\u8fc7\u963f\u91cc\u4e91\u7684\u65f6\u95f4\u6821\u51c6\u670d\u52a1\u5668\u624b\u52a8\u6821\u51c6\u65f6\u95f4\uff1a<code>ntpdate -u ntp.aliyun.com</code></p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#ip","title":"ip\u5730\u5740","text":"<p>\u683c\u5f0f\uff1aa.b.c.d</p> <ul> <li>abcd\u4e3a0~255\u7684\u6570\u5b57</li> </ul> <p>\u7279\u6b8aIP\uff1a</p> <ul> <li>127.0.0.1\uff0c\u8868\u793a\u672c\u673a</li> <li>0.0.0.0</li> <li>\u53ef\u4ee5\u8868\u793a\u672c\u673a</li> <li>\u4e5f\u53ef\u4ee5\u8868\u793a\u4efb\u610fIP\uff08\u770b\u4f7f\u7528\u573a\u666f\uff09\uff0c\u653e\u884cip\u8bbe\u7f6e\u4e3a0.0.0.0\uff0c\u8868\u793a\u5141\u8bb8\u4efb\u610fip</li> </ul> <p>\u67e5\u770bip\uff1a<code>ifconfig</code></p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#_5","title":"\u4e3b\u673a\u540d","text":"<p>\u529f\u80fd\uff1aLinux\u7cfb\u7edf\u7684\u540d\u79f0</p> <p>\u67e5\u770b\uff1a<code>hostname</code></p> <p>\u8bbe\u7f6e\uff1a<code>hostnamectl set-hostname \u4e3b\u673a\u540d</code></p> <p>\u767e\u5ea6\u7f51\u7ad9\u7684ip\u5730\u5740\u53ef\u4ee5\u88ab\u89e3\u6790\u4e3awww.baidu.com\u8fd9\u4e2a\u57df\u540d  </p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#vmwareip","title":"\u914d\u7f6eVmware\u56fa\u5b9aIP","text":"<p> 1. \u4fee\u6539Vmware\u7f51\u7edc\uff0c\u53c2\u9605PPT\uff0c\u56fe\u592a\u591a</p> <ol> <li>\u8bbe\u7f6eLinux\u5185\u90e8\u56fa\u5b9aIP</li> </ol> <p>\u4fee\u6539\u6587\u4ef6\uff1a<code>/etc/sysconfig/network-scripts/ifcfg-ens33</code></p> <p>\u793a\u4f8b\u6587\u4ef6\u5185\u5bb9\uff1a</p> <pre><code>TYPE=\"Ethernet\"\nPROXY_METHOD=\"none\"\nBROWSER_ONLY=\"no\"\nBOOTPROTO=\"static\"           # \u6539\u4e3astatic\uff0c\u56fa\u5b9aIP\nDEFROUTE=\"yes\"\nIPV4_FAILURE_FATAL=\"no\"\nIPV6INIT=\"yes\"\nIPV6_AUTOCONF=\"yes\"\nIPV6_DEFROUTE=\"yes\"\nIPV6_FAILURE_FATAL=\"no\"\nIPV6_ADDR_GEN_MODE=\"stable-privacy\"\nNAME=\"ens33\"\nUUID=\"1b0011cb-0d2e-4eaa-8a11-af7d50ebc876\"\nDEVICE=\"ens33\"\nONBOOT=\"yes\"\nIPADDR=\"192.168.88.131\"      # IP\u5730\u5740\uff0c\u81ea\u5df1\u8bbe\u7f6e\uff0c\u8981\u5339\u914d\u7f51\u7edc\u8303\u56f4\nNETMASK=\"255.255.255.0\"      # \u5b50\u7f51\u63a9\u7801\uff0c\u56fa\u5b9a\u5199\u6cd5255.255.255.0\nGATEWAY=\"192.168.88.2\"       # \u7f51\u5173\uff0c\u8981\u548cVMware\u4e2d\u914d\u7f6e\u7684\u4e00\u81f4\nDNS1=\"192.168.88.2\"          # DNS1\u670d\u52a1\u5668\uff0c\u548c\u7f51\u5173\u4e00\u81f4\u5373\u53ef\n</code></pre>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#ps","title":"ps\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u67e5\u770b\u8fdb\u7a0b\u4fe1\u606f</p> <p>\u8bed\u6cd5\uff1a<code>ps -ef</code>\uff0c\u67e5\u770b\u5168\u90e8\u8fdb\u7a0b\u4fe1\u606f\uff0c\u53ef\u4ee5\u642d\u914dgrep\u505a\u8fc7\u6ee4\uff1a<code>ps -ef | grep xxx</code> </p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#kill","title":"kill\u547d\u4ee4","text":""},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#nmap","title":"nmap\u547d\u4ee4","text":""},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#netstat","title":"netstat\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u67e5\u770b\u7aef\u53e3\u5360\u7528</p> <p>\u7528\u6cd5\uff1a<code>netstat -anp | grep xxx</code>  xxx\u4ee3\u8868\u8981\u67e5\u770b\u7684\u7aef\u53e3</p> <p> </p> <p>nmap\u547d\u4ee4\u4e5f\u53ef\u4ee5\u67e5\u770b\u7aef\u53e3, e.g. nmap 127.0.0.1 \u67e5\u770b\u672c\u673a\u5360\u7528\u7aef\u53e3 </p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#ping","title":"ping\u547d\u4ee4","text":"<p>\u6d4b\u8bd5\u7f51\u7edc\u662f\u5426\u8054\u901a</p> <p>\u8bed\u6cd5\uff1a<code>ping [-c num] \u53c2\u6570</code></p> <p></p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#wget","title":"wget\u547d\u4ee4","text":""},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#curl","title":"curl\u547d\u4ee4","text":""},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#top","title":"top\u547d\u4ee4","text":"<p>\u529f\u80fd\uff1a\u67e5\u770b\u4e3b\u673a\u8fd0\u884c\u72b6\u6001</p> <p>\u8bed\u6cd5\uff1a<code>top</code>\uff0c\u67e5\u770b\u57fa\u7840\u4fe1\u606f  \u8d1f\u8f7d\u4e3a1\u53ef\u4ee5\u7406\u89e3\u4e3a\u6709\u4e00\u9897cpu\u5f88\u7e41\u5fd9 </p> <p>\u53ef\u7528\u9009\u9879\uff1a</p> <p></p> <p>\u4ea4\u4e92\u5f0f\u6a21\u5f0f\u4e2d\uff0c\u53ef\u7528\u5feb\u6377\u952e\uff1a</p> <p></p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#df","title":"df\u547d\u4ee4","text":"<p>\u67e5\u770b\u78c1\u76d8\u5360\u7528</p> <p></p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#iostat","title":"iostat\u547d\u4ee4","text":"<p>\u67e5\u770bCPU\u3001\u78c1\u76d8\u7684\u76f8\u5173\u4fe1\u606f</p> <p></p> <p></p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#sar","title":"sar\u547d\u4ee4","text":"<p>\u67e5\u770b\u7f51\u7edc\u7edf\u8ba1</p> <p></p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#_6","title":"\u73af\u5883\u53d8\u91cf","text":"<p>  - export \u7528\u4e8e\u6dfb\u52a0\u73af\u5883\u53d8\u91cf - \u4e34\u65f6\u8bbe\u7f6e\uff1aexport \u53d8\u91cf\u540d=\u53d8\u91cf\u503c - \u6c38\u4e45\u8bbe\u7f6e\uff1a   - \u9488\u5bf9\u7528\u6237\uff0c\u8bbe\u7f6e\u7528\u6237HOME\u76ee\u5f55\u5185\uff1a<code>~/.bashrc</code>\u6587\u4ef6(bash) \u6216<code>~/.zshrc</code>\u6587\u4ef6(zsh)   - \u9488\u5bf9\u5168\u5c40\uff0c\u8bbe\u7f6e<code>/etc/profile</code>     * \u5728\u6587\u4ef6\u4e2d\u6dfb\u52a0 <code>export \u53d8\u91cf\u540d=\u53d8\u91cf\u503c</code>      * \u8f93\u5165\u547d\u4ee4<code>source \u4fee\u6539\u7684\u8def\u5f84\u540d\u79f0</code>\u8ba9\u4fee\u6539\u751f\u6548 - \u67e5\u770b\u73af\u5883\u53d8\u91cf: echo $env_var_name</p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#path","title":"PATH\u53d8\u91cf","text":"<ul> <li> <p>PATH\u662f\u4e00\u4e2a\u7279\u6b8a\u4e14\u975e\u5e38\u91cd\u8981\u7684\u73af\u5883\u53d8\u91cf\u3002\u5b83\u5b9a\u4e49\u4e86\u7cfb\u7edf\u5728\u6267\u884c\u547d\u4ee4\u65f6\u641c\u7d22\u53ef\u6267\u884c\u6587\u4ef6\u7684\u76ee\u5f55\u5217\u8868\u3002</p> </li> <li> <p>\u53ef\u4ee5\u5c06\u81ea\u5b9a\u4e49\u8def\u5f84\u52a0\u5165PATH\u5185\uff0c\u5b9e\u73b0\u81ea\u5b9a\u4e49\u547d\u4ee4\u5728\u4efb\u610f\u5730\u65b9\u5747\u53ef\u6267\u884c\u7684\u6548\u679c\u3002</p> </li> <li> <p>\u5982\u679cexport PATH=\"~./bin:$PATH\"\uff0c\u90a3\u4e48\u5728~./bin\u76ee\u5f55\u4e0b\u7684\u6240\u6709\u53ef\u6267\u884c\u6587\u4ef6\uff0c\u90fd\u53ef\u4ee5\u5728zsh\u7ec8\u7aef\u8fd0\u884c\u65f6\u88ab\u7cfb\u7edf\u67e5\u627e\u5230 </p> </li> <li>\u4f8b\u5982\uff0c\u5c06python\u6dfb\u52a0\u5230\u53ef\u6267\u884c\u7a0b\u5e8f\u7684\u641c\u7d22\u8def\u5f84: export PATH=\"/Users/wenglongao/anaconda3/envs/torch/bin/python:$PATH\" </li> <li>\u6ce8\u610f\u4e24\u79cdexport\u7684\u5199\u6cd5\u7684\u533a\u522b</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#_7","title":"$\u7b26\u53f7","text":"<p>\u53ef\u4ee5\u53d6\u51fa\u6307\u5b9a\u7684\u73af\u5883\u53d8\u91cf\u7684\u503c</p> <p>\u8bed\u6cd5\uff1a<code>$\u53d8\u91cf\u540d</code></p> <p>\u793a\u4f8b\uff1a</p> <p><code>echo $PATH</code>\uff0c\u8f93\u51faPATH\u73af\u5883\u53d8\u91cf\u7684\u503c</p> <p><code>echo ${PATH}ABC</code>\uff0c\u8f93\u51faPATH\u73af\u5883\u53d8\u91cf\u7684\u503c\u4ee5\u53caABC</p> <p>\u5982\u679c\u53d8\u91cf\u540d\u548c\u5176\u5b83\u5185\u5bb9\u6df7\u6dc6\u5728\u4e00\u8d77\uff0c\u53ef\u4ee5\u4f7f\u7528${}</p> <p></p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#_8","title":"\u538b\u7f29\u89e3\u538b","text":""},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#_9","title":"\u538b\u7f29","text":"<p><code>tar -zcvf \u538b\u7f29\u5305 \u88ab\u538b\u7f291 \u88ab\u538b\u7f292 ... \u88ab\u538b\u7f29N</code> * .tar\u683c\u5f0f\uff1atar -cvf\uff0c\u4f53\u79ef\u4e0d\u4f1a\u53d8\u5c0f * .tar.gz\u683c\u5f0f\uff1atar -zcvf\uff0c\u4f53\u79ef\u53d8\u5c0f\u660e\u663e - -z\u8868\u793a\u4f7f\u7528gzip\uff0c\u53ef\u4ee5\u4e0d\u5199 </p> <p><code>zip [-r] \u53c2\u65701 \u53c2\u65702 \u53c2\u6570N</code></p> <p></p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#_10","title":"\u89e3\u538b","text":"<p><code>tar -zxvf \u88ab\u89e3\u538b\u7684\u6587\u4ef6 -C \u8981\u89e3\u538b\u53bb\u7684\u5730\u65b9</code></p> <ul> <li>-z\u8868\u793a\u4f7f\u7528gzip\uff0c\u53ef\u4ee5\u7701\u7565</li> <li>-C\uff0c\u53ef\u4ee5\u7701\u7565\uff0c\u6307\u5b9a\u8981\u89e3\u538b\u53bb\u7684\u5730\u65b9\uff0c\u4e0d\u5199\u89e3\u538b\u5230\u5f53\u524d\u76ee\u5f55</li> </ul> <p></p> <p><code>unzip</code> </p> <p>\u603b\u7ed3</p> <p></p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#_11","title":"\u4e0a\u4f20\u3001\u4e0b\u8f7d","text":"<ul> <li>\u901a\u8fc7final shell\u76f4\u63a5\u62d6\u62fd</li> </ul> <p> * \u901a\u8fc7rz\u3001sz\u547d\u4ee4</p> <p></p> <p><code>unzip [-d] \u53c2\u6570</code></p> <p></p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#su","title":"su\u547d\u4ee4","text":"<p>\u5207\u6362\u7528\u6237</p> <p>\u8bed\u6cd5\uff1a<code>su [-] [\u7528\u6237]</code></p> <p></p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#sudo","title":"sudo\u547d\u4ee4","text":"<p>\u6bd4\u5982\uff1a</p> <pre><code>itheima ALL=(ALL)       NOPASSWD: ALL\n</code></pre> <p>\u5728visudo\u5185\u914d\u7f6e\u5982\u4e0a\u5185\u5bb9\uff0c\u53ef\u4ee5\u8ba9itheima\u7528\u6237\uff0c\u65e0\u9700\u5bc6\u7801\u76f4\u63a5\u4f7f\u7528<code>sudo</code></p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#chmod","title":"chmod\u547d\u4ee4","text":"<p>\u4fee\u6539\u6587\u4ef6\u3001\u6587\u4ef6\u5939\u6743\u9650</p> <p>\u8bed\u6cd5\uff1a<code>chmod [-R] \u6743\u9650 \u53c2\u6570</code></p> <ul> <li>\u6743\u9650\uff0c\u8981\u8bbe\u7f6e\u7684\u6743\u9650\uff0c\u6bd4\u5982755\uff0c\u8868\u793a\uff1a<code>rwxr-xr-x</code></li> </ul> <p></p> <ul> <li> <p>\u53c2\u6570\uff0c\u88ab\u4fee\u6539\u7684\u6587\u4ef6\u3001\u6587\u4ef6\u5939</p> </li> <li> <p>\u9009\u9879-R\uff0c\u8bbe\u7f6e\u6587\u4ef6\u5939\u548c\u5176\u5185\u90e8\u5168\u90e8\u5185\u5bb9\u4e00\u6837\u751f\u6548</p> </li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#chown","title":"chown\u547d\u4ee4","text":"<p>\u4fee\u6539\u6587\u4ef6\u3001\u6587\u4ef6\u5939\u6240\u5c5e\u7528\u6237\u3001\u7ec4</p> <p>\u8bed\u6cd5\uff1a<code>chown [-R] [\u7528\u6237][:][\u7528\u6237\u7ec4] \u6587\u4ef6\u6216\u6587\u4ef6\u5939</code></p> <p></p>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#_12","title":"\u7528\u6237\u7ec4\u7ba1\u7406","text":""},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#_13","title":"\u7528\u6237\u7ba1\u7406","text":""},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#genenv","title":"genenv\u547d\u4ee4","text":"<ul> <li><code>getenv group</code>\uff0c\u67e5\u770b\u7cfb\u7edf\u5168\u90e8\u7684\u7528\u6237\u7ec4</li> </ul> <ul> <li><code>getenv passwd</code>\uff0c\u67e5\u770b\u7cfb\u7edf\u5168\u90e8\u7684\u7528\u6237</li> </ul>"},{"location":"markdown/operation_utils/Linux%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#env","title":"env\u547d\u4ee4","text":"<p>\u67e5\u770b\u7cfb\u7edf\u5168\u90e8\u7684\u73af\u5883\u53d8\u91cf</p> <p>\u8bed\u6cd5\uff1a<code>env</code></p>"},{"location":"markdown/operation_utils/OS%E5%BF%AB%E6%8D%B7%E6%93%8D%E4%BD%9C/","title":"MacOS\u64cd\u4f5c","text":"<p>\u8bb0\u5f55\u4e00\u4e9bOS\u5e38\u7528\u7684\u5feb\u6377\u64cd\u4f5c</p> <ul> <li><code>shift + cmd + \u3002</code> \u663e\u793a\u8bbf\u8fbe\u9690\u85cf\u6587\u4ef6</li> <li><code>mkdir \u201cpath\u201d</code>  \u5728\u5f53\u524d\u8def\u5f84\u4e0b\u65b0\u5efa\u8def\u5f84</li> <li><code>cd \u201cpath\u201d</code>  \u524d\u5f80\u8def\u5f84</li> <li><code>rm test.txt</code>   \u5728\u5f53\u524d\u8def\u5f84\u4e0b\u5220\u9664\u6587\u4ef6</li> <li><code>pwd</code>         \u67e5\u770b\u5f53\u524d\u8def\u5f84</li> <li><code>cat test.txt</code>  \u67e5\u770b\u5f53\u524d\u8def\u5f84\u4e0b\u7684\u6307\u5b9a\u6587\u4ef6\u5185\u5bb9</li> <li><code>chsh -s /bin/zsh</code> \u5c06\u7ec8\u7aef\u4e2d\u4f7f\u7528zsh\u547d\u4ee4\uff0c\u91cd\u542f\u540e\u751f\u6548</li> <li><code>chsh -s /bin/bash</code> \u5c06\u7ec8\u7aef\u4e2d\u4f7f\u7528bash\u547d\u4ee4\uff0c\u91cd\u542f\u540e\u751f\u6548</li> <li><code>alias | grep python</code> \u68c0\u67e5\u662f\u5426\u4e3apython\u8bbe\u7f6e\u522b\u540d\uff0c\u5982\u679c\u8bbe\u7f6e\u4e86\u522b\u540d\uff0c\u90a3\u4e48\u5728\u7ec8\u7aef\u8fd0\u884cpython\u547d\u4ee4\uff0c\u5c31\u4f1a\u81ea\u52a8\u8c03\u7528\u522b\u540d</li> <li><code>unalias python</code> \u79fb\u9664python\u7684\u522b\u540d</li> <li><code>source ~/.zshrc</code> \u91cd\u65b0\u52a0\u8f7dzsh\u914d\u7f6e\u6587\u4ef6\u3002.zshrc</li> </ul> <p>MacOS\u63d0\u793a\u6587\u4ef6\u635f\u574f * <code>sudo spctl \u2013master-disable</code>\uff0c\u8f93\u5165\u5bc6\u7801\u56de\u8f66\uff0c\u7136\u540e\u53bb\u8bbe\u7f6e\u4e2d\u6253\u5f00\u4efb\u610f\u6765\u6e90 * <code>sudo xattr -cr \u62d6\u5165\u8981\u6253\u5f00\u7684app</code> \u7136\u540e\u53bb\u8bbe\u7f6e\u4e2d\u70b9\u51fb\u4ecd\u8981\u6253\u5f00\u5373\u53ef \u53c2\u8003\u6587\u7ae0 \u53c2\u8003\u6587\u7ae0</p>"},{"location":"markdown/operation_utils/OS%E5%BF%AB%E6%8D%B7%E6%93%8D%E4%BD%9C/#vim","title":"Vim\u76f8\u5173\u64cd\u4f5c","text":"<ul> <li>:q! \u5f3a\u5236\u9000\u51favim</li> <li>:wq! </li> </ul>"},{"location":"markdown/operation_utils/conda%E6%93%8D%E4%BD%9C/","title":"Conda\u64cd\u4f5c","text":""},{"location":"markdown/operation_utils/conda%E6%93%8D%E4%BD%9C/#conda","title":"conda\u7b49\u7684\u64cd\u4f5c","text":""},{"location":"markdown/operation_utils/conda%E6%93%8D%E4%BD%9C/#conda_1","title":"conda\u64cd\u4f5c","text":"<ul> <li><code>conda --version</code>  \u67e5\u770b\u5b89\u88c5\u7684conda\u7684\u7248\u672c</li> <li><code>conda env list</code>  \u67e5\u770b\u5df2\u7ecf\u5b89\u88c5\u7684\u73af\u5883\u5217\u8868</li> <li><code>conda create -n leoweng_test python==3.9</code> \u521b\u5efa\u73af\u5883</li> <li><code>conda activate leoweng_test</code> \u6fc0\u6d3b\u73af\u5883</li> <li><code>conda remove -n leoweng1.0 --all</code> \u5220\u9664\u73af\u5883</li> <li><code>conda remove -h  pandas</code>   \u5220\u9664\u5305</li> <li><code>conda create -n leoweng_test_1 --clone leoweng_test</code> \u5c06\u5df2\u6709\u73af\u5883\u590d\u5236\u4e00\u4efd\uff0c\u6765\u521b\u5efa\u65b0\u7684\u73af\u5883</li> <li><code>conda env export &gt; /Users/wenglongao/Downloads/leoweng_test.yaml</code> \u5c06\u73af\u5883\u5bfc\u51fa\u4e3ayaml\u6587\u4ef6</li> <li><code>conda env create -f /Users/wenglongao/prep/code/platform-engineering/psaconda/pm_1.6.yaml</code>  \u7528yaml\u6587\u4ef6\u521b\u5efa\u73af\u5883</li> <li><code>conda install -p /Users/wenglongao/miniforge3/envs/lgbm package_name</code> \u5728miniforge3\u521b\u5efa\u7684\u73af\u5883\u4e2d\u5b89\u88c5package</li> <li><code>/Users/wenglongao/miniforge3/bin/conda init zsh</code> \u542f\u52a8miniforge3\u5b89\u88c5\u7684base</li> <li><code>/Users/wenglongao/anaconda3/bin/conda init zsh</code> \u542f\u52a8anaconda\u5b89\u88c5\u7684base\uff0c\u4e24\u8005\u7684\u5173\u952e\u90fd\u5728\u4e8e\u770bconda\u7684Unix\u6587\u4ef6\u5728\u54ea\u91cc\uff0c\u7136\u540e\u521d\u59cb\u5316anaconda\u4e0eminiforge3\u7684base\u5207\u6362_miniforge3\u548canaconda-CSDN\u535a\u5ba2\u6ce8\u610f\uff01\u8fd9\u4e00\u6b65\u9700\u8981\u6574\u884c\u547d\u4ee4\u4e00\u8d77\u6267\u884c\uff0c\u6267\u884c\u5b8c\u6210\u540e\u91cd\u542f\u7ec8\u7aef\uff0c\u4e0d\u7136\u65e0\u6cd5\u5207\u6362\u3002</li> </ul>"},{"location":"markdown/operation_utils/conda%E6%93%8D%E4%BD%9C/#pip","title":"pip\u64cd\u4f5c","text":"<ul> <li><code>pip list</code>  \u67e5\u770b\u5f53\u524d\u73af\u5883\u4e0b\u5df2\u5b89\u88c5\u7684\u5305</li> <li><code>pip install package</code>  \u5b89\u88c5package\uff0c\u7248\u672c\u53f7\u4e3a\u6700\u65b0\u53d1\u5e03\u7684</li> <li><code>pip install pandas==2.0.3</code>  \u6307\u5b9a\u7248\u672c\u53f7\u5b89\u88c5package</li> <li><code>pip install --upgrade pandas</code>  \u66f4\u65b0package\u5230\u6700\u65b0\u53d1\u5e03\u7684\u7248\u672c\u53f7</li> <li><code>pip install --upgrade pip</code>  \u66f4\u65b0pip\u81ea\u8eab</li> <li><code>pip install --upgrade pandas==2.0.1</code>  \u5c06\u5df2\u7ecf\u5b89\u88c5\u7684package\u66f4\u65b0\u5230\u6307\u5b9a\u7248\u672c\u53f7</li> <li><code>pip uninstall</code>  pandas \u5378\u8f7d\u5305</li> <li><code>pip show --files pandas</code>  \u67e5\u770b\u5305\u5185\u8be6\u7ec6\u7684\u6587\u4ef6</li> <li><code>pip show pandas</code>  \u67e5\u770b\u5305\u8def\u5f84\u7b49</li> <li><code>pip --help</code>  \u83b7\u53d6\u547d\u4ee4\u5e2e\u52a9</li> <li><code>pip list --help</code></li> <li><code>pip show --help</code>  \u6839\u636e\u5177\u4f53\u547d\u4ee4\u83b7\u5f97\u5e2e\u52a9\uff0c\u53ef\u4ee5\u5f97\u5230pip show \u4e4b\u540e\u7684\u5177\u4f53\u64cd\u4f5c</li> <li><code>pip install &lt;package-name&gt; -i https://pypi.tuna.tsinghua.edu.cn/simple</code> \u4e34\u65f6\u8bbe\u7f6e\u6e05\u534e\u955c\u50cf\u6e90</li> <li><code>pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple</code> \u6c38\u4e45\u8bbe\u7f6e\u6e05\u534e\u955c\u50cf\u6e90</li> <li><code>pip config unset global.index-url</code> \u5c06pip\u5207\u6362\u4e3a\u9ed8\u8ba4\u6e90</li> <li><code>pip config list</code> \u67e5\u770bpip\u7684\u5b89\u88c5\u6e90</li> </ul>"},{"location":"markdown/operation_utils/conda%E6%93%8D%E4%BD%9C/#_1","title":"\u5176\u5b83\u4e00\u4e9b\u64cd\u4f5c","text":"<ul> <li><code>python -m ipykernel install --user --name leoweng_test --display-name \"Python (leoweng_test)\"</code>  \u5c06\u65b0\u73af\u5883\u6dfb\u52a0\u5230jupyter notebook\u7684kernel\uff0c\u6ce8\u610f\u5982\u679c\u51fa\u73b0dquote\u8bf4\u660e\u5f15\u53f7\u8f93\u5165\u6210\u4e2d\u6587\u7684\u4e86\uff0c\u8981\u7528\u82f1\u6587\u5f15\u53f7\u201d\u201d\u3002\u6dfb\u52a0\u65b0\u73af\u5883\u540e\u53ef\u80fd\u9700\u8981\u91cd\u542fvscode\u624d\u80fd\u751f\u6548\u3002</li> <li><code>jupyter kernelspec list</code>\u67e5\u770bjupyter notebook\u4e2d\u5df2\u7ecf\u6dfb\u52a0\u7684kernel</li> <li><code>jupyter kernelspec remove leoweng1.2</code>\u5220\u9664\u6307\u5b9a\u7684kernel\uff0c\u6ce8\u610f\u6709\u53ef\u80fd\u9700\u8981\u5148\u6fc0\u6d3b\u5bf9\u5e94\u73af\u5883\uff0c\u518d\u6267\u884c\uff0c\u5426\u5219\u6709\u53ef\u80fd\u65e0\u6cd5\u5220\u9664\u3002</li> <li>ctrl + c  \u7ec8\u6b62zsh\u547d\u4ee4\u7a97\u53e3</li> </ul>"},{"location":"markdown/operation_utils/conda%E6%93%8D%E4%BD%9C/#pipconda-","title":"\u603b\u7ed3\u4e00\u4e0b\uff0c\u5f88\u591a\u64cd\u4f5c\u7684\u7ed3\u6784\u4e3a pip/conda(\u8868\u793a\u8fd0\u7528\u7684\u7ba1\u7406\u5668) \u64cd\u4f5c\u540d\u79f0 --\u6307\u5b9a\u64cd\u4f5c\u5177\u4f53\u53c2\u6570(\u53ef\u80fd\u53ef\u4ee5\u7701\u7565\uff09\uff0c\u5373\u7a7a\u683c \u52a0\u4e0a -- \u7684\u7ed3\u6784","text":"<p>\u2003\u2003\u5982\u679c\u5728\u672c\u5730\u5bfc\u51fa\u540e\u60f3\u518d\u6b21create new environment\uff0c\u56e0\u4e3a\u672c\u5730\u5df2\u7ecf\u5b58\u5728\u5bfc\u51fa\u7684\u73af\u5883\u4e86\uff0c\u4f1a\u62a5\u9519\uff1aCondaValueError: prefix already exists: /Users/wenglongao/anaconda3/envs/leoweng_test\uff0c\u5219\u6211\u4eec\u9700\u8981\u7f16\u8f91yaml\u6587\u4ef6\uff0c\u5c06name\u5b57\u6bb5\u7684value\u4fee\u6539\u4e3a\u65b0\u7684\u73af\u5883\u540d\u79f0\uff0c\u7136\u540e\u53ef\u901a\u8fc7yaml\u6587\u4ef6\u521b\u5efa\u65b0\u73af\u5883\u3002</p>"},{"location":"markdown/operation_utils/debug/","title":"\u8bb0\u5f55\u4e00\u4e9bbug\u7684\u4ea7\u751f\u539f\u56e0","text":""},{"location":"markdown/operation_utils/debug/#1-jupyter-notebook-500-internal-server-error","title":"1. jupyter notebook 500 internal server error","text":"<ol> <li>pip install --upgrade jupyterhub -i https://pypi.tuna.tsinghua.edu.cn/simple</li> <li>pip install --upgrade --user nbconvert -i https://pypi.tuna.tsinghua.edu.cn/simple \u5c31\u641e\u5b9a\uff01guide</li> </ol>"},{"location":"markdown/operation_utils/debugging/","title":"\u6d4b\u8bd5\u548cdebug\u7684\u65b9\u6cd5","text":"<ul> <li> <p>\u4f7f\u7528breakpoint\uff0c\u53ef\u4ee5\u76f4\u63a5\u5c06breakpoint()\u63d2\u5165\u4ee3\u7801 p x: \u6253\u5370\u53d8\u91cfx\u7684\u503c </p> </li> <li> <p>pycharm\u81ea\u5e26debugger https://blog.csdn.net/weixin_41447567/article/details/131945495</p> </li> </ul>"},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/","title":"git \u64cd\u4f5c","text":""},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/#git_1","title":"git\u547d\u4ee4","text":"<ul> <li><code>git config --global user.name Leo Weng</code>\u57fa\u672c\u914d\u7f6e</li> <li><code>git config --global user.email wlaleo@stu.xjtu.edu.cn</code>\u57fa\u672c\u914d\u7f6e</li> <li><code>git config --list</code>  \u67e5\u770bgit\u7684\u8bbe\u7f6e\u53c2\u6570</li> <li><code>git init</code>  \u5728\u5de5\u4f5c\u533a\u521d\u59cb\u5316\u5f53\u524d\u76ee\u5f55\uff0c\u628a\u8fd9\u4e2a\u76ee\u5f55\u53d8\u6210Git\u53ef\u4ee5\u7ba1\u7406\u7684\u4ed3\u5e93</li> <li><code>git status</code>  \u67e5\u770b\u4ed3\u5e93\u5f53\u524d\u7684\u72b6\u6001</li> <li><code>git add</code>  \u628a\u6587\u4ef6\u4ece\u5de5\u4f5c\u533a&gt;&gt;&gt;&gt;\u6682\u5b58\u533a</li> <li><code>git commit -m \"Initial Commit\"</code>  \u628a\u6587\u4ef6\u4ece\u6682\u5b58\u533a&gt;&gt;&gt;&gt;\u4ed3\u5e93\u3002\u6ce8\u610fcommit\u524d\u9700\u8981\u5148checkout\u5230\u9700\u8981commit\u7684\u5206\u652f\u4e0a\u3002</li> <li><code>git diff</code>  \u67e5\u770b\u5dee\u5f02\uff08\u5177\u4f53\u770b\u540e\u6587\u8bf4\u660e\uff09</li> <li><code>git log</code>  \u67e5\u770b\u5386\u53f2\u63d0\u4ea4\u65e5\u5fd7</li> <li><code>git reset --hard HEAD^</code>  \u56de\u9000\u5230\u4e0a\u4e00\u4e2a\u7248\u672c</li> <li><code>git checkout -- readme.txt</code>  \u628areadme.txt\u5728\u5de5\u4f5c\u533a\u7684\u4fee\u6539\u5168\u90e8\u64a4\u9500</li> <li><code>git reset HEAD readme.txt</code>  \u628areadme.txt\u5728\u6682\u5b58\u533a\u7684\u4fee\u6539\u5168\u90e8\u64a4\u9500</li> <li><code>git rm file</code>\u4ece\u7248\u672c\u5e93\u4e2d\u5220\u9664\u6587\u4ef6</li> <li><code>git remote add origin https://gitee.com/weng-longao/mypackage2.git</code>  \u6dfb\u52a0\u8fdc\u7a0b\u4ed3\u5e93</li> <li><code>git remote set-url origin https://gitee.com/weng-longao/micrograd.git</code>  \u66f4\u65b0\u539f\u5148\u7684\u8fdc\u7a0b\u4ed3\u5e93url</li> <li><code>git push -u origin main</code>  \u628a\u672c\u5730main\u5206\u652fpush\u5230\u8fdc\u7a0b\uff08\u8fdc\u7a0b\u5206\u652f\u9ed8\u8ba4\u540d\u79f0\u5c31\u4e3aorigin\uff09\uff0c\u7b2c\u4e00\u6b21\u63a8\u9001\u52a0\u4e0a -u\u53c2\u6570</li> <li><code>git push origin main</code>  \u63a8\u9001\u4fee\u6539\u5230\u8fdc\u7a0bmain\u5206\u652f\uff0c\u5176\u4e2dorigin\u662f\u8fdc\u7a0b\u4ed3\u5e93\u7684\u9ed8\u8ba4\u540d\u79f0</li> <li><code>git push origin your-branch</code>  \u63a8\u9001\u4fee\u6539\u5230\u8fdc\u7a0b\u7684\u6307\u5b9ayour-branch\u5206\u652f</li> <li><code>git remote -v</code>  \u67e5\u770bgit\u8fdc\u7a0b\u4ed3\u5e93</li> <li><code>git remote rm main</code>  \u5220\u9664\u8fdc\u7a0b\u4ed3\u5e93</li> <li><code>git clone https://gitee.com/weng-longao/gitskills.git</code>  \u514b\u9686\u8fdc\u7a0b\u4ed3\u5e93\uff0c\u76f4\u63a5\u5728\u5de5\u4f5c\u76ee\u5f55\u4e0b\u514b\u9686\uff0c\u4f1a\u81ea\u52a8\u521b\u5efa\u6587\u4ef6\u5939 ~/gitskills</li> <li><code>git checkout -b dev</code>  \u521b\u5efadev\u5206\u652f\uff0c\u5e76\u4e14checkout\u5230\u8fd9\u4e2a\u5206\u652f\u4e0a\uff0c\u7b49\u4e8e<code>git branch dev</code> \u52a0\u4e0a <code>git checkout dev</code></li> <li><code>git merge dev</code>  \u5408\u5e76dev\u5206\u652f\u5230main\uff08fast forward\u65b9\u6cd5\uff09</li> <li><code>git branch -d dev</code>  \u5220\u9664dev\u5206\u652f</li> <li><code>git branch -D dev</code>  \u5728\u8fd8\u6709\u6539\u52a8\u6ca1\u5408\u5e76\u7684\u65f6\u5019\u5f3a\u5236\u5220\u9664dev\u5206\u652f</li> <li><code>git log --graph --pretty=oneline --abbrev-commit</code>  \u67e5\u770b\u5206\u652f\u5408\u5e76\u60c5\u51b5</li> <li><code>git stash</code>  \u628a\u5f53\u524d\u5de5\u4f5c\u73b0\u573a\u201c\u50a8\u85cf\u201d\u8d77\u6765\uff0c\u7b49\u4ee5\u540e\u6062\u590d\u73b0\u573a\u540e\u7ee7\u7eed\u5de5\u4f5c</li> <li><code>git stash list</code>  \u67e5\u770b\u50a8\u85cf\u7684\u5de5\u4f5c\u73b0\u573a</li> <li><code>git cherry-pick 4c805e2</code>  \u590d\u52364c805e2\u8fd9\u4e2a\u63d0\u4ea4\u4e0a\u7684\u6539\u52a8\u5230\u5f53\u524d\u5206\u652f</li> <li><code>git stash pop</code>  \u6062\u590d\u5de5\u4f5c\u73b0\u573a\u540c\u65f6\u628astash\u7684\u5185\u5bb9\u5220\u9664</li> <li><code>git stash apply</code>  \u6062\u590d\u5de5\u4f5c\u73b0\u573a\uff0c\u4fdd\u7559stash\u7684\u5185\u5bb9</li> <li><code>git stash drop</code>  \u5220\u9664stash\u7684\u5185\u5bb9</li> <li><code>git push origin dev</code>  \u628a\u672c\u5730\u7684\u5f00\u53d1\u5206\u652fpush\u5230\u8fdc\u7a0b</li> <li><code>git checkout -b dev origin/dev</code>  pull\u8fdc\u7a0b\u7684\u5f00\u53d1\u5206\u652f\u5230\u672c\u5730</li> </ul>"},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/#git_2","title":"git\u73af\u5883\u914d\u7f6e","text":""},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/#1-git","title":"1. \u5b89\u88c5git\uff0c\u9ed8\u8ba4\u5b89\u88c5\u8def\u5f84\u5373\u53ef","text":""},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/#2-pycharm","title":"2. pycharm\u4e2d\u8bbe\u7f6e","text":""},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/#3-pycharmgitee","title":"3. pycharm\u4e2d\u767b\u5f55gitee","text":""},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/#4","title":"4. \u6dfb\u52a0\u8fdc\u7a0b\u4ed3\u5e93","text":""},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/#5-pycharm","title":"5. \u5728pycharm\u4e2d\u6253\u5f00\u4ece\u8fdc\u7a0b\u514b\u9686\u7684\u4ed3\u5e93\uff08\u5373\u672c\u5730\u4ed3\u5e93\uff09\uff0c\u5373\u53ef\u5f00\u59cb\u5f00\u53d1\u3002","text":""},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/#_1","title":"\u9644\u5f55","text":""},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/#1-git_1","title":"1. git\u57fa\u672c\u6982\u5ff5\u7684\u7406\u89e3","text":"<ul> <li>git\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u7248\u672c\u7ba1\u7406\u7cfb\u7edf\uff0cgithub\u662fgit\u7684\u4e2d\u5fc3\u670d\u52a1\u5546\uff0c\u4f5c\u7528\u662f\u65b9\u4fbf\u534f\u540c\u5f00\u53d1\u65f6\u7684\u7248\u672c\u540c\u6b65\u7b49\u3002  </li> </ul>"},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/#2-macos","title":"2. macos\u7cfb\u7edf\u9690\u85cf\u6587\u4ef6\u7684\u8bf4\u660e","text":""},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/#3-git","title":"3. git\u7684\u672c\u5730\u7ed3\u6784","text":"<p> * Git\u7ba1\u7406\u7684\u6587\u4ef6\u5206\u4e3a\uff1a\u5de5\u4f5c\u533aworking dictionary\uff0c\u7248\u672c\u5e93repository\uff0c\u7248\u672c\u5e93\u53c8\u5206\u4e3a\u6682\u5b58\u533astage\u548c\u6682\u5b58\u533a\u5206\u652fmaster(\u4ed3\u5e93)</p> <ul> <li> <p>\u5de5\u4f5c\u533a&gt;&gt;&gt;&gt;\u6682\u5b58\u533a&gt;&gt;&gt;&gt;\u4ed3\u5e93</p> </li> <li> <p><code>git add</code>\u628a\u6587\u4ef6\u4ece\u5de5\u4f5c\u533a&gt;&gt;&gt;&gt;\u6682\u5b58\u533a\uff0cgit commit\u628a\u6587\u4ef6\u4ece\u6682\u5b58\u533a&gt;&gt;&gt;&gt;\u4ed3\u5e93\uff0c</p> </li> <li> <p><code>git diff</code>\u67e5\u770b\u5de5\u4f5c\u533a\u548c\u6682\u5b58\u533a\u5dee\u5f02\uff0c</p> </li> </ul> <p>\u2003\u2003\u8865\u5145\uff1agit diff \u5206\u4e3a\u4e24\u79cd\u60c5\u51b5\uff1a\u6682\u5b58\u533a\u4e3a\u7a7a\u548c\u6682\u5b58\u533a\u4e0d\u4e3a\u7a7a\u3002 \u9996\u5148\u6211\u4eec\u660e\u786e\u77e5\u9053git diff\u662f\u6bd4\u8f83\u5de5\u4f5c\u533a\u548c\u6682\u5b58\u533a\u7684\u6587\u4ef6\u7684\uff0c\u5982\u679c\u6b64\u65f6\u6682\u5b58\u533a\u4e3a\u7a7a\uff0c\u90a3\u4e48\u7a0d\u5fae\u6709\u70b9\u4e0d\u540c\uff0c\u5373\uff1a \u2003\u20031. \u6682\u5b58\u533a\u4e3a\u7a7a\u4f7f\u7528git diff\uff1a\u56e0\u4e3a\u6b64\u65f6\u6682\u5b58\u533a\u4e3a\u7a7a\uff0c\u6b64\u65f6\u4f7f\u7528git diff\u540c\u6837\u4e5f\u662f\u6bd4\u8f83\u5de5\u4f5c\u533a\u548c\u4ed3\u5e93\uff0c\u5373\u548c\u4f7f\u7528git diff HEAD\u7ed3\u679c\u76f8\u540c \u2003\u20032. \u6682\u5b58\u533a\u4e0d\u4e3a\u7a7a\u4f7f\u7528git diff:\u56e0\u4e3a\u6b64\u65f6\u6682\u5b58\u533a\u4e0d\u4e3a\u7a7a\uff0c\u6b64\u65f6\u4f7f\u7528git diff\u6bd4\u8f83\u7684\u5c31\u662f\u5de5\u4f5c\u533a\u548c\u6682\u5b58\u533a\u3002</p> <ul> <li> <p><code>git diff --cached</code>\u67e5\u770b\u6682\u5b58\u533a\u548c\u4ed3\u5e93\u5dee\u5f02\uff0c</p> </li> <li> <p><code>git diff HEAD</code> \u67e5\u770b\u5de5\u4f5c\u533a\u548c\u4ed3\u5e93\u7684\u5dee\u5f02\uff0c</p> </li> <li> <p><code>git add</code>\u7684\u53cd\u5411\u547d\u4ee4<code>git checkout</code>\uff0c\u64a4\u9500\u5de5\u4f5c\u533a\u4fee\u6539\uff0c\u5373\u628a\u6682\u5b58\u533a\u6700\u65b0\u7248\u672c\u8f6c\u79fb\u5230\u5de5\u4f5c\u533a\uff0c</p> </li> <li> <p><code>git commit</code>\u7684\u53cd\u5411\u547d\u4ee4<code>git reset HEAD</code>\uff0c\u5c31\u662f\u628a\u4ed3\u5e93\u6700\u65b0\u7248\u672c\u8f6c\u79fb\u5230\u6682\u5b58\u533a\u3002</p> </li> </ul>"},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/#_2","title":"\u5229\u7528\u522b\u4eba\u7684\u8fdc\u7a0b\u4ed3\u5e93\u5f00\u53d1","text":"<p>\u6211\u4eec\u5f88\u591a\u65f6\u5019\u9700\u8981\u5c06\u522b\u4eba\u7684\u4ed3\u5e93clone\u4e0b\u6765\uff0c\u8fdb\u884c\u4e8c\u6b21\u5f00\u53d1\u7b49\u3002\u5177\u4f53\u64cd\u4f5c\u5982\u4e0b\u3002 1. git clone \u522b\u4eba\u7684\u4ed3\u5e93\u5230\u672c\u5730 repo     \u6ce8\u610f\uff1a\u8fd9\u4e00\u6b65\u5982\u679c\u65e0\u6cd5\u514b\u9686\u53ef\u4ee5\u76f4\u63a5\u4e0b\u8f7dzip\u6587\u4ef6\u89e3\u538b\u5230work_repo\u4e2d\uff0c\u63a5\u4e0b\u6765\u64cd\u4f5c\u6b65\u9aa4\u76f8\u540c 2. \u5220\u9664\u4ed3\u5e93\u4e2d\u7684.git\u7b49\u6587\u4ef6\uff0c\u91cd\u65b0 git init, git add .\uff08\u8868\u793aadd\u6240\u6709\u6587\u4ef6 3. \u65b0\u5efa\u4e00\u4e2a\u81ea\u5df1\u7684\u7a7a\u7684\u8fdc\u7a0b\u4ed3\u5e93\uff0c\u6ce8\u610f\u4e0d\u8981\u6dfb\u52a0\u4efb\u4f55\u5305\u62ecREADME\u5728\u5185\u7684\u6587\u4ef6 4. git remote add origin \"\u81ea\u5df1\u7684\u8fdc\u7a0b\u4ed3\u5e93\u5730\u5740\" 5. git commit -m \"Initial commit\" \u5148commit\uff0c\u4e3a\u4e86\u4e0b\u4e00\u6b65push 6. git push -u origin main \u5c06\u672c\u5730\u7684\u4ed3\u5e93\u63a8\u9001\u5230\u81ea\u5df1\u7684\u7a7a\u7684\u8fdc\u7a0b\u4ed3\u5e93</p> <p>\u6ce8\u610f\uff0c\u6211\u4eec\u901a\u5e38\u6839\u636e\u76f4\u63a5\u901a\u8fc7pycharm\u7b49\u56fe\u5f62\u5316\u64cd\u4f5c\u3002</p>"},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/#_3","title":"\u5c06\u672c\u5730\u9879\u76ee\u4e0a\u4f20\u5230\u8fdc\u7a0b","text":"<p>\u5c06\u672c\u5730\u5df2\u6709\u7684\u9879\u76ee\u4e0a\u4f20\u3002\u8fd9\u91cc\u6211\u4eec\u65e2\u53ef\u4ee5\u521b\u5efa\u4e00\u4e2a\u65b0\u7684\u672c\u5730\u9879\u76ee\uff0c\u7136\u540e\u4e0a\u4f20git\u8fdc\u7a0b\u4ed3\u5e93\uff0c\u4e5f\u53ef\u4ee5\u5c06\u5df2\u6709\u9879\u76ee\u4e0a\u4f20\u3002\u6211\u4eec\u4e00\u822c\u6709\u5982\u4e0b\u4e24\u79cd\u65b9\u6cd5\u3002</p>"},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/#1","title":"\u65b9\u6cd51","text":"<ol> <li>\u5728pycharm\u4e2d\u6253\u5f00\u672c\u5730\u9879\u76ee</li> <li>gitee\u4e2d\u521b\u5efa\u7a7a\u7684\u8fdc\u7a0b\u4ed3\u5e93\uff0c\u6ce8\u610f\u4e0d\u8981\u6dfb\u52a0\u4efb\u4f55\u5305\u62ecREADME\u5728\u5185\u7684\u6587\u4ef6</li> <li>pycharm\u4e2dmanage remote\uff0c\u6dfb\u52a0\u8fdc\u7a0b\u4ed3\u5e93\u5730\u5740</li> <li>\u76f4\u63a5\u5c06\u672c\u5730\u7684main\u5206\u652f commit and push</li> <li>\u6b64\u65f6\u56e0\u4e3a\u53ea\u6709\u4e00\u4e2a\u5206\u652f\uff0c\u5219\u8fdc\u7a0b\u4ed3\u5e93\u65e0\u9700merge\uff0c\u76f4\u63a5\u6536\u5230\u4e86\u4fee\u6539\u3002\u6b64\u65f6\u53ef\u4ee5\u901a\u8fc7gitee\u6dfb\u52a0\u4e00\u4e2aREADME\u6587\u4ef6\u8fdb\u884c\u6d4b\u8bd5</li> <li>pull \u8fdc\u7a0b\uff0c\u5982\u679c\u53d1\u73b0\u672c\u5730\u591a\u4e86\u4e00\u4e2aREADME\u6587\u4ef6\uff0c\u90a3\u4e48\u6211\u4eec\u5c31\u6210\u529f\u5efa\u7acb\u8d77\u4e86\u548c\u8fdc\u7a0b\u4ed3\u5e93\u7684\u8fde\u63a5\u3002</li> </ol>"},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/#2","title":"\u65b9\u6cd52","text":"<ol> <li>\u5728pycharm\u6253\u5f00\u672c\u5730project\u3002</li> <li>\u4f7f\u7528Git - share project on gitee\uff0cpycharm\u5c31\u4f1a\u81ea\u52a8\u5e2e\u6211\u4eec\u5728gitee\u4e0a\u521b\u5efa\u8fdc\u7a0b\u4ed3\u5e93\u3002</li> </ol>"},{"location":"markdown/operation_utils/git%E6%93%8D%E4%BD%9C/#_4","title":"\u5982\u4f55\u89e3\u51b3\u6587\u4ef6\u5927\u5c0f\u9650\u5236","text":"<p>\u5728\u5c06\u672c\u5730\u4fee\u6539push\u5230\u8fdc\u7a0b\u65f6\uff0c\u5982\u679c\u6709\u6587\u4ef6\u8fc7\u5927\u5c31\u4f1a\u62a5\u9519\u3002\u89e3\u51b3\u65b9\u6cd5\u6709\u4e24\u79cd\u3002 1. \u63a8\u8350\u65b9\u6848\uff1a\u4f7f\u7528git-version-clean\uff0c\u53c2\u8003\u300a\u4ed3\u5e93\u4f53\u79ef\u8fc7\u5927\uff0c\u5982\u4f55\u51cf\u5c0f\uff1f\u300b\u6587\u7ae0\u4e2d\u7684\u65b9\u6848\u4e00\u3002 2. \u5907\u9009\u65b9\u6848\uff1a\u5148\u5220\u9664\u5927\u6587\u4ef6\uff0c\u518dpush\u3002\u53c2\u8003\u300a\u4ed3\u5e93\u4f53\u79ef\u8fc7\u5927\uff0c\u5982\u4f55\u51cf\u5c0f\uff1f\u300b\u6587\u7ae0\u4e2d\u7684\u5907\u9009\u65b9\u6848\u3002</p> <p>\u53c2\u8003\u94fe\u63a5 Git-LFS \u4ed3\u5e93\u4f53\u79ef\u8fc7\u5927\uff0c\u5982\u4f55\u51cf\u5c0f\uff1f git-repo-clean</p>"},{"location":"markdown/operation_utils/mkdocs_guide/","title":"mkdocs\u7684\u64cd\u4f5c","text":""},{"location":"markdown/operation_utils/mkdocs_guide/#packagematerialmkdocs","title":"\u5b89\u88c5\u5fc5\u8981package\uff0c\u8fd9\u662f\u57fa\u4e8ematerial\u7684mkdocs","text":"<pre><code>pip install mkdocs-material\npip install mkdocs-jupyter\n</code></pre>"},{"location":"markdown/operation_utils/mkdocs_guide/#gitmkdocs","title":"\u4f7f\u7528git\u521b\u5efamkdocs\u7684\u672c\u5730\u4ed3\u5e93","text":""},{"location":"markdown/operation_utils/mkdocs_guide/#yaml","title":"\u521d\u59cb\u5316\uff0c\u6dfb\u52a0yaml\u6587\u4ef6\u548c\u521d\u59cb\u9875\u9762\u3002\u5728\u7ec8\u7aef\u8f93\u5165\uff1a","text":"<p><pre><code>mkdocs new .\n</code></pre> \u53ef\u4ee5\u770b\u51fa\u76ee\u5f55\u4e0b\u591a\u4e86\u4e24\u4e2a\u6211\u4eec\u9700\u8981\u7684\u6587\u4ef6</p>"},{"location":"markdown/operation_utils/mkdocs_guide/#mkdocs_1","title":"\u542f\u52a8mkdocs\u670d\u52a1","text":"<pre><code>mkdocs serve\n</code></pre> <p>\u7f51\u9875\u6210\u529f\u542f\u52a8\uff01</p> <ul> <li>yaml\u6587\u4ef6\u53c2\u6570\u8bbe\u7f6e\u53ef\u4ee5\u53c2\u8003 https://new.qq.com/rain/a/20211001A05T3700</li> </ul>"}]}